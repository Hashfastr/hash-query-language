{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_dicts() bs\n",
    "How to handle inconsistent schemas in regards to input from nosql databases such as elastic?\n",
    "\n",
    "Probably not going to use this code.\n",
    "The problem is that what if you write a detection and the fields change per query?\n",
    "But you're writing the detection for a specific set of logs that probably won't change schema.\n",
    "Think I'm going to move to a multi-dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "import Types as t\n",
    "import importlib\n",
    "importlib.reload(t)\n",
    "\n",
    "# Simple examples\n",
    "a = [\n",
    "    {\n",
    "        \"log\": {\n",
    "            \"file\": {\n",
    "                \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/suricata/eve-2022-11-10-07:20.json\"\n",
    "            },\n",
    "            \"offset\": 9491215,\n",
    "            \"id\": {\n",
    "                \"uid\": \"1017858934534263\",\n",
    "                \"resp_fuids\": None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "b = [\n",
    "    {  \n",
    "        \"log\": {\n",
    "            \"file\": {\n",
    "                \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/zeek/logs/files.log\"\n",
    "            },\n",
    "            \"offset\": 7559607,\n",
    "            \"id\": {\n",
    "                \"uid\": [\n",
    "                    \"CAnltOiClThlO6ZFk\"\n",
    "                ],\n",
    "                \"fuid\": \"FdZyiY2Kf5yf3L4239\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "with open('./so-network-index.json') as f:\n",
    "    index = json.loads(f.read())\n",
    "    \n",
    "with open('./so-network-data.json') as f:\n",
    "    json_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorities = {\n",
    "    'multivalue': {\n",
    "        'name': 'multivalue',\n",
    "        'priority': 5,\n",
    "        'super': set(),\n",
    "    },\n",
    "    'string': {\n",
    "        'name': 'string',\n",
    "        'priority': 4,\n",
    "        'super': {'list'}\n",
    "    },\n",
    "    'float': {\n",
    "        'name': 'float',\n",
    "        'priority': 3,\n",
    "        'super': {'str', 'list'}\n",
    "    },\n",
    "    'int': {\n",
    "        'name': 'int',\n",
    "        'priority': 2,\n",
    "        'super': {'float', 'str', 'list'}\n",
    "    },\n",
    "    'bool': {\n",
    "        'name': 'bool',\n",
    "        'priority': 1,\n",
    "        'super': {'str', 'list'}\n",
    "    },\n",
    "    'null': {\n",
    "        'name': 'null',\n",
    "        'priority': 0,\n",
    "        'super': {'bool', 'int', 'float', 'string', 'multivalue'}\n",
    "    }\n",
    "}\n",
    "\n",
    "types = {\n",
    "    'multivalue': t.multivalue,\n",
    "    'string': t.string,\n",
    "    'float': t.float,\n",
    "    'int': t.int,\n",
    "    'bool': t.bool,\n",
    "    'null': t.null\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"log\": {\n",
      "    \"offset\": \"int\",\n",
      "    \"id\": {\n",
      "      \"resp_fuids\": \"null\",\n",
      "      \"fuid\": \"string\",\n",
      "      \"uid\": \"multivalue(string)\"\n",
      "    },\n",
      "    \"file\": {\n",
      "      \"path\": \"string\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "[\n",
      "  {\n",
      "    \"log\": {\n",
      "      \"offset\": 9491215,\n",
      "      \"id\": {\n",
      "        \"resp_fuids\": null,\n",
      "        \"fuid\": null,\n",
      "        \"uid\": [\n",
      "          \"1017858934534263\"\n",
      "        ]\n",
      "      },\n",
      "      \"file\": {\n",
      "        \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/suricata/eve-2022-11-10-07:20.json\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"log\": {\n",
      "      \"offset\": 7559607,\n",
      "      \"id\": {\n",
      "        \"resp_fuids\": null,\n",
      "        \"fuid\": \"FdZyiY2Kf5yf3L4239\",\n",
      "        \"uid\": [\n",
      "          \"CAnltOiClThlO6ZFk\"\n",
      "        ]\n",
      "      },\n",
      "      \"file\": {\n",
      "        \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/zeek/logs/files.log\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "class Schema():\n",
    "    def __init__(self, data:list[dict]):\n",
    "        # [['foo', 'bar'], ['cat']]\n",
    "        self.mv_fields = []\n",
    "        self.schema = self.gen_schema(data)\n",
    "\n",
    "    # Gets the appropriate Hql type for a particular piece of data\n",
    "    def to_hql_type(self, proto):\n",
    "        prototype = type(proto)\n",
    "\n",
    "        if prototype == dict:\n",
    "            return prototype\n",
    "        elif prototype in (list, tuple):\n",
    "            inner = self.resolve_conflict([self.to_hql_type(x) for x in proto])\n",
    "            return t.multivalue(inner)\n",
    "        elif prototype == str:\n",
    "            return t.string()\n",
    "        elif prototype == int:\n",
    "            return t.int()\n",
    "        elif prototype == float:\n",
    "            return t.float()\n",
    "        elif prototype == bool:\n",
    "            return t.bool()\n",
    "        elif prototype == type(None):\n",
    "            return t.null()\n",
    "        else:\n",
    "            print(f'Unhandled conversion type {prototype}')\n",
    "\n",
    "    def to_pl_schema(self, src:dict=None):\n",
    "        if not src:\n",
    "            src = self.schema\n",
    "\n",
    "        schema = {}\n",
    "        for i in src:\n",
    "            j = src[i]\n",
    "\n",
    "            if isinstance(j, dict):\n",
    "                schema[i] = pl.Struct(self.to_pl_schema(j))\n",
    "                continue\n",
    "\n",
    "            if isinstance(j, t.multivalue):\n",
    "                schema[i] = j.pl_schema()\n",
    "                continue\n",
    "\n",
    "            schema[i] = j().pl_schema()\n",
    "\n",
    "        return schema\n",
    "\n",
    "    def resolve_conflict(self, ts:list):\n",
    "        # Check to see if there's a multivalue we need to handle\n",
    "        mv = False\n",
    "        for i in ts:\n",
    "            if isinstance(i, t.multivalue):\n",
    "                mv = True\n",
    "                break\n",
    "        \n",
    "        # Handle multivalue\n",
    "        if mv:\n",
    "            inner_set = set()\n",
    "            for i in ts:\n",
    "                if isinstance(i, t.multivalue):\n",
    "                    inner_set.add(i.inner)\n",
    "                else:\n",
    "                    inner_set.add(i)\n",
    "            inner = self.resolve_conflict(list(inner_set))\n",
    "            return t.multivalue(inner)\n",
    "\n",
    "        l = priorities['null']\n",
    "        for i in [str(x) for x in ts]:\n",
    "            r = priorities[i]\n",
    "            if l['priority'] > r['priority']:\n",
    "                continue\n",
    "\n",
    "            if r['name'] in l['super']:\n",
    "                l = r\n",
    "                continue\n",
    "\n",
    "        return types[l['name']]\n",
    "\n",
    "    def gen_schema(self, data:list[dict]):\n",
    "        # get a set of keys to handle\n",
    "        keyset = set()\n",
    "        for i in data:\n",
    "            if i:\n",
    "                keyset |= set(i.keys())\n",
    "        keyset = list(keyset)\n",
    "\n",
    "        new = dict()\n",
    "        for key in keyset:\n",
    "            typeset = set()\n",
    "            for datum in data:\n",
    "                if key not in datum:\n",
    "                    typeset.add(t.null())\n",
    "                    continue\n",
    "\n",
    "                if isinstance(datum[key], dict):\n",
    "                    typeset.add(dict)\n",
    "                    continue\n",
    "\n",
    "                typeset.add(self.to_hql_type(datum[key]))\n",
    "\n",
    "            if dict in typeset:\n",
    "                if len(typeset) != 1 and t.null() not in typeset:\n",
    "                    raise Exception(f\"Cannot merge types {list(typeset)}\")\n",
    "                \n",
    "                sub_data = []\n",
    "                for i in data:\n",
    "                    if key in i:\n",
    "                        sub_data.append(i[key])\n",
    "                new_schema = Schema(sub_data)\n",
    "\n",
    "                new[key] = new_schema.schema\n",
    "                self.mv_fields += [[key] + x for x in new_schema.mv_fields]\n",
    "\n",
    "                continue\n",
    "\n",
    "            new[key] = self.resolve_conflict(list(typeset))\n",
    "            if isinstance(new[key], t.multivalue):\n",
    "                self.mv_fields.append([key])\n",
    "\n",
    "        return new\n",
    "    \n",
    "    def adjust_mv(self, data:list[dict], mv_fields:list[list[str]]=None):        \n",
    "        if not mv_fields:\n",
    "            mv_fields = self.mv_fields\n",
    "\n",
    "        for field in mv_fields:\n",
    "            key = field[0]\n",
    "            if len(field) == 1:\n",
    "                for row in data:\n",
    "                    if key not in row:\n",
    "                        continue\n",
    "\n",
    "                    if isinstance(row[key], list):\n",
    "                        continue\n",
    "\n",
    "                    row[key] = [row[key]]\n",
    "            else:\n",
    "                rows = []\n",
    "                for i in data:\n",
    "                    if key in i:\n",
    "                        rows.append(i[key])\n",
    "                self.adjust_mv(rows, [field[1:]])\n",
    "\n",
    "        return data\n",
    "            \n",
    "\n",
    "df1 = pl.from_dicts(a)\n",
    "df2 = pl.from_dicts(b)\n",
    "ab_schema = Schema(a+b)\n",
    "print(json.dumps(ab_schema.schema, indent=2, default=repr))\n",
    "\n",
    "data = ab_schema.adjust_mv(a+b)\n",
    "df3 = pl.from_dicts(data, schema=Schema(a+b).to_pl_schema())\n",
    "print(json.dumps(df3.to_dicts(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "1331\n",
      "71\n",
      "1331\n",
      "361\n",
      "478\n",
      "1331\n",
      "384\n",
      "387\n",
      "812\n",
      "83\n",
      "229\n",
      "86\n",
      "86\n",
      "91\n",
      "361\n",
      "353\n",
      "355\n",
      "712\n",
      "1371\n",
      "610\n",
      "1331\n",
      "1331\n",
      "1331\n",
      "1331\n",
      "1331\n",
      "1371\n",
      "2010\n",
      "1331\n",
      "5480\n",
      "812\n",
      "14634\n",
      "812\n",
      "91\n",
      "1331\n",
      "3445\n",
      "100\n",
      "5480\n",
      "825\n",
      "86\n",
      "800\n",
      "812\n",
      "800\n",
      "2748\n",
      "385\n",
      "800\n",
      "71\n",
      "80\n",
      "71\n",
      "9588\n",
      "1371\n",
      "1371\n",
      "1371\n",
      "87\n",
      "380\n",
      "800\n",
      "1331\n",
      "387\n",
      "800\n",
      "800\n",
      "86\n",
      "86\n",
      "1331\n",
      "84\n",
      "1331\n",
      "355\n",
      "1331\n",
      "345\n",
      "384\n",
      "1331\n",
      "100\n",
      "375\n",
      "1331\n",
      "1331\n",
      "2604\n",
      "1331\n",
      "353\n",
      "71\n",
      "73\n",
      "392\n",
      "83\n",
      "1624\n",
      "1932\n",
      "388\n",
      "2010\n",
      "84\n",
      "1331\n",
      "71\n",
      "800\n",
      "1331\n",
      "1331\n",
      "1371\n",
      "1331\n",
      "812\n",
      "458\n",
      "392\n",
      "152\n",
      "1331\n",
      "800\n",
      "384\n",
      "812\n",
      "1331\n",
      "1371\n",
      "4400\n",
      "71\n",
      "71\n",
      "1331\n",
      "1556\n",
      "345\n",
      "312\n",
      "1331\n",
      "152\n",
      "3445\n",
      "2366\n",
      "83\n",
      "800\n",
      "385\n",
      "800\n",
      "812\n",
      "381\n",
      "83\n",
      "1331\n",
      "73\n",
      "1331\n",
      "370\n",
      "812\n",
      "1371\n",
      "812\n",
      "1208\n",
      "183\n",
      "4400\n",
      "71\n",
      "380\n",
      "1331\n",
      "1331\n",
      "83\n",
      "11739\n",
      "1624\n",
      "1331\n",
      "86\n",
      "388\n",
      "856\n",
      "4925\n",
      "385\n",
      "2700\n",
      "384\n",
      "380\n",
      "825\n",
      "812\n",
      "1331\n",
      "1371\n",
      "1331\n",
      "380\n",
      "286\n",
      "91\n",
      "812\n",
      "370\n",
      "1371\n",
      "812\n",
      "304\n",
      "800\n",
      "1371\n",
      "181\n",
      "1371\n",
      "181\n",
      "183\n",
      "2045\n",
      "80\n",
      "1208\n",
      "1331\n",
      "381\n",
      "812\n",
      "73\n",
      "83\n",
      "1331\n",
      "1371\n",
      "812\n",
      "56\n",
      "1331\n",
      "800\n",
      "800\n",
      "800\n",
      "1331\n",
      "91\n",
      "1331\n",
      "1331\n",
      "9588\n",
      "375\n",
      "388\n",
      "1331\n",
      "86\n",
      "1371\n",
      "1331\n",
      "91\n",
      "1331\n",
      "1331\n",
      "73\n",
      "1331\n",
      "1331\n",
      "152\n",
      "86\n",
      "1331\n",
      "385\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "unnested = [x['_source'] for x in json_data]\n",
    "jschema = Schema(unnested)\n",
    "unnested = jschema.adjust_mv(unnested)\n",
    "df4 = pl.from_dicts(unnested, schema=jschema.to_pl_schema())\n",
    "\n",
    "for i in df4.to_dicts():\n",
    "    if 'client' in i and i['client'] and i['client']['ip_bytes']:\n",
    "        print(i['client']['ip_bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_elastic_schema(props:dict):\n",
    "    schema = {}\n",
    "    for i in props:\n",
    "        if 'properties' in props[i]:\n",
    "            schema[i] = gen_schema(props[i]['properties'])\n",
    "            continue\n",
    "        \n",
    "        ptype = props[i]['type']\n",
    "        if ptype in  ('scaled_float'):\n",
    "            schema[i] = t.decimal()\n",
    "        elif ptype in ('half_float', 'float'):\n",
    "            schema[i] = t.float()\n",
    "        elif ptype in ('double'):\n",
    "            schema[i] = t.double()\n",
    "        elif ptype in ('byte'):\n",
    "            schema[i] = t.byte()\n",
    "        elif ptype in ('short'):\n",
    "            schema[i] = t.short()\n",
    "        elif ptype in ('integer'):\n",
    "            schema[i] = t.int()\n",
    "        elif ptype in ('long'):\n",
    "            schema[i] = t.long()\n",
    "        elif ptype in ('unsigned_long'):\n",
    "            schema[i] = t.ulong()\n",
    "        elif ptype in ('ip'):\n",
    "            schema[i] = t.ip()\n",
    "        elif ptype in ('date', 'date_nanos'):\n",
    "            schema[i] = t.datetime()\n",
    "        elif ptype in ('date_range', 'integer_range', 'float_range', 'long_range', 'double_range', 'ip_range'):\n",
    "            rtype = gen_schema({'rtype': {'type': ptype.replace('_range', '')}})['rtype']\n",
    "            schema[i] = t.range(rtype, rtype)\n",
    "        elif ptype in ('keyword', 'constant_keyword', 'wildcard', 'binary', 'text', 'match_only_text'):\n",
    "            schema[i] = t.string()\n",
    "        elif ptype in ('boolean'):\n",
    "            schema[i] = t.bool()\n",
    "        elif ptype in ('object', 'flattened', 'nested'):\n",
    "            schema[i] = t.string()\n",
    "        elif ptype in ('point', 'geo_point'):\n",
    "            ptype = t.float()\n",
    "            schema[i] = t.multivalue(ptype)\n",
    "        # elif ptype in ('object', 'flattened', 'nested'):\n",
    "        #     schema[i] = pl.\n",
    "        # elif ptype in ('geo_point'):\n",
    "        #     schema[i] = pl.String\n",
    "        # elif ptype in ('')\n",
    "        else:\n",
    "            print(f'{i} {ptype}')\n",
    "\n",
    "    return schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
