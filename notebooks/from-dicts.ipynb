{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_dicts() bs\n",
    "How to handle inconsistent schemas in regards to input from nosql databases such as elastic?\n",
    "\n",
    "Probably not going to use this code.\n",
    "The problem is that what if you write a detection and the fields change per query?\n",
    "But you're writing the detection for a specific set of logs that probably won't change schema.\n",
    "Think I'm going to move to a multi-dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "import Types as t\n",
    "import importlib\n",
    "importlib.reload(t)\n",
    "\n",
    "# Simple examples\n",
    "a = [\n",
    "    {\n",
    "        \"log\": {\n",
    "            \"file\": {\n",
    "                \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/suricata/eve-2022-11-10-07:20.json\"\n",
    "            },\n",
    "            \"offset\": 9491215,\n",
    "            \"id\": {\n",
    "                \"uid\": \"1017858934534263\",\n",
    "                \"resp_fuids\": None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "b = [\n",
    "    {  \n",
    "        \"log\": {\n",
    "            \"file\": {\n",
    "                \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/zeek/logs/files.log\"\n",
    "            },\n",
    "            \"offset\": 7559607,\n",
    "            \"id\": {\n",
    "                \"uid\": [\n",
    "                    \"CAnltOiClThlO6ZFk\"\n",
    "                ],\n",
    "                \"fuid\": \"FdZyiY2Kf5yf3L4239\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "with open('./so-network-data.json') as f:\n",
    "    json_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorities = {\n",
    "    'multivalue': {\n",
    "        'name': 'multivalue',\n",
    "        'priority': 5,\n",
    "        'super': set(),\n",
    "    },\n",
    "    'string': {\n",
    "        'name': 'string',\n",
    "        'priority': 4,\n",
    "        'super': {'list'}\n",
    "    },\n",
    "    'float': {\n",
    "        'name': 'float',\n",
    "        'priority': 3,\n",
    "        'super': {'str', 'list'}\n",
    "    },\n",
    "    'int': {\n",
    "        'name': 'int',\n",
    "        'priority': 2,\n",
    "        'super': {'float', 'str', 'list'}\n",
    "    },\n",
    "    'bool': {\n",
    "        'name': 'bool',\n",
    "        'priority': 1,\n",
    "        'super': {'str', 'list'}\n",
    "    },\n",
    "    'null': {\n",
    "        'name': 'null',\n",
    "        'priority': 0,\n",
    "        'super': {'bool', 'int', 'float', 'string', 'multivalue'}\n",
    "    }\n",
    "}\n",
    "\n",
    "types = {\n",
    "    'multivalue': t.multivalue,\n",
    "    'string': t.string,\n",
    "    'float': t.float,\n",
    "    'int': t.int,\n",
    "    'bool': t.bool,\n",
    "    'null': t.null\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"log\": {\n",
      "    \"id\": {\n",
      "      \"uid\": \"multivalue(string)\",\n",
      "      \"fuid\": \"string\",\n",
      "      \"resp_fuids\": \"null\"\n",
      "    },\n",
      "    \"file\": {\n",
      "      \"path\": \"string\"\n",
      "    },\n",
      "    \"offset\": \"int\"\n",
      "  }\n",
      "}\n",
      "[\n",
      "  {\n",
      "    \"log\": {\n",
      "      \"id\": {\n",
      "        \"uid\": [\n",
      "          \"1017858934534263\"\n",
      "        ],\n",
      "        \"fuid\": null,\n",
      "        \"resp_fuids\": null\n",
      "      },\n",
      "      \"file\": {\n",
      "        \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/suricata/eve-2022-11-10-07:20.json\"\n",
      "      },\n",
      "      \"offset\": 9491215\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"log\": {\n",
      "      \"id\": {\n",
      "        \"uid\": [\n",
      "          \"CAnltOiClThlO6ZFk\"\n",
      "        ],\n",
      "        \"fuid\": \"FdZyiY2Kf5yf3L4239\",\n",
      "        \"resp_fuids\": null\n",
      "      },\n",
      "      \"file\": {\n",
      "        \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/zeek/logs/files.log\"\n",
      "      },\n",
      "      \"offset\": 7559607\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "class Schema():\n",
    "    def __init__(self, data:list[dict]=None, schema:dict=None):\n",
    "        # [['foo', 'bar'], ['cat']]\n",
    "        self.mv_fields = []\n",
    "        self.schema = dict()\n",
    "\n",
    "        if data:\n",
    "            if isinstance(data, list):\n",
    "                self.schema = self.gen_schema(data)\n",
    "            else:\n",
    "                self.schema = self.gen_schema([data])\n",
    "        elif schema:\n",
    "            self.schema = schema\n",
    "        else:\n",
    "            raise Exception('Attemping to initialize Schema() with no data!')\n",
    "\n",
    "    # Gets the appropriate Hql type for a particular piece of data\n",
    "    def to_hql_type(self, proto):\n",
    "        prototype = type(proto)\n",
    "\n",
    "        if prototype == dict:\n",
    "            return prototype\n",
    "        elif prototype in (list, tuple):\n",
    "            inner = self.resolve_conflict([self.to_hql_type(x) for x in proto])\n",
    "            return t.multivalue(inner)\n",
    "        elif prototype == str:\n",
    "            return t.string()\n",
    "        elif prototype == int:\n",
    "            return t.int()\n",
    "        elif prototype == float:\n",
    "            return t.float()\n",
    "        elif prototype == bool:\n",
    "            return t.bool()\n",
    "        elif prototype == type(None):\n",
    "            return t.null()\n",
    "        else:\n",
    "            print(f'Unhandled conversion type {prototype}')\n",
    "\n",
    "    def to_pl_schema(self, src:dict=None):\n",
    "        if not src:\n",
    "            src = self.schema\n",
    "\n",
    "        schema = {}\n",
    "        for i in src:\n",
    "            j = src[i]\n",
    "\n",
    "            if isinstance(j, dict):\n",
    "                if i == 'error':\n",
    "                    print(j)\n",
    "                schema[i] = pl.Struct(self.to_pl_schema(src=j))\n",
    "                continue\n",
    "\n",
    "            if isinstance(j, t.multivalue):\n",
    "                schema[i] = j.pl_schema()\n",
    "                continue\n",
    "\n",
    "            if isinstance(j, t.object):\n",
    "                schema[i] = j.pl_schema()\n",
    "                continue\n",
    "            \n",
    "            schema[i] = j().pl_schema()\n",
    "\n",
    "        return schema\n",
    "\n",
    "    def resolve_conflict(self, ts:list):\n",
    "        # Check to see if there's a multivalue we need to handle\n",
    "        mv = False\n",
    "        for i in ts:\n",
    "            if isinstance(i, t.multivalue):\n",
    "                mv = True\n",
    "                break\n",
    "        \n",
    "        # Handle multivalue\n",
    "        if mv:\n",
    "            inner_set = set()\n",
    "            for i in ts:\n",
    "                if isinstance(i, t.multivalue):\n",
    "                    inner_set.add(i.inner)\n",
    "                else:\n",
    "                    inner_set.add(i)\n",
    "            inner = self.resolve_conflict(list(inner_set))\n",
    "            return t.multivalue(inner)\n",
    "\n",
    "        l = priorities['null']\n",
    "        for i in [str(x) for x in ts]:\n",
    "            r = priorities[i]\n",
    "            if l['priority'] > r['priority']:\n",
    "                continue\n",
    "\n",
    "            if r['name'] in l['super']:\n",
    "                l = r\n",
    "                continue\n",
    "\n",
    "        return types[l['name']]\n",
    "\n",
    "    def gen_schema(self, data:list[dict]):\n",
    "        # get a set of keys to handle\n",
    "        keyset = set()\n",
    "        for i in data:\n",
    "            if i:\n",
    "                keyset |= set(i.keys())\n",
    "        keyset = list(keyset)\n",
    "\n",
    "        new = dict()\n",
    "        for key in keyset:\n",
    "            typeset = set()\n",
    "            for datum in data:\n",
    "                if key not in datum:\n",
    "                    typeset.add(t.null())\n",
    "                    continue\n",
    "\n",
    "                if isinstance(datum[key], dict):\n",
    "                    typeset.add(dict)\n",
    "                    continue\n",
    "\n",
    "                typeset.add(self.to_hql_type(datum[key]))\n",
    "\n",
    "            # recurse on an object\n",
    "            if dict in typeset:\n",
    "                if len(typeset) != 1 and t.null() not in typeset:\n",
    "                    raise Exception(f\"Cannot merge types {list(typeset)}\")\n",
    "                \n",
    "                sub_data = []\n",
    "                for i in data:\n",
    "                    if key in i:\n",
    "                        sub_data.append(i[key])\n",
    "                new_schema = Schema(sub_data)\n",
    "\n",
    "                new[key] = new_schema.schema\n",
    "                # absorb the new schema's multivalue fields, adding our key onto it\n",
    "                self.mv_fields += [[key] + x for x in new_schema.mv_fields]\n",
    "\n",
    "                continue\n",
    "\n",
    "            \n",
    "            new[key] = self.resolve_conflict(list(typeset))\n",
    "            if isinstance(new[key], t.multivalue):\n",
    "                self.mv_fields.append([key])\n",
    "\n",
    "        return new\n",
    "    \n",
    "    def adjust_mv(self, data:list[dict], mv_fields:list[list[str]]=None):        \n",
    "        if not mv_fields:\n",
    "            mv_fields = self.mv_fields\n",
    "\n",
    "        for field in mv_fields:\n",
    "            key = field[0]\n",
    "            if len(field) == 1:\n",
    "                for row in data:\n",
    "                    if key not in row:\n",
    "                        continue\n",
    "\n",
    "                    if isinstance(row[key], list):\n",
    "                        continue\n",
    "\n",
    "                    row[key] = [row[key]]\n",
    "            else:\n",
    "                rows = []\n",
    "                for i in data:\n",
    "                    if key in i:\n",
    "                        rows.append(i[key])\n",
    "                self.adjust_mv(rows, [field[1:]])\n",
    "\n",
    "        return data\n",
    "            \n",
    "\n",
    "df1 = pl.from_dicts(a)\n",
    "df2 = pl.from_dicts(b)\n",
    "ab_schema = Schema(a+b)\n",
    "print(json.dumps(ab_schema.schema, indent=2, default=repr))\n",
    "\n",
    "data = ab_schema.adjust_mv(a+b)\n",
    "df3 = pl.from_dicts(data, schema=Schema(a+b).to_pl_schema())\n",
    "print(json.dumps(df3.to_dicts(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "1331\n",
      "71\n",
      "1331\n",
      "361\n",
      "478\n",
      "1331\n",
      "384\n",
      "387\n",
      "812\n",
      "83\n",
      "229\n",
      "86\n",
      "86\n",
      "91\n",
      "361\n",
      "353\n",
      "355\n",
      "712\n",
      "1371\n",
      "610\n",
      "1331\n",
      "1331\n",
      "1331\n",
      "1331\n",
      "1331\n",
      "1371\n",
      "2010\n",
      "1331\n",
      "5480\n",
      "812\n",
      "14634\n",
      "812\n",
      "91\n",
      "1331\n",
      "3445\n",
      "100\n",
      "5480\n",
      "825\n",
      "86\n",
      "800\n",
      "812\n",
      "800\n",
      "2748\n",
      "385\n",
      "800\n",
      "71\n",
      "80\n",
      "71\n",
      "9588\n",
      "1371\n",
      "1371\n",
      "1371\n",
      "87\n",
      "380\n",
      "800\n",
      "1331\n",
      "387\n",
      "800\n",
      "800\n",
      "86\n",
      "86\n",
      "1331\n",
      "84\n",
      "1331\n",
      "355\n",
      "1331\n",
      "345\n",
      "384\n",
      "1331\n",
      "100\n",
      "375\n",
      "1331\n",
      "1331\n",
      "2604\n",
      "1331\n",
      "353\n",
      "71\n",
      "73\n",
      "392\n",
      "83\n",
      "1624\n",
      "1932\n",
      "388\n",
      "2010\n",
      "84\n",
      "1331\n",
      "71\n",
      "800\n",
      "1331\n",
      "1331\n",
      "1371\n",
      "1331\n",
      "812\n",
      "458\n",
      "392\n",
      "152\n",
      "1331\n",
      "800\n",
      "384\n",
      "812\n",
      "1331\n",
      "1371\n",
      "4400\n",
      "71\n",
      "71\n",
      "1331\n",
      "1556\n",
      "345\n",
      "312\n",
      "1331\n",
      "152\n",
      "3445\n",
      "2366\n",
      "83\n",
      "800\n",
      "385\n",
      "800\n",
      "812\n",
      "381\n",
      "83\n",
      "1331\n",
      "73\n",
      "1331\n",
      "370\n",
      "812\n",
      "1371\n",
      "812\n",
      "1208\n",
      "183\n",
      "4400\n",
      "71\n",
      "380\n",
      "1331\n",
      "1331\n",
      "83\n",
      "11739\n",
      "1624\n",
      "1331\n",
      "86\n",
      "388\n",
      "856\n",
      "4925\n",
      "385\n",
      "2700\n",
      "384\n",
      "380\n",
      "825\n",
      "812\n",
      "1331\n",
      "1371\n",
      "1331\n",
      "380\n",
      "286\n",
      "91\n",
      "812\n",
      "370\n",
      "1371\n",
      "812\n",
      "304\n",
      "800\n",
      "1371\n",
      "181\n",
      "1371\n",
      "181\n",
      "183\n",
      "2045\n",
      "80\n",
      "1208\n",
      "1331\n",
      "381\n",
      "812\n",
      "73\n",
      "83\n",
      "1331\n",
      "1371\n",
      "812\n",
      "56\n",
      "1331\n",
      "800\n",
      "800\n",
      "800\n",
      "1331\n",
      "91\n",
      "1331\n",
      "1331\n",
      "9588\n",
      "375\n",
      "388\n",
      "1331\n",
      "86\n",
      "1371\n",
      "1331\n",
      "91\n",
      "1331\n",
      "1331\n",
      "73\n",
      "1331\n",
      "1331\n",
      "152\n",
      "86\n",
      "1331\n",
      "385\n",
      "812\n"
     ]
    }
   ],
   "source": [
    "unnested = [x['_source'] for x in json_data]\n",
    "jschema = Schema(unnested)\n",
    "unnested = jschema.adjust_mv(unnested)\n",
    "df4 = pl.from_dicts(unnested, schema=jschema.to_pl_schema())\n",
    "\n",
    "for i in df4.to_dicts():\n",
    "    if 'client' in i and i['client'] and i['client']['ip_bytes']:\n",
    "        print(i['client']['ip_bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': string, 'id': string, 'message': string, 'stack_trace': string, 'type': string}\n",
      "{'code': string, 'id': string, 'message': string, 'stack_trace': string, 'type': string}\n",
      "{'code': string, 'id': string, 'message': string, 'stack_trace': string, 'type': string}\n",
      "{'code': string, 'id': string, 'message': string, 'stack_trace': string, 'type': string}\n"
     ]
    }
   ],
   "source": [
    "with open('./so-network-index.json') as f:\n",
    "    index = json.loads(f.read())\n",
    "\n",
    "def gen_elastic_schema(props:dict):\n",
    "    schema = {}\n",
    "    for i in props:\n",
    "        if 'properties' in props[i]:\n",
    "            schema[i] = gen_elastic_schema(props[i]['properties'])\n",
    "            continue\n",
    "        \n",
    "        ptype = props[i]['type']\n",
    "        if ptype in  ('scaled_float'):\n",
    "            schema[i] = t.decimal\n",
    "        elif ptype in ('half_float', 'float'):\n",
    "            schema[i] = t.float\n",
    "        elif ptype in ('double'):\n",
    "            schema[i] = t.double\n",
    "        elif ptype in ('byte'):\n",
    "            schema[i] = t.byte\n",
    "        elif ptype in ('short'):\n",
    "            schema[i] = t.short\n",
    "        elif ptype in ('integer'):\n",
    "            schema[i] = t.int\n",
    "        elif ptype in ('long'):\n",
    "            schema[i] = t.long\n",
    "        elif ptype in ('unsigned_long'):\n",
    "            schema[i] = t.ulong\n",
    "        elif ptype in ('ip'):\n",
    "            schema[i] = t.ip\n",
    "        elif ptype in ('date', 'date_nanos'):\n",
    "            schema[i] = t.datetime\n",
    "        elif ptype in ('date_range', 'integer_range', 'float_range', 'long_range', 'double_range', 'ip_range'):\n",
    "            rtype = gen_elastic_schema({'rtype': {'type': ptype.replace('_range', '')}})['rtype']\n",
    "            schema[i] = t.range(rtype, rtype)\n",
    "        elif ptype in ('keyword', 'constant_keyword', 'wildcard', 'binary', 'text', 'match_only_text'):\n",
    "            schema[i] = t.string\n",
    "        elif ptype in ('boolean'):\n",
    "            schema[i] = t.bool\n",
    "        elif ptype in ('flattened', 'object'):\n",
    "            schema[i] = t.object([])\n",
    "        elif ptype in ('nested'):\n",
    "            schema[i] = t.string\n",
    "        elif ptype in ('point', 'geo_point'):\n",
    "            # ptype = t.float\n",
    "            # schema[i] = t.multivalue(ptype)\n",
    "            schema[i] = {\n",
    "                'lon': t.float,\n",
    "                'lat': t.float\n",
    "            }\n",
    "        # elif ptype in ('object', 'flattened', 'nested'):\n",
    "        #     schema[i] = pl.\n",
    "        # elif ptype in ('geo_point'):\n",
    "        #     schema[i] = pl.String\n",
    "        # elif ptype in ('')\n",
    "        else:\n",
    "            print(f'{i} {ptype}')\n",
    "\n",
    "    return schema\n",
    "\n",
    "class Schema(Schema):\n",
    "    def cast_to_schema(self, data:pl.DataFrame, schema:dict=None, mv_fields:list=None):\n",
    "        newdf = {}\n",
    "\n",
    "        schema = schema if schema else self.schema\n",
    "        mv_fields = mv_fields if mv_fields else self.mv_fields\n",
    "\n",
    "        for col in data:\n",
    "            # Base case, we don't specify anything in the target schema\n",
    "            # so pass through\n",
    "            if isinstance(schema, dict) and col.name not in schema:\n",
    "                newdf[col.name] = col\n",
    "                continue\n",
    "\n",
    "            # Generic unspecified object\n",
    "            if schema[col.name] == t.object:\n",
    "                newdf[col.name] = col\n",
    "                continue\n",
    "\n",
    "            # Case to recurse on a nested object\n",
    "            if col.dtype == pl.Struct:\n",
    "                subdata = pl.DataFrame(\n",
    "                    data.select(col.name).unnest(col.name),\n",
    "                    # schema=self.to_pl_schema(schema)[col.name]\n",
    "                )\n",
    "\n",
    "                # advance the multivalue fields to only those applicable to the recurse\n",
    "                new_fields = []\n",
    "                for i in mv_fields:\n",
    "                    if i[0] == col.name:\n",
    "                        new_fields.append(i[1:])\n",
    "\n",
    "                newdf[col.name] = self.cast_to_schema(\n",
    "                    subdata, \n",
    "                    schema=schema[col.name],\n",
    "                    mv_fields=new_fields\n",
    "                )\n",
    "\n",
    "                continue\n",
    "\n",
    "\n",
    "            # See if the current field is designated multi-value\n",
    "            mv = False\n",
    "            for i in mv_fields:\n",
    "                if len(i) == 1 and i[0] == col.name:\n",
    "                    mv = True\n",
    "\n",
    "            # mv should always be specified by the schema\n",
    "            # Unhandled fields are skipped at the top\n",
    "            if mv:\n",
    "                intermediate = col.dtype.inner\n",
    "                target = schema[col.name]().pl_schema()\n",
    "\n",
    "                if intermediate != target:\n",
    "                    newdf[col.name] = t.cast(col, pl.List(target))\n",
    "                else:\n",
    "                    newdf[col.name] = col\n",
    "\n",
    "                continue\n",
    "                \n",
    "\n",
    "            dtype = col.dtype.inner if isinstance(col.dtype, pl.List) else col.dtype\n",
    "            if dtype == schema[col.name]().pl_schema():\n",
    "                newdf[col.name] = col\n",
    "\n",
    "            newdf[col.name] = col.cast(self.to_pl_schema(src=schema)[col.name])\n",
    "\n",
    "        return pl.DataFrame(newdf)\n",
    "\n",
    "\n",
    "unnested = [x['_source'] for x in json_data]\n",
    "\n",
    "jschema = Schema(unnested)\n",
    "unnested = jschema.adjust_mv(unnested)\n",
    "\n",
    "# Intermediate dataframe\n",
    "df5 = pl.from_dicts(unnested, schema=jschema.to_pl_schema())\n",
    "\n",
    "eschema = Schema(schema=gen_elastic_schema(index['so-network-2022.10']['mappings']['properties']))\n",
    "df6 = eschema.cast_to_schema(df5, mv_fields=jschema.mv_fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./big.json') as f:\n",
    "    json_data = json.loads(f.read())\n",
    "\n",
    "with open('./so-beats-index.json') as f:\n",
    "    index = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hash\": {\n",
      "    \"md5\": \"string\",\n",
      "    \"sha1\": \"string\",\n",
      "    \"ja3\": \"string\",\n",
      "    \"ja3s\": \"string\"\n",
      "  },\n",
      "  \"rule\": {\n",
      "    \"action\": \"string\",\n",
      "    \"uuid\": \"string\",\n",
      "    \"rule\": \"string\",\n",
      "    \"severity\": \"int\",\n",
      "    \"ruleset\": \"string\",\n",
      "    \"name\": \"string\",\n",
      "    \"metadata\": {\n",
      "      \"updated_at\": \"multivalue(string)\",\n",
      "      \"signature_severity\": \"multivalue(string)\",\n",
      "      \"created_at\": \"multivalue(string)\",\n",
      "      \"affected_product\": \"multivalue(string)\",\n",
      "      \"attack_target\": \"multivalue(string)\",\n",
      "      \"deployment\": \"multivalue(string)\"\n",
      "    },\n",
      "    \"gid\": \"int\",\n",
      "    \"category\": \"string\",\n",
      "    \"rev\": \"int\",\n",
      "    \"reference\": \"string\"\n",
      "  },\n",
      "  \"weird\": {\n",
      "    \"name\": \"string\",\n",
      "    \"notice\": \"bool\",\n",
      "    \"peer\": \"string\"\n",
      "  },\n",
      "  \"observer\": {\n",
      "    \"name\": \"string\"\n",
      "  },\n",
      "  \"metadata\": {\n",
      "    \"beat\": \"string\",\n",
      "    \"ip_address\": \"string\",\n",
      "    \"type\": \"string\",\n",
      "    \"version\": \"string\"\n",
      "  },\n",
      "  \"tags\": \"multivalue(string)\",\n",
      "  \"ecs\": {\n",
      "    \"version\": \"string\"\n",
      "  },\n",
      "  \"connection\": {\n",
      "    \"bytes\": {\n",
      "      \"missed\": \"int\"\n",
      "    },\n",
      "    \"state\": \"string\",\n",
      "    \"history\": \"string\",\n",
      "    \"state_description\": \"string\"\n",
      "  },\n",
      "  \"source\": {\n",
      "    \"ip\": \"string\",\n",
      "    \"port\": \"int\",\n",
      "    \"geo\": {\n",
      "      \"location\": {\n",
      "        \"lat\": \"float\",\n",
      "        \"lon\": \"float\"\n",
      "      },\n",
      "      \"ip\": \"string\",\n",
      "      \"timezone\": \"string\",\n",
      "      \"country_iso_code\": \"string\",\n",
      "      \"city_name\": \"string\",\n",
      "      \"region_iso_code\": \"string\",\n",
      "      \"country_name\": \"string\",\n",
      "      \"region_name\": \"string\",\n",
      "      \"continent_name\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"message\": \"string\",\n",
      "  \"log\": {\n",
      "    \"id\": {\n",
      "      \"fuid\": \"string\",\n",
      "      \"resp_fuids\": \"multivalue(string)\",\n",
      "      \"uid\": \"multivalue(string)\"\n",
      "    },\n",
      "    \"file\": {\n",
      "      \"path\": \"string\"\n",
      "    },\n",
      "    \"offset\": \"int\"\n",
      "  },\n",
      "  \"destination\": {\n",
      "    \"ip\": \"string\",\n",
      "    \"port\": \"int\",\n",
      "    \"geo\": {\n",
      "      \"location\": {\n",
      "        \"lat\": \"float\",\n",
      "        \"lon\": \"float\"\n",
      "      },\n",
      "      \"ip\": \"string\",\n",
      "      \"timezone\": \"string\",\n",
      "      \"country_iso_code\": \"string\",\n",
      "      \"city_name\": \"string\",\n",
      "      \"region_iso_code\": \"string\",\n",
      "      \"country_name\": \"string\",\n",
      "      \"region_name\": \"string\",\n",
      "      \"continent_name\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"@timestamp\": \"string\",\n",
      "  \"host\": {\n",
      "    \"name\": \"string\"\n",
      "  },\n",
      "  \"network\": {\n",
      "    \"transport\": \"string\",\n",
      "    \"bytes\": \"int\",\n",
      "    \"data\": {\n",
      "      \"decoded\": \"string\"\n",
      "    },\n",
      "    \"protocol\": \"string\",\n",
      "    \"community_id\": \"string\"\n",
      "  },\n",
      "  \"event\": {\n",
      "    \"dataset\": \"string\",\n",
      "    \"module\": \"string\",\n",
      "    \"severity\": \"int\",\n",
      "    \"duration\": \"float\",\n",
      "    \"category\": \"string\",\n",
      "    \"severity_label\": \"string\",\n",
      "    \"ingested\": \"string\"\n",
      "  },\n",
      "  \"server\": {\n",
      "    \"packets\": \"int\",\n",
      "    \"ip\": \"string\",\n",
      "    \"bytes\": \"int\",\n",
      "    \"port\": \"string\",\n",
      "    \"ip_bytes\": \"int\"\n",
      "  },\n",
      "  \"import\": {\n",
      "    \"id\": \"string\",\n",
      "    \"file\": \"string\"\n",
      "  },\n",
      "  \"x509\": {\n",
      "    \"san_dns\": \"multivalue(string)\",\n",
      "    \"certificate\": {\n",
      "      \"subject\": \"string\",\n",
      "      \"not_valid_after\": \"int\",\n",
      "      \"key\": {\n",
      "        \"algorithm\": \"string\",\n",
      "        \"length\": \"int\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"exponent\": \"string\",\n",
      "      \"serial\": \"string\",\n",
      "      \"signing_algorithm\": \"string\",\n",
      "      \"issuer\": \"string\",\n",
      "      \"version\": \"int\",\n",
      "      \"not_valid_before\": \"int\"\n",
      "    },\n",
      "    \"basic_constraints\": {\n",
      "      \"ca\": \"bool\"\n",
      "    }\n",
      "  },\n",
      "  \"dns\": {\n",
      "    \"parent_domain\": \"string\",\n",
      "    \"query\": {\n",
      "      \"length\": \"int\",\n",
      "      \"type_name\": \"string\",\n",
      "      \"class_name\": \"string\",\n",
      "      \"rejected\": \"bool\",\n",
      "      \"class\": \"int\",\n",
      "      \"name\": \"string\",\n",
      "      \"type\": \"int\"\n",
      "    },\n",
      "    \"authoritative\": \"bool\",\n",
      "    \"top_level_domain\": \"string\",\n",
      "    \"truncated\": \"bool\",\n",
      "    \"parent_domain_length\": \"int\",\n",
      "    \"id\": \"int\",\n",
      "    \"ttls\": \"multivalue(int)\",\n",
      "    \"subdomain_length\": \"int\",\n",
      "    \"subdomain\": \"string\",\n",
      "    \"recursion\": {\n",
      "      \"desired\": \"bool\",\n",
      "      \"available\": \"bool\"\n",
      "    },\n",
      "    \"response\": {\n",
      "      \"code\": \"int\",\n",
      "      \"code_name\": \"string\"\n",
      "    },\n",
      "    \"answers\": {\n",
      "      \"name\": \"multivalue(string)\"\n",
      "    },\n",
      "    \"reserved\": \"int\",\n",
      "    \"highest_registered_domain\": \"string\"\n",
      "  },\n",
      "  \"notice\": {\n",
      "    \"action\": \"multivalue(string)\",\n",
      "    \"sub_message\": \"string\",\n",
      "    \"note\": \"string\",\n",
      "    \"p\": \"int\",\n",
      "    \"message\": \"string\",\n",
      "    \"suppress_for\": \"int\"\n",
      "  },\n",
      "  \"imported\": \"bool\",\n",
      "  \"@version\": \"string\",\n",
      "  \"source_geo\": {\n",
      "    \"network\": \"string\",\n",
      "    \"organization_name\": \"string\",\n",
      "    \"ip\": \"string\",\n",
      "    \"asn\": \"int\"\n",
      "  },\n",
      "  \"http\": {\n",
      "    \"status_message\": \"string\",\n",
      "    \"method\": \"string\",\n",
      "    \"virtual_host\": \"string\",\n",
      "    \"uri\": \"string\",\n",
      "    \"request\": {\n",
      "      \"body\": {\n",
      "        \"length\": \"int\"\n",
      "      }\n",
      "    },\n",
      "    \"response\": {\n",
      "      \"body\": {\n",
      "        \"length\": \"int\"\n",
      "      }\n",
      "    },\n",
      "    \"trans_depth\": \"int\",\n",
      "    \"status_code\": \"int\",\n",
      "    \"useragent\": \"string\",\n",
      "    \"version\": \"string\"\n",
      "  },\n",
      "  \"ssl\": {\n",
      "    \"cipher\": \"string\",\n",
      "    \"next_protocol\": \"string\",\n",
      "    \"server_name\": \"string\",\n",
      "    \"established\": \"bool\",\n",
      "    \"certificate\": {\n",
      "      \"issuer\": \"string\",\n",
      "      \"chain_fuids\": \"multivalue(string)\",\n",
      "      \"subject\": \"string\"\n",
      "    },\n",
      "    \"resumed\": \"bool\",\n",
      "    \"curve\": \"string\",\n",
      "    \"client\": {\n",
      "      \"certificate\": {\n",
      "        \"chain_fuids\": \"multivalue(null)\"\n",
      "      }\n",
      "    },\n",
      "    \"validation_status\": \"string\",\n",
      "    \"version\": \"string\"\n",
      "  },\n",
      "  \"file\": {\n",
      "    \"is_orig\": \"bool\",\n",
      "    \"bytes\": {\n",
      "      \"seen\": \"int\",\n",
      "      \"missing\": \"int\",\n",
      "      \"overflow\": \"int\",\n",
      "      \"total\": \"int\"\n",
      "    },\n",
      "    \"source\": \"string\",\n",
      "    \"timed_out\": \"bool\",\n",
      "    \"mime_type\": \"string\",\n",
      "    \"resp_mime_types\": \"multivalue(string)\",\n",
      "    \"depth\": \"int\",\n",
      "    \"analyzer\": \"multivalue(string)\"\n",
      "  },\n",
      "  \"client\": {\n",
      "    \"packets\": \"int\",\n",
      "    \"ip\": \"string\",\n",
      "    \"bytes\": \"int\",\n",
      "    \"port\": \"string\",\n",
      "    \"ip_bytes\": \"int\"\n",
      "  },\n",
      "  \"destination_geo\": {\n",
      "    \"network\": \"string\",\n",
      "    \"organization_name\": \"string\",\n",
      "    \"ip\": \"string\",\n",
      "    \"asn\": \"int\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Schema(Schema):\n",
    "    def to_pl_schema(self, src:dict=None):\n",
    "        if not src:\n",
    "            src = self.schema\n",
    "\n",
    "        schema = {}\n",
    "        for i in src:\n",
    "            j = src[i]\n",
    "\n",
    "            if isinstance(j, dict):\n",
    "                if len(j) == 0:\n",
    "                    schema[i] = pl.Struct([])\n",
    "                else:\n",
    "                    schema[i] = pl.Struct(self.to_pl_schema(src=j))\n",
    "                continue\n",
    "\n",
    "            if isinstance(j, t.multivalue):\n",
    "                schema[i] = j.pl_schema()\n",
    "                continue\n",
    "\n",
    "            if isinstance(j, t.object):\n",
    "                schema[i] = j.pl_schema()\n",
    "                continue\n",
    "            \n",
    "            schema[i] = j().pl_schema()\n",
    "\n",
    "        return schema\n",
    "\n",
    "jschema = Schema(unnested)\n",
    "unnested = jschema.adjust_mv(json_data)\n",
    "\n",
    "print(json.dumps(jschema.schema, indent=2, default=repr))\n",
    "\n",
    "# Intermediate dataframe\n",
    "df7 = pl.from_dicts(unnested, schema=jschema.to_pl_schema())\n",
    "\n",
    "eschema = Schema(schema=gen_elastic_schema(index['so-beats-2022.10.15']['mappings']['properties']))\n",
    "df8 = eschema.cast_to_schema(df5, mv_fields=jschema.mv_fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
