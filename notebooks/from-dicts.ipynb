{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_dicts() bs\n",
    "How to handle inconsistent schemas in regards to input from nosql databases such as elastic?\n",
    "\n",
    "Probably not going to use this code.\n",
    "The problem is that what if you write a detection and the fields change per query?\n",
    "But you're writing the detection for a specific set of logs that probably won't change schema.\n",
    "Think I'm going to move to a multi-dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Simple examples\n",
    "a = [\n",
    "    {\n",
    "        \"log\": {\n",
    "            \"file\": {\n",
    "                \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/suricata/eve-2022-11-10-07:20.json\"\n",
    "            },\n",
    "            \"offset\": 9491215,\n",
    "            \"id\": {\n",
    "                \"uid\": \"1017858934534263\",\n",
    "                \"resp_fuids\": None\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "b = [\n",
    "    {  \n",
    "        \"log\": {\n",
    "            \"file\": {\n",
    "                \"path\": \"/nsm/import/acb5b3eacd804c4c17d25fb312581610/zeek/logs/files.log\"\n",
    "            },\n",
    "            \"offset\": 7559607,\n",
    "            \"id\": {\n",
    "                \"uid\": [\n",
    "                    \"CAnltOiClThlO6ZFk\"\n",
    "                ],\n",
    "                \"fuid\": \"FdZyiY2Kf5yf3L4239\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "dfa = pl.from_dicts(a)\n",
    "dfb = pl.from_dicts(b)\n",
    "dfc = pl.from_dicts(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging\n",
      "Merging\n",
      "Merging\n",
      "Merging\n",
      "Merging\n"
     ]
    }
   ],
   "source": [
    "priorities = {\n",
    "    'list': {\n",
    "        'name': 'list',\n",
    "        'priority': 5,\n",
    "        'super': set(),\n",
    "    },\n",
    "    'str': {\n",
    "        'name': 'str',\n",
    "        'priority': 4,\n",
    "        'super': {'list'}\n",
    "    },\n",
    "    'float': {\n",
    "        'name': 'float',\n",
    "        'priority': 3,\n",
    "        'super': {'str', 'list'}\n",
    "    },\n",
    "    'int': {\n",
    "        'name': 'int',\n",
    "        'priority': 2,\n",
    "        'super': {'float', 'str', 'list'}\n",
    "    },\n",
    "    'bool': {\n",
    "        'name': 'bool',\n",
    "        'priority': 1,\n",
    "        'super': {'str', 'list'}\n",
    "    },\n",
    "}\n",
    "\n",
    "types = {\n",
    "    'list': list,\n",
    "    'str': str,\n",
    "    'float': float,\n",
    "    'int': int,\n",
    "    'bool': bool\n",
    "}\n",
    "\n",
    "# Takes in two schemas and figures it out\n",
    "# Should be an end type, that is in the priorities dict\n",
    "def resolve_conflict(a, b, sorted=False):\n",
    "    aname = type(a).__name__\n",
    "    pa = priorities[aname]\n",
    "    bname = type(b).__name__\n",
    "    pb = priorities[bname]\n",
    "    \n",
    "    if aname == bname:\n",
    "        return a\n",
    "    \n",
    "    if not sorted:\n",
    "        if pa['priority'] > pb['priority']:\n",
    "            return resolve_conflict(a, b, sorted=True)\n",
    "        else:\n",
    "            return resolve_conflict(b, a, sorted=True)\n",
    "        \n",
    "    # At this point a should be a higher priority than b\n",
    "    \n",
    "    # See if we can super b\n",
    "    if aname in pb['super']:\n",
    "        if aname == 'list':\n",
    "            c = resolve_conflict(a[0], b)\n",
    "            return [c]\n",
    "        \n",
    "        return a\n",
    "    # Find a common parent\n",
    "    # Likely either a str or list\n",
    "    else:\n",
    "        s = tuple(pa['super'] & pb['super'])\n",
    "        \n",
    "        if len(s) == 0:\n",
    "            logging.warning(f'Could not find a sutable agreement for types {aname} > {bname} when merging, defaulting to str...')\n",
    "            return str\n",
    "        \n",
    "        if s[0] != 'list':\n",
    "            return type[s[0]]\n",
    "        \n",
    "        raise Exception(f'Could only raise types {aname} > {bname} to list')\n",
    "\n",
    "def gen_schema(data:dict):\n",
    "    schema = {}\n",
    "    for i in data:\n",
    "        itype = type(data[i])\n",
    "        \n",
    "        if itype == dict:\n",
    "            schema[i] = gen_schema(data[i])\n",
    "        elif itype == list:\n",
    "            schema[i] = [type(data[i][0])]\n",
    "        else:\n",
    "            schema[i] = itype\n",
    "        \n",
    "    return schema\n",
    "\n",
    "def merge_schema(a:dict, b:dict):\n",
    "    if not a:\n",
    "        return a\n",
    "    \n",
    "    if not b:\n",
    "        return b\n",
    "    \n",
    "    c = {}\n",
    "    for i in a:\n",
    "        if i in b:\n",
    "            ta = type(a[i])\n",
    "            tb = type(b[i])\n",
    "            \n",
    "            if ta == tb and dict not in (ta, tb):\n",
    "                c[i] = ta\n",
    "            elif ta == tb and dict in (ta, tb):\n",
    "                # yeah you can only compromise between a dict and anything as stringing both\n",
    "                # and for that reason I'm out\n",
    "                pass\n",
    "\n",
    "def gen_super_schema(data:list[dict]):\n",
    "    ss = {}\n",
    "    for i in data:\n",
    "        s = gen_schema(i)\n",
    "        \n",
    "        if s != ss:\n",
    "            print('Merging')\n",
    "            ss = merge_schema(s, ss)\n",
    "            \n",
    "\n",
    "#pl.concat([dfa, dfb], how=\"diagonal_relaxed\")\n",
    "\n",
    "#print('what the feds want you to believe')\n",
    "#print(json.dumps(dfc.to_dicts(), indent=2))\n",
    "\n",
    "gen_super_schema(a+a+b+a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the schema from elastic itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "could not append value: [\"import\", \"beats_input_codec_plain_applied\"] of type: list[str] to the builder; make sure that all rows have the same schema or consider increasing `infer_schema_length`\n\nit might also be that a value overflows the data-type's capacity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m schema \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mSchema(gen_schema(props))\n\u001b[1;32m     52\u001b[0m unnested \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m json_data]\n\u001b[0;32m---> 53\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dicts\u001b[49m\u001b[43m(\u001b[49m\u001b[43munnested\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m ddicts \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_dicts()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ddicts:\n",
      "File \u001b[0;32m~/git/hash-query-language/.venv/lib64/python3.9/site-packages/polars/convert/general.py:216\u001b[0m, in \u001b[0;36mfrom_dicts\u001b[0;34m(data, schema, schema_overrides, strict, infer_schema_length)\u001b[0m\n\u001b[1;32m    213\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno data, cannot infer schema\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoDataError(msg)\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/hash-query-language/.venv/lib64/python3.9/site-packages/polars/dataframe/frame.py:375\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, schema, schema_overrides, strict, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m dict_to_pydf(\n\u001b[1;32m    367\u001b[0m         data,\n\u001b[1;32m    368\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m         nan_to_null\u001b[38;5;241m=\u001b[39mnan_to_null,\n\u001b[1;32m    372\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, Sequence)):\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m \u001b[43msequence_to_pydf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pl\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m series_to_pydf(\n\u001b[1;32m    387\u001b[0m         data, schema\u001b[38;5;241m=\u001b[39mschema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[1;32m    388\u001b[0m     )\n",
      "File \u001b[0;32m~/git/hash-query-language/.venv/lib64/python3.9/site-packages/polars/_utils/construction/dataframe.py:460\u001b[0m, in \u001b[0;36msequence_to_pydf\u001b[0;34m(data, schema, schema_overrides, strict, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_to_pydf({}, schema\u001b[38;5;241m=\u001b[39mschema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sequence_to_pydf_dispatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/functools.py:888\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    886\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/hash-query-language/.venv/lib64/python3.9/site-packages/polars/_utils/construction/dataframe.py:711\u001b[0m, in \u001b[0;36m_sequence_of_dict_to_pydf\u001b[0;34m(first_element, data, schema, schema_overrides, strict, infer_schema_length, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m column_names, schema_overrides \u001b[38;5;241m=\u001b[39m _unpack_schema(\n\u001b[1;32m    703\u001b[0m     schema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides\n\u001b[1;32m    704\u001b[0m )\n\u001b[1;32m    705\u001b[0m dicts_schema \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    706\u001b[0m     _include_unknowns(schema_overrides, column_names \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(schema_overrides))\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_names\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    709\u001b[0m )\n\u001b[0;32m--> 711\u001b[0m pydf \u001b[38;5;241m=\u001b[39m \u001b[43mPyDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdicts_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# TODO: we can remove this `schema_overrides` block completely\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m#  once https://github.com/pola-rs/polars/issues/11044 is fixed\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema_overrides:\n",
      "\u001b[0;31mComputeError\u001b[0m: could not append value: [\"import\", \"beats_input_codec_plain_applied\"] of type: list[str] to the builder; make sure that all rows have the same schema or consider increasing `infer_schema_length`\n\nit might also be that a value overflows the data-type's capacity"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "\n",
    "with open('./so-network-index.json') as f:\n",
    "    index = json.loads(f.read())\n",
    "    \n",
    "with open('./so-network-data.json') as f:\n",
    "    json_data = json.loads(f.read())\n",
    "    \n",
    "props = index['so-network-2022.10']['mappings']['properties']\n",
    "\n",
    "def gen_schema(props:dict):\n",
    "    schema = {}\n",
    "    for i in props:\n",
    "        if 'properties' in props[i]:\n",
    "            schema[i] = pl.Struct(gen_schema(props[i]['properties']))\n",
    "            continue\n",
    "        \n",
    "        ptype = props[i]['type']\n",
    "        if ptype in ('date', 'date_nanos'):\n",
    "            schema[i] = pl.String\n",
    "        elif ptype in ('keyword', 'text', 'constant_keyword', 'ip', 'binary',\n",
    "                       'wildcard', 'match_only_text'):\n",
    "            schema[i] = pl.String\n",
    "        elif ptype in ('long', 'scaled_float'):\n",
    "            schema[i] = pl.Int64\n",
    "        elif ptype in ('integer'):\n",
    "            schema[i] = pl.Int32\n",
    "        elif ptype in ('short'):\n",
    "            schema[i] = pl.Int16\n",
    "        elif ptype in ('byte'):\n",
    "            schema[i] = pl.Int8\n",
    "        elif ptype in ('double'):\n",
    "            schema[i] = pl.Float64\n",
    "        elif ptype in ('float', 'half_float'):\n",
    "            schema[i] = pl.Float32\n",
    "        elif ptype in ('unsigned_long'):\n",
    "            schema[i] = pl.UInt64\n",
    "        elif ptype in ('boolean'):\n",
    "            schema[i] = pl.Boolean\n",
    "        elif ptype in ('object', 'flattened', 'nested'):\n",
    "            schema[i] = pl.String\n",
    "        elif ptype in ('geo_point'):\n",
    "            schema[i] = pl.String\n",
    "        # elif ptype in ('')\n",
    "        else:\n",
    "            print(f'{i} {ptype}')\n",
    "\n",
    "    return schema\n",
    "\n",
    "schema = pl.Schema(gen_schema(props))\n",
    "unnested = [x['_source'] for x in json_data]\n",
    "data = pl.from_dicts(unnested, schema=schema, infer_schema_length=4096)\n",
    "ddicts = data.to_dicts()\n",
    "\n",
    "for i in ddicts:\n",
    "    if 'client' in i:\n",
    "        print(i['client'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
