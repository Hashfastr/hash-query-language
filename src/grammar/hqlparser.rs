// Generated from Hql.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
#![allow(unused_braces)]
use antlr_rust::PredictionContextCache;
use antlr_rust::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use antlr_rust::token_stream::TokenStream;
use antlr_rust::TokenSource;
use antlr_rust::parser_atn_simulator::ParserATNSimulator;
use antlr_rust::errors::*;
use antlr_rust::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use antlr_rust::recognizer::{Recognizer,Actions};
use antlr_rust::atn_deserializer::ATNDeserializer;
use antlr_rust::dfa::DFA;
use antlr_rust::atn::{ATN, INVALID_ALT};
use antlr_rust::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use antlr_rust::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use antlr_rust::tree::*;
use antlr_rust::token::{TOKEN_EOF,OwningToken,Token};
use antlr_rust::int_stream::EOF;
use antlr_rust::vocabulary::{Vocabulary,VocabularyImpl};
use antlr_rust::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::hqllistener::*;
use super::hqlvisitor::*;

use antlr_rust::lazy_static;
use antlr_rust::{TidAble,TidExt};

use std::marker::PhantomData;
use std::sync::Arc;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const ASTERISK:isize=1; 
		pub const ATSIGN:isize=2; 
		pub const BAR:isize=3; 
		pub const CLOSEBRACE:isize=4; 
		pub const CLOSEBRACKET:isize=5; 
		pub const CLOSEBRACKET_DASH:isize=6; 
		pub const CLOSEBRACKET_DASH_GREATERTHAN:isize=7; 
		pub const CLOSEPAREN:isize=8; 
		pub const COMMA:isize=9; 
		pub const COLON:isize=10; 
		pub const DASH:isize=11; 
		pub const DASHDASH:isize=12; 
		pub const DASHDASH_GREATERTHAN:isize=13; 
		pub const DASH_OPENBRACKET:isize=14; 
		pub const DOT:isize=15; 
		pub const DOTDOT:isize=16; 
		pub const EQUAL:isize=17; 
		pub const EQUALEQUAL:isize=18; 
		pub const EQUALTILDE:isize=19; 
		pub const EXCLAIMATIONPOINT_EQUAL:isize=20; 
		pub const EXCLAIMATIONPOINT_TILDE:isize=21; 
		pub const GREATERTHAN:isize=22; 
		pub const GREATERTHAN_EQUAL:isize=23; 
		pub const LESSTHAN:isize=24; 
		pub const LESSTHAN_DASHDASH:isize=25; 
		pub const LESSTHAN_DASH_OPENBRACKET:isize=26; 
		pub const LESSTHAN_EQUAL:isize=27; 
		pub const LESSTHAN_GREATERTHAN:isize=28; 
		pub const OPENBRACE:isize=29; 
		pub const OPENBRACKET:isize=30; 
		pub const OPENPAREN:isize=31; 
		pub const PERCENTSIGN:isize=32; 
		pub const PLUS:isize=33; 
		pub const SEMICOLON:isize=34; 
		pub const SLASH:isize=35; 
		pub const EQUAL_GREATERTHAN:isize=36; 
		pub const CHART3D_:isize=37; 
		pub const ACCESS:isize=38; 
		pub const ACCUMULATE:isize=39; 
		pub const AGGREGATIONS:isize=40; 
		pub const ALIAS:isize=41; 
		pub const ALL:isize=42; 
		pub const AND:isize=43; 
		pub const ANOMALYCHART:isize=44; 
		pub const ANOMALYCOLUMNS:isize=45; 
		pub const AREACHART:isize=46; 
		pub const AS:isize=47; 
		pub const ASC:isize=48; 
		pub const ASSERTSCHEMA:isize=49; 
		pub const AXES:isize=50; 
		pub const BAGEXPANSION:isize=51; 
		pub const BARCHART:isize=52; 
		pub const BASE:isize=53; 
		pub const BETWEEN:isize=54; 
		pub const BIN:isize=55; 
		pub const BIN_LEGACY:isize=56; 
		pub const BY:isize=57; 
		pub const CARD:isize=58; 
		pub const CLUSTER:isize=59; 
		pub const COLUMNCHART:isize=60; 
		pub const CONSUME:isize=61; 
		pub const CONTAINS:isize=62; 
		pub const CONTAINSCS:isize=63; 
		pub const CONTAINS_CS:isize=64; 
		pub const CONTEXTUAL_DATATABLE:isize=65; 
		pub const COUNT:isize=66; 
		pub const CROSSCLUSTER__:isize=67; 
		pub const CROSSDB__:isize=68; 
		pub const DATABASE:isize=69; 
		pub const DATASCOPE:isize=70; 
		pub const DATATABLE:isize=71; 
		pub const DECLARE:isize=72; 
		pub const DECODEBLOCKS:isize=73; 
		pub const DEFAULT:isize=74; 
		pub const DELTA:isize=75; 
		pub const DESC:isize=76; 
		pub const DISTINCT:isize=77; 
		pub const EDGES:isize=78; 
		pub const ENDSWITH:isize=79; 
		pub const ENDSWITH_CS:isize=80; 
		pub const ENTITYGROUP:isize=81; 
		pub const EVALUATE:isize=82; 
		pub const EXECUTE:isize=83; 
		pub const EXECUTE_AND_CACHE:isize=84; 
		pub const EXPANDOUTPUT:isize=85; 
		pub const EXTEND:isize=86; 
		pub const EXTERNALDATA:isize=87; 
		pub const EXTERNAL_DATA:isize=88; 
		pub const FACET:isize=89; 
		pub const FILTER:isize=90; 
		pub const FIND:isize=91; 
		pub const FIRST:isize=92; 
		pub const FLAGS:isize=93; 
		pub const FORK:isize=94; 
		pub const FROM:isize=95; 
		pub const GETSCHEMA:isize=96; 
		pub const GRANNYASC:isize=97; 
		pub const GRANNYDESC:isize=98; 
		pub const GRAPHMARKCOMPONENTS:isize=99; 
		pub const GRAPHMATCH:isize=100; 
		pub const GRAPHMERGE:isize=101; 
		pub const GRAPHSHORTESTPATHS:isize=102; 
		pub const GRAPHTOTABLE:isize=103; 
		pub const HAS:isize=104; 
		pub const HAS_ALL:isize=105; 
		pub const HAS_ANY:isize=106; 
		pub const HAS_CS:isize=107; 
		pub const HASPREFIX:isize=108; 
		pub const HASPREFIX_CS:isize=109; 
		pub const HASSUFFIX:isize=110; 
		pub const HASSUFFIX_CS:isize=111; 
		pub const HIDDEN_:isize=112; 
		pub const HINT_CONCURRENCY:isize=113; 
		pub const HINT_DISTRIBUTION:isize=114; 
		pub const HINT_MATERIALIZED:isize=115; 
		pub const HINT_NUM_PARTITIONS:isize=116; 
		pub const HINT_PASS_FILTERS:isize=117; 
		pub const HINT_PASS_FILTERS_COLUMN:isize=118; 
		pub const HINT_PROGRESSIVE_TOP:isize=119; 
		pub const HINT_REMOTE:isize=120; 
		pub const HINT_SUFFLEKEY:isize=121; 
		pub const HINT_SPREAD:isize=122; 
		pub const HINT_STRATEGY:isize=123; 
		pub const HOT:isize=124; 
		pub const HOTCACHE:isize=125; 
		pub const HOTDATA:isize=126; 
		pub const HOTINDEX:isize=127; 
		pub const ID:isize=128; 
		pub const ID__:isize=129; 
		pub const IN:isize=130; 
		pub const IN_CI:isize=131; 
		pub const INTO:isize=132; 
		pub const INVOKE:isize=133; 
		pub const ISFUZZY:isize=134; 
		pub const ISFUZZY__:isize=135; 
		pub const JOIN:isize=136; 
		pub const KIND:isize=137; 
		pub const LADDERCHART:isize=138; 
		pub const LAST:isize=139; 
		pub const LEGEND:isize=140; 
		pub const LET:isize=141; 
		pub const LIKE:isize=142; 
		pub const LIKECS:isize=143; 
		pub const LIMIT:isize=144; 
		pub const LINEAR:isize=145; 
		pub const LINECHART:isize=146; 
		pub const LIST:isize=147; 
		pub const LOOKUP:isize=148; 
		pub const LOG:isize=149; 
		pub const MACROEXPAND:isize=150; 
		pub const MAKEGRAPH:isize=151; 
		pub const MAKESERIES:isize=152; 
		pub const MAP:isize=153; 
		pub const MATCHES_REGEX:isize=154; 
		pub const MATERIALIZE:isize=155; 
		pub const MATERIALIZED_VIEW_COMBINE:isize=156; 
		pub const MV_APPLY:isize=157; 
		pub const MV_EXPAND:isize=158; 
		pub const MVAPPLY:isize=159; 
		pub const MVEXPAND:isize=160; 
		pub const NODES:isize=161; 
		pub const NONE:isize=162; 
		pub const NOOPTIMIZATION:isize=163; 
		pub const NOT_BETWEEN:isize=164; 
		pub const NOT_CONTAINS:isize=165; 
		pub const NOT_CONTAINS_CS:isize=166; 
		pub const NOT_ENDSWITH_CS:isize=167; 
		pub const NOT_ENDSWITH:isize=168; 
		pub const NOT_HAS:isize=169; 
		pub const NOT_HAS_CS:isize=170; 
		pub const NOT_HASPREFIX:isize=171; 
		pub const NOT_HASPREFIX_CS:isize=172; 
		pub const NOT_HASSUFFIX:isize=173; 
		pub const NOT_HASSUFFIX_CS:isize=174; 
		pub const NOT_IN:isize=175; 
		pub const NOT_IN_CI:isize=176; 
		pub const NOT_STARTSWITH:isize=177; 
		pub const NOT_STARTSWITH_CS:isize=178; 
		pub const NOTCONTAINS:isize=179; 
		pub const NOTCONTAINSCS:isize=180; 
		pub const NOTLIKE:isize=181; 
		pub const NOTLIKECS:isize=182; 
		pub const NULL:isize=183; 
		pub const NULLS:isize=184; 
		pub const OF:isize=185; 
		pub const ON:isize=186; 
		pub const OPTIONAL:isize=187; 
		pub const OR:isize=188; 
		pub const ORDER:isize=189; 
		pub const OTHERS:isize=190; 
		pub const OUTPUT:isize=191; 
		pub const PACK:isize=192; 
		pub const PANELS:isize=193; 
		pub const PARSE:isize=194; 
		pub const PARSEKV:isize=195; 
		pub const PARSEWHERE:isize=196; 
		pub const PARTITION:isize=197; 
		pub const PARTITIONBY:isize=198; 
		pub const PARTITIONEDBY:isize=199; 
		pub const PATTERN:isize=200; 
		pub const PACKEDCOLUMN__:isize=201; 
		pub const PIECHART:isize=202; 
		pub const PIVOTCHART:isize=203; 
		pub const PLUGIN:isize=204; 
		pub const PRINT:isize=205; 
		pub const PROJECT:isize=206; 
		pub const PROJECTAWAY:isize=207; 
		pub const PROJECTAWAY_:isize=208; 
		pub const PROJECTKEEP:isize=209; 
		pub const PROJECTRENAME:isize=210; 
		pub const PROJECTREORDER:isize=211; 
		pub const PROJECTSMART:isize=212; 
		pub const QUERYPARAMETERS:isize=213; 
		pub const RANGE:isize=214; 
		pub const REDUCE:isize=215; 
		pub const REGEX:isize=216; 
		pub const RELAXED:isize=217; 
		pub const RENDER:isize=218; 
		pub const REPLACE:isize=219; 
		pub const RESTRICT:isize=220; 
		pub const SAMPLE:isize=221; 
		pub const SAMPLE_DISTINCT:isize=222; 
		pub const SCAN:isize=223; 
		pub const SCATTERCHART:isize=224; 
		pub const SEARCH:isize=225; 
		pub const SERIALIZE:isize=226; 
		pub const SERIES:isize=227; 
		pub const SET:isize=228; 
		pub const SIMPLE:isize=229; 
		pub const SORT:isize=230; 
		pub const SOURCECOLUMNINDEX__:isize=231; 
		pub const STACKED:isize=232; 
		pub const STACKED100:isize=233; 
		pub const STACKEDAREACHART:isize=234; 
		pub const STARTSWITH:isize=235; 
		pub const STARTSWITH_CS:isize=236; 
		pub const STEP:isize=237; 
		pub const SUMMARIZE:isize=238; 
		pub const TABLE:isize=239; 
		pub const TAKE:isize=240; 
		pub const THRESHOLD:isize=241; 
		pub const TIMECHART:isize=242; 
		pub const TIMELINE:isize=243; 
		pub const TIMEPIVOT:isize=244; 
		pub const TITLE:isize=245; 
		pub const TO:isize=246; 
		pub const TOP:isize=247; 
		pub const TOP_HITTERS:isize=248; 
		pub const TOP_NESTED:isize=249; 
		pub const TOSCALAR:isize=250; 
		pub const TOTABLE:isize=251; 
		pub const TREEMAP:isize=252; 
		pub const TYPEOF:isize=253; 
		pub const UNION:isize=254; 
		pub const UNSTACKED:isize=255; 
		pub const UUID:isize=256; 
		pub const VIEW:isize=257; 
		pub const VISIBLE:isize=258; 
		pub const WHERE:isize=259; 
		pub const WITH:isize=260; 
		pub const WITHNOSOURCE__:isize=261; 
		pub const WITHSOURCE:isize=262; 
		pub const WITH_ITEM_INDEX:isize=263; 
		pub const WITH_MATCH_ID:isize=264; 
		pub const WITH_NODE_ID:isize=265; 
		pub const WITH_SOURCE:isize=266; 
		pub const WITH_STEP_NAME:isize=267; 
		pub const XAXIS:isize=268; 
		pub const XCOLUMN:isize=269; 
		pub const XMAX:isize=270; 
		pub const XMIN:isize=271; 
		pub const XTITLE:isize=272; 
		pub const YAXIS:isize=273; 
		pub const YCOLUMNS:isize=274; 
		pub const YMAX:isize=275; 
		pub const YMIN:isize=276; 
		pub const YSPLIT:isize=277; 
		pub const YTITLE:isize=278; 
		pub const BOOL:isize=279; 
		pub const BOOLEAN:isize=280; 
		pub const DATE:isize=281; 
		pub const DATETIME:isize=282; 
		pub const DECIMAL:isize=283; 
		pub const DOUBLE:isize=284; 
		pub const DYNAMIC:isize=285; 
		pub const FLOAT:isize=286; 
		pub const GUID:isize=287; 
		pub const INT:isize=288; 
		pub const INT8:isize=289; 
		pub const INT16:isize=290; 
		pub const INT32:isize=291; 
		pub const INT64:isize=292; 
		pub const LONG:isize=293; 
		pub const STRING:isize=294; 
		pub const REAL:isize=295; 
		pub const TIME:isize=296; 
		pub const TIMESPAN:isize=297; 
		pub const UINT:isize=298; 
		pub const UINT8:isize=299; 
		pub const UINT16:isize=300; 
		pub const UINT32:isize=301; 
		pub const UINT64:isize=302; 
		pub const ULONG:isize=303; 
		pub const UNIQUEID:isize=304; 
		pub const LONGLITERAL:isize=305; 
		pub const INTLITERAL:isize=306; 
		pub const REALLITERAL:isize=307; 
		pub const DECIMALLITERAL:isize=308; 
		pub const STRINGLITERAL:isize=309; 
		pub const BOOLEANLITERAL:isize=310; 
		pub const DATETIMELITERAL:isize=311; 
		pub const TIMESPANLITERAL:isize=312; 
		pub const TYPELITERAL:isize=313; 
		pub const RAWGUIDLITERAL:isize=314; 
		pub const GUIDLITERAL:isize=315; 
		pub const IDENTIFIER:isize=316; 
		pub const WHITESPACE:isize=317; 
		pub const COMMENT:isize=318;
	pub const RULE_top:usize = 0; 
	pub const RULE_query:usize = 1; 
	pub const RULE_statement:usize = 2; 
	pub const RULE_aliasDatabaseStatement:usize = 3; 
	pub const RULE_letStatement:usize = 4; 
	pub const RULE_letVariableDeclaration:usize = 5; 
	pub const RULE_letFunctionDeclaration:usize = 6; 
	pub const RULE_letViewDeclaration:usize = 7; 
	pub const RULE_letViewParameterList:usize = 8; 
	pub const RULE_letMaterializeDeclaration:usize = 9; 
	pub const RULE_letEntityGroupDeclaration:usize = 10; 
	pub const RULE_letFunctionParameterList:usize = 11; 
	pub const RULE_scalarParameter:usize = 12; 
	pub const RULE_scalarParameterDefault:usize = 13; 
	pub const RULE_tabularParameter:usize = 14; 
	pub const RULE_tabularParameterOpenSchema:usize = 15; 
	pub const RULE_tabularParameterRowSchema:usize = 16; 
	pub const RULE_tabularParameterRowSchemaColumnDeclaration:usize = 17; 
	pub const RULE_letFunctionBody:usize = 18; 
	pub const RULE_letFunctionBodyStatement:usize = 19; 
	pub const RULE_declarePatternStatement:usize = 20; 
	pub const RULE_declarePatternDefinition:usize = 21; 
	pub const RULE_declarePatternParameterList:usize = 22; 
	pub const RULE_declarePatternParameter:usize = 23; 
	pub const RULE_declarePatternPathParameter:usize = 24; 
	pub const RULE_declarePatternRule:usize = 25; 
	pub const RULE_declarePatternRuleArgumentList:usize = 26; 
	pub const RULE_declarePatternRulePathArgument:usize = 27; 
	pub const RULE_declarePatternRuleArgument:usize = 28; 
	pub const RULE_declarePatternBody:usize = 29; 
	pub const RULE_restrictAccessStatement:usize = 30; 
	pub const RULE_restrictAccessStatementEntity:usize = 31; 
	pub const RULE_setStatement:usize = 32; 
	pub const RULE_setStatementOptionValue:usize = 33; 
	pub const RULE_declareQueryParametersStatement:usize = 34; 
	pub const RULE_declareQueryParametersStatementParameter:usize = 35; 
	pub const RULE_queryStatement:usize = 36; 
	pub const RULE_expression:usize = 37; 
	pub const RULE_pipeExpression:usize = 38; 
	pub const RULE_pipedOperator:usize = 39; 
	pub const RULE_pipeSubExpression:usize = 40; 
	pub const RULE_beforePipeExpression:usize = 41; 
	pub const RULE_afterPipeOperator:usize = 42; 
	pub const RULE_beforeOrAfterPipeOperator:usize = 43; 
	pub const RULE_forkPipeOperator:usize = 44; 
	pub const RULE_asOperator:usize = 45; 
	pub const RULE_assertSchemaOperator:usize = 46; 
	pub const RULE_consumeOperator:usize = 47; 
	pub const RULE_countOperator:usize = 48; 
	pub const RULE_countOperatorAsClause:usize = 49; 
	pub const RULE_distinctOperator:usize = 50; 
	pub const RULE_distinctOperatorStarTarget:usize = 51; 
	pub const RULE_distinctOperatorColumnListTarget:usize = 52; 
	pub const RULE_evaluateOperator:usize = 53; 
	pub const RULE_evaluateOperatorSchemaClause:usize = 54; 
	pub const RULE_extendOperator:usize = 55; 
	pub const RULE_executeAndCacheOperator:usize = 56; 
	pub const RULE_facetByOperator:usize = 57; 
	pub const RULE_facetByOperatorWithOperatorClause:usize = 58; 
	pub const RULE_facetByOperatorWithExpressionClause:usize = 59; 
	pub const RULE_findOperator:usize = 60; 
	pub const RULE_findOperatorParametersWhereClause:usize = 61; 
	pub const RULE_findOperatorInClause:usize = 62; 
	pub const RULE_findOperatorProjectClause:usize = 63; 
	pub const RULE_findOperatorProjectExpression:usize = 64; 
	pub const RULE_findOperatorColumnExpression:usize = 65; 
	pub const RULE_findOperatorOptionalColumnType:usize = 66; 
	pub const RULE_findOperatorPackExpression:usize = 67; 
	pub const RULE_findOperatorProjectSmartClause:usize = 68; 
	pub const RULE_findOperatorProjectAwayClause:usize = 69; 
	pub const RULE_findOperatorProjectAwayStar:usize = 70; 
	pub const RULE_findOperatorProjectAwayColumnList:usize = 71; 
	pub const RULE_findOperatorSource:usize = 72; 
	pub const RULE_findOperatorSourceEntityExpression:usize = 73; 
	pub const RULE_forkOperator:usize = 74; 
	pub const RULE_forkOperatorFork:usize = 75; 
	pub const RULE_forkOperatorExpressionName:usize = 76; 
	pub const RULE_forkOperatorExpression:usize = 77; 
	pub const RULE_forkOperatorPipedOperator:usize = 78; 
	pub const RULE_getSchemaOperator:usize = 79; 
	pub const RULE_graphMarkComponentsOperator:usize = 80; 
	pub const RULE_graphMatchOperator:usize = 81; 
	pub const RULE_graphMatchPattern:usize = 82; 
	pub const RULE_graphMatchPatternNode:usize = 83; 
	pub const RULE_graphMatchPatternUnnamedEdge:usize = 84; 
	pub const RULE_graphMatchPatternNamedEdge:usize = 85; 
	pub const RULE_graphMatchPatternRange:usize = 86; 
	pub const RULE_graphMatchWhereClause:usize = 87; 
	pub const RULE_graphMatchProjectClause:usize = 88; 
	pub const RULE_graphMergeOperator:usize = 89; 
	pub const RULE_graphToTableOperator:usize = 90; 
	pub const RULE_graphToTableOutput:usize = 91; 
	pub const RULE_graphToTableAsClause:usize = 92; 
	pub const RULE_graphShortestPathsOperator:usize = 93; 
	pub const RULE_invokeOperator:usize = 94; 
	pub const RULE_joinOperator:usize = 95; 
	pub const RULE_joinOperatorOnClause:usize = 96; 
	pub const RULE_joinOperatorWhereClause:usize = 97; 
	pub const RULE_lookupOperator:usize = 98; 
	pub const RULE_macroExpandOperator:usize = 99; 
	pub const RULE_macroExpandEntityGroup:usize = 100; 
	pub const RULE_entityGroupExpression:usize = 101; 
	pub const RULE_makeGraphOperator:usize = 102; 
	pub const RULE_makeGraphIdClause:usize = 103; 
	pub const RULE_makeGraphTablesAndKeysClause:usize = 104; 
	pub const RULE_makeGraphPartitionedByClause:usize = 105; 
	pub const RULE_makeSeriesOperator:usize = 106; 
	pub const RULE_makeSeriesOperatorOnClause:usize = 107; 
	pub const RULE_makeSeriesOperatorAggregation:usize = 108; 
	pub const RULE_makeSeriesOperatorExpressionDefaultClause:usize = 109; 
	pub const RULE_makeSeriesOperatorInRangeClause:usize = 110; 
	pub const RULE_makeSeriesOperatorFromToStepClause:usize = 111; 
	pub const RULE_makeSeriesOperatorByClause:usize = 112; 
	pub const RULE_mvapplyOperator:usize = 113; 
	pub const RULE_mvapplyOperatorLimitClause:usize = 114; 
	pub const RULE_mvapplyOperatorIdClause:usize = 115; 
	pub const RULE_mvapplyOperatorExpression:usize = 116; 
	pub const RULE_mvapplyOperatorExpressionToClause:usize = 117; 
	pub const RULE_mvexpandOperator:usize = 118; 
	pub const RULE_mvexpandOperatorExpression:usize = 119; 
	pub const RULE_parseOperator:usize = 120; 
	pub const RULE_parseOperatorKindClause:usize = 121; 
	pub const RULE_parseOperatorFlagsClause:usize = 122; 
	pub const RULE_parseOperatorNameAndOptionalType:usize = 123; 
	pub const RULE_parseOperatorPattern:usize = 124; 
	pub const RULE_parseOperatorPatternSegment:usize = 125; 
	pub const RULE_parseWhereOperator:usize = 126; 
	pub const RULE_parseKvOperator:usize = 127; 
	pub const RULE_parseKvWithClause:usize = 128; 
	pub const RULE_partitionOperator:usize = 129; 
	pub const RULE_partitionOperatorInClause:usize = 130; 
	pub const RULE_partitionOperatorSubExpressionBody:usize = 131; 
	pub const RULE_partitionOperatorFullExpressionBody:usize = 132; 
	pub const RULE_partitionByOperator:usize = 133; 
	pub const RULE_partitionByOperatorIdClause:usize = 134; 
	pub const RULE_printOperator:usize = 135; 
	pub const RULE_projectAwayOperator:usize = 136; 
	pub const RULE_projectKeepOperator:usize = 137; 
	pub const RULE_projectOperator:usize = 138; 
	pub const RULE_projectRenameOperator:usize = 139; 
	pub const RULE_projectReorderOperator:usize = 140; 
	pub const RULE_projectReorderExpression:usize = 141; 
	pub const RULE_reduceByOperator:usize = 142; 
	pub const RULE_reduceByWithClause:usize = 143; 
	pub const RULE_renderOperator:usize = 144; 
	pub const RULE_renderOperatorWithClause:usize = 145; 
	pub const RULE_renderOperatorLegacyPropertyList:usize = 146; 
	pub const RULE_renderOperatorProperty:usize = 147; 
	pub const RULE_renderPropertyNameList:usize = 148; 
	pub const RULE_renderOperatorLegacyProperty:usize = 149; 
	pub const RULE_sampleDistinctOperator:usize = 150; 
	pub const RULE_sampleOperator:usize = 151; 
	pub const RULE_scanOperator:usize = 152; 
	pub const RULE_scanOperatorOrderByClause:usize = 153; 
	pub const RULE_scanOperatorPartitionByClause:usize = 154; 
	pub const RULE_scanOperatorDeclareClause:usize = 155; 
	pub const RULE_scanOperatorStep:usize = 156; 
	pub const RULE_scanOperatorStepOutputClause:usize = 157; 
	pub const RULE_scanOperatorBody:usize = 158; 
	pub const RULE_scanOperatorAssignment:usize = 159; 
	pub const RULE_searchOperator:usize = 160; 
	pub const RULE_searchOperatorStarAndExpression:usize = 161; 
	pub const RULE_searchOperatorInClause:usize = 162; 
	pub const RULE_serializeOperator:usize = 163; 
	pub const RULE_sortOperator:usize = 164; 
	pub const RULE_orderedExpression:usize = 165; 
	pub const RULE_sortOrdering:usize = 166; 
	pub const RULE_summarizeOperator:usize = 167; 
	pub const RULE_summarizeOperatorByClause:usize = 168; 
	pub const RULE_summarizeOperatorLegacyBinClause:usize = 169; 
	pub const RULE_takeOperator:usize = 170; 
	pub const RULE_topOperator:usize = 171; 
	pub const RULE_topHittersOperator:usize = 172; 
	pub const RULE_topHittersOperatorByClause:usize = 173; 
	pub const RULE_topNestedOperator:usize = 174; 
	pub const RULE_topNestedOperatorPart:usize = 175; 
	pub const RULE_topNestedOperatorWithOthersClause:usize = 176; 
	pub const RULE_unionOperator:usize = 177; 
	pub const RULE_unionOperatorExpression:usize = 178; 
	pub const RULE_whereOperator:usize = 179; 
	pub const RULE_contextualSubExpression:usize = 180; 
	pub const RULE_contextualPipeExpression:usize = 181; 
	pub const RULE_contextualPipeExpressionPipedOperator:usize = 182; 
	pub const RULE_strictQueryOperatorParameter:usize = 183; 
	pub const RULE_relaxedQueryOperatorParameter:usize = 184; 
	pub const RULE_queryOperatorProperty:usize = 185; 
	pub const RULE_namedExpression:usize = 186; 
	pub const RULE_namedExpressionNameClause:usize = 187; 
	pub const RULE_namedExpressionNameList:usize = 188; 
	pub const RULE_scopedFunctionCallExpression:usize = 189; 
	pub const RULE_unnamedExpression:usize = 190; 
	pub const RULE_logicalOrExpression:usize = 191; 
	pub const RULE_logicalOrOperation:usize = 192; 
	pub const RULE_logicalAndExpression:usize = 193; 
	pub const RULE_logicalAndOperation:usize = 194; 
	pub const RULE_equalityExpression:usize = 195; 
	pub const RULE_equalsEqualityExpression:usize = 196; 
	pub const RULE_listEqualityExpression:usize = 197; 
	pub const RULE_betweenEqualityExpression:usize = 198; 
	pub const RULE_starEqualityExpression:usize = 199; 
	pub const RULE_relationalExpression:usize = 200; 
	pub const RULE_additiveExpression:usize = 201; 
	pub const RULE_additiveOperation:usize = 202; 
	pub const RULE_multiplicativeExpression:usize = 203; 
	pub const RULE_multiplicativeOperation:usize = 204; 
	pub const RULE_stringOperatorExpression:usize = 205; 
	pub const RULE_stringBinaryOperatorExpression:usize = 206; 
	pub const RULE_stringBinaryOperation:usize = 207; 
	pub const RULE_stringBinaryOperator:usize = 208; 
	pub const RULE_stringStarOperatorExpression:usize = 209; 
	pub const RULE_invocationExpression:usize = 210; 
	pub const RULE_functionCallOrPathExpression:usize = 211; 
	pub const RULE_functionCallOrPathRoot:usize = 212; 
	pub const RULE_functionCallOrPathPathExpression:usize = 213; 
	pub const RULE_functionCallOrPathOperation:usize = 214; 
	pub const RULE_functionalCallOrPathPathOperation:usize = 215; 
	pub const RULE_functionCallOrPathElementOperation:usize = 216; 
	pub const RULE_legacyFunctionCallOrPathElementOperation:usize = 217; 
	pub const RULE_toScalarExpression:usize = 218; 
	pub const RULE_toTableExpression:usize = 219; 
	pub const RULE_noOptimizationParameter:usize = 220; 
	pub const RULE_dotCompositeFunctionCallExpression:usize = 221; 
	pub const RULE_dotCompositeFunctionCallOperation:usize = 222; 
	pub const RULE_functionCallExpression:usize = 223; 
	pub const RULE_namedFunctionCallExpression:usize = 224; 
	pub const RULE_argumentExpression:usize = 225; 
	pub const RULE_countExpression:usize = 226; 
	pub const RULE_starExpression:usize = 227; 
	pub const RULE_primaryExpression:usize = 228; 
	pub const RULE_nameReferenceWithDataScope:usize = 229; 
	pub const RULE_dataScopeClause:usize = 230; 
	pub const RULE_parenthesizedExpression:usize = 231; 
	pub const RULE_rangeExpression:usize = 232; 
	pub const RULE_entityExpression:usize = 233; 
	pub const RULE_entityPathOrElementExpression:usize = 234; 
	pub const RULE_entityPathOrElementOperator:usize = 235; 
	pub const RULE_entityPathOperator:usize = 236; 
	pub const RULE_entityElementOperator:usize = 237; 
	pub const RULE_legacyEntityPathElementOperator:usize = 238; 
	pub const RULE_entityName:usize = 239; 
	pub const RULE_entityNameReference:usize = 240; 
	pub const RULE_atSignName:usize = 241; 
	pub const RULE_extendedPathName:usize = 242; 
	pub const RULE_wildcardedEntityExpression:usize = 243; 
	pub const RULE_wildcardedPathExpression:usize = 244; 
	pub const RULE_wildcardedPathName:usize = 245; 
	pub const RULE_contextualDataTableExpression:usize = 246; 
	pub const RULE_dataTableExpression:usize = 247; 
	pub const RULE_rowSchema:usize = 248; 
	pub const RULE_rowSchemaColumnDeclaration:usize = 249; 
	pub const RULE_externalDataExpression:usize = 250; 
	pub const RULE_externalDataWithClause:usize = 251; 
	pub const RULE_externalDataWithClauseProperty:usize = 252; 
	pub const RULE_materializedViewCombineExpression:usize = 253; 
	pub const RULE_materializeViewCombineBaseClause:usize = 254; 
	pub const RULE_materializedViewCombineDeltaClause:usize = 255; 
	pub const RULE_materializedViewCombineAggregationsClause:usize = 256; 
	pub const RULE_scalarType:usize = 257; 
	pub const RULE_extendedScalarType:usize = 258; 
	pub const RULE_parameterName:usize = 259; 
	pub const RULE_simpleNameReference:usize = 260; 
	pub const RULE_extendedNameReference:usize = 261; 
	pub const RULE_wildcardedNameReference:usize = 262; 
	pub const RULE_simpleOrWildcardedNameReference:usize = 263; 
	pub const RULE_identifierName:usize = 264; 
	pub const RULE_keywordName:usize = 265; 
	pub const RULE_extendedKeywordName:usize = 266; 
	pub const RULE_escapedName:usize = 267; 
	pub const RULE_identifierOrKeywordName:usize = 268; 
	pub const RULE_identifierOrKeywordOrEscapedName:usize = 269; 
	pub const RULE_identifierOrExtendedKeywordOrEscapedName:usize = 270; 
	pub const RULE_identifierOrExtendedKeywordName:usize = 271; 
	pub const RULE_wildcardedName:usize = 272; 
	pub const RULE_wildcardedNamePrefix:usize = 273; 
	pub const RULE_wildcardedNameSegment:usize = 274; 
	pub const RULE_literalExpression:usize = 275; 
	pub const RULE_unsignedLiteralExpression:usize = 276; 
	pub const RULE_numberLikeLiteralExpression:usize = 277; 
	pub const RULE_numericLiteralExpression:usize = 278; 
	pub const RULE_signedLiteralExpression:usize = 279; 
	pub const RULE_longLiteralExpression:usize = 280; 
	pub const RULE_intLiteralExpression:usize = 281; 
	pub const RULE_realLiteralExpression:usize = 282; 
	pub const RULE_decimalLiteralExpression:usize = 283; 
	pub const RULE_dateTimeLiteralExpression:usize = 284; 
	pub const RULE_timeSpanLiteralExpression:usize = 285; 
	pub const RULE_booleanLiteralExpression:usize = 286; 
	pub const RULE_guidLiteralExpression:usize = 287; 
	pub const RULE_typeLiteralExpression:usize = 288; 
	pub const RULE_signedLongLiteralExpression:usize = 289; 
	pub const RULE_signedRealLiteralExpression:usize = 290; 
	pub const RULE_stringLiteralExpression:usize = 291; 
	pub const RULE_dynamicLiteralExpression:usize = 292; 
	pub const RULE_jsonValue:usize = 293; 
	pub const RULE_jsonObject:usize = 294; 
	pub const RULE_jsonPair:usize = 295; 
	pub const RULE_jsonArray:usize = 296; 
	pub const RULE_jsonBoolean:usize = 297; 
	pub const RULE_jsonDateTime:usize = 298; 
	pub const RULE_jsonGuid:usize = 299; 
	pub const RULE_jsonNull:usize = 300; 
	pub const RULE_jsonString:usize = 301; 
	pub const RULE_jsonTimeSpan:usize = 302; 
	pub const RULE_jsonLong:usize = 303; 
	pub const RULE_jsonReal:usize = 304;
	pub const ruleNames: [&'static str; 305] =  [
		"top", "query", "statement", "aliasDatabaseStatement", "letStatement", 
		"letVariableDeclaration", "letFunctionDeclaration", "letViewDeclaration", 
		"letViewParameterList", "letMaterializeDeclaration", "letEntityGroupDeclaration", 
		"letFunctionParameterList", "scalarParameter", "scalarParameterDefault", 
		"tabularParameter", "tabularParameterOpenSchema", "tabularParameterRowSchema", 
		"tabularParameterRowSchemaColumnDeclaration", "letFunctionBody", "letFunctionBodyStatement", 
		"declarePatternStatement", "declarePatternDefinition", "declarePatternParameterList", 
		"declarePatternParameter", "declarePatternPathParameter", "declarePatternRule", 
		"declarePatternRuleArgumentList", "declarePatternRulePathArgument", "declarePatternRuleArgument", 
		"declarePatternBody", "restrictAccessStatement", "restrictAccessStatementEntity", 
		"setStatement", "setStatementOptionValue", "declareQueryParametersStatement", 
		"declareQueryParametersStatementParameter", "queryStatement", "expression", 
		"pipeExpression", "pipedOperator", "pipeSubExpression", "beforePipeExpression", 
		"afterPipeOperator", "beforeOrAfterPipeOperator", "forkPipeOperator", 
		"asOperator", "assertSchemaOperator", "consumeOperator", "countOperator", 
		"countOperatorAsClause", "distinctOperator", "distinctOperatorStarTarget", 
		"distinctOperatorColumnListTarget", "evaluateOperator", "evaluateOperatorSchemaClause", 
		"extendOperator", "executeAndCacheOperator", "facetByOperator", "facetByOperatorWithOperatorClause", 
		"facetByOperatorWithExpressionClause", "findOperator", "findOperatorParametersWhereClause", 
		"findOperatorInClause", "findOperatorProjectClause", "findOperatorProjectExpression", 
		"findOperatorColumnExpression", "findOperatorOptionalColumnType", "findOperatorPackExpression", 
		"findOperatorProjectSmartClause", "findOperatorProjectAwayClause", "findOperatorProjectAwayStar", 
		"findOperatorProjectAwayColumnList", "findOperatorSource", "findOperatorSourceEntityExpression", 
		"forkOperator", "forkOperatorFork", "forkOperatorExpressionName", "forkOperatorExpression", 
		"forkOperatorPipedOperator", "getSchemaOperator", "graphMarkComponentsOperator", 
		"graphMatchOperator", "graphMatchPattern", "graphMatchPatternNode", "graphMatchPatternUnnamedEdge", 
		"graphMatchPatternNamedEdge", "graphMatchPatternRange", "graphMatchWhereClause", 
		"graphMatchProjectClause", "graphMergeOperator", "graphToTableOperator", 
		"graphToTableOutput", "graphToTableAsClause", "graphShortestPathsOperator", 
		"invokeOperator", "joinOperator", "joinOperatorOnClause", "joinOperatorWhereClause", 
		"lookupOperator", "macroExpandOperator", "macroExpandEntityGroup", "entityGroupExpression", 
		"makeGraphOperator", "makeGraphIdClause", "makeGraphTablesAndKeysClause", 
		"makeGraphPartitionedByClause", "makeSeriesOperator", "makeSeriesOperatorOnClause", 
		"makeSeriesOperatorAggregation", "makeSeriesOperatorExpressionDefaultClause", 
		"makeSeriesOperatorInRangeClause", "makeSeriesOperatorFromToStepClause", 
		"makeSeriesOperatorByClause", "mvapplyOperator", "mvapplyOperatorLimitClause", 
		"mvapplyOperatorIdClause", "mvapplyOperatorExpression", "mvapplyOperatorExpressionToClause", 
		"mvexpandOperator", "mvexpandOperatorExpression", "parseOperator", "parseOperatorKindClause", 
		"parseOperatorFlagsClause", "parseOperatorNameAndOptionalType", "parseOperatorPattern", 
		"parseOperatorPatternSegment", "parseWhereOperator", "parseKvOperator", 
		"parseKvWithClause", "partitionOperator", "partitionOperatorInClause", 
		"partitionOperatorSubExpressionBody", "partitionOperatorFullExpressionBody", 
		"partitionByOperator", "partitionByOperatorIdClause", "printOperator", 
		"projectAwayOperator", "projectKeepOperator", "projectOperator", "projectRenameOperator", 
		"projectReorderOperator", "projectReorderExpression", "reduceByOperator", 
		"reduceByWithClause", "renderOperator", "renderOperatorWithClause", "renderOperatorLegacyPropertyList", 
		"renderOperatorProperty", "renderPropertyNameList", "renderOperatorLegacyProperty", 
		"sampleDistinctOperator", "sampleOperator", "scanOperator", "scanOperatorOrderByClause", 
		"scanOperatorPartitionByClause", "scanOperatorDeclareClause", "scanOperatorStep", 
		"scanOperatorStepOutputClause", "scanOperatorBody", "scanOperatorAssignment", 
		"searchOperator", "searchOperatorStarAndExpression", "searchOperatorInClause", 
		"serializeOperator", "sortOperator", "orderedExpression", "sortOrdering", 
		"summarizeOperator", "summarizeOperatorByClause", "summarizeOperatorLegacyBinClause", 
		"takeOperator", "topOperator", "topHittersOperator", "topHittersOperatorByClause", 
		"topNestedOperator", "topNestedOperatorPart", "topNestedOperatorWithOthersClause", 
		"unionOperator", "unionOperatorExpression", "whereOperator", "contextualSubExpression", 
		"contextualPipeExpression", "contextualPipeExpressionPipedOperator", "strictQueryOperatorParameter", 
		"relaxedQueryOperatorParameter", "queryOperatorProperty", "namedExpression", 
		"namedExpressionNameClause", "namedExpressionNameList", "scopedFunctionCallExpression", 
		"unnamedExpression", "logicalOrExpression", "logicalOrOperation", "logicalAndExpression", 
		"logicalAndOperation", "equalityExpression", "equalsEqualityExpression", 
		"listEqualityExpression", "betweenEqualityExpression", "starEqualityExpression", 
		"relationalExpression", "additiveExpression", "additiveOperation", "multiplicativeExpression", 
		"multiplicativeOperation", "stringOperatorExpression", "stringBinaryOperatorExpression", 
		"stringBinaryOperation", "stringBinaryOperator", "stringStarOperatorExpression", 
		"invocationExpression", "functionCallOrPathExpression", "functionCallOrPathRoot", 
		"functionCallOrPathPathExpression", "functionCallOrPathOperation", "functionalCallOrPathPathOperation", 
		"functionCallOrPathElementOperation", "legacyFunctionCallOrPathElementOperation", 
		"toScalarExpression", "toTableExpression", "noOptimizationParameter", 
		"dotCompositeFunctionCallExpression", "dotCompositeFunctionCallOperation", 
		"functionCallExpression", "namedFunctionCallExpression", "argumentExpression", 
		"countExpression", "starExpression", "primaryExpression", "nameReferenceWithDataScope", 
		"dataScopeClause", "parenthesizedExpression", "rangeExpression", "entityExpression", 
		"entityPathOrElementExpression", "entityPathOrElementOperator", "entityPathOperator", 
		"entityElementOperator", "legacyEntityPathElementOperator", "entityName", 
		"entityNameReference", "atSignName", "extendedPathName", "wildcardedEntityExpression", 
		"wildcardedPathExpression", "wildcardedPathName", "contextualDataTableExpression", 
		"dataTableExpression", "rowSchema", "rowSchemaColumnDeclaration", "externalDataExpression", 
		"externalDataWithClause", "externalDataWithClauseProperty", "materializedViewCombineExpression", 
		"materializeViewCombineBaseClause", "materializedViewCombineDeltaClause", 
		"materializedViewCombineAggregationsClause", "scalarType", "extendedScalarType", 
		"parameterName", "simpleNameReference", "extendedNameReference", "wildcardedNameReference", 
		"simpleOrWildcardedNameReference", "identifierName", "keywordName", "extendedKeywordName", 
		"escapedName", "identifierOrKeywordName", "identifierOrKeywordOrEscapedName", 
		"identifierOrExtendedKeywordOrEscapedName", "identifierOrExtendedKeywordName", 
		"wildcardedName", "wildcardedNamePrefix", "wildcardedNameSegment", "literalExpression", 
		"unsignedLiteralExpression", "numberLikeLiteralExpression", "numericLiteralExpression", 
		"signedLiteralExpression", "longLiteralExpression", "intLiteralExpression", 
		"realLiteralExpression", "decimalLiteralExpression", "dateTimeLiteralExpression", 
		"timeSpanLiteralExpression", "booleanLiteralExpression", "guidLiteralExpression", 
		"typeLiteralExpression", "signedLongLiteralExpression", "signedRealLiteralExpression", 
		"stringLiteralExpression", "dynamicLiteralExpression", "jsonValue", "jsonObject", 
		"jsonPair", "jsonArray", "jsonBoolean", "jsonDateTime", "jsonGuid", "jsonNull", 
		"jsonString", "jsonTimeSpan", "jsonLong", "jsonReal"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;305] = [
		None, Some("'*'"), Some("'@'"), Some("'|'"), Some("'}'"), Some("']'"), 
		Some("']-'"), Some("']->'"), Some("')'"), Some("','"), Some("':'"), Some("'-'"), 
		Some("'--'"), Some("'-->'"), Some("'-['"), Some("'.'"), Some("'..'"), 
		Some("'='"), Some("'=='"), Some("'=~'"), Some("'!='"), Some("'!~'"), Some("'>'"), 
		Some("'>='"), Some("'<'"), Some("'<--'"), Some("'<-['"), Some("'<='"), 
		Some("'<>'"), Some("'{'"), Some("'['"), Some("'('"), Some("'%'"), Some("'+'"), 
		Some("';'"), Some("'/'"), Some("'=>'"), Some("'3Dchart'"), Some("'access'"), 
		Some("'accumulate'"), Some("'aggregations'"), Some("'alias'"), Some("'all'"), 
		Some("'and'"), Some("'anomalychart'"), Some("'anomalycolumns'"), Some("'areachart'"), 
		Some("'as'"), Some("'asc'"), Some("'assert-schema'"), Some("'axes'"), 
		Some("'bagexpansion'"), Some("'barchart'"), Some("'base'"), Some("'between'"), 
		Some("'bin'"), Some("'bin_legacy'"), Some("'by'"), Some("'card'"), Some("'cluster'"), 
		Some("'columnchart'"), Some("'consume'"), Some("'contains'"), Some("'containscs'"), 
		Some("'contains_cs'"), Some("'__contextual_datatable'"), Some("'count'"), 
		Some("'__crossCluster'"), Some("'__crossDB'"), Some("'database'"), Some("'datascope'"), 
		Some("'datatable'"), Some("'declare'"), Some("'decodeblocks'"), Some("'default'"), 
		Some("'delta'"), Some("'desc'"), Some("'distinct'"), Some("'edges'"), 
		Some("'endswith'"), Some("'endswith_cs'"), Some("'entity_group'"), Some("'evaluate'"), 
		Some("'execute'"), Some("'__executeAndCache'"), Some("'expandoutput'"), 
		Some("'extend'"), Some("'externaldata'"), Some("'external_data'"), Some("'facet'"), 
		Some("'filter'"), Some("'find'"), Some("'first'"), Some("'flags'"), Some("'fork'"), 
		Some("'from'"), Some("'getschema'"), Some("'granny-asc'"), Some("'granny-desc'"), 
		Some("'graph-mark-components'"), Some("'graph-match'"), Some("'graph-merge'"), 
		Some("'graph-shortest-paths'"), Some("'graph-to-table'"), Some("'has'"), 
		Some("'has_all'"), Some("'has_any'"), Some("'has_cs'"), Some("'hasprefix'"), 
		Some("'hasprefix_cs'"), Some("'hassuffix'"), Some("'hassuffix_cs'"), Some("'hidden'"), 
		Some("'hint.concurrency'"), Some("'hint.distribution'"), Some("'hint.materialized'"), 
		Some("'hint.num_partitions'"), Some("'hint.pass_filters'"), Some("'hint.pass_filters_column'"), 
		Some("'hint.progressive_top'"), Some("'hint.remote'"), Some("'hint.shufflekey'"), 
		Some("'hint.spread'"), Some("'hint.strategy'"), Some("'hot'"), Some("'hotcache'"), 
		Some("'hotdata'"), Some("'hotindex'"), Some("'id'"), Some("'__id'"), Some("'in'"), 
		Some("'in~'"), Some("'into'"), Some("'invoke'"), Some("'isfuzzy'"), Some("'__isFuzzy'"), 
		Some("'join'"), Some("'kind'"), Some("'ladderchart'"), Some("'last'"), 
		Some("'legend'"), Some("'let'"), Some("'like'"), Some("'likecs'"), Some("'limit'"), 
		Some("'linear'"), Some("'linechart'"), Some("'list'"), Some("'lookup'"), 
		Some("'log'"), Some("'macro-expand'"), Some("'make-graph'"), Some("'make-series'"), 
		Some("'map'"), Some("'matches regex'"), Some("'materialize'"), Some("'materialized-view-combine'"), 
		Some("'mv-apply'"), Some("'mv-expand'"), Some("'mvapply'"), Some("'mvexpand'"), 
		Some("'nodes'"), Some("'none'"), Some("'nooptimization'"), Some("'!between'"), 
		Some("'!contains'"), Some("'!contains_cs'"), Some("'!endswith_cs'"), Some("'!endswith'"), 
		Some("'!has'"), Some("'!has_cs'"), Some("'!hasprefix'"), Some("'!hasprefix_cs'"), 
		Some("'!hassuffix'"), Some("'!hassuffix_cs'"), Some("'!in'"), Some("'!in~'"), 
		Some("'!startswith'"), Some("'!startswith_cs'"), Some("'notcontains'"), 
		Some("'notcontainscs'"), Some("'notlike'"), Some("'notlikecs'"), Some("'null'"), 
		Some("'nulls'"), Some("'of'"), Some("'on'"), Some("'optional'"), Some("'or'"), 
		Some("'order'"), Some("'others'"), Some("'output'"), Some("'pack'"), Some("'panels'"), 
		Some("'parse'"), Some("'parse-kv'"), Some("'parse-where'"), Some("'partition'"), 
		Some("'__partitionby'"), Some("'partitioned-by'"), Some("'pattern'"), 
		Some("'__packedColumn'"), Some("'piechart'"), Some("'pivotchart'"), Some("'plugin'"), 
		Some("'print'"), Some("'project'"), Some("'project-away'"), Some("'__projectAway'"), 
		Some("'project-keep'"), Some("'project-rename'"), Some("'project-reorder'"), 
		Some("'project-smart'"), Some("'query_parameters'"), Some("'range'"), 
		Some("'reduce'"), Some("'regex'"), Some("'relaxed'"), Some("'render'"), 
		Some("'replace'"), Some("'restrict'"), Some("'sample'"), Some("'sample-distinct'"), 
		Some("'scan'"), Some("'scatterchart'"), Some("'search'"), Some("'serialize'"), 
		Some("'series'"), Some("'set'"), Some("'simple'"), Some("'sort'"), Some("'__sourceColumnIndex'"), 
		Some("'stacked'"), Some("'stacked100'"), Some("'stackedareachart'"), Some("'startswith'"), 
		Some("'startswith_cs'"), Some("'step'"), Some("'summarize'"), Some("'table'"), 
		Some("'take'"), Some("'threshold'"), Some("'timechart'"), Some("'timeline'"), 
		Some("'timepivot'"), Some("'title'"), Some("'to'"), Some("'top'"), Some("'top-hitters'"), 
		Some("'top-nested'"), Some("'toscalar'"), Some("'totable'"), Some("'treemap'"), 
		Some("'typeof'"), Some("'union'"), Some("'unstacked'"), Some("'uuid'"), 
		Some("'view'"), Some("'visible'"), Some("'where'"), Some("'with'"), Some("'__noWithSource'"), 
		Some("'withsource'"), Some("'with_itemindex'"), Some("'with_match_id'"), 
		Some("'with_node_id'"), Some("'with_source'"), Some("'with_step_name'"), 
		Some("'xaxis'"), Some("'xcolumn'"), Some("'xmax'"), Some("'xmin'"), Some("'xtitle'"), 
		Some("'yaxis'"), Some("'ycolumns'"), Some("'ymax'"), Some("'ymin'"), Some("'ysplit'"), 
		Some("'ytitle'"), Some("'bool'"), Some("'boolean'"), Some("'date'"), Some("'datetime'"), 
		Some("'decimal'"), Some("'double'"), Some("'dynamic'"), Some("'float'"), 
		Some("'guid'"), Some("'int'"), Some("'int8'"), Some("'int16'"), Some("'int32'"), 
		Some("'int64'"), Some("'long'"), Some("'string'"), Some("'real'"), Some("'time'"), 
		Some("'timespan'"), Some("'uint'"), Some("'uint8'"), Some("'uint16'"), 
		Some("'uint32'"), Some("'uint64'"), Some("'ulong'"), Some("'uniqueid'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;319]  = [
		None, Some("ASTERISK"), Some("ATSIGN"), Some("BAR"), Some("CLOSEBRACE"), 
		Some("CLOSEBRACKET"), Some("CLOSEBRACKET_DASH"), Some("CLOSEBRACKET_DASH_GREATERTHAN"), 
		Some("CLOSEPAREN"), Some("COMMA"), Some("COLON"), Some("DASH"), Some("DASHDASH"), 
		Some("DASHDASH_GREATERTHAN"), Some("DASH_OPENBRACKET"), Some("DOT"), Some("DOTDOT"), 
		Some("EQUAL"), Some("EQUALEQUAL"), Some("EQUALTILDE"), Some("EXCLAIMATIONPOINT_EQUAL"), 
		Some("EXCLAIMATIONPOINT_TILDE"), Some("GREATERTHAN"), Some("GREATERTHAN_EQUAL"), 
		Some("LESSTHAN"), Some("LESSTHAN_DASHDASH"), Some("LESSTHAN_DASH_OPENBRACKET"), 
		Some("LESSTHAN_EQUAL"), Some("LESSTHAN_GREATERTHAN"), Some("OPENBRACE"), 
		Some("OPENBRACKET"), Some("OPENPAREN"), Some("PERCENTSIGN"), Some("PLUS"), 
		Some("SEMICOLON"), Some("SLASH"), Some("EQUAL_GREATERTHAN"), Some("CHART3D_"), 
		Some("ACCESS"), Some("ACCUMULATE"), Some("AGGREGATIONS"), Some("ALIAS"), 
		Some("ALL"), Some("AND"), Some("ANOMALYCHART"), Some("ANOMALYCOLUMNS"), 
		Some("AREACHART"), Some("AS"), Some("ASC"), Some("ASSERTSCHEMA"), Some("AXES"), 
		Some("BAGEXPANSION"), Some("BARCHART"), Some("BASE"), Some("BETWEEN"), 
		Some("BIN"), Some("BIN_LEGACY"), Some("BY"), Some("CARD"), Some("CLUSTER"), 
		Some("COLUMNCHART"), Some("CONSUME"), Some("CONTAINS"), Some("CONTAINSCS"), 
		Some("CONTAINS_CS"), Some("CONTEXTUAL_DATATABLE"), Some("COUNT"), Some("CROSSCLUSTER__"), 
		Some("CROSSDB__"), Some("DATABASE"), Some("DATASCOPE"), Some("DATATABLE"), 
		Some("DECLARE"), Some("DECODEBLOCKS"), Some("DEFAULT"), Some("DELTA"), 
		Some("DESC"), Some("DISTINCT"), Some("EDGES"), Some("ENDSWITH"), Some("ENDSWITH_CS"), 
		Some("ENTITYGROUP"), Some("EVALUATE"), Some("EXECUTE"), Some("EXECUTE_AND_CACHE"), 
		Some("EXPANDOUTPUT"), Some("EXTEND"), Some("EXTERNALDATA"), Some("EXTERNAL_DATA"), 
		Some("FACET"), Some("FILTER"), Some("FIND"), Some("FIRST"), Some("FLAGS"), 
		Some("FORK"), Some("FROM"), Some("GETSCHEMA"), Some("GRANNYASC"), Some("GRANNYDESC"), 
		Some("GRAPHMARKCOMPONENTS"), Some("GRAPHMATCH"), Some("GRAPHMERGE"), Some("GRAPHSHORTESTPATHS"), 
		Some("GRAPHTOTABLE"), Some("HAS"), Some("HAS_ALL"), Some("HAS_ANY"), Some("HAS_CS"), 
		Some("HASPREFIX"), Some("HASPREFIX_CS"), Some("HASSUFFIX"), Some("HASSUFFIX_CS"), 
		Some("HIDDEN_"), Some("HINT_CONCURRENCY"), Some("HINT_DISTRIBUTION"), 
		Some("HINT_MATERIALIZED"), Some("HINT_NUM_PARTITIONS"), Some("HINT_PASS_FILTERS"), 
		Some("HINT_PASS_FILTERS_COLUMN"), Some("HINT_PROGRESSIVE_TOP"), Some("HINT_REMOTE"), 
		Some("HINT_SUFFLEKEY"), Some("HINT_SPREAD"), Some("HINT_STRATEGY"), Some("HOT"), 
		Some("HOTCACHE"), Some("HOTDATA"), Some("HOTINDEX"), Some("ID"), Some("ID__"), 
		Some("IN"), Some("IN_CI"), Some("INTO"), Some("INVOKE"), Some("ISFUZZY"), 
		Some("ISFUZZY__"), Some("JOIN"), Some("KIND"), Some("LADDERCHART"), Some("LAST"), 
		Some("LEGEND"), Some("LET"), Some("LIKE"), Some("LIKECS"), Some("LIMIT"), 
		Some("LINEAR"), Some("LINECHART"), Some("LIST"), Some("LOOKUP"), Some("LOG"), 
		Some("MACROEXPAND"), Some("MAKEGRAPH"), Some("MAKESERIES"), Some("MAP"), 
		Some("MATCHES_REGEX"), Some("MATERIALIZE"), Some("MATERIALIZED_VIEW_COMBINE"), 
		Some("MV_APPLY"), Some("MV_EXPAND"), Some("MVAPPLY"), Some("MVEXPAND"), 
		Some("NODES"), Some("NONE"), Some("NOOPTIMIZATION"), Some("NOT_BETWEEN"), 
		Some("NOT_CONTAINS"), Some("NOT_CONTAINS_CS"), Some("NOT_ENDSWITH_CS"), 
		Some("NOT_ENDSWITH"), Some("NOT_HAS"), Some("NOT_HAS_CS"), Some("NOT_HASPREFIX"), 
		Some("NOT_HASPREFIX_CS"), Some("NOT_HASSUFFIX"), Some("NOT_HASSUFFIX_CS"), 
		Some("NOT_IN"), Some("NOT_IN_CI"), Some("NOT_STARTSWITH"), Some("NOT_STARTSWITH_CS"), 
		Some("NOTCONTAINS"), Some("NOTCONTAINSCS"), Some("NOTLIKE"), Some("NOTLIKECS"), 
		Some("NULL"), Some("NULLS"), Some("OF"), Some("ON"), Some("OPTIONAL"), 
		Some("OR"), Some("ORDER"), Some("OTHERS"), Some("OUTPUT"), Some("PACK"), 
		Some("PANELS"), Some("PARSE"), Some("PARSEKV"), Some("PARSEWHERE"), Some("PARTITION"), 
		Some("PARTITIONBY"), Some("PARTITIONEDBY"), Some("PATTERN"), Some("PACKEDCOLUMN__"), 
		Some("PIECHART"), Some("PIVOTCHART"), Some("PLUGIN"), Some("PRINT"), Some("PROJECT"), 
		Some("PROJECTAWAY"), Some("PROJECTAWAY_"), Some("PROJECTKEEP"), Some("PROJECTRENAME"), 
		Some("PROJECTREORDER"), Some("PROJECTSMART"), Some("QUERYPARAMETERS"), 
		Some("RANGE"), Some("REDUCE"), Some("REGEX"), Some("RELAXED"), Some("RENDER"), 
		Some("REPLACE"), Some("RESTRICT"), Some("SAMPLE"), Some("SAMPLE_DISTINCT"), 
		Some("SCAN"), Some("SCATTERCHART"), Some("SEARCH"), Some("SERIALIZE"), 
		Some("SERIES"), Some("SET"), Some("SIMPLE"), Some("SORT"), Some("SOURCECOLUMNINDEX__"), 
		Some("STACKED"), Some("STACKED100"), Some("STACKEDAREACHART"), Some("STARTSWITH"), 
		Some("STARTSWITH_CS"), Some("STEP"), Some("SUMMARIZE"), Some("TABLE"), 
		Some("TAKE"), Some("THRESHOLD"), Some("TIMECHART"), Some("TIMELINE"), 
		Some("TIMEPIVOT"), Some("TITLE"), Some("TO"), Some("TOP"), Some("TOP_HITTERS"), 
		Some("TOP_NESTED"), Some("TOSCALAR"), Some("TOTABLE"), Some("TREEMAP"), 
		Some("TYPEOF"), Some("UNION"), Some("UNSTACKED"), Some("UUID"), Some("VIEW"), 
		Some("VISIBLE"), Some("WHERE"), Some("WITH"), Some("WITHNOSOURCE__"), 
		Some("WITHSOURCE"), Some("WITH_ITEM_INDEX"), Some("WITH_MATCH_ID"), Some("WITH_NODE_ID"), 
		Some("WITH_SOURCE"), Some("WITH_STEP_NAME"), Some("XAXIS"), Some("XCOLUMN"), 
		Some("XMAX"), Some("XMIN"), Some("XTITLE"), Some("YAXIS"), Some("YCOLUMNS"), 
		Some("YMAX"), Some("YMIN"), Some("YSPLIT"), Some("YTITLE"), Some("BOOL"), 
		Some("BOOLEAN"), Some("DATE"), Some("DATETIME"), Some("DECIMAL"), Some("DOUBLE"), 
		Some("DYNAMIC"), Some("FLOAT"), Some("GUID"), Some("INT"), Some("INT8"), 
		Some("INT16"), Some("INT32"), Some("INT64"), Some("LONG"), Some("STRING"), 
		Some("REAL"), Some("TIME"), Some("TIMESPAN"), Some("UINT"), Some("UINT8"), 
		Some("UINT16"), Some("UINT32"), Some("UINT64"), Some("ULONG"), Some("UNIQUEID"), 
		Some("LONGLITERAL"), Some("INTLITERAL"), Some("REALLITERAL"), Some("DECIMALLITERAL"), 
		Some("STRINGLITERAL"), Some("BOOLEANLITERAL"), Some("DATETIMELITERAL"), 
		Some("TIMESPANLITERAL"), Some("TYPELITERAL"), Some("RAWGUIDLITERAL"), 
		Some("GUIDLITERAL"), Some("IDENTIFIER"), Some("WHITESPACE"), Some("COMMENT")
	];
	lazy_static!{
	    static ref _shared_context_cache: Arc<PredictionContextCache> = Arc::new(PredictionContextCache::new());
		static ref VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,HqlParserExt<'input>, I, HqlParserContextType , dyn HqlListener<'input> + 'input >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;
pub type LocalTokenFactory<'input> = CommonTokenFactory;

pub type HqlTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, HqlParserContextType , dyn HqlListener<'input> + 'a>;

/// Parser for Hql grammar
pub struct HqlParser<'input,I,H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	base:BaseParserType<'input,I>,
	interpreter:Arc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: H,
}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn get_serialized_atn() -> &'static str { _serializedATN }

    pub fn set_error_strategy(&mut self, strategy: H) {
        self.err_handler = strategy
    }

    pub fn with_strategy(input: I, strategy: H) -> Self {
		antlr_rust::recognizer::check_version("0","3");
		let interpreter = Arc::new(ParserATNSimulator::new(
			_ATN.clone(),
			_decision_to_DFA.clone(),
			_shared_context_cache.clone(),
		));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Arc::clone(&interpreter),
				HqlParserExt{
					_pd: Default::default(),
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: strategy,
        }
    }

}

type DynStrategy<'input,I> = Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>;

impl<'input, I> HqlParser<'input, I, DynStrategy<'input,I>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn with_dyn_strategy(input: I) -> Self{
    	Self::with_strategy(input,Box::new(DefaultErrorStrategy::new()))
    }
}

impl<'input, I> HqlParser<'input, I, DefaultErrorStrategy<'input,HqlParserContextType>>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
{
    pub fn new(input: I) -> Self{
    	Self::with_strategy(input,DefaultErrorStrategy::new())
    }
}

/// Trait for monomorphized trait object that corresponds to the nodes of parse tree generated for HqlParser
pub trait HqlParserContext<'input>:
	for<'x> Listenable<dyn HqlListener<'input> + 'x > + 
	for<'x> Visitable<dyn HqlVisitor<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=HqlParserContextType>
{}

antlr_rust::coerce_from!{ 'input : HqlParserContext<'input> }

impl<'input, 'x, T> VisitableDyn<T> for dyn HqlParserContext<'input> + 'input
where
    T: HqlVisitor<'input> + 'x,
{
    fn accept_dyn(&self, visitor: &mut T) {
        self.accept(visitor as &mut (dyn HqlVisitor<'input> + 'x))
    }
}

impl<'input> HqlParserContext<'input> for TerminalNode<'input,HqlParserContextType> {}
impl<'input> HqlParserContext<'input> for ErrorNode<'input,HqlParserContextType> {}

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn HqlParserContext<'input> + 'input }

antlr_rust::tid! { impl<'input> TidAble<'input> for dyn HqlListener<'input> + 'input }

pub struct HqlParserContextType;
antlr_rust::tid!{HqlParserContextType}

impl<'input> ParserNodeType<'input> for HqlParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn HqlParserContext<'input> + 'input;
}

impl<'input, I, H> Deref for HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input, I, H> DerefMut for HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct HqlParserExt<'input>{
	_pd: PhantomData<&'input str>,
}

impl<'input> HqlParserExt<'input>{
}
antlr_rust::tid! { HqlParserExt<'a> }

impl<'input> TokenAware<'input> for HqlParserExt<'input>{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> ParserRecog<'input, BaseParserType<'input,I>> for HqlParserExt<'input>{}

impl<'input,I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>> Actions<'input, BaseParserType<'input,I>> for HqlParserExt<'input>{
	fn get_grammar_file_name(&self) -> & str{ "Hql.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { &**VOCABULARY }
}
//------------------- top ----------------
pub type TopContextAll<'input> = TopContext<'input>;


pub type TopContext<'input> = BaseParserRuleContext<'input,TopContextExt<'input>>;

#[derive(Clone)]
pub struct TopContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_top(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_top(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_top(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_top }
	//fn type_rule_index() -> usize where Self: Sized { RULE_top }
}
antlr_rust::tid!{TopContextExt<'a>}

impl<'input> TopContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TopContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopContextExt<'input>>{

fn query(&self) -> Option<Rc<QueryContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TopContextAttrs<'input> for TopContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn top(&mut self,)
	-> Result<Rc<TopContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_top);
        let mut _localctx: Rc<TopContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule query*/
			recog.base.set_state(610);
			recog.query()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- query ----------------
pub type QueryContextAll<'input> = QueryContext<'input>;


pub type QueryContext<'input> = BaseParserRuleContext<'input,QueryContextExt<'input>>;

#[derive(Clone)]
pub struct QueryContextExt<'input>{
	pub statement: Option<Rc<StatementContextAll<'input>>>,
	pub Statements:Vec<Rc<StatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for QueryContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for QueryContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_query(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_query(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for QueryContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_query(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_query }
	//fn type_rule_index() -> usize where Self: Sized { RULE_query }
}
antlr_rust::tid!{QueryContextExt<'a>}

impl<'input> QueryContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryContextExt{
				statement: None, 
				Statements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<QueryContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EOF
/// Returns `None` if there is no child corresponding to token EOF
fn EOF(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EOF, 0)
}
fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMICOLON in current rule
fn SEMICOLON_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMICOLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMICOLON is less or equal than `i`.
fn SEMICOLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, i)
}

}

impl<'input> QueryContextAttrs<'input> for QueryContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn query(&mut self,)
	-> Result<Rc<QueryContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 2, RULE_query);
        let mut _localctx: Rc<QueryContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule statement*/
			recog.base.set_state(612);
			let tmp = recog.statement()?;
			 cast_mut::<_,QueryContext >(&mut _localctx).statement = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,QueryContext >(&mut _localctx).statement.clone().unwrap()
			 ;
			 cast_mut::<_,QueryContext >(&mut _localctx).Statements.push(temp);
			  
			recog.base.set_state(617);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(0,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(613);
					recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

					/*InvokeRule statement*/
					recog.base.set_state(614);
					let tmp = recog.statement()?;
					 cast_mut::<_,QueryContext >(&mut _localctx).statement = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,QueryContext >(&mut _localctx).statement.clone().unwrap()
					 ;
					 cast_mut::<_,QueryContext >(&mut _localctx).Statements.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(619);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(0,&mut recog.base)?;
			}
			recog.base.set_state(621);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMICOLON {
				{
				recog.base.set_state(620);
				recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(623);
			recog.base.match_token(EOF,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- statement ----------------
pub type StatementContextAll<'input> = StatementContext<'input>;


pub type StatementContext<'input> = BaseParserRuleContext<'input,StatementContextExt<'input>>;

#[derive(Clone)]
pub struct StatementContextExt<'input>{
	pub AliasDatabase: Option<Rc<AliasDatabaseStatementContextAll<'input>>>,
	pub DeclarePattern: Option<Rc<DeclarePatternStatementContextAll<'input>>>,
	pub DeclareQueryParameters: Option<Rc<DeclareQueryParametersStatementContextAll<'input>>>,
	pub Let: Option<Rc<LetStatementContextAll<'input>>>,
	pub Query: Option<Rc<QueryStatementContextAll<'input>>>,
	pub RestrictAccess: Option<Rc<RestrictAccessStatementContextAll<'input>>>,
	pub Set: Option<Rc<SetStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_statement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_statement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_statement(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_statement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_statement }
}
antlr_rust::tid!{StatementContextExt<'a>}

impl<'input> StatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatementContextExt{
				AliasDatabase: None, DeclarePattern: None, DeclareQueryParameters: None, Let: None, Query: None, RestrictAccess: None, Set: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait StatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StatementContextExt<'input>>{

fn aliasDatabaseStatement(&self) -> Option<Rc<AliasDatabaseStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declarePatternStatement(&self) -> Option<Rc<DeclarePatternStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declareQueryParametersStatement(&self) -> Option<Rc<DeclareQueryParametersStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letStatement(&self) -> Option<Rc<LetStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn queryStatement(&self) -> Option<Rc<QueryStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn restrictAccessStatement(&self) -> Option<Rc<RestrictAccessStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn setStatement(&self) -> Option<Rc<SetStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StatementContextAttrs<'input> for StatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn statement(&mut self,)
	-> Result<Rc<StatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 4, RULE_statement);
        let mut _localctx: Rc<StatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(632);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(2,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule aliasDatabaseStatement*/
					recog.base.set_state(625);
					let tmp = recog.aliasDatabaseStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).AliasDatabase = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule declarePatternStatement*/
					recog.base.set_state(626);
					let tmp = recog.declarePatternStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).DeclarePattern = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule declareQueryParametersStatement*/
					recog.base.set_state(627);
					let tmp = recog.declareQueryParametersStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).DeclareQueryParameters = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule letStatement*/
					recog.base.set_state(628);
					let tmp = recog.letStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).Let = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule queryStatement*/
					recog.base.set_state(629);
					let tmp = recog.queryStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).Query = Some(tmp.clone());
					  

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule restrictAccessStatement*/
					recog.base.set_state(630);
					let tmp = recog.restrictAccessStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).RestrictAccess = Some(tmp.clone());
					  

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule setStatement*/
					recog.base.set_state(631);
					let tmp = recog.setStatement()?;
					 cast_mut::<_,StatementContext >(&mut _localctx).Set = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- aliasDatabaseStatement ----------------
pub type AliasDatabaseStatementContextAll<'input> = AliasDatabaseStatementContext<'input>;


pub type AliasDatabaseStatementContext<'input> = BaseParserRuleContext<'input,AliasDatabaseStatementContextExt<'input>>;

#[derive(Clone)]
pub struct AliasDatabaseStatementContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AliasDatabaseStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AliasDatabaseStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_aliasDatabaseStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_aliasDatabaseStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AliasDatabaseStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_aliasDatabaseStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for AliasDatabaseStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_aliasDatabaseStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_aliasDatabaseStatement }
}
antlr_rust::tid!{AliasDatabaseStatementContextExt<'a>}

impl<'input> AliasDatabaseStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AliasDatabaseStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AliasDatabaseStatementContextExt{
				Name: None, Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AliasDatabaseStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AliasDatabaseStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ALIAS
/// Returns `None` if there is no child corresponding to token ALIAS
fn ALIAS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ALIAS, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AliasDatabaseStatementContextAttrs<'input> for AliasDatabaseStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn aliasDatabaseStatement(&mut self,)
	-> Result<Rc<AliasDatabaseStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AliasDatabaseStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 6, RULE_aliasDatabaseStatement);
        let mut _localctx: Rc<AliasDatabaseStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(634);
			recog.base.match_token(ALIAS,&mut recog.err_handler)?;

			recog.base.set_state(635);
			recog.base.match_token(DATABASE,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(636);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,AliasDatabaseStatementContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(637);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(638);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,AliasDatabaseStatementContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letStatement ----------------
pub type LetStatementContextAll<'input> = LetStatementContext<'input>;


pub type LetStatementContext<'input> = BaseParserRuleContext<'input,LetStatementContextExt<'input>>;

#[derive(Clone)]
pub struct LetStatementContextExt<'input>{
	pub Function: Option<Rc<LetFunctionDeclarationContextAll<'input>>>,
	pub View: Option<Rc<LetViewDeclarationContextAll<'input>>>,
	pub Variable: Option<Rc<LetVariableDeclarationContextAll<'input>>>,
	pub Materialized: Option<Rc<LetMaterializeDeclarationContextAll<'input>>>,
	pub EntityGroup: Option<Rc<LetEntityGroupDeclarationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letStatement }
}
antlr_rust::tid!{LetStatementContextExt<'a>}

impl<'input> LetStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetStatementContextExt{
				Function: None, View: None, Variable: None, Materialized: None, EntityGroup: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetStatementContextExt<'input>>{

fn letFunctionDeclaration(&self) -> Option<Rc<LetFunctionDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letViewDeclaration(&self) -> Option<Rc<LetViewDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letVariableDeclaration(&self) -> Option<Rc<LetVariableDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letMaterializeDeclaration(&self) -> Option<Rc<LetMaterializeDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letEntityGroupDeclaration(&self) -> Option<Rc<LetEntityGroupDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetStatementContextAttrs<'input> for LetStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letStatement(&mut self,)
	-> Result<Rc<LetStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 8, RULE_letStatement);
        let mut _localctx: Rc<LetStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(645);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(3,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule letFunctionDeclaration*/
					recog.base.set_state(640);
					let tmp = recog.letFunctionDeclaration()?;
					 cast_mut::<_,LetStatementContext >(&mut _localctx).Function = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule letViewDeclaration*/
					recog.base.set_state(641);
					let tmp = recog.letViewDeclaration()?;
					 cast_mut::<_,LetStatementContext >(&mut _localctx).View = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule letVariableDeclaration*/
					recog.base.set_state(642);
					let tmp = recog.letVariableDeclaration()?;
					 cast_mut::<_,LetStatementContext >(&mut _localctx).Variable = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule letMaterializeDeclaration*/
					recog.base.set_state(643);
					let tmp = recog.letMaterializeDeclaration()?;
					 cast_mut::<_,LetStatementContext >(&mut _localctx).Materialized = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule letEntityGroupDeclaration*/
					recog.base.set_state(644);
					let tmp = recog.letEntityGroupDeclaration()?;
					 cast_mut::<_,LetStatementContext >(&mut _localctx).EntityGroup = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letVariableDeclaration ----------------
pub type LetVariableDeclarationContextAll<'input> = LetVariableDeclarationContext<'input>;


pub type LetVariableDeclarationContext<'input> = BaseParserRuleContext<'input,LetVariableDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct LetVariableDeclarationContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetVariableDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetVariableDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letVariableDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letVariableDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetVariableDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letVariableDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetVariableDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letVariableDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letVariableDeclaration }
}
antlr_rust::tid!{LetVariableDeclarationContextExt<'a>}

impl<'input> LetVariableDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetVariableDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetVariableDeclarationContextExt{
				Name: None, Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetVariableDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetVariableDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LET
/// Returns `None` if there is no child corresponding to token LET
fn LET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LET, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetVariableDeclarationContextAttrs<'input> for LetVariableDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letVariableDeclaration(&mut self,)
	-> Result<Rc<LetVariableDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetVariableDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 10, RULE_letVariableDeclaration);
        let mut _localctx: Rc<LetVariableDeclarationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(647);
			recog.base.match_token(LET,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(648);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,LetVariableDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(649);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(650);
			let tmp = recog.expression()?;
			 cast_mut::<_,LetVariableDeclarationContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letFunctionDeclaration ----------------
pub type LetFunctionDeclarationContextAll<'input> = LetFunctionDeclarationContext<'input>;


pub type LetFunctionDeclarationContext<'input> = BaseParserRuleContext<'input,LetFunctionDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct LetFunctionDeclarationContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub ParameterList: Option<Rc<LetFunctionParameterListContextAll<'input>>>,
	pub Body: Option<Rc<LetFunctionBodyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetFunctionDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetFunctionDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letFunctionDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letFunctionDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetFunctionDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letFunctionDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetFunctionDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letFunctionDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letFunctionDeclaration }
}
antlr_rust::tid!{LetFunctionDeclarationContextExt<'a>}

impl<'input> LetFunctionDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetFunctionDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetFunctionDeclarationContextExt{
				Name: None, ParameterList: None, Body: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetFunctionDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetFunctionDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LET
/// Returns `None` if there is no child corresponding to token LET
fn LET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LET, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letFunctionBody(&self) -> Option<Rc<LetFunctionBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letFunctionParameterList(&self) -> Option<Rc<LetFunctionParameterListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetFunctionDeclarationContextAttrs<'input> for LetFunctionDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letFunctionDeclaration(&mut self,)
	-> Result<Rc<LetFunctionDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetFunctionDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 12, RULE_letFunctionDeclaration);
        let mut _localctx: Rc<LetFunctionDeclarationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(652);
			recog.base.match_token(LET,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(653);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,LetFunctionDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(654);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(655);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(657);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (ACCUMULATE - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AS - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (BY - 30)) | (1usize << (CLUSTER - 30)) | (1usize << (CONSUME - 30)))) != 0) || ((((_la - 62)) & !0x3f) == 0 && ((1usize << (_la - 62)) & ((1usize << (CONTAINS - 62)) | (1usize << (COUNT - 62)) | (1usize << (DATABASE - 62)) | (1usize << (DATATABLE - 62)) | (1usize << (DECLARE - 62)) | (1usize << (DEFAULT - 62)) | (1usize << (DELTA - 62)) | (1usize << (DISTINCT - 62)) | (1usize << (EDGES - 62)) | (1usize << (EVALUATE - 62)) | (1usize << (EXECUTE - 62)) | (1usize << (EXTEND - 62)) | (1usize << (EXTERNALDATA - 62)) | (1usize << (FACET - 62)) | (1usize << (FILTER - 62)) | (1usize << (FIND - 62)))) != 0) || ((((_la - 94)) & !0x3f) == 0 && ((1usize << (_la - 94)) & ((1usize << (FORK - 94)) | (1usize << (FROM - 94)) | (1usize << (HAS - 94)) | (1usize << (HIDDEN_ - 94)) | (1usize << (HOT - 94)))) != 0) || ((((_la - 126)) & !0x3f) == 0 && ((1usize << (_la - 126)) & ((1usize << (HOTDATA - 126)) | (1usize << (HOTINDEX - 126)) | (1usize << (ID - 126)) | (1usize << (IN - 126)) | (1usize << (INTO - 126)) | (1usize << (INVOKE - 126)) | (1usize << (LEGEND - 126)) | (1usize << (LET - 126)) | (1usize << (LIMIT - 126)) | (1usize << (LINEAR - 126)) | (1usize << (LIST - 126)) | (1usize << (LOOKUP - 126)) | (1usize << (LOG - 126)) | (1usize << (MAP - 126)) | (1usize << (MATERIALIZE - 126)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (NODES - 161)) | (1usize << (NONE - 161)) | (1usize << (NULL - 161)) | (1usize << (NULLS - 161)) | (1usize << (OF - 161)) | (1usize << (ON - 161)) | (1usize << (OPTIONAL - 161)) | (1usize << (OUTPUT - 161)) | (1usize << (PACK - 161)))) != 0) || ((((_la - 194)) & !0x3f) == 0 && ((1usize << (_la - 194)) & ((1usize << (PARSE - 194)) | (1usize << (PARTITION - 194)) | (1usize << (PARTITIONBY - 194)) | (1usize << (PATTERN - 194)) | (1usize << (PLUGIN - 194)) | (1usize << (PRINT - 194)) | (1usize << (QUERYPARAMETERS - 194)) | (1usize << (RANGE - 194)) | (1usize << (REDUCE - 194)) | (1usize << (RENDER - 194)) | (1usize << (REPLACE - 194)) | (1usize << (RESTRICT - 194)) | (1usize << (SAMPLE - 194)) | (1usize << (SAMPLE_DISTINCT - 194)) | (1usize << (SCAN - 194)) | (1usize << (SEARCH - 194)))) != 0) || ((((_la - 226)) & !0x3f) == 0 && ((1usize << (_la - 226)) & ((1usize << (SERIALIZE - 226)) | (1usize << (SERIES - 226)) | (1usize << (SET - 226)) | (1usize << (SORT - 226)) | (1usize << (STACKED - 226)) | (1usize << (STACKED100 - 226)) | (1usize << (STEP - 226)) | (1usize << (SUMMARIZE - 226)) | (1usize << (TAKE - 226)) | (1usize << (THRESHOLD - 226)) | (1usize << (TITLE - 226)) | (1usize << (TO - 226)) | (1usize << (TOP - 226)) | (1usize << (TOP_HITTERS - 226)) | (1usize << (TOP_NESTED - 226)) | (1usize << (TOSCALAR - 226)) | (1usize << (TOTABLE - 226)) | (1usize << (TYPEOF - 226)) | (1usize << (UNSTACKED - 226)) | (1usize << (UUID - 226)) | (1usize << (VIEW - 226)))) != 0) || ((((_la - 258)) & !0x3f) == 0 && ((1usize << (_la - 258)) & ((1usize << (VISIBLE - 258)) | (1usize << (WHERE - 258)) | (1usize << (WITH - 258)) | (1usize << (XAXIS - 258)) | (1usize << (XCOLUMN - 258)) | (1usize << (XMAX - 258)) | (1usize << (XMIN - 258)) | (1usize << (XTITLE - 258)) | (1usize << (YAXIS - 258)) | (1usize << (YCOLUMNS - 258)) | (1usize << (YMAX - 258)) | (1usize << (YMIN - 258)) | (1usize << (YSPLIT - 258)) | (1usize << (YTITLE - 258)) | (1usize << (BOOL - 258)) | (1usize << (GUID - 258)))) != 0) || _la==IDENTIFIER {
				{
				/*InvokeRule letFunctionParameterList*/
				recog.base.set_state(656);
				let tmp = recog.letFunctionParameterList()?;
				 cast_mut::<_,LetFunctionDeclarationContext >(&mut _localctx).ParameterList = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(659);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			/*InvokeRule letFunctionBody*/
			recog.base.set_state(660);
			let tmp = recog.letFunctionBody()?;
			 cast_mut::<_,LetFunctionDeclarationContext >(&mut _localctx).Body = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letViewDeclaration ----------------
pub type LetViewDeclarationContextAll<'input> = LetViewDeclarationContext<'input>;


pub type LetViewDeclarationContext<'input> = BaseParserRuleContext<'input,LetViewDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct LetViewDeclarationContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub ParameterList: Option<Rc<LetViewParameterListContextAll<'input>>>,
	pub Body: Option<Rc<LetFunctionBodyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetViewDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetViewDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letViewDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letViewDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetViewDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letViewDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetViewDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letViewDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letViewDeclaration }
}
antlr_rust::tid!{LetViewDeclarationContextExt<'a>}

impl<'input> LetViewDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetViewDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetViewDeclarationContextExt{
				Name: None, ParameterList: None, Body: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetViewDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetViewDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LET
/// Returns `None` if there is no child corresponding to token LET
fn LET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LET, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letFunctionBody(&self) -> Option<Rc<LetFunctionBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn letViewParameterList(&self) -> Option<Rc<LetViewParameterListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetViewDeclarationContextAttrs<'input> for LetViewDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letViewDeclaration(&mut self,)
	-> Result<Rc<LetViewDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetViewDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 14, RULE_letViewDeclaration);
        let mut _localctx: Rc<LetViewDeclarationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(662);
			recog.base.match_token(LET,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(663);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,LetViewDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(664);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(665);
			recog.base.match_token(VIEW,&mut recog.err_handler)?;

			recog.base.set_state(666);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(668);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (ACCUMULATE - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AS - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (BY - 30)) | (1usize << (CLUSTER - 30)) | (1usize << (CONSUME - 30)))) != 0) || ((((_la - 62)) & !0x3f) == 0 && ((1usize << (_la - 62)) & ((1usize << (CONTAINS - 62)) | (1usize << (COUNT - 62)) | (1usize << (DATABASE - 62)) | (1usize << (DATATABLE - 62)) | (1usize << (DECLARE - 62)) | (1usize << (DEFAULT - 62)) | (1usize << (DELTA - 62)) | (1usize << (DISTINCT - 62)) | (1usize << (EDGES - 62)) | (1usize << (EVALUATE - 62)) | (1usize << (EXECUTE - 62)) | (1usize << (EXTEND - 62)) | (1usize << (EXTERNALDATA - 62)) | (1usize << (FACET - 62)) | (1usize << (FILTER - 62)) | (1usize << (FIND - 62)))) != 0) || ((((_la - 94)) & !0x3f) == 0 && ((1usize << (_la - 94)) & ((1usize << (FORK - 94)) | (1usize << (FROM - 94)) | (1usize << (HAS - 94)) | (1usize << (HIDDEN_ - 94)) | (1usize << (HOT - 94)))) != 0) || ((((_la - 126)) & !0x3f) == 0 && ((1usize << (_la - 126)) & ((1usize << (HOTDATA - 126)) | (1usize << (HOTINDEX - 126)) | (1usize << (ID - 126)) | (1usize << (IN - 126)) | (1usize << (INTO - 126)) | (1usize << (INVOKE - 126)) | (1usize << (LEGEND - 126)) | (1usize << (LET - 126)) | (1usize << (LIMIT - 126)) | (1usize << (LINEAR - 126)) | (1usize << (LIST - 126)) | (1usize << (LOOKUP - 126)) | (1usize << (LOG - 126)) | (1usize << (MAP - 126)) | (1usize << (MATERIALIZE - 126)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (NODES - 161)) | (1usize << (NONE - 161)) | (1usize << (NULL - 161)) | (1usize << (NULLS - 161)) | (1usize << (OF - 161)) | (1usize << (ON - 161)) | (1usize << (OPTIONAL - 161)) | (1usize << (OUTPUT - 161)) | (1usize << (PACK - 161)))) != 0) || ((((_la - 194)) & !0x3f) == 0 && ((1usize << (_la - 194)) & ((1usize << (PARSE - 194)) | (1usize << (PARTITION - 194)) | (1usize << (PARTITIONBY - 194)) | (1usize << (PATTERN - 194)) | (1usize << (PLUGIN - 194)) | (1usize << (PRINT - 194)) | (1usize << (QUERYPARAMETERS - 194)) | (1usize << (RANGE - 194)) | (1usize << (REDUCE - 194)) | (1usize << (RENDER - 194)) | (1usize << (REPLACE - 194)) | (1usize << (RESTRICT - 194)) | (1usize << (SAMPLE - 194)) | (1usize << (SAMPLE_DISTINCT - 194)) | (1usize << (SCAN - 194)) | (1usize << (SEARCH - 194)))) != 0) || ((((_la - 226)) & !0x3f) == 0 && ((1usize << (_la - 226)) & ((1usize << (SERIALIZE - 226)) | (1usize << (SERIES - 226)) | (1usize << (SET - 226)) | (1usize << (SORT - 226)) | (1usize << (STACKED - 226)) | (1usize << (STACKED100 - 226)) | (1usize << (STEP - 226)) | (1usize << (SUMMARIZE - 226)) | (1usize << (TAKE - 226)) | (1usize << (THRESHOLD - 226)) | (1usize << (TITLE - 226)) | (1usize << (TO - 226)) | (1usize << (TOP - 226)) | (1usize << (TOP_HITTERS - 226)) | (1usize << (TOP_NESTED - 226)) | (1usize << (TOSCALAR - 226)) | (1usize << (TOTABLE - 226)) | (1usize << (TYPEOF - 226)) | (1usize << (UNSTACKED - 226)) | (1usize << (UUID - 226)) | (1usize << (VIEW - 226)))) != 0) || ((((_la - 258)) & !0x3f) == 0 && ((1usize << (_la - 258)) & ((1usize << (VISIBLE - 258)) | (1usize << (WHERE - 258)) | (1usize << (WITH - 258)) | (1usize << (XAXIS - 258)) | (1usize << (XCOLUMN - 258)) | (1usize << (XMAX - 258)) | (1usize << (XMIN - 258)) | (1usize << (XTITLE - 258)) | (1usize << (YAXIS - 258)) | (1usize << (YCOLUMNS - 258)) | (1usize << (YMAX - 258)) | (1usize << (YMIN - 258)) | (1usize << (YSPLIT - 258)) | (1usize << (YTITLE - 258)) | (1usize << (BOOL - 258)) | (1usize << (GUID - 258)))) != 0) || _la==IDENTIFIER {
				{
				/*InvokeRule letViewParameterList*/
				recog.base.set_state(667);
				let tmp = recog.letViewParameterList()?;
				 cast_mut::<_,LetViewDeclarationContext >(&mut _localctx).ParameterList = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(670);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			/*InvokeRule letFunctionBody*/
			recog.base.set_state(671);
			let tmp = recog.letFunctionBody()?;
			 cast_mut::<_,LetViewDeclarationContext >(&mut _localctx).Body = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letViewParameterList ----------------
pub type LetViewParameterListContextAll<'input> = LetViewParameterListContext<'input>;


pub type LetViewParameterListContext<'input> = BaseParserRuleContext<'input,LetViewParameterListContextExt<'input>>;

#[derive(Clone)]
pub struct LetViewParameterListContextExt<'input>{
	pub scalarParameter: Option<Rc<ScalarParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<ScalarParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetViewParameterListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetViewParameterListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letViewParameterList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letViewParameterList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetViewParameterListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letViewParameterList(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetViewParameterListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letViewParameterList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letViewParameterList }
}
antlr_rust::tid!{LetViewParameterListContextExt<'a>}

impl<'input> LetViewParameterListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetViewParameterListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetViewParameterListContextExt{
				scalarParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetViewParameterListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetViewParameterListContextExt<'input>>{

fn scalarParameter_all(&self) ->  Vec<Rc<ScalarParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn scalarParameter(&self, i: usize) -> Option<Rc<ScalarParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> LetViewParameterListContextAttrs<'input> for LetViewParameterListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letViewParameterList(&mut self,)
	-> Result<Rc<LetViewParameterListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetViewParameterListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 16, RULE_letViewParameterList);
        let mut _localctx: Rc<LetViewParameterListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule scalarParameter*/
			recog.base.set_state(673);
			let tmp = recog.scalarParameter()?;
			 cast_mut::<_,LetViewParameterListContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,LetViewParameterListContext >(&mut _localctx).scalarParameter.clone().unwrap()
			 ;
			 cast_mut::<_,LetViewParameterListContext >(&mut _localctx).Parameters.push(temp);
			  
			recog.base.set_state(678);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(674);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule scalarParameter*/
				recog.base.set_state(675);
				let tmp = recog.scalarParameter()?;
				 cast_mut::<_,LetViewParameterListContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,LetViewParameterListContext >(&mut _localctx).scalarParameter.clone().unwrap()
				 ;
				 cast_mut::<_,LetViewParameterListContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(680);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letMaterializeDeclaration ----------------
pub type LetMaterializeDeclarationContextAll<'input> = LetMaterializeDeclarationContext<'input>;


pub type LetMaterializeDeclarationContext<'input> = BaseParserRuleContext<'input,LetMaterializeDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct LetMaterializeDeclarationContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub Expression: Option<Rc<PipeExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetMaterializeDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetMaterializeDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letMaterializeDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letMaterializeDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetMaterializeDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letMaterializeDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetMaterializeDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letMaterializeDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letMaterializeDeclaration }
}
antlr_rust::tid!{LetMaterializeDeclarationContextExt<'a>}

impl<'input> LetMaterializeDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetMaterializeDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetMaterializeDeclarationContextExt{
				Name: None, Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetMaterializeDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetMaterializeDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LET
/// Returns `None` if there is no child corresponding to token LET
fn LET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LET, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZE
/// Returns `None` if there is no child corresponding to token MATERIALIZE
fn MATERIALIZE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pipeExpression(&self) -> Option<Rc<PipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetMaterializeDeclarationContextAttrs<'input> for LetMaterializeDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letMaterializeDeclaration(&mut self,)
	-> Result<Rc<LetMaterializeDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetMaterializeDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 18, RULE_letMaterializeDeclaration);
        let mut _localctx: Rc<LetMaterializeDeclarationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(681);
			recog.base.match_token(LET,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(682);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,LetMaterializeDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(683);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(684);
			recog.base.match_token(MATERIALIZE,&mut recog.err_handler)?;

			recog.base.set_state(685);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule pipeExpression*/
			recog.base.set_state(686);
			let tmp = recog.pipeExpression()?;
			 cast_mut::<_,LetMaterializeDeclarationContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(687);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letEntityGroupDeclaration ----------------
pub type LetEntityGroupDeclarationContextAll<'input> = LetEntityGroupDeclarationContext<'input>;


pub type LetEntityGroupDeclarationContext<'input> = BaseParserRuleContext<'input,LetEntityGroupDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct LetEntityGroupDeclarationContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetEntityGroupDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetEntityGroupDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letEntityGroupDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letEntityGroupDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetEntityGroupDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letEntityGroupDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetEntityGroupDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letEntityGroupDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letEntityGroupDeclaration }
}
antlr_rust::tid!{LetEntityGroupDeclarationContextExt<'a>}

impl<'input> LetEntityGroupDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetEntityGroupDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetEntityGroupDeclarationContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetEntityGroupDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetEntityGroupDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LET
/// Returns `None` if there is no child corresponding to token LET
fn LET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LET, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn entityGroupExpression(&self) -> Option<Rc<EntityGroupExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetEntityGroupDeclarationContextAttrs<'input> for LetEntityGroupDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letEntityGroupDeclaration(&mut self,)
	-> Result<Rc<LetEntityGroupDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetEntityGroupDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 20, RULE_letEntityGroupDeclaration);
        let mut _localctx: Rc<LetEntityGroupDeclarationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(689);
			recog.base.match_token(LET,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(690);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,LetEntityGroupDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(691);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule entityGroupExpression*/
			recog.base.set_state(692);
			recog.entityGroupExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letFunctionParameterList ----------------
pub type LetFunctionParameterListContextAll<'input> = LetFunctionParameterListContext<'input>;


pub type LetFunctionParameterListContext<'input> = BaseParserRuleContext<'input,LetFunctionParameterListContextExt<'input>>;

#[derive(Clone)]
pub struct LetFunctionParameterListContextExt<'input>{
	pub tabularParameter: Option<Rc<TabularParameterContextAll<'input>>>,
	pub TabularParameters:Vec<Rc<TabularParameterContextAll<'input>>>,
	pub scalarParameter: Option<Rc<ScalarParameterContextAll<'input>>>,
	pub ScalarParameters:Vec<Rc<ScalarParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetFunctionParameterListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetFunctionParameterListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letFunctionParameterList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letFunctionParameterList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetFunctionParameterListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letFunctionParameterList(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetFunctionParameterListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letFunctionParameterList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letFunctionParameterList }
}
antlr_rust::tid!{LetFunctionParameterListContextExt<'a>}

impl<'input> LetFunctionParameterListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetFunctionParameterListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetFunctionParameterListContextExt{
				tabularParameter: None, scalarParameter: None, 
				TabularParameters: Vec::new(), ScalarParameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetFunctionParameterListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetFunctionParameterListContextExt<'input>>{

fn tabularParameter_all(&self) ->  Vec<Rc<TabularParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tabularParameter(&self, i: usize) -> Option<Rc<TabularParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn scalarParameter_all(&self) ->  Vec<Rc<ScalarParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn scalarParameter(&self, i: usize) -> Option<Rc<ScalarParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> LetFunctionParameterListContextAttrs<'input> for LetFunctionParameterListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letFunctionParameterList(&mut self,)
	-> Result<Rc<LetFunctionParameterListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetFunctionParameterListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 22, RULE_letFunctionParameterList);
        let mut _localctx: Rc<LetFunctionParameterListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(705);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(7,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule tabularParameter*/
					recog.base.set_state(694);
					let tmp = recog.tabularParameter()?;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).tabularParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).tabularParameter.clone().unwrap()
					 ;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).TabularParameters.push(temp);
					  
					{
					recog.base.set_state(695);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule tabularParameter*/
					recog.base.set_state(696);
					let tmp = recog.tabularParameter()?;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).tabularParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).tabularParameter.clone().unwrap()
					 ;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).TabularParameters.push(temp);
					  
					}
					{
					recog.base.set_state(698);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule scalarParameter*/
					recog.base.set_state(699);
					let tmp = recog.scalarParameter()?;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).scalarParameter.clone().unwrap()
					 ;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).ScalarParameters.push(temp);
					  
					}
					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule scalarParameter*/
					recog.base.set_state(701);
					let tmp = recog.scalarParameter()?;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).scalarParameter.clone().unwrap()
					 ;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).ScalarParameters.push(temp);
					  
					{
					recog.base.set_state(702);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule scalarParameter*/
					recog.base.set_state(703);
					let tmp = recog.scalarParameter()?;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).scalarParameter.clone().unwrap()
					 ;
					 cast_mut::<_,LetFunctionParameterListContext >(&mut _localctx).ScalarParameters.push(temp);
					  
					}
					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scalarParameter ----------------
pub type ScalarParameterContextAll<'input> = ScalarParameterContext<'input>;


pub type ScalarParameterContext<'input> = BaseParserRuleContext<'input,ScalarParameterContextExt<'input>>;

#[derive(Clone)]
pub struct ScalarParameterContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub Type: Option<Rc<ScalarTypeContextAll<'input>>>,
	pub Default: Option<Rc<ScalarParameterDefaultContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScalarParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScalarParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scalarParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scalarParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScalarParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scalarParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScalarParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scalarParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scalarParameter }
}
antlr_rust::tid!{ScalarParameterContextExt<'a>}

impl<'input> ScalarParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScalarParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScalarParameterContextExt{
				Name: None, Type: None, Default: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScalarParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScalarParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarType(&self) -> Option<Rc<ScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarParameterDefault(&self) -> Option<Rc<ScalarParameterDefaultContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ScalarParameterContextAttrs<'input> for ScalarParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scalarParameter(&mut self,)
	-> Result<Rc<ScalarParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScalarParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 24, RULE_scalarParameter);
        let mut _localctx: Rc<ScalarParameterContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(707);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,ScalarParameterContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(708);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule scalarType*/
			recog.base.set_state(709);
			let tmp = recog.scalarType()?;
			 cast_mut::<_,ScalarParameterContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			recog.base.set_state(711);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EQUAL {
				{
				/*InvokeRule scalarParameterDefault*/
				recog.base.set_state(710);
				let tmp = recog.scalarParameterDefault()?;
				 cast_mut::<_,ScalarParameterContext >(&mut _localctx).Default = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scalarParameterDefault ----------------
pub type ScalarParameterDefaultContextAll<'input> = ScalarParameterDefaultContext<'input>;


pub type ScalarParameterDefaultContext<'input> = BaseParserRuleContext<'input,ScalarParameterDefaultContextExt<'input>>;

#[derive(Clone)]
pub struct ScalarParameterDefaultContextExt<'input>{
	pub Value: Option<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScalarParameterDefaultContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScalarParameterDefaultContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scalarParameterDefault(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scalarParameterDefault(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScalarParameterDefaultContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scalarParameterDefault(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScalarParameterDefaultContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scalarParameterDefault }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scalarParameterDefault }
}
antlr_rust::tid!{ScalarParameterDefaultContextExt<'a>}

impl<'input> ScalarParameterDefaultContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScalarParameterDefaultContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScalarParameterDefaultContextExt{
				Value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScalarParameterDefaultContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScalarParameterDefaultContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn literalExpression(&self) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ScalarParameterDefaultContextAttrs<'input> for ScalarParameterDefaultContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scalarParameterDefault(&mut self,)
	-> Result<Rc<ScalarParameterDefaultContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScalarParameterDefaultContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 26, RULE_scalarParameterDefault);
        let mut _localctx: Rc<ScalarParameterDefaultContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(713);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule literalExpression*/
			recog.base.set_state(714);
			let tmp = recog.literalExpression()?;
			 cast_mut::<_,ScalarParameterDefaultContext >(&mut _localctx).Value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tabularParameter ----------------
pub type TabularParameterContextAll<'input> = TabularParameterContext<'input>;


pub type TabularParameterContext<'input> = BaseParserRuleContext<'input,TabularParameterContextExt<'input>>;

#[derive(Clone)]
pub struct TabularParameterContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub OpenSchema: Option<Rc<TabularParameterOpenSchemaContextAll<'input>>>,
	pub RowSchema: Option<Rc<TabularParameterRowSchemaContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TabularParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TabularParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tabularParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_tabularParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TabularParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_tabularParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for TabularParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tabularParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tabularParameter }
}
antlr_rust::tid!{TabularParameterContextExt<'a>}

impl<'input> TabularParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TabularParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TabularParameterContextExt{
				Name: None, OpenSchema: None, RowSchema: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TabularParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TabularParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tabularParameterOpenSchema(&self) -> Option<Rc<TabularParameterOpenSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn tabularParameterRowSchema(&self) -> Option<Rc<TabularParameterRowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TabularParameterContextAttrs<'input> for TabularParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tabularParameter(&mut self,)
	-> Result<Rc<TabularParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TabularParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 28, RULE_tabularParameter);
        let mut _localctx: Rc<TabularParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(716);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,TabularParameterContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(717);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			recog.base.set_state(720);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(9,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule tabularParameterOpenSchema*/
					recog.base.set_state(718);
					let tmp = recog.tabularParameterOpenSchema()?;
					 cast_mut::<_,TabularParameterContext >(&mut _localctx).OpenSchema = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					/*InvokeRule tabularParameterRowSchema*/
					recog.base.set_state(719);
					let tmp = recog.tabularParameterRowSchema()?;
					 cast_mut::<_,TabularParameterContext >(&mut _localctx).RowSchema = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tabularParameterOpenSchema ----------------
pub type TabularParameterOpenSchemaContextAll<'input> = TabularParameterOpenSchemaContext<'input>;


pub type TabularParameterOpenSchemaContext<'input> = BaseParserRuleContext<'input,TabularParameterOpenSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct TabularParameterOpenSchemaContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TabularParameterOpenSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TabularParameterOpenSchemaContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tabularParameterOpenSchema(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_tabularParameterOpenSchema(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TabularParameterOpenSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_tabularParameterOpenSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for TabularParameterOpenSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tabularParameterOpenSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tabularParameterOpenSchema }
}
antlr_rust::tid!{TabularParameterOpenSchemaContextExt<'a>}

impl<'input> TabularParameterOpenSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TabularParameterOpenSchemaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TabularParameterOpenSchemaContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait TabularParameterOpenSchemaContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TabularParameterOpenSchemaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}

}

impl<'input> TabularParameterOpenSchemaContextAttrs<'input> for TabularParameterOpenSchemaContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tabularParameterOpenSchema(&mut self,)
	-> Result<Rc<TabularParameterOpenSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TabularParameterOpenSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 30, RULE_tabularParameterOpenSchema);
        let mut _localctx: Rc<TabularParameterOpenSchemaContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(722);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(723);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			recog.base.set_state(724);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tabularParameterRowSchema ----------------
pub type TabularParameterRowSchemaContextAll<'input> = TabularParameterRowSchemaContext<'input>;


pub type TabularParameterRowSchemaContext<'input> = BaseParserRuleContext<'input,TabularParameterRowSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct TabularParameterRowSchemaContextExt<'input>{
	pub tabularParameterRowSchemaColumnDeclaration: Option<Rc<TabularParameterRowSchemaColumnDeclarationContextAll<'input>>>,
	pub Columns:Vec<Rc<TabularParameterRowSchemaColumnDeclarationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TabularParameterRowSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TabularParameterRowSchemaContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tabularParameterRowSchema(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_tabularParameterRowSchema(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TabularParameterRowSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_tabularParameterRowSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for TabularParameterRowSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tabularParameterRowSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tabularParameterRowSchema }
}
antlr_rust::tid!{TabularParameterRowSchemaContextExt<'a>}

impl<'input> TabularParameterRowSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TabularParameterRowSchemaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TabularParameterRowSchemaContextExt{
				tabularParameterRowSchemaColumnDeclaration: None, 
				Columns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TabularParameterRowSchemaContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TabularParameterRowSchemaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn tabularParameterRowSchemaColumnDeclaration_all(&self) ->  Vec<Rc<TabularParameterRowSchemaColumnDeclarationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn tabularParameterRowSchemaColumnDeclaration(&self, i: usize) -> Option<Rc<TabularParameterRowSchemaColumnDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TabularParameterRowSchemaContextAttrs<'input> for TabularParameterRowSchemaContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tabularParameterRowSchema(&mut self,)
	-> Result<Rc<TabularParameterRowSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TabularParameterRowSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 32, RULE_tabularParameterRowSchema);
        let mut _localctx: Rc<TabularParameterRowSchemaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(726);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule tabularParameterRowSchemaColumnDeclaration*/
			recog.base.set_state(727);
			let tmp = recog.tabularParameterRowSchemaColumnDeclaration()?;
			 cast_mut::<_,TabularParameterRowSchemaContext >(&mut _localctx).tabularParameterRowSchemaColumnDeclaration = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,TabularParameterRowSchemaContext >(&mut _localctx).tabularParameterRowSchemaColumnDeclaration.clone().unwrap()
			 ;
			 cast_mut::<_,TabularParameterRowSchemaContext >(&mut _localctx).Columns.push(temp);
			  
			recog.base.set_state(732);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(728);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule tabularParameterRowSchemaColumnDeclaration*/
				recog.base.set_state(729);
				let tmp = recog.tabularParameterRowSchemaColumnDeclaration()?;
				 cast_mut::<_,TabularParameterRowSchemaContext >(&mut _localctx).tabularParameterRowSchemaColumnDeclaration = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,TabularParameterRowSchemaContext >(&mut _localctx).tabularParameterRowSchemaColumnDeclaration.clone().unwrap()
				 ;
				 cast_mut::<_,TabularParameterRowSchemaContext >(&mut _localctx).Columns.push(temp);
				  
				}
				}
				recog.base.set_state(734);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(735);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- tabularParameterRowSchemaColumnDeclaration ----------------
pub type TabularParameterRowSchemaColumnDeclarationContextAll<'input> = TabularParameterRowSchemaColumnDeclarationContext<'input>;


pub type TabularParameterRowSchemaColumnDeclarationContext<'input> = BaseParserRuleContext<'input,TabularParameterRowSchemaColumnDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct TabularParameterRowSchemaColumnDeclarationContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub Type: Option<Rc<ScalarTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TabularParameterRowSchemaColumnDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TabularParameterRowSchemaColumnDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_tabularParameterRowSchemaColumnDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_tabularParameterRowSchemaColumnDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TabularParameterRowSchemaColumnDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_tabularParameterRowSchemaColumnDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for TabularParameterRowSchemaColumnDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_tabularParameterRowSchemaColumnDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_tabularParameterRowSchemaColumnDeclaration }
}
antlr_rust::tid!{TabularParameterRowSchemaColumnDeclarationContextExt<'a>}

impl<'input> TabularParameterRowSchemaColumnDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TabularParameterRowSchemaColumnDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TabularParameterRowSchemaColumnDeclarationContextExt{
				Name: None, Type: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TabularParameterRowSchemaColumnDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TabularParameterRowSchemaColumnDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarType(&self) -> Option<Rc<ScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TabularParameterRowSchemaColumnDeclarationContextAttrs<'input> for TabularParameterRowSchemaColumnDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn tabularParameterRowSchemaColumnDeclaration(&mut self,)
	-> Result<Rc<TabularParameterRowSchemaColumnDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TabularParameterRowSchemaColumnDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 34, RULE_tabularParameterRowSchemaColumnDeclaration);
        let mut _localctx: Rc<TabularParameterRowSchemaColumnDeclarationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(737);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,TabularParameterRowSchemaColumnDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(738);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule scalarType*/
			recog.base.set_state(739);
			let tmp = recog.scalarType()?;
			 cast_mut::<_,TabularParameterRowSchemaColumnDeclarationContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letFunctionBody ----------------
pub type LetFunctionBodyContextAll<'input> = LetFunctionBodyContext<'input>;


pub type LetFunctionBodyContext<'input> = BaseParserRuleContext<'input,LetFunctionBodyContextExt<'input>>;

#[derive(Clone)]
pub struct LetFunctionBodyContextExt<'input>{
	pub letFunctionBodyStatement: Option<Rc<LetFunctionBodyStatementContextAll<'input>>>,
	pub Statements:Vec<Rc<LetFunctionBodyStatementContextAll<'input>>>,
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetFunctionBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetFunctionBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letFunctionBody(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letFunctionBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetFunctionBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letFunctionBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetFunctionBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letFunctionBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letFunctionBody }
}
antlr_rust::tid!{LetFunctionBodyContextExt<'a>}

impl<'input> LetFunctionBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetFunctionBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetFunctionBodyContextExt{
				letFunctionBodyStatement: None, Expression: None, 
				Statements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetFunctionBodyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetFunctionBodyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACE
/// Returns `None` if there is no child corresponding to token OPENBRACE
fn OPENBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACE
/// Returns `None` if there is no child corresponding to token CLOSEBRACE
fn CLOSEBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACE, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMICOLON in current rule
fn SEMICOLON_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMICOLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMICOLON is less or equal than `i`.
fn SEMICOLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, i)
}
fn letFunctionBodyStatement_all(&self) ->  Vec<Rc<LetFunctionBodyStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn letFunctionBodyStatement(&self, i: usize) -> Option<Rc<LetFunctionBodyStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetFunctionBodyContextAttrs<'input> for LetFunctionBodyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letFunctionBody(&mut self,)
	-> Result<Rc<LetFunctionBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetFunctionBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 36, RULE_letFunctionBody);
        let mut _localctx: Rc<LetFunctionBodyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(741);
			recog.base.match_token(OPENBRACE,&mut recog.err_handler)?;

			recog.base.set_state(747);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(11,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule letFunctionBodyStatement*/
					recog.base.set_state(742);
					let tmp = recog.letFunctionBodyStatement()?;
					 cast_mut::<_,LetFunctionBodyContext >(&mut _localctx).letFunctionBodyStatement = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LetFunctionBodyContext >(&mut _localctx).letFunctionBodyStatement.clone().unwrap()
					 ;
					 cast_mut::<_,LetFunctionBodyContext >(&mut _localctx).Statements.push(temp);
					  
					recog.base.set_state(743);
					recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

					}
					} 
				}
				recog.base.set_state(749);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(11,&mut recog.base)?;
			}
			recog.base.set_state(751);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ASTERISK) | (1usize << DASH) | (1usize << OPENBRACKET) | (1usize << OPENPAREN))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (PLUS - 33)) | (1usize << (ACCESS - 33)) | (1usize << (AGGREGATIONS - 33)) | (1usize << (ALIAS - 33)) | (1usize << (ALL - 33)) | (1usize << (AXES - 33)) | (1usize << (BASE - 33)) | (1usize << (BIN - 33)) | (1usize << (CLUSTER - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (CONTEXTUAL_DATATABLE - 65)) | (1usize << (COUNT - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATATABLE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DELTA - 65)) | (1usize << (EDGES - 65)) | (1usize << (EVALUATE - 65)) | (1usize << (EXECUTE - 65)) | (1usize << (EXTERNALDATA - 65)) | (1usize << (EXTERNAL_DATA - 65)) | (1usize << (FACET - 65)) | (1usize << (FIND - 65)) | (1usize << (FORK - 65)) | (1usize << (FROM - 65)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MACROEXPAND - 145)) | (1usize << (MAP - 145)) | (1usize << (MATERIALIZED_VIEW_COMBINE - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 250)) & !0x3f) == 0 && ((1usize << (_la - 250)) & ((1usize << (TOSCALAR - 250)) | (1usize << (TOTABLE - 250)) | (1usize << (TYPEOF - 250)) | (1usize << (UNION - 250)) | (1usize << (UNSTACKED - 250)) | (1usize << (UUID - 250)) | (1usize << (VIEW - 250)) | (1usize << (VISIBLE - 250)) | (1usize << (WITH - 250)) | (1usize << (XAXIS - 250)) | (1usize << (XCOLUMN - 250)) | (1usize << (XMAX - 250)) | (1usize << (XMIN - 250)) | (1usize << (XTITLE - 250)) | (1usize << (YAXIS - 250)) | (1usize << (YCOLUMNS - 250)) | (1usize << (YMAX - 250)) | (1usize << (YMIN - 250)) | (1usize << (YSPLIT - 250)) | (1usize << (YTITLE - 250)) | (1usize << (BOOL - 250)))) != 0) || ((((_la - 285)) & !0x3f) == 0 && ((1usize << (_la - 285)) & ((1usize << (DYNAMIC - 285)) | (1usize << (GUID - 285)) | (1usize << (LONGLITERAL - 285)) | (1usize << (INTLITERAL - 285)) | (1usize << (REALLITERAL - 285)) | (1usize << (DECIMALLITERAL - 285)) | (1usize << (STRINGLITERAL - 285)) | (1usize << (BOOLEANLITERAL - 285)) | (1usize << (DATETIMELITERAL - 285)) | (1usize << (TIMESPANLITERAL - 285)) | (1usize << (TYPELITERAL - 285)) | (1usize << (GUIDLITERAL - 285)) | (1usize << (IDENTIFIER - 285)))) != 0) {
				{
				/*InvokeRule expression*/
				recog.base.set_state(750);
				let tmp = recog.expression()?;
				 cast_mut::<_,LetFunctionBodyContext >(&mut _localctx).Expression = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(754);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMICOLON {
				{
				recog.base.set_state(753);
				recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(756);
			recog.base.match_token(CLOSEBRACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- letFunctionBodyStatement ----------------
pub type LetFunctionBodyStatementContextAll<'input> = LetFunctionBodyStatementContext<'input>;


pub type LetFunctionBodyStatementContext<'input> = BaseParserRuleContext<'input,LetFunctionBodyStatementContextExt<'input>>;

#[derive(Clone)]
pub struct LetFunctionBodyStatementContextExt<'input>{
	pub Let: Option<Rc<LetStatementContextAll<'input>>>,
	pub DeclareQueryParameters: Option<Rc<DeclareQueryParametersStatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LetFunctionBodyStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LetFunctionBodyStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_letFunctionBodyStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_letFunctionBodyStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LetFunctionBodyStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_letFunctionBodyStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for LetFunctionBodyStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_letFunctionBodyStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_letFunctionBodyStatement }
}
antlr_rust::tid!{LetFunctionBodyStatementContextExt<'a>}

impl<'input> LetFunctionBodyStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LetFunctionBodyStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LetFunctionBodyStatementContextExt{
				Let: None, DeclareQueryParameters: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LetFunctionBodyStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LetFunctionBodyStatementContextExt<'input>>{

fn letStatement(&self) -> Option<Rc<LetStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declareQueryParametersStatement(&self) -> Option<Rc<DeclareQueryParametersStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LetFunctionBodyStatementContextAttrs<'input> for LetFunctionBodyStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn letFunctionBodyStatement(&mut self,)
	-> Result<Rc<LetFunctionBodyStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LetFunctionBodyStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 38, RULE_letFunctionBodyStatement);
        let mut _localctx: Rc<LetFunctionBodyStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(760);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule letStatement*/
					recog.base.set_state(758);
					let tmp = recog.letStatement()?;
					 cast_mut::<_,LetFunctionBodyStatementContext >(&mut _localctx).Let = Some(tmp.clone());
					  

					}
				}

			 DECLARE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule declareQueryParametersStatement*/
					recog.base.set_state(759);
					let tmp = recog.declareQueryParametersStatement()?;
					 cast_mut::<_,LetFunctionBodyStatementContext >(&mut _localctx).DeclareQueryParameters = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternStatement ----------------
pub type DeclarePatternStatementContextAll<'input> = DeclarePatternStatementContext<'input>;


pub type DeclarePatternStatementContext<'input> = BaseParserRuleContext<'input,DeclarePatternStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternStatementContextExt<'input>{
	pub Name: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub Definition: Option<Rc<DeclarePatternDefinitionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternStatement }
}
antlr_rust::tid!{DeclarePatternStatementContextExt<'a>}

impl<'input> DeclarePatternStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternStatementContextExt{
				Name: None, Definition: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token PATTERN
/// Returns `None` if there is no child corresponding to token PATTERN
fn PATTERN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PATTERN, 0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declarePatternDefinition(&self) -> Option<Rc<DeclarePatternDefinitionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclarePatternStatementContextAttrs<'input> for DeclarePatternStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternStatement(&mut self,)
	-> Result<Rc<DeclarePatternStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 40, RULE_declarePatternStatement);
        let mut _localctx: Rc<DeclarePatternStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(762);
			recog.base.match_token(DECLARE,&mut recog.err_handler)?;

			recog.base.set_state(763);
			recog.base.match_token(PATTERN,&mut recog.err_handler)?;

			/*InvokeRule simpleNameReference*/
			recog.base.set_state(764);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,DeclarePatternStatementContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(766);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EQUAL {
				{
				/*InvokeRule declarePatternDefinition*/
				recog.base.set_state(765);
				let tmp = recog.declarePatternDefinition()?;
				 cast_mut::<_,DeclarePatternStatementContext >(&mut _localctx).Definition = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternDefinition ----------------
pub type DeclarePatternDefinitionContextAll<'input> = DeclarePatternDefinitionContext<'input>;


pub type DeclarePatternDefinitionContext<'input> = BaseParserRuleContext<'input,DeclarePatternDefinitionContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternDefinitionContextExt<'input>{
	pub ParameterList: Option<Rc<DeclarePatternParameterListContextAll<'input>>>,
	pub Path: Option<Rc<DeclarePatternPathParameterContextAll<'input>>>,
	pub declarePatternRule: Option<Rc<DeclarePatternRuleContextAll<'input>>>,
	pub Rules:Vec<Rc<DeclarePatternRuleContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternDefinitionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternDefinitionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternDefinition(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternDefinition(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternDefinitionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternDefinition(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternDefinitionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternDefinition }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternDefinition }
}
antlr_rust::tid!{DeclarePatternDefinitionContextExt<'a>}

impl<'input> DeclarePatternDefinitionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternDefinitionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternDefinitionContextExt{
				ParameterList: None, Path: None, declarePatternRule: None, 
				Rules: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternDefinitionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternDefinitionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENBRACE
/// Returns `None` if there is no child corresponding to token OPENBRACE
fn OPENBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACE
/// Returns `None` if there is no child corresponding to token CLOSEBRACE
fn CLOSEBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACE, 0)
}
fn declarePatternParameterList(&self) -> Option<Rc<DeclarePatternParameterListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declarePatternPathParameter(&self) -> Option<Rc<DeclarePatternPathParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declarePatternRule_all(&self) ->  Vec<Rc<DeclarePatternRuleContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn declarePatternRule(&self, i: usize) -> Option<Rc<DeclarePatternRuleContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DeclarePatternDefinitionContextAttrs<'input> for DeclarePatternDefinitionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternDefinition(&mut self,)
	-> Result<Rc<DeclarePatternDefinitionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternDefinitionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 42, RULE_declarePatternDefinition);
        let mut _localctx: Rc<DeclarePatternDefinitionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(768);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule declarePatternParameterList*/
			recog.base.set_state(769);
			let tmp = recog.declarePatternParameterList()?;
			 cast_mut::<_,DeclarePatternDefinitionContext >(&mut _localctx).ParameterList = Some(tmp.clone());
			  

			recog.base.set_state(771);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OPENBRACKET {
				{
				/*InvokeRule declarePatternPathParameter*/
				recog.base.set_state(770);
				let tmp = recog.declarePatternPathParameter()?;
				 cast_mut::<_,DeclarePatternDefinitionContext >(&mut _localctx).Path = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(773);
			recog.base.match_token(OPENBRACE,&mut recog.err_handler)?;

			recog.base.set_state(775); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule declarePatternRule*/
				recog.base.set_state(774);
				let tmp = recog.declarePatternRule()?;
				 cast_mut::<_,DeclarePatternDefinitionContext >(&mut _localctx).declarePatternRule = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DeclarePatternDefinitionContext >(&mut _localctx).declarePatternRule.clone().unwrap()
				 ;
				 cast_mut::<_,DeclarePatternDefinitionContext >(&mut _localctx).Rules.push(temp);
				  
				}
				}
				recog.base.set_state(777); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==OPENPAREN) {break}
			}
			recog.base.set_state(779);
			recog.base.match_token(CLOSEBRACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternParameterList ----------------
pub type DeclarePatternParameterListContextAll<'input> = DeclarePatternParameterListContext<'input>;


pub type DeclarePatternParameterListContext<'input> = BaseParserRuleContext<'input,DeclarePatternParameterListContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternParameterListContextExt<'input>{
	pub declarePatternParameter: Option<Rc<DeclarePatternParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<DeclarePatternParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternParameterListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternParameterListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternParameterList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternParameterList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternParameterListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternParameterList(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternParameterListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternParameterList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternParameterList }
}
antlr_rust::tid!{DeclarePatternParameterListContextExt<'a>}

impl<'input> DeclarePatternParameterListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternParameterListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternParameterListContextExt{
				declarePatternParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternParameterListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternParameterListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn declarePatternParameter_all(&self) ->  Vec<Rc<DeclarePatternParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn declarePatternParameter(&self, i: usize) -> Option<Rc<DeclarePatternParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> DeclarePatternParameterListContextAttrs<'input> for DeclarePatternParameterListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternParameterList(&mut self,)
	-> Result<Rc<DeclarePatternParameterListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternParameterListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 44, RULE_declarePatternParameterList);
        let mut _localctx: Rc<DeclarePatternParameterListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(781);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule declarePatternParameter*/
			recog.base.set_state(782);
			let tmp = recog.declarePatternParameter()?;
			 cast_mut::<_,DeclarePatternParameterListContext >(&mut _localctx).declarePatternParameter = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,DeclarePatternParameterListContext >(&mut _localctx).declarePatternParameter.clone().unwrap()
			 ;
			 cast_mut::<_,DeclarePatternParameterListContext >(&mut _localctx).Parameters.push(temp);
			  
			recog.base.set_state(787);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(783);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule declarePatternParameter*/
				recog.base.set_state(784);
				let tmp = recog.declarePatternParameter()?;
				 cast_mut::<_,DeclarePatternParameterListContext >(&mut _localctx).declarePatternParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DeclarePatternParameterListContext >(&mut _localctx).declarePatternParameter.clone().unwrap()
				 ;
				 cast_mut::<_,DeclarePatternParameterListContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(789);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(790);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternParameter ----------------
pub type DeclarePatternParameterContextAll<'input> = DeclarePatternParameterContext<'input>;


pub type DeclarePatternParameterContext<'input> = BaseParserRuleContext<'input,DeclarePatternParameterContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternParameterContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub Type: Option<Rc<ScalarTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternParameter }
}
antlr_rust::tid!{DeclarePatternParameterContextExt<'a>}

impl<'input> DeclarePatternParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternParameterContextExt{
				Name: None, Type: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarType(&self) -> Option<Rc<ScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclarePatternParameterContextAttrs<'input> for DeclarePatternParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternParameter(&mut self,)
	-> Result<Rc<DeclarePatternParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 46, RULE_declarePatternParameter);
        let mut _localctx: Rc<DeclarePatternParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(792);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,DeclarePatternParameterContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(793);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule scalarType*/
			recog.base.set_state(794);
			let tmp = recog.scalarType()?;
			 cast_mut::<_,DeclarePatternParameterContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternPathParameter ----------------
pub type DeclarePatternPathParameterContextAll<'input> = DeclarePatternPathParameterContext<'input>;


pub type DeclarePatternPathParameterContext<'input> = BaseParserRuleContext<'input,DeclarePatternPathParameterContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternPathParameterContextExt<'input>{
	pub Parameter: Option<Rc<DeclarePatternParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternPathParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternPathParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternPathParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternPathParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternPathParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternPathParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternPathParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternPathParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternPathParameter }
}
antlr_rust::tid!{DeclarePatternPathParameterContextExt<'a>}

impl<'input> DeclarePatternPathParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternPathParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternPathParameterContextExt{
				Parameter: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternPathParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternPathParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn declarePatternParameter(&self) -> Option<Rc<DeclarePatternParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclarePatternPathParameterContextAttrs<'input> for DeclarePatternPathParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternPathParameter(&mut self,)
	-> Result<Rc<DeclarePatternPathParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternPathParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 48, RULE_declarePatternPathParameter);
        let mut _localctx: Rc<DeclarePatternPathParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(796);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule declarePatternParameter*/
			recog.base.set_state(797);
			let tmp = recog.declarePatternParameter()?;
			 cast_mut::<_,DeclarePatternPathParameterContext >(&mut _localctx).Parameter = Some(tmp.clone());
			  

			recog.base.set_state(798);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternRule ----------------
pub type DeclarePatternRuleContextAll<'input> = DeclarePatternRuleContext<'input>;


pub type DeclarePatternRuleContext<'input> = BaseParserRuleContext<'input,DeclarePatternRuleContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternRuleContextExt<'input>{
	pub ArgumentList: Option<Rc<DeclarePatternRuleArgumentListContextAll<'input>>>,
	pub PathArgument: Option<Rc<DeclarePatternRulePathArgumentContextAll<'input>>>,
	pub Body: Option<Rc<DeclarePatternBodyContextAll<'input>>>,
	pub TrailingSemicolon: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternRuleContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternRuleContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternRule(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternRule(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternRuleContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternRule(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternRuleContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternRule }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternRule }
}
antlr_rust::tid!{DeclarePatternRuleContextExt<'a>}

impl<'input> DeclarePatternRuleContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternRuleContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternRuleContextExt{
				TrailingSemicolon: None, 
				ArgumentList: None, PathArgument: None, Body: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternRuleContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternRuleContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn declarePatternRuleArgumentList(&self) -> Option<Rc<DeclarePatternRuleArgumentListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declarePatternBody(&self) -> Option<Rc<DeclarePatternBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn declarePatternRulePathArgument(&self) -> Option<Rc<DeclarePatternRulePathArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SEMICOLON
/// Returns `None` if there is no child corresponding to token SEMICOLON
fn SEMICOLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, 0)
}

}

impl<'input> DeclarePatternRuleContextAttrs<'input> for DeclarePatternRuleContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternRule(&mut self,)
	-> Result<Rc<DeclarePatternRuleContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternRuleContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 50, RULE_declarePatternRule);
        let mut _localctx: Rc<DeclarePatternRuleContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule declarePatternRuleArgumentList*/
			recog.base.set_state(800);
			let tmp = recog.declarePatternRuleArgumentList()?;
			 cast_mut::<_,DeclarePatternRuleContext >(&mut _localctx).ArgumentList = Some(tmp.clone());
			  

			recog.base.set_state(802);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DOT {
				{
				/*InvokeRule declarePatternRulePathArgument*/
				recog.base.set_state(801);
				let tmp = recog.declarePatternRulePathArgument()?;
				 cast_mut::<_,DeclarePatternRuleContext >(&mut _localctx).PathArgument = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(804);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule declarePatternBody*/
			recog.base.set_state(805);
			let tmp = recog.declarePatternBody()?;
			 cast_mut::<_,DeclarePatternRuleContext >(&mut _localctx).Body = Some(tmp.clone());
			  

			recog.base.set_state(807);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMICOLON {
				{
				recog.base.set_state(806);
				let tmp = recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;
				 cast_mut::<_,DeclarePatternRuleContext >(&mut _localctx).TrailingSemicolon = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternRuleArgumentList ----------------
pub type DeclarePatternRuleArgumentListContextAll<'input> = DeclarePatternRuleArgumentListContext<'input>;


pub type DeclarePatternRuleArgumentListContext<'input> = BaseParserRuleContext<'input,DeclarePatternRuleArgumentListContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternRuleArgumentListContextExt<'input>{
	pub declarePatternRuleArgument: Option<Rc<DeclarePatternRuleArgumentContextAll<'input>>>,
	pub Arguments:Vec<Rc<DeclarePatternRuleArgumentContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternRuleArgumentListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternRuleArgumentListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternRuleArgumentList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternRuleArgumentList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternRuleArgumentListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternRuleArgumentList(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternRuleArgumentListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternRuleArgumentList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternRuleArgumentList }
}
antlr_rust::tid!{DeclarePatternRuleArgumentListContextExt<'a>}

impl<'input> DeclarePatternRuleArgumentListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternRuleArgumentListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternRuleArgumentListContextExt{
				declarePatternRuleArgument: None, 
				Arguments: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternRuleArgumentListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternRuleArgumentListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn declarePatternRuleArgument_all(&self) ->  Vec<Rc<DeclarePatternRuleArgumentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn declarePatternRuleArgument(&self, i: usize) -> Option<Rc<DeclarePatternRuleArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> DeclarePatternRuleArgumentListContextAttrs<'input> for DeclarePatternRuleArgumentListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternRuleArgumentList(&mut self,)
	-> Result<Rc<DeclarePatternRuleArgumentListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternRuleArgumentListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 52, RULE_declarePatternRuleArgumentList);
        let mut _localctx: Rc<DeclarePatternRuleArgumentListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(809);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule declarePatternRuleArgument*/
			recog.base.set_state(810);
			let tmp = recog.declarePatternRuleArgument()?;
			 cast_mut::<_,DeclarePatternRuleArgumentListContext >(&mut _localctx).declarePatternRuleArgument = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,DeclarePatternRuleArgumentListContext >(&mut _localctx).declarePatternRuleArgument.clone().unwrap()
			 ;
			 cast_mut::<_,DeclarePatternRuleArgumentListContext >(&mut _localctx).Arguments.push(temp);
			  
			recog.base.set_state(815);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(811);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule declarePatternRuleArgument*/
				recog.base.set_state(812);
				let tmp = recog.declarePatternRuleArgument()?;
				 cast_mut::<_,DeclarePatternRuleArgumentListContext >(&mut _localctx).declarePatternRuleArgument = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DeclarePatternRuleArgumentListContext >(&mut _localctx).declarePatternRuleArgument.clone().unwrap()
				 ;
				 cast_mut::<_,DeclarePatternRuleArgumentListContext >(&mut _localctx).Arguments.push(temp);
				  
				}
				}
				recog.base.set_state(817);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(818);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternRulePathArgument ----------------
pub type DeclarePatternRulePathArgumentContextAll<'input> = DeclarePatternRulePathArgumentContext<'input>;


pub type DeclarePatternRulePathArgumentContext<'input> = BaseParserRuleContext<'input,DeclarePatternRulePathArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternRulePathArgumentContextExt<'input>{
	pub Expression: Option<Rc<DeclarePatternRuleArgumentContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternRulePathArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternRulePathArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternRulePathArgument(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternRulePathArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternRulePathArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternRulePathArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternRulePathArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternRulePathArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternRulePathArgument }
}
antlr_rust::tid!{DeclarePatternRulePathArgumentContextExt<'a>}

impl<'input> DeclarePatternRulePathArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternRulePathArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternRulePathArgumentContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternRulePathArgumentContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternRulePathArgumentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn declarePatternRuleArgument(&self) -> Option<Rc<DeclarePatternRuleArgumentContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclarePatternRulePathArgumentContextAttrs<'input> for DeclarePatternRulePathArgumentContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternRulePathArgument(&mut self,)
	-> Result<Rc<DeclarePatternRulePathArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternRulePathArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 54, RULE_declarePatternRulePathArgument);
        let mut _localctx: Rc<DeclarePatternRulePathArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(820);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			recog.base.set_state(821);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule declarePatternRuleArgument*/
			recog.base.set_state(822);
			let tmp = recog.declarePatternRuleArgument()?;
			 cast_mut::<_,DeclarePatternRulePathArgumentContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(823);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternRuleArgument ----------------
pub type DeclarePatternRuleArgumentContextAll<'input> = DeclarePatternRuleArgumentContext<'input>;


pub type DeclarePatternRuleArgumentContext<'input> = BaseParserRuleContext<'input,DeclarePatternRuleArgumentContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternRuleArgumentContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternRuleArgumentContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternRuleArgumentContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternRuleArgument(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternRuleArgument(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternRuleArgumentContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternRuleArgument(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternRuleArgumentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternRuleArgument }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternRuleArgument }
}
antlr_rust::tid!{DeclarePatternRuleArgumentContextExt<'a>}

impl<'input> DeclarePatternRuleArgumentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternRuleArgumentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternRuleArgumentContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternRuleArgumentContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternRuleArgumentContextExt<'input>>{

fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclarePatternRuleArgumentContextAttrs<'input> for DeclarePatternRuleArgumentContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternRuleArgument(&mut self,)
	-> Result<Rc<DeclarePatternRuleArgumentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternRuleArgumentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 56, RULE_declarePatternRuleArgument);
        let mut _localctx: Rc<DeclarePatternRuleArgumentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule stringLiteralExpression*/
			recog.base.set_state(825);
			recog.stringLiteralExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declarePatternBody ----------------
pub type DeclarePatternBodyContextAll<'input> = DeclarePatternBodyContext<'input>;


pub type DeclarePatternBodyContext<'input> = BaseParserRuleContext<'input,DeclarePatternBodyContextExt<'input>>;

#[derive(Clone)]
pub struct DeclarePatternBodyContextExt<'input>{
	pub letFunctionBodyStatement: Option<Rc<LetFunctionBodyStatementContextAll<'input>>>,
	pub Statements:Vec<Rc<LetFunctionBodyStatementContextAll<'input>>>,
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclarePatternBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclarePatternBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declarePatternBody(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declarePatternBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclarePatternBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declarePatternBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclarePatternBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declarePatternBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declarePatternBody }
}
antlr_rust::tid!{DeclarePatternBodyContextExt<'a>}

impl<'input> DeclarePatternBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclarePatternBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclarePatternBodyContextExt{
				letFunctionBodyStatement: None, Expression: None, 
				Statements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclarePatternBodyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclarePatternBodyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACE
/// Returns `None` if there is no child corresponding to token OPENBRACE
fn OPENBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACE
/// Returns `None` if there is no child corresponding to token CLOSEBRACE
fn CLOSEBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACE, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMICOLON in current rule
fn SEMICOLON_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMICOLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMICOLON is less or equal than `i`.
fn SEMICOLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, i)
}
fn letFunctionBodyStatement_all(&self) ->  Vec<Rc<LetFunctionBodyStatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn letFunctionBodyStatement(&self, i: usize) -> Option<Rc<LetFunctionBodyStatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DeclarePatternBodyContextAttrs<'input> for DeclarePatternBodyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declarePatternBody(&mut self,)
	-> Result<Rc<DeclarePatternBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclarePatternBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 58, RULE_declarePatternBody);
        let mut _localctx: Rc<DeclarePatternBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(827);
			recog.base.match_token(OPENBRACE,&mut recog.err_handler)?;

			recog.base.set_state(833);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(22,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule letFunctionBodyStatement*/
					recog.base.set_state(828);
					let tmp = recog.letFunctionBodyStatement()?;
					 cast_mut::<_,DeclarePatternBodyContext >(&mut _localctx).letFunctionBodyStatement = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,DeclarePatternBodyContext >(&mut _localctx).letFunctionBodyStatement.clone().unwrap()
					 ;
					 cast_mut::<_,DeclarePatternBodyContext >(&mut _localctx).Statements.push(temp);
					  
					recog.base.set_state(829);
					recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

					}
					} 
				}
				recog.base.set_state(835);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(22,&mut recog.base)?;
			}
			/*InvokeRule expression*/
			recog.base.set_state(836);
			let tmp = recog.expression()?;
			 cast_mut::<_,DeclarePatternBodyContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(837);
			recog.base.match_token(CLOSEBRACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- restrictAccessStatement ----------------
pub type RestrictAccessStatementContextAll<'input> = RestrictAccessStatementContext<'input>;


pub type RestrictAccessStatementContext<'input> = BaseParserRuleContext<'input,RestrictAccessStatementContextExt<'input>>;

#[derive(Clone)]
pub struct RestrictAccessStatementContextExt<'input>{
	pub restrictAccessStatementEntity: Option<Rc<RestrictAccessStatementEntityContextAll<'input>>>,
	pub Entities:Vec<Rc<RestrictAccessStatementEntityContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RestrictAccessStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RestrictAccessStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_restrictAccessStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_restrictAccessStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RestrictAccessStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_restrictAccessStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for RestrictAccessStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_restrictAccessStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_restrictAccessStatement }
}
antlr_rust::tid!{RestrictAccessStatementContextExt<'a>}

impl<'input> RestrictAccessStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RestrictAccessStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RestrictAccessStatementContextExt{
				restrictAccessStatementEntity: None, 
				Entities: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait RestrictAccessStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RestrictAccessStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token ACCESS
/// Returns `None` if there is no child corresponding to token ACCESS
fn ACCESS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ACCESS, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn restrictAccessStatementEntity_all(&self) ->  Vec<Rc<RestrictAccessStatementEntityContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn restrictAccessStatementEntity(&self, i: usize) -> Option<Rc<RestrictAccessStatementEntityContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RestrictAccessStatementContextAttrs<'input> for RestrictAccessStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn restrictAccessStatement(&mut self,)
	-> Result<Rc<RestrictAccessStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RestrictAccessStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 60, RULE_restrictAccessStatement);
        let mut _localctx: Rc<RestrictAccessStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(839);
			recog.base.match_token(RESTRICT,&mut recog.err_handler)?;

			recog.base.set_state(840);
			recog.base.match_token(ACCESS,&mut recog.err_handler)?;

			recog.base.set_state(841);
			recog.base.match_token(TO,&mut recog.err_handler)?;

			recog.base.set_state(842);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule restrictAccessStatementEntity*/
			recog.base.set_state(843);
			let tmp = recog.restrictAccessStatementEntity()?;
			 cast_mut::<_,RestrictAccessStatementContext >(&mut _localctx).restrictAccessStatementEntity = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,RestrictAccessStatementContext >(&mut _localctx).restrictAccessStatementEntity.clone().unwrap()
			 ;
			 cast_mut::<_,RestrictAccessStatementContext >(&mut _localctx).Entities.push(temp);
			  
			recog.base.set_state(848);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(844);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule restrictAccessStatementEntity*/
				recog.base.set_state(845);
				let tmp = recog.restrictAccessStatementEntity()?;
				 cast_mut::<_,RestrictAccessStatementContext >(&mut _localctx).restrictAccessStatementEntity = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,RestrictAccessStatementContext >(&mut _localctx).restrictAccessStatementEntity.clone().unwrap()
				 ;
				 cast_mut::<_,RestrictAccessStatementContext >(&mut _localctx).Entities.push(temp);
				  
				}
				}
				recog.base.set_state(850);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(851);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- restrictAccessStatementEntity ----------------
pub type RestrictAccessStatementEntityContextAll<'input> = RestrictAccessStatementEntityContext<'input>;


pub type RestrictAccessStatementEntityContext<'input> = BaseParserRuleContext<'input,RestrictAccessStatementEntityContextExt<'input>>;

#[derive(Clone)]
pub struct RestrictAccessStatementEntityContextExt<'input>{
	pub SimpleName: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub WildcardedEntity: Option<Rc<WildcardedEntityExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RestrictAccessStatementEntityContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RestrictAccessStatementEntityContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_restrictAccessStatementEntity(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_restrictAccessStatementEntity(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RestrictAccessStatementEntityContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_restrictAccessStatementEntity(self);
	}
}

impl<'input> CustomRuleContext<'input> for RestrictAccessStatementEntityContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_restrictAccessStatementEntity }
	//fn type_rule_index() -> usize where Self: Sized { RULE_restrictAccessStatementEntity }
}
antlr_rust::tid!{RestrictAccessStatementEntityContextExt<'a>}

impl<'input> RestrictAccessStatementEntityContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RestrictAccessStatementEntityContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RestrictAccessStatementEntityContextExt{
				SimpleName: None, WildcardedEntity: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RestrictAccessStatementEntityContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RestrictAccessStatementEntityContextExt<'input>>{

fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn wildcardedEntityExpression(&self) -> Option<Rc<WildcardedEntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RestrictAccessStatementEntityContextAttrs<'input> for RestrictAccessStatementEntityContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn restrictAccessStatementEntity(&mut self,)
	-> Result<Rc<RestrictAccessStatementEntityContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RestrictAccessStatementEntityContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 62, RULE_restrictAccessStatementEntity);
        let mut _localctx: Rc<RestrictAccessStatementEntityContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(855);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(24,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule simpleNameReference*/
					recog.base.set_state(853);
					let tmp = recog.simpleNameReference()?;
					 cast_mut::<_,RestrictAccessStatementEntityContext >(&mut _localctx).SimpleName = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule wildcardedEntityExpression*/
					recog.base.set_state(854);
					let tmp = recog.wildcardedEntityExpression()?;
					 cast_mut::<_,RestrictAccessStatementEntityContext >(&mut _localctx).WildcardedEntity = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setStatement ----------------
pub type SetStatementContextAll<'input> = SetStatementContext<'input>;


pub type SetStatementContext<'input> = BaseParserRuleContext<'input,SetStatementContextExt<'input>>;

#[derive(Clone)]
pub struct SetStatementContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordNameContextAll<'input>>>,
	pub Value: Option<Rc<SetStatementOptionValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SetStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SetStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_setStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SetStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_setStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setStatement }
}
antlr_rust::tid!{SetStatementContextExt<'a>}

impl<'input> SetStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetStatementContextExt{
				Name: None, Value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SetStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
fn identifierOrKeywordName(&self) -> Option<Rc<IdentifierOrKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn setStatementOptionValue(&self) -> Option<Rc<SetStatementOptionValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetStatementContextAttrs<'input> for SetStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setStatement(&mut self,)
	-> Result<Rc<SetStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 64, RULE_setStatement);
        let mut _localctx: Rc<SetStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(857);
			recog.base.match_token(SET,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordName*/
			recog.base.set_state(858);
			let tmp = recog.identifierOrKeywordName()?;
			 cast_mut::<_,SetStatementContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(861);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EQUAL {
				{
				recog.base.set_state(859);
				recog.base.match_token(EQUAL,&mut recog.err_handler)?;

				/*InvokeRule setStatementOptionValue*/
				recog.base.set_state(860);
				let tmp = recog.setStatementOptionValue()?;
				 cast_mut::<_,SetStatementContext >(&mut _localctx).Value = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- setStatementOptionValue ----------------
pub type SetStatementOptionValueContextAll<'input> = SetStatementOptionValueContext<'input>;


pub type SetStatementOptionValueContext<'input> = BaseParserRuleContext<'input,SetStatementOptionValueContextExt<'input>>;

#[derive(Clone)]
pub struct SetStatementOptionValueContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordNameContextAll<'input>>>,
	pub Literal: Option<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SetStatementOptionValueContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SetStatementOptionValueContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_setStatementOptionValue(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_setStatementOptionValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SetStatementOptionValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_setStatementOptionValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for SetStatementOptionValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_setStatementOptionValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_setStatementOptionValue }
}
antlr_rust::tid!{SetStatementOptionValueContextExt<'a>}

impl<'input> SetStatementOptionValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SetStatementOptionValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SetStatementOptionValueContextExt{
				Name: None, Literal: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SetStatementOptionValueContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SetStatementOptionValueContextExt<'input>>{

fn identifierOrKeywordName(&self) -> Option<Rc<IdentifierOrKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn literalExpression(&self) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SetStatementOptionValueContextAttrs<'input> for SetStatementOptionValueContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn setStatementOptionValue(&mut self,)
	-> Result<Rc<SetStatementOptionValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SetStatementOptionValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 66, RULE_setStatementOptionValue);
        let mut _localctx: Rc<SetStatementOptionValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(865);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifierOrKeywordName*/
					recog.base.set_state(863);
					let tmp = recog.identifierOrKeywordName()?;
					 cast_mut::<_,SetStatementOptionValueContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					}
				}

			 DASH | PLUS | DYNAMIC | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL |
			 STRINGLITERAL | BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL |
			 TYPELITERAL | GUIDLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule literalExpression*/
					recog.base.set_state(864);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,SetStatementOptionValueContext >(&mut _localctx).Literal = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declareQueryParametersStatement ----------------
pub type DeclareQueryParametersStatementContextAll<'input> = DeclareQueryParametersStatementContext<'input>;


pub type DeclareQueryParametersStatementContext<'input> = BaseParserRuleContext<'input,DeclareQueryParametersStatementContextExt<'input>>;

#[derive(Clone)]
pub struct DeclareQueryParametersStatementContextExt<'input>{
	pub declareQueryParametersStatementParameter: Option<Rc<DeclareQueryParametersStatementParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<DeclareQueryParametersStatementParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclareQueryParametersStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclareQueryParametersStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declareQueryParametersStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declareQueryParametersStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclareQueryParametersStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declareQueryParametersStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclareQueryParametersStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declareQueryParametersStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declareQueryParametersStatement }
}
antlr_rust::tid!{DeclareQueryParametersStatementContextExt<'a>}

impl<'input> DeclareQueryParametersStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclareQueryParametersStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclareQueryParametersStatementContextExt{
				declareQueryParametersStatementParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclareQueryParametersStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclareQueryParametersStatementContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token QUERYPARAMETERS
/// Returns `None` if there is no child corresponding to token QUERYPARAMETERS
fn QUERYPARAMETERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(QUERYPARAMETERS, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn declareQueryParametersStatementParameter_all(&self) ->  Vec<Rc<DeclareQueryParametersStatementParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn declareQueryParametersStatementParameter(&self, i: usize) -> Option<Rc<DeclareQueryParametersStatementParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> DeclareQueryParametersStatementContextAttrs<'input> for DeclareQueryParametersStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declareQueryParametersStatement(&mut self,)
	-> Result<Rc<DeclareQueryParametersStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclareQueryParametersStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 68, RULE_declareQueryParametersStatement);
        let mut _localctx: Rc<DeclareQueryParametersStatementContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(867);
			recog.base.match_token(DECLARE,&mut recog.err_handler)?;

			recog.base.set_state(868);
			recog.base.match_token(QUERYPARAMETERS,&mut recog.err_handler)?;

			recog.base.set_state(869);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule declareQueryParametersStatementParameter*/
			recog.base.set_state(870);
			let tmp = recog.declareQueryParametersStatementParameter()?;
			 cast_mut::<_,DeclareQueryParametersStatementContext >(&mut _localctx).declareQueryParametersStatementParameter = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,DeclareQueryParametersStatementContext >(&mut _localctx).declareQueryParametersStatementParameter.clone().unwrap()
			 ;
			 cast_mut::<_,DeclareQueryParametersStatementContext >(&mut _localctx).Parameters.push(temp);
			  
			recog.base.set_state(875);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(871);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule declareQueryParametersStatementParameter*/
				recog.base.set_state(872);
				let tmp = recog.declareQueryParametersStatementParameter()?;
				 cast_mut::<_,DeclareQueryParametersStatementContext >(&mut _localctx).declareQueryParametersStatementParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DeclareQueryParametersStatementContext >(&mut _localctx).declareQueryParametersStatementParameter.clone().unwrap()
				 ;
				 cast_mut::<_,DeclareQueryParametersStatementContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(877);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(878);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- declareQueryParametersStatementParameter ----------------
pub type DeclareQueryParametersStatementParameterContextAll<'input> = DeclareQueryParametersStatementParameterContext<'input>;


pub type DeclareQueryParametersStatementParameterContext<'input> = BaseParserRuleContext<'input,DeclareQueryParametersStatementParameterContextExt<'input>>;

#[derive(Clone)]
pub struct DeclareQueryParametersStatementParameterContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub Type: Option<Rc<ScalarTypeContextAll<'input>>>,
	pub Default: Option<Rc<ScalarParameterDefaultContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DeclareQueryParametersStatementParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DeclareQueryParametersStatementParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_declareQueryParametersStatementParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_declareQueryParametersStatementParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DeclareQueryParametersStatementParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_declareQueryParametersStatementParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for DeclareQueryParametersStatementParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_declareQueryParametersStatementParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_declareQueryParametersStatementParameter }
}
antlr_rust::tid!{DeclareQueryParametersStatementParameterContextExt<'a>}

impl<'input> DeclareQueryParametersStatementParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DeclareQueryParametersStatementParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DeclareQueryParametersStatementParameterContextExt{
				Name: None, Type: None, Default: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DeclareQueryParametersStatementParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DeclareQueryParametersStatementParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarType(&self) -> Option<Rc<ScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarParameterDefault(&self) -> Option<Rc<ScalarParameterDefaultContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DeclareQueryParametersStatementParameterContextAttrs<'input> for DeclareQueryParametersStatementParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn declareQueryParametersStatementParameter(&mut self,)
	-> Result<Rc<DeclareQueryParametersStatementParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DeclareQueryParametersStatementParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 70, RULE_declareQueryParametersStatementParameter);
        let mut _localctx: Rc<DeclareQueryParametersStatementParameterContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(880);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,DeclareQueryParametersStatementParameterContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(881);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule scalarType*/
			recog.base.set_state(882);
			let tmp = recog.scalarType()?;
			 cast_mut::<_,DeclareQueryParametersStatementParameterContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			recog.base.set_state(884);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EQUAL {
				{
				/*InvokeRule scalarParameterDefault*/
				recog.base.set_state(883);
				let tmp = recog.scalarParameterDefault()?;
				 cast_mut::<_,DeclareQueryParametersStatementParameterContext >(&mut _localctx).Default = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryStatement ----------------
pub type QueryStatementContextAll<'input> = QueryStatementContext<'input>;


pub type QueryStatementContext<'input> = BaseParserRuleContext<'input,QueryStatementContextExt<'input>>;

#[derive(Clone)]
pub struct QueryStatementContextExt<'input>{
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for QueryStatementContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for QueryStatementContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryStatement(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_queryStatement(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for QueryStatementContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_queryStatement(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryStatementContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryStatement }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryStatement }
}
antlr_rust::tid!{QueryStatementContextExt<'a>}

impl<'input> QueryStatementContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryStatementContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryStatementContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryStatementContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<QueryStatementContextExt<'input>>{

fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryStatementContextAttrs<'input> for QueryStatementContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryStatement(&mut self,)
	-> Result<Rc<QueryStatementContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryStatementContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 72, RULE_queryStatement);
        let mut _localctx: Rc<QueryStatementContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule expression*/
			recog.base.set_state(886);
			let tmp = recog.expression()?;
			 cast_mut::<_,QueryStatementContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expression ----------------
pub type ExpressionContextAll<'input> = ExpressionContext<'input>;


pub type ExpressionContext<'input> = BaseParserRuleContext<'input,ExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_expression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_expression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_expression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expression }
}
antlr_rust::tid!{ExpressionContextExt<'a>}

impl<'input> ExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExpressionContextExt<'input>>{

fn pipeExpression(&self) -> Option<Rc<PipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExpressionContextAttrs<'input> for ExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn expression(&mut self,)
	-> Result<Rc<ExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 74, RULE_expression);
        let mut _localctx: Rc<ExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule pipeExpression*/
			recog.base.set_state(888);
			recog.pipeExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pipeExpression ----------------
pub type PipeExpressionContextAll<'input> = PipeExpressionContext<'input>;


pub type PipeExpressionContext<'input> = BaseParserRuleContext<'input,PipeExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PipeExpressionContextExt<'input>{
	pub Expression: Option<Rc<BeforePipeExpressionContextAll<'input>>>,
	pub pipedOperator: Option<Rc<PipedOperatorContextAll<'input>>>,
	pub PipedOperators:Vec<Rc<PipedOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PipeExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PipeExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pipeExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_pipeExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PipeExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_pipeExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PipeExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pipeExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pipeExpression }
}
antlr_rust::tid!{PipeExpressionContextExt<'a>}

impl<'input> PipeExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PipeExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PipeExpressionContextExt{
				Expression: None, pipedOperator: None, 
				PipedOperators: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PipeExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PipeExpressionContextExt<'input>>{

fn beforePipeExpression(&self) -> Option<Rc<BeforePipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pipedOperator_all(&self) ->  Vec<Rc<PipedOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn pipedOperator(&self, i: usize) -> Option<Rc<PipedOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PipeExpressionContextAttrs<'input> for PipeExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pipeExpression(&mut self,)
	-> Result<Rc<PipeExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PipeExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 76, RULE_pipeExpression);
        let mut _localctx: Rc<PipeExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule beforePipeExpression*/
			recog.base.set_state(890);
			let tmp = recog.beforePipeExpression()?;
			 cast_mut::<_,PipeExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(894);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(29,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule pipedOperator*/
					recog.base.set_state(891);
					let tmp = recog.pipedOperator()?;
					 cast_mut::<_,PipeExpressionContext >(&mut _localctx).pipedOperator = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,PipeExpressionContext >(&mut _localctx).pipedOperator.clone().unwrap()
					 ;
					 cast_mut::<_,PipeExpressionContext >(&mut _localctx).PipedOperators.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(896);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(29,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pipedOperator ----------------
pub type PipedOperatorContextAll<'input> = PipedOperatorContext<'input>;


pub type PipedOperatorContext<'input> = BaseParserRuleContext<'input,PipedOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PipedOperatorContextExt<'input>{
	pub Operator: Option<Rc<AfterPipeOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PipedOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PipedOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pipedOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_pipedOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PipedOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_pipedOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for PipedOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pipedOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pipedOperator }
}
antlr_rust::tid!{PipedOperatorContextExt<'a>}

impl<'input> PipedOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PipedOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PipedOperatorContextExt{
				Operator: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PipedOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PipedOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BAR
/// Returns `None` if there is no child corresponding to token BAR
fn BAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BAR, 0)
}
fn afterPipeOperator(&self) -> Option<Rc<AfterPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PipedOperatorContextAttrs<'input> for PipedOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pipedOperator(&mut self,)
	-> Result<Rc<PipedOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PipedOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 78, RULE_pipedOperator);
        let mut _localctx: Rc<PipedOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(897);
			recog.base.match_token(BAR,&mut recog.err_handler)?;

			/*InvokeRule afterPipeOperator*/
			recog.base.set_state(898);
			let tmp = recog.afterPipeOperator()?;
			 cast_mut::<_,PipedOperatorContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- pipeSubExpression ----------------
pub type PipeSubExpressionContextAll<'input> = PipeSubExpressionContext<'input>;


pub type PipeSubExpressionContext<'input> = BaseParserRuleContext<'input,PipeSubExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PipeSubExpressionContextExt<'input>{
	pub Expression: Option<Rc<AfterPipeOperatorContextAll<'input>>>,
	pub pipedOperator: Option<Rc<PipedOperatorContextAll<'input>>>,
	pub PipedOperators:Vec<Rc<PipedOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PipeSubExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PipeSubExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_pipeSubExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_pipeSubExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PipeSubExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_pipeSubExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PipeSubExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_pipeSubExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_pipeSubExpression }
}
antlr_rust::tid!{PipeSubExpressionContextExt<'a>}

impl<'input> PipeSubExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PipeSubExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PipeSubExpressionContextExt{
				Expression: None, pipedOperator: None, 
				PipedOperators: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PipeSubExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PipeSubExpressionContextExt<'input>>{

fn afterPipeOperator(&self) -> Option<Rc<AfterPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn pipedOperator_all(&self) ->  Vec<Rc<PipedOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn pipedOperator(&self, i: usize) -> Option<Rc<PipedOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> PipeSubExpressionContextAttrs<'input> for PipeSubExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn pipeSubExpression(&mut self,)
	-> Result<Rc<PipeSubExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PipeSubExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 80, RULE_pipeSubExpression);
        let mut _localctx: Rc<PipeSubExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule afterPipeOperator*/
			recog.base.set_state(900);
			let tmp = recog.afterPipeOperator()?;
			 cast_mut::<_,PipeSubExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(904);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BAR {
				{
				{
				/*InvokeRule pipedOperator*/
				recog.base.set_state(901);
				let tmp = recog.pipedOperator()?;
				 cast_mut::<_,PipeSubExpressionContext >(&mut _localctx).pipedOperator = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,PipeSubExpressionContext >(&mut _localctx).pipedOperator.clone().unwrap()
				 ;
				 cast_mut::<_,PipeSubExpressionContext >(&mut _localctx).PipedOperators.push(temp);
				  
				}
				}
				recog.base.set_state(906);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- beforePipeExpression ----------------
pub type BeforePipeExpressionContextAll<'input> = BeforePipeExpressionContext<'input>;


pub type BeforePipeExpressionContext<'input> = BaseParserRuleContext<'input,BeforePipeExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BeforePipeExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for BeforePipeExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for BeforePipeExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_beforePipeExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_beforePipeExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for BeforePipeExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_beforePipeExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeforePipeExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_beforePipeExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_beforePipeExpression }
}
antlr_rust::tid!{BeforePipeExpressionContextExt<'a>}

impl<'input> BeforePipeExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BeforePipeExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BeforePipeExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BeforePipeExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<BeforePipeExpressionContextExt<'input>>{

fn beforeOrAfterPipeOperator(&self) -> Option<Rc<BeforeOrAfterPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn printOperator(&self) -> Option<Rc<PrintOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn macroExpandOperator(&self) -> Option<Rc<MacroExpandOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rangeExpression(&self) -> Option<Rc<RangeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scopedFunctionCallExpression(&self) -> Option<Rc<ScopedFunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> BeforePipeExpressionContextAttrs<'input> for BeforePipeExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn beforePipeExpression(&mut self,)
	-> Result<Rc<BeforePipeExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BeforePipeExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 82, RULE_beforePipeExpression);
        let mut _localctx: Rc<BeforePipeExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(913);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(31,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule beforeOrAfterPipeOperator*/
					recog.base.set_state(907);
					recog.beforeOrAfterPipeOperator()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule printOperator*/
					recog.base.set_state(908);
					recog.printOperator()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule macroExpandOperator*/
					recog.base.set_state(909);
					recog.macroExpandOperator()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule rangeExpression*/
					recog.base.set_state(910);
					recog.rangeExpression()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule scopedFunctionCallExpression*/
					recog.base.set_state(911);
					recog.scopedFunctionCallExpression()?;

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule unnamedExpression*/
					recog.base.set_state(912);
					recog.unnamedExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- afterPipeOperator ----------------
pub type AfterPipeOperatorContextAll<'input> = AfterPipeOperatorContext<'input>;


pub type AfterPipeOperatorContext<'input> = BaseParserRuleContext<'input,AfterPipeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct AfterPipeOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AfterPipeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AfterPipeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_afterPipeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_afterPipeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AfterPipeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_afterPipeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for AfterPipeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_afterPipeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_afterPipeOperator }
}
antlr_rust::tid!{AfterPipeOperatorContextExt<'a>}

impl<'input> AfterPipeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AfterPipeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AfterPipeOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait AfterPipeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AfterPipeOperatorContextExt<'input>>{

fn asOperator(&self) -> Option<Rc<AsOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn assertSchemaOperator(&self) -> Option<Rc<AssertSchemaOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn consumeOperator(&self) -> Option<Rc<ConsumeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn countOperator(&self) -> Option<Rc<CountOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn distinctOperator(&self) -> Option<Rc<DistinctOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn executeAndCacheOperator(&self) -> Option<Rc<ExecuteAndCacheOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendOperator(&self) -> Option<Rc<ExtendOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn facetByOperator(&self) -> Option<Rc<FacetByOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperator(&self) -> Option<Rc<FindOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn forkOperator(&self) -> Option<Rc<ForkOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn getSchemaOperator(&self) -> Option<Rc<GetSchemaOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMarkComponentsOperator(&self) -> Option<Rc<GraphMarkComponentsOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMatchOperator(&self) -> Option<Rc<GraphMatchOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMergeOperator(&self) -> Option<Rc<GraphMergeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphShortestPathsOperator(&self) -> Option<Rc<GraphShortestPathsOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphToTableOperator(&self) -> Option<Rc<GraphToTableOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn invokeOperator(&self) -> Option<Rc<InvokeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinOperator(&self) -> Option<Rc<JoinOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn lookupOperator(&self) -> Option<Rc<LookupOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn makeGraphOperator(&self) -> Option<Rc<MakeGraphOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn makeSeriesOperator(&self) -> Option<Rc<MakeSeriesOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mvexpandOperator(&self) -> Option<Rc<MvexpandOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mvapplyOperator(&self) -> Option<Rc<MvapplyOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn evaluateOperator(&self) -> Option<Rc<EvaluateOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperator(&self) -> Option<Rc<ParseOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseKvOperator(&self) -> Option<Rc<ParseKvOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseWhereOperator(&self) -> Option<Rc<ParseWhereOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionOperator(&self) -> Option<Rc<PartitionOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionByOperator(&self) -> Option<Rc<PartitionByOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectOperator(&self) -> Option<Rc<ProjectOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectAwayOperator(&self) -> Option<Rc<ProjectAwayOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectRenameOperator(&self) -> Option<Rc<ProjectRenameOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectReorderOperator(&self) -> Option<Rc<ProjectReorderOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectKeepOperator(&self) -> Option<Rc<ProjectKeepOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn reduceByOperator(&self) -> Option<Rc<ReduceByOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn renderOperator(&self) -> Option<Rc<RenderOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sampleOperator(&self) -> Option<Rc<SampleOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sampleDistinctOperator(&self) -> Option<Rc<SampleDistinctOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scanOperator(&self) -> Option<Rc<ScanOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn searchOperator(&self) -> Option<Rc<SearchOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn serializeOperator(&self) -> Option<Rc<SerializeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sortOperator(&self) -> Option<Rc<SortOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn summarizeOperator(&self) -> Option<Rc<SummarizeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn takeOperator(&self) -> Option<Rc<TakeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topHittersOperator(&self) -> Option<Rc<TopHittersOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topOperator(&self) -> Option<Rc<TopOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topNestedOperator(&self) -> Option<Rc<TopNestedOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unionOperator(&self) -> Option<Rc<UnionOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereOperator(&self) -> Option<Rc<WhereOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AfterPipeOperatorContextAttrs<'input> for AfterPipeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn afterPipeOperator(&mut self,)
	-> Result<Rc<AfterPipeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AfterPipeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 84, RULE_afterPipeOperator);
        let mut _localctx: Rc<AfterPipeOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(964);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 AS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule asOperator*/
					recog.base.set_state(915);
					recog.asOperator()?;

					}
				}

			 ASSERTSCHEMA 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule assertSchemaOperator*/
					recog.base.set_state(916);
					recog.assertSchemaOperator()?;

					}
				}

			 CONSUME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule consumeOperator*/
					recog.base.set_state(917);
					recog.consumeOperator()?;

					}
				}

			 COUNT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule countOperator*/
					recog.base.set_state(918);
					recog.countOperator()?;

					}
				}

			 DISTINCT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule distinctOperator*/
					recog.base.set_state(919);
					recog.distinctOperator()?;

					}
				}

			 EXECUTE_AND_CACHE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule executeAndCacheOperator*/
					recog.base.set_state(920);
					recog.executeAndCacheOperator()?;

					}
				}

			 EXTEND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule extendOperator*/
					recog.base.set_state(921);
					recog.extendOperator()?;

					}
				}

			 FACET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule facetByOperator*/
					recog.base.set_state(922);
					recog.facetByOperator()?;

					}
				}

			 FIND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule findOperator*/
					recog.base.set_state(923);
					recog.findOperator()?;

					}
				}

			 FORK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule forkOperator*/
					recog.base.set_state(924);
					recog.forkOperator()?;

					}
				}

			 GETSCHEMA 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule getSchemaOperator*/
					recog.base.set_state(925);
					recog.getSchemaOperator()?;

					}
				}

			 GRAPHMARKCOMPONENTS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule graphMarkComponentsOperator*/
					recog.base.set_state(926);
					recog.graphMarkComponentsOperator()?;

					}
				}

			 GRAPHMATCH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule graphMatchOperator*/
					recog.base.set_state(927);
					recog.graphMatchOperator()?;

					}
				}

			 GRAPHMERGE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule graphMergeOperator*/
					recog.base.set_state(928);
					recog.graphMergeOperator()?;

					}
				}

			 GRAPHSHORTESTPATHS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					/*InvokeRule graphShortestPathsOperator*/
					recog.base.set_state(929);
					recog.graphShortestPathsOperator()?;

					}
				}

			 GRAPHTOTABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					/*InvokeRule graphToTableOperator*/
					recog.base.set_state(930);
					recog.graphToTableOperator()?;

					}
				}

			 INVOKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					/*InvokeRule invokeOperator*/
					recog.base.set_state(931);
					recog.invokeOperator()?;

					}
				}

			 JOIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 18);
					recog.base.enter_outer_alt(None, 18);
					{
					/*InvokeRule joinOperator*/
					recog.base.set_state(932);
					recog.joinOperator()?;

					}
				}

			 LOOKUP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 19);
					recog.base.enter_outer_alt(None, 19);
					{
					/*InvokeRule lookupOperator*/
					recog.base.set_state(933);
					recog.lookupOperator()?;

					}
				}

			 MAKEGRAPH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 20);
					recog.base.enter_outer_alt(None, 20);
					{
					/*InvokeRule makeGraphOperator*/
					recog.base.set_state(934);
					recog.makeGraphOperator()?;

					}
				}

			 MAKESERIES 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 21);
					recog.base.enter_outer_alt(None, 21);
					{
					/*InvokeRule makeSeriesOperator*/
					recog.base.set_state(935);
					recog.makeSeriesOperator()?;

					}
				}

			 MV_EXPAND | MVEXPAND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 22);
					recog.base.enter_outer_alt(None, 22);
					{
					/*InvokeRule mvexpandOperator*/
					recog.base.set_state(936);
					recog.mvexpandOperator()?;

					}
				}

			 MV_APPLY | MVAPPLY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 23);
					recog.base.enter_outer_alt(None, 23);
					{
					/*InvokeRule mvapplyOperator*/
					recog.base.set_state(937);
					recog.mvapplyOperator()?;

					}
				}

			 EVALUATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 24);
					recog.base.enter_outer_alt(None, 24);
					{
					/*InvokeRule evaluateOperator*/
					recog.base.set_state(938);
					recog.evaluateOperator()?;

					}
				}

			 PARSE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 25);
					recog.base.enter_outer_alt(None, 25);
					{
					/*InvokeRule parseOperator*/
					recog.base.set_state(939);
					recog.parseOperator()?;

					}
				}

			 PARSEKV 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 26);
					recog.base.enter_outer_alt(None, 26);
					{
					/*InvokeRule parseKvOperator*/
					recog.base.set_state(940);
					recog.parseKvOperator()?;

					}
				}

			 PARSEWHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 27);
					recog.base.enter_outer_alt(None, 27);
					{
					/*InvokeRule parseWhereOperator*/
					recog.base.set_state(941);
					recog.parseWhereOperator()?;

					}
				}

			 PARTITION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 28);
					recog.base.enter_outer_alt(None, 28);
					{
					/*InvokeRule partitionOperator*/
					recog.base.set_state(942);
					recog.partitionOperator()?;

					}
				}

			 PARTITIONBY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 29);
					recog.base.enter_outer_alt(None, 29);
					{
					/*InvokeRule partitionByOperator*/
					recog.base.set_state(943);
					recog.partitionByOperator()?;

					}
				}

			 PROJECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 30);
					recog.base.enter_outer_alt(None, 30);
					{
					/*InvokeRule projectOperator*/
					recog.base.set_state(944);
					recog.projectOperator()?;

					}
				}

			 PROJECTAWAY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 31);
					recog.base.enter_outer_alt(None, 31);
					{
					/*InvokeRule projectAwayOperator*/
					recog.base.set_state(945);
					recog.projectAwayOperator()?;

					}
				}

			 PROJECTRENAME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 32);
					recog.base.enter_outer_alt(None, 32);
					{
					/*InvokeRule projectRenameOperator*/
					recog.base.set_state(946);
					recog.projectRenameOperator()?;

					}
				}

			 PROJECTREORDER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 33);
					recog.base.enter_outer_alt(None, 33);
					{
					/*InvokeRule projectReorderOperator*/
					recog.base.set_state(947);
					recog.projectReorderOperator()?;

					}
				}

			 PROJECTKEEP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 34);
					recog.base.enter_outer_alt(None, 34);
					{
					/*InvokeRule projectKeepOperator*/
					recog.base.set_state(948);
					recog.projectKeepOperator()?;

					}
				}

			 REDUCE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 35);
					recog.base.enter_outer_alt(None, 35);
					{
					/*InvokeRule reduceByOperator*/
					recog.base.set_state(949);
					recog.reduceByOperator()?;

					}
				}

			 RENDER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 36);
					recog.base.enter_outer_alt(None, 36);
					{
					/*InvokeRule renderOperator*/
					recog.base.set_state(950);
					recog.renderOperator()?;

					}
				}

			 SAMPLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 37);
					recog.base.enter_outer_alt(None, 37);
					{
					/*InvokeRule sampleOperator*/
					recog.base.set_state(951);
					recog.sampleOperator()?;

					}
				}

			 SAMPLE_DISTINCT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 38);
					recog.base.enter_outer_alt(None, 38);
					{
					/*InvokeRule sampleDistinctOperator*/
					recog.base.set_state(952);
					recog.sampleDistinctOperator()?;

					}
				}

			 SCAN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 39);
					recog.base.enter_outer_alt(None, 39);
					{
					/*InvokeRule scanOperator*/
					recog.base.set_state(953);
					recog.scanOperator()?;

					}
				}

			 SEARCH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 40);
					recog.base.enter_outer_alt(None, 40);
					{
					/*InvokeRule searchOperator*/
					recog.base.set_state(954);
					recog.searchOperator()?;

					}
				}

			 SERIALIZE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 41);
					recog.base.enter_outer_alt(None, 41);
					{
					/*InvokeRule serializeOperator*/
					recog.base.set_state(955);
					recog.serializeOperator()?;

					}
				}

			 ORDER | SORT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 42);
					recog.base.enter_outer_alt(None, 42);
					{
					/*InvokeRule sortOperator*/
					recog.base.set_state(956);
					recog.sortOperator()?;

					}
				}

			 SUMMARIZE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 43);
					recog.base.enter_outer_alt(None, 43);
					{
					/*InvokeRule summarizeOperator*/
					recog.base.set_state(957);
					recog.summarizeOperator()?;

					}
				}

			 LIMIT | TAKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 44);
					recog.base.enter_outer_alt(None, 44);
					{
					/*InvokeRule takeOperator*/
					recog.base.set_state(958);
					recog.takeOperator()?;

					}
				}

			 TOP_HITTERS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 45);
					recog.base.enter_outer_alt(None, 45);
					{
					/*InvokeRule topHittersOperator*/
					recog.base.set_state(959);
					recog.topHittersOperator()?;

					}
				}

			 TOP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 46);
					recog.base.enter_outer_alt(None, 46);
					{
					/*InvokeRule topOperator*/
					recog.base.set_state(960);
					recog.topOperator()?;

					}
				}

			 TOP_NESTED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 47);
					recog.base.enter_outer_alt(None, 47);
					{
					/*InvokeRule topNestedOperator*/
					recog.base.set_state(961);
					recog.topNestedOperator()?;

					}
				}

			 UNION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 48);
					recog.base.enter_outer_alt(None, 48);
					{
					/*InvokeRule unionOperator*/
					recog.base.set_state(962);
					recog.unionOperator()?;

					}
				}

			 FILTER | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 49);
					recog.base.enter_outer_alt(None, 49);
					{
					/*InvokeRule whereOperator*/
					recog.base.set_state(963);
					recog.whereOperator()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- beforeOrAfterPipeOperator ----------------
pub type BeforeOrAfterPipeOperatorContextAll<'input> = BeforeOrAfterPipeOperatorContext<'input>;


pub type BeforeOrAfterPipeOperatorContext<'input> = BaseParserRuleContext<'input,BeforeOrAfterPipeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct BeforeOrAfterPipeOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for BeforeOrAfterPipeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for BeforeOrAfterPipeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_beforeOrAfterPipeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_beforeOrAfterPipeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for BeforeOrAfterPipeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_beforeOrAfterPipeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for BeforeOrAfterPipeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_beforeOrAfterPipeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_beforeOrAfterPipeOperator }
}
antlr_rust::tid!{BeforeOrAfterPipeOperatorContextExt<'a>}

impl<'input> BeforeOrAfterPipeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BeforeOrAfterPipeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BeforeOrAfterPipeOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait BeforeOrAfterPipeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<BeforeOrAfterPipeOperatorContextExt<'input>>{

fn findOperator(&self) -> Option<Rc<FindOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn searchOperator(&self) -> Option<Rc<SearchOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unionOperator(&self) -> Option<Rc<UnionOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn evaluateOperator(&self) -> Option<Rc<EvaluateOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> BeforeOrAfterPipeOperatorContextAttrs<'input> for BeforeOrAfterPipeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn beforeOrAfterPipeOperator(&mut self,)
	-> Result<Rc<BeforeOrAfterPipeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BeforeOrAfterPipeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 86, RULE_beforeOrAfterPipeOperator);
        let mut _localctx: Rc<BeforeOrAfterPipeOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(970);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 FIND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule findOperator*/
					recog.base.set_state(966);
					recog.findOperator()?;

					}
				}

			 SEARCH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule searchOperator*/
					recog.base.set_state(967);
					recog.searchOperator()?;

					}
				}

			 UNION 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule unionOperator*/
					recog.base.set_state(968);
					recog.unionOperator()?;

					}
				}

			 EVALUATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule evaluateOperator*/
					recog.base.set_state(969);
					recog.evaluateOperator()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forkPipeOperator ----------------
pub type ForkPipeOperatorContextAll<'input> = ForkPipeOperatorContext<'input>;


pub type ForkPipeOperatorContext<'input> = BaseParserRuleContext<'input,ForkPipeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ForkPipeOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ForkPipeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ForkPipeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forkPipeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_forkPipeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ForkPipeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_forkPipeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForkPipeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forkPipeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forkPipeOperator }
}
antlr_rust::tid!{ForkPipeOperatorContextExt<'a>}

impl<'input> ForkPipeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForkPipeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForkPipeOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ForkPipeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ForkPipeOperatorContextExt<'input>>{

fn countOperator(&self) -> Option<Rc<CountOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendOperator(&self) -> Option<Rc<ExtendOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn whereOperator(&self) -> Option<Rc<WhereOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperator(&self) -> Option<Rc<ParseOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseWhereOperator(&self) -> Option<Rc<ParseWhereOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn takeOperator(&self) -> Option<Rc<TakeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topNestedOperator(&self) -> Option<Rc<TopNestedOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectOperator(&self) -> Option<Rc<ProjectOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectAwayOperator(&self) -> Option<Rc<ProjectAwayOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectRenameOperator(&self) -> Option<Rc<ProjectRenameOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectReorderOperator(&self) -> Option<Rc<ProjectReorderOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn projectKeepOperator(&self) -> Option<Rc<ProjectKeepOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn summarizeOperator(&self) -> Option<Rc<SummarizeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn distinctOperator(&self) -> Option<Rc<DistinctOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topHittersOperator(&self) -> Option<Rc<TopHittersOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topOperator(&self) -> Option<Rc<TopOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sortOperator(&self) -> Option<Rc<SortOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mvexpandOperator(&self) -> Option<Rc<MvexpandOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn reduceByOperator(&self) -> Option<Rc<ReduceByOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sampleOperator(&self) -> Option<Rc<SampleOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sampleDistinctOperator(&self) -> Option<Rc<SampleDistinctOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn asOperator(&self) -> Option<Rc<AsOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn invokeOperator(&self) -> Option<Rc<InvokeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn executeAndCacheOperator(&self) -> Option<Rc<ExecuteAndCacheOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scanOperator(&self) -> Option<Rc<ScanOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForkPipeOperatorContextAttrs<'input> for ForkPipeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forkPipeOperator(&mut self,)
	-> Result<Rc<ForkPipeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForkPipeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 88, RULE_forkPipeOperator);
        let mut _localctx: Rc<ForkPipeOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(997);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 COUNT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule countOperator*/
					recog.base.set_state(972);
					recog.countOperator()?;

					}
				}

			 EXTEND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule extendOperator*/
					recog.base.set_state(973);
					recog.extendOperator()?;

					}
				}

			 FILTER | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule whereOperator*/
					recog.base.set_state(974);
					recog.whereOperator()?;

					}
				}

			 PARSE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule parseOperator*/
					recog.base.set_state(975);
					recog.parseOperator()?;

					}
				}

			 PARSEWHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule parseWhereOperator*/
					recog.base.set_state(976);
					recog.parseWhereOperator()?;

					}
				}

			 LIMIT | TAKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule takeOperator*/
					recog.base.set_state(977);
					recog.takeOperator()?;

					}
				}

			 TOP_NESTED 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule topNestedOperator*/
					recog.base.set_state(978);
					recog.topNestedOperator()?;

					}
				}

			 PROJECT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule projectOperator*/
					recog.base.set_state(979);
					recog.projectOperator()?;

					}
				}

			 PROJECTAWAY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule projectAwayOperator*/
					recog.base.set_state(980);
					recog.projectAwayOperator()?;

					}
				}

			 PROJECTRENAME 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule projectRenameOperator*/
					recog.base.set_state(981);
					recog.projectRenameOperator()?;

					}
				}

			 PROJECTREORDER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule projectReorderOperator*/
					recog.base.set_state(982);
					recog.projectReorderOperator()?;

					}
				}

			 PROJECTKEEP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					/*InvokeRule projectKeepOperator*/
					recog.base.set_state(983);
					recog.projectKeepOperator()?;

					}
				}

			 SUMMARIZE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					/*InvokeRule summarizeOperator*/
					recog.base.set_state(984);
					recog.summarizeOperator()?;

					}
				}

			 DISTINCT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					/*InvokeRule distinctOperator*/
					recog.base.set_state(985);
					recog.distinctOperator()?;

					}
				}

			 TOP_HITTERS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					/*InvokeRule topHittersOperator*/
					recog.base.set_state(986);
					recog.topHittersOperator()?;

					}
				}

			 TOP 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					/*InvokeRule topOperator*/
					recog.base.set_state(987);
					recog.topOperator()?;

					}
				}

			 ORDER | SORT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					/*InvokeRule sortOperator*/
					recog.base.set_state(988);
					recog.sortOperator()?;

					}
				}

			 MV_EXPAND | MVEXPAND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 18);
					recog.base.enter_outer_alt(None, 18);
					{
					/*InvokeRule mvexpandOperator*/
					recog.base.set_state(989);
					recog.mvexpandOperator()?;

					}
				}

			 REDUCE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 19);
					recog.base.enter_outer_alt(None, 19);
					{
					/*InvokeRule reduceByOperator*/
					recog.base.set_state(990);
					recog.reduceByOperator()?;

					}
				}

			 SAMPLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 20);
					recog.base.enter_outer_alt(None, 20);
					{
					/*InvokeRule sampleOperator*/
					recog.base.set_state(991);
					recog.sampleOperator()?;

					}
				}

			 SAMPLE_DISTINCT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 21);
					recog.base.enter_outer_alt(None, 21);
					{
					/*InvokeRule sampleDistinctOperator*/
					recog.base.set_state(992);
					recog.sampleDistinctOperator()?;

					}
				}

			 AS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 22);
					recog.base.enter_outer_alt(None, 22);
					{
					/*InvokeRule asOperator*/
					recog.base.set_state(993);
					recog.asOperator()?;

					}
				}

			 INVOKE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 23);
					recog.base.enter_outer_alt(None, 23);
					{
					/*InvokeRule invokeOperator*/
					recog.base.set_state(994);
					recog.invokeOperator()?;

					}
				}

			 EXECUTE_AND_CACHE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 24);
					recog.base.enter_outer_alt(None, 24);
					{
					/*InvokeRule executeAndCacheOperator*/
					recog.base.set_state(995);
					recog.executeAndCacheOperator()?;

					}
				}

			 SCAN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 25);
					recog.base.enter_outer_alt(None, 25);
					{
					/*InvokeRule scanOperator*/
					recog.base.set_state(996);
					recog.scanOperator()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- asOperator ----------------
pub type AsOperatorContextAll<'input> = AsOperatorContext<'input>;


pub type AsOperatorContext<'input> = BaseParserRuleContext<'input,AsOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct AsOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AsOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AsOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_asOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_asOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AsOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_asOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for AsOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_asOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_asOperator }
}
antlr_rust::tid!{AsOperatorContextExt<'a>}

impl<'input> AsOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AsOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AsOperatorContextExt{
				relaxedQueryOperatorParameter: None, Name: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait AsOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AsOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> AsOperatorContextAttrs<'input> for AsOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn asOperator(&mut self,)
	-> Result<Rc<AsOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AsOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 90, RULE_asOperator);
        let mut _localctx: Rc<AsOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(999);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			recog.base.set_state(1003);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(35,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1000);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,AsOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,AsOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,AsOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1005);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(35,&mut recog.base)?;
			}
			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1006);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,AsOperatorContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- assertSchemaOperator ----------------
pub type AssertSchemaOperatorContextAll<'input> = AssertSchemaOperatorContext<'input>;


pub type AssertSchemaOperatorContext<'input> = BaseParserRuleContext<'input,AssertSchemaOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct AssertSchemaOperatorContextExt<'input>{
	pub Schema: Option<Rc<RowSchemaContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AssertSchemaOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AssertSchemaOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_assertSchemaOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_assertSchemaOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AssertSchemaOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_assertSchemaOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for AssertSchemaOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_assertSchemaOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_assertSchemaOperator }
}
antlr_rust::tid!{AssertSchemaOperatorContextExt<'a>}

impl<'input> AssertSchemaOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AssertSchemaOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AssertSchemaOperatorContextExt{
				Schema: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AssertSchemaOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AssertSchemaOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASSERTSCHEMA
/// Returns `None` if there is no child corresponding to token ASSERTSCHEMA
fn ASSERTSCHEMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASSERTSCHEMA, 0)
}
fn rowSchema(&self) -> Option<Rc<RowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> AssertSchemaOperatorContextAttrs<'input> for AssertSchemaOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn assertSchemaOperator(&mut self,)
	-> Result<Rc<AssertSchemaOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AssertSchemaOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 92, RULE_assertSchemaOperator);
        let mut _localctx: Rc<AssertSchemaOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1008);
			recog.base.match_token(ASSERTSCHEMA,&mut recog.err_handler)?;

			/*InvokeRule rowSchema*/
			recog.base.set_state(1009);
			let tmp = recog.rowSchema()?;
			 cast_mut::<_,AssertSchemaOperatorContext >(&mut _localctx).Schema = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- consumeOperator ----------------
pub type ConsumeOperatorContextAll<'input> = ConsumeOperatorContext<'input>;


pub type ConsumeOperatorContext<'input> = BaseParserRuleContext<'input,ConsumeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ConsumeOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ConsumeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ConsumeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_consumeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_consumeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ConsumeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_consumeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ConsumeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_consumeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_consumeOperator }
}
antlr_rust::tid!{ConsumeOperatorContextExt<'a>}

impl<'input> ConsumeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ConsumeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ConsumeOperatorContextExt{
				relaxedQueryOperatorParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ConsumeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ConsumeOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CONSUME
/// Returns `None` if there is no child corresponding to token CONSUME
fn CONSUME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONSUME, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ConsumeOperatorContextAttrs<'input> for ConsumeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn consumeOperator(&mut self,)
	-> Result<Rc<ConsumeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ConsumeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 94, RULE_consumeOperator);
        let mut _localctx: Rc<ConsumeOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1011);
			recog.base.match_token(CONSUME,&mut recog.err_handler)?;

			recog.base.set_state(1015);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1012);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,ConsumeOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ConsumeOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,ConsumeOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1017);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- countOperator ----------------
pub type CountOperatorContextAll<'input> = CountOperatorContext<'input>;


pub type CountOperatorContext<'input> = BaseParserRuleContext<'input,CountOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct CountOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for CountOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for CountOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_countOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_countOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for CountOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_countOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for CountOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_countOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_countOperator }
}
antlr_rust::tid!{CountOperatorContextExt<'a>}

impl<'input> CountOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CountOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CountOperatorContextExt{
				relaxedQueryOperatorParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait CountOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<CountOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> CountOperatorContextAttrs<'input> for CountOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn countOperator(&mut self,)
	-> Result<Rc<CountOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CountOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 96, RULE_countOperator);
        let mut _localctx: Rc<CountOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1018);
			recog.base.match_token(COUNT,&mut recog.err_handler)?;

			recog.base.set_state(1022);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1019);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,CountOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,CountOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,CountOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1024);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- countOperatorAsClause ----------------
pub type CountOperatorAsClauseContextAll<'input> = CountOperatorAsClauseContext<'input>;


pub type CountOperatorAsClauseContext<'input> = BaseParserRuleContext<'input,CountOperatorAsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct CountOperatorAsClauseContextExt<'input>{
	pub Name: Option<Rc<IdentifierNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for CountOperatorAsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for CountOperatorAsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_countOperatorAsClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_countOperatorAsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for CountOperatorAsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_countOperatorAsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for CountOperatorAsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_countOperatorAsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_countOperatorAsClause }
}
antlr_rust::tid!{CountOperatorAsClauseContextExt<'a>}

impl<'input> CountOperatorAsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CountOperatorAsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CountOperatorAsClauseContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CountOperatorAsClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<CountOperatorAsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierName(&self) -> Option<Rc<IdentifierNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CountOperatorAsClauseContextAttrs<'input> for CountOperatorAsClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn countOperatorAsClause(&mut self,)
	-> Result<Rc<CountOperatorAsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CountOperatorAsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 98, RULE_countOperatorAsClause);
        let mut _localctx: Rc<CountOperatorAsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1025);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule identifierName*/
			recog.base.set_state(1026);
			let tmp = recog.identifierName()?;
			 cast_mut::<_,CountOperatorAsClauseContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- distinctOperator ----------------
pub type DistinctOperatorContextAll<'input> = DistinctOperatorContext<'input>;


pub type DistinctOperatorContext<'input> = BaseParserRuleContext<'input,DistinctOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct DistinctOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Star: Option<Rc<DistinctOperatorStarTargetContextAll<'input>>>,
	pub ColumnList: Option<Rc<DistinctOperatorColumnListTargetContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DistinctOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DistinctOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_distinctOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_distinctOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DistinctOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_distinctOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for DistinctOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_distinctOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_distinctOperator }
}
antlr_rust::tid!{DistinctOperatorContextExt<'a>}

impl<'input> DistinctOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DistinctOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DistinctOperatorContextExt{
				relaxedQueryOperatorParameter: None, Star: None, ColumnList: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DistinctOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DistinctOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
fn distinctOperatorStarTarget(&self) -> Option<Rc<DistinctOperatorStarTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn distinctOperatorColumnListTarget(&self) -> Option<Rc<DistinctOperatorColumnListTargetContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DistinctOperatorContextAttrs<'input> for DistinctOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn distinctOperator(&mut self,)
	-> Result<Rc<DistinctOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DistinctOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 100, RULE_distinctOperator);
        let mut _localctx: Rc<DistinctOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1028);
			recog.base.match_token(DISTINCT,&mut recog.err_handler)?;

			recog.base.set_state(1032);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(38,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1029);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,DistinctOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,DistinctOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,DistinctOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1034);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(38,&mut recog.base)?;
			}
			recog.base.set_state(1037);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(39,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule distinctOperatorStarTarget*/
					recog.base.set_state(1035);
					let tmp = recog.distinctOperatorStarTarget()?;
					 cast_mut::<_,DistinctOperatorContext >(&mut _localctx).Star = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					/*InvokeRule distinctOperatorColumnListTarget*/
					recog.base.set_state(1036);
					let tmp = recog.distinctOperatorColumnListTarget()?;
					 cast_mut::<_,DistinctOperatorContext >(&mut _localctx).ColumnList = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- distinctOperatorStarTarget ----------------
pub type DistinctOperatorStarTargetContextAll<'input> = DistinctOperatorStarTargetContext<'input>;


pub type DistinctOperatorStarTargetContext<'input> = BaseParserRuleContext<'input,DistinctOperatorStarTargetContextExt<'input>>;

#[derive(Clone)]
pub struct DistinctOperatorStarTargetContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DistinctOperatorStarTargetContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DistinctOperatorStarTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_distinctOperatorStarTarget(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_distinctOperatorStarTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DistinctOperatorStarTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_distinctOperatorStarTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for DistinctOperatorStarTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_distinctOperatorStarTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_distinctOperatorStarTarget }
}
antlr_rust::tid!{DistinctOperatorStarTargetContextExt<'a>}

impl<'input> DistinctOperatorStarTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DistinctOperatorStarTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DistinctOperatorStarTargetContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait DistinctOperatorStarTargetContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DistinctOperatorStarTargetContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> DistinctOperatorStarTargetContextAttrs<'input> for DistinctOperatorStarTargetContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn distinctOperatorStarTarget(&mut self,)
	-> Result<Rc<DistinctOperatorStarTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DistinctOperatorStarTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 102, RULE_distinctOperatorStarTarget);
        let mut _localctx: Rc<DistinctOperatorStarTargetContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1039);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- distinctOperatorColumnListTarget ----------------
pub type DistinctOperatorColumnListTargetContextAll<'input> = DistinctOperatorColumnListTargetContext<'input>;


pub type DistinctOperatorColumnListTargetContext<'input> = BaseParserRuleContext<'input,DistinctOperatorColumnListTargetContextExt<'input>>;

#[derive(Clone)]
pub struct DistinctOperatorColumnListTargetContextExt<'input>{
	pub unnamedExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DistinctOperatorColumnListTargetContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DistinctOperatorColumnListTargetContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_distinctOperatorColumnListTarget(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_distinctOperatorColumnListTarget(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DistinctOperatorColumnListTargetContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_distinctOperatorColumnListTarget(self);
	}
}

impl<'input> CustomRuleContext<'input> for DistinctOperatorColumnListTargetContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_distinctOperatorColumnListTarget }
	//fn type_rule_index() -> usize where Self: Sized { RULE_distinctOperatorColumnListTarget }
}
antlr_rust::tid!{DistinctOperatorColumnListTargetContextExt<'a>}

impl<'input> DistinctOperatorColumnListTargetContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DistinctOperatorColumnListTargetContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DistinctOperatorColumnListTargetContextExt{
				unnamedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DistinctOperatorColumnListTargetContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DistinctOperatorColumnListTargetContextExt<'input>>{

fn unnamedExpression_all(&self) ->  Vec<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unnamedExpression(&self, i: usize) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> DistinctOperatorColumnListTargetContextAttrs<'input> for DistinctOperatorColumnListTargetContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn distinctOperatorColumnListTarget(&mut self,)
	-> Result<Rc<DistinctOperatorColumnListTargetContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DistinctOperatorColumnListTargetContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 104, RULE_distinctOperatorColumnListTarget);
        let mut _localctx: Rc<DistinctOperatorColumnListTargetContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1041);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,DistinctOperatorColumnListTargetContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,DistinctOperatorColumnListTargetContext >(&mut _localctx).unnamedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,DistinctOperatorColumnListTargetContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1046);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1042);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unnamedExpression*/
				recog.base.set_state(1043);
				let tmp = recog.unnamedExpression()?;
				 cast_mut::<_,DistinctOperatorColumnListTargetContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DistinctOperatorColumnListTargetContext >(&mut _localctx).unnamedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,DistinctOperatorColumnListTargetContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1048);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- evaluateOperator ----------------
pub type EvaluateOperatorContextAll<'input> = EvaluateOperatorContext<'input>;


pub type EvaluateOperatorContext<'input> = BaseParserRuleContext<'input,EvaluateOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct EvaluateOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub PlugInCall: Option<Rc<FunctionCallExpressionContextAll<'input>>>,
	pub SchemaClause: Option<Rc<EvaluateOperatorSchemaClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EvaluateOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EvaluateOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_evaluateOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_evaluateOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EvaluateOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_evaluateOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for EvaluateOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_evaluateOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_evaluateOperator }
}
antlr_rust::tid!{EvaluateOperatorContextExt<'a>}

impl<'input> EvaluateOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EvaluateOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EvaluateOperatorContextExt{
				relaxedQueryOperatorParameter: None, PlugInCall: None, SchemaClause: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait EvaluateOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EvaluateOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EVALUATE
/// Returns `None` if there is no child corresponding to token EVALUATE
fn EVALUATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EVALUATE, 0)
}
fn functionCallExpression(&self) -> Option<Rc<FunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn evaluateOperatorSchemaClause(&self) -> Option<Rc<EvaluateOperatorSchemaClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EvaluateOperatorContextAttrs<'input> for EvaluateOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn evaluateOperator(&mut self,)
	-> Result<Rc<EvaluateOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EvaluateOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 106, RULE_evaluateOperator);
        let mut _localctx: Rc<EvaluateOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1049);
			recog.base.match_token(EVALUATE,&mut recog.err_handler)?;

			recog.base.set_state(1053);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(41,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1050);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,EvaluateOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,EvaluateOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,EvaluateOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1055);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(41,&mut recog.base)?;
			}
			/*InvokeRule functionCallExpression*/
			recog.base.set_state(1056);
			let tmp = recog.functionCallExpression()?;
			 cast_mut::<_,EvaluateOperatorContext >(&mut _localctx).PlugInCall = Some(tmp.clone());
			  

			recog.base.set_state(1058);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COLON {
				{
				/*InvokeRule evaluateOperatorSchemaClause*/
				recog.base.set_state(1057);
				let tmp = recog.evaluateOperatorSchemaClause()?;
				 cast_mut::<_,EvaluateOperatorContext >(&mut _localctx).SchemaClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- evaluateOperatorSchemaClause ----------------
pub type EvaluateOperatorSchemaClauseContextAll<'input> = EvaluateOperatorSchemaClauseContext<'input>;


pub type EvaluateOperatorSchemaClauseContext<'input> = BaseParserRuleContext<'input,EvaluateOperatorSchemaClauseContextExt<'input>>;

#[derive(Clone)]
pub struct EvaluateOperatorSchemaClauseContextExt<'input>{
	pub Schema: Option<Rc<RowSchemaContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EvaluateOperatorSchemaClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EvaluateOperatorSchemaClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_evaluateOperatorSchemaClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_evaluateOperatorSchemaClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EvaluateOperatorSchemaClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_evaluateOperatorSchemaClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for EvaluateOperatorSchemaClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_evaluateOperatorSchemaClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_evaluateOperatorSchemaClause }
}
antlr_rust::tid!{EvaluateOperatorSchemaClauseContextExt<'a>}

impl<'input> EvaluateOperatorSchemaClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EvaluateOperatorSchemaClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EvaluateOperatorSchemaClauseContextExt{
				Schema: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EvaluateOperatorSchemaClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EvaluateOperatorSchemaClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn rowSchema(&self) -> Option<Rc<RowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EvaluateOperatorSchemaClauseContextAttrs<'input> for EvaluateOperatorSchemaClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn evaluateOperatorSchemaClause(&mut self,)
	-> Result<Rc<EvaluateOperatorSchemaClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EvaluateOperatorSchemaClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 108, RULE_evaluateOperatorSchemaClause);
        let mut _localctx: Rc<EvaluateOperatorSchemaClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1060);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule rowSchema*/
			recog.base.set_state(1061);
			let tmp = recog.rowSchema()?;
			 cast_mut::<_,EvaluateOperatorSchemaClauseContext >(&mut _localctx).Schema = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extendOperator ----------------
pub type ExtendOperatorContextAll<'input> = ExtendOperatorContext<'input>;


pub type ExtendOperatorContext<'input> = BaseParserRuleContext<'input,ExtendOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ExtendOperatorContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExtendOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExtendOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extendOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_extendOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExtendOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_extendOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtendOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extendOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extendOperator }
}
antlr_rust::tid!{ExtendOperatorContextExt<'a>}

impl<'input> ExtendOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtendOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtendOperatorContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtendOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExtendOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EXTEND
/// Returns `None` if there is no child corresponding to token EXTEND
fn EXTEND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXTEND, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExtendOperatorContextAttrs<'input> for ExtendOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extendOperator(&mut self,)
	-> Result<Rc<ExtendOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtendOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 110, RULE_extendOperator);
        let mut _localctx: Rc<ExtendOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1063);
			recog.base.match_token(EXTEND,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1064);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,ExtendOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ExtendOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ExtendOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1069);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1065);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1066);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,ExtendOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ExtendOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ExtendOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1071);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- executeAndCacheOperator ----------------
pub type ExecuteAndCacheOperatorContextAll<'input> = ExecuteAndCacheOperatorContext<'input>;


pub type ExecuteAndCacheOperatorContext<'input> = BaseParserRuleContext<'input,ExecuteAndCacheOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ExecuteAndCacheOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExecuteAndCacheOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExecuteAndCacheOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_executeAndCacheOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_executeAndCacheOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExecuteAndCacheOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_executeAndCacheOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExecuteAndCacheOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_executeAndCacheOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_executeAndCacheOperator }
}
antlr_rust::tid!{ExecuteAndCacheOperatorContextExt<'a>}

impl<'input> ExecuteAndCacheOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExecuteAndCacheOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExecuteAndCacheOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExecuteAndCacheOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExecuteAndCacheOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EXECUTE_AND_CACHE
/// Returns `None` if there is no child corresponding to token EXECUTE_AND_CACHE
fn EXECUTE_AND_CACHE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE_AND_CACHE, 0)
}

}

impl<'input> ExecuteAndCacheOperatorContextAttrs<'input> for ExecuteAndCacheOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn executeAndCacheOperator(&mut self,)
	-> Result<Rc<ExecuteAndCacheOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExecuteAndCacheOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 112, RULE_executeAndCacheOperator);
        let mut _localctx: Rc<ExecuteAndCacheOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1072);
			recog.base.match_token(EXECUTE_AND_CACHE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- facetByOperator ----------------
pub type FacetByOperatorContextAll<'input> = FacetByOperatorContext<'input>;


pub type FacetByOperatorContext<'input> = BaseParserRuleContext<'input,FacetByOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct FacetByOperatorContextExt<'input>{
	pub entityExpression: Option<Rc<EntityExpressionContextAll<'input>>>,
	pub Entities:Vec<Rc<EntityExpressionContextAll<'input>>>,
	pub WithOperatorClause: Option<Rc<FacetByOperatorWithOperatorClauseContextAll<'input>>>,
	pub WithExpressionClause: Option<Rc<FacetByOperatorWithExpressionClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FacetByOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FacetByOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_facetByOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_facetByOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FacetByOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_facetByOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for FacetByOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_facetByOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_facetByOperator }
}
antlr_rust::tid!{FacetByOperatorContextExt<'a>}

impl<'input> FacetByOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FacetByOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FacetByOperatorContextExt{
				entityExpression: None, WithOperatorClause: None, WithExpressionClause: None, 
				Entities: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FacetByOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FacetByOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FACET
/// Returns `None` if there is no child corresponding to token FACET
fn FACET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FACET, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn entityExpression_all(&self) ->  Vec<Rc<EntityExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn entityExpression(&self, i: usize) -> Option<Rc<EntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn facetByOperatorWithOperatorClause(&self) -> Option<Rc<FacetByOperatorWithOperatorClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn facetByOperatorWithExpressionClause(&self) -> Option<Rc<FacetByOperatorWithExpressionClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FacetByOperatorContextAttrs<'input> for FacetByOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn facetByOperator(&mut self,)
	-> Result<Rc<FacetByOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FacetByOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 114, RULE_facetByOperator);
        let mut _localctx: Rc<FacetByOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1074);
			recog.base.match_token(FACET,&mut recog.err_handler)?;

			recog.base.set_state(1075);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule entityExpression*/
			recog.base.set_state(1076);
			let tmp = recog.entityExpression()?;
			 cast_mut::<_,FacetByOperatorContext >(&mut _localctx).entityExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,FacetByOperatorContext >(&mut _localctx).entityExpression.clone().unwrap()
			 ;
			 cast_mut::<_,FacetByOperatorContext >(&mut _localctx).Entities.push(temp);
			  
			recog.base.set_state(1081);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1077);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule entityExpression*/
				recog.base.set_state(1078);
				let tmp = recog.entityExpression()?;
				 cast_mut::<_,FacetByOperatorContext >(&mut _localctx).entityExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FacetByOperatorContext >(&mut _localctx).entityExpression.clone().unwrap()
				 ;
				 cast_mut::<_,FacetByOperatorContext >(&mut _localctx).Entities.push(temp);
				  
				}
				}
				recog.base.set_state(1083);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1086);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(45,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule facetByOperatorWithOperatorClause*/
					recog.base.set_state(1084);
					let tmp = recog.facetByOperatorWithOperatorClause()?;
					 cast_mut::<_,FacetByOperatorContext >(&mut _localctx).WithOperatorClause = Some(tmp.clone());
					  

					}
				}

				x if x == 2=>{
					{
					/*InvokeRule facetByOperatorWithExpressionClause*/
					recog.base.set_state(1085);
					let tmp = recog.facetByOperatorWithExpressionClause()?;
					 cast_mut::<_,FacetByOperatorContext >(&mut _localctx).WithExpressionClause = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- facetByOperatorWithOperatorClause ----------------
pub type FacetByOperatorWithOperatorClauseContextAll<'input> = FacetByOperatorWithOperatorClauseContext<'input>;


pub type FacetByOperatorWithOperatorClauseContext<'input> = BaseParserRuleContext<'input,FacetByOperatorWithOperatorClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FacetByOperatorWithOperatorClauseContextExt<'input>{
	pub Operator: Option<Rc<ForkPipeOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FacetByOperatorWithOperatorClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FacetByOperatorWithOperatorClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_facetByOperatorWithOperatorClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_facetByOperatorWithOperatorClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FacetByOperatorWithOperatorClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_facetByOperatorWithOperatorClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FacetByOperatorWithOperatorClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_facetByOperatorWithOperatorClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_facetByOperatorWithOperatorClause }
}
antlr_rust::tid!{FacetByOperatorWithOperatorClauseContextExt<'a>}

impl<'input> FacetByOperatorWithOperatorClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FacetByOperatorWithOperatorClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FacetByOperatorWithOperatorClauseContextExt{
				Operator: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FacetByOperatorWithOperatorClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FacetByOperatorWithOperatorClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn forkPipeOperator(&self) -> Option<Rc<ForkPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FacetByOperatorWithOperatorClauseContextAttrs<'input> for FacetByOperatorWithOperatorClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn facetByOperatorWithOperatorClause(&mut self,)
	-> Result<Rc<FacetByOperatorWithOperatorClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FacetByOperatorWithOperatorClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 116, RULE_facetByOperatorWithOperatorClause);
        let mut _localctx: Rc<FacetByOperatorWithOperatorClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1088);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule forkPipeOperator*/
			recog.base.set_state(1089);
			let tmp = recog.forkPipeOperator()?;
			 cast_mut::<_,FacetByOperatorWithOperatorClauseContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- facetByOperatorWithExpressionClause ----------------
pub type FacetByOperatorWithExpressionClauseContextAll<'input> = FacetByOperatorWithExpressionClauseContext<'input>;


pub type FacetByOperatorWithExpressionClauseContext<'input> = BaseParserRuleContext<'input,FacetByOperatorWithExpressionClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FacetByOperatorWithExpressionClauseContextExt<'input>{
	pub Expression: Option<Rc<ForkOperatorExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FacetByOperatorWithExpressionClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FacetByOperatorWithExpressionClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_facetByOperatorWithExpressionClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_facetByOperatorWithExpressionClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FacetByOperatorWithExpressionClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_facetByOperatorWithExpressionClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FacetByOperatorWithExpressionClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_facetByOperatorWithExpressionClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_facetByOperatorWithExpressionClause }
}
antlr_rust::tid!{FacetByOperatorWithExpressionClauseContextExt<'a>}

impl<'input> FacetByOperatorWithExpressionClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FacetByOperatorWithExpressionClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FacetByOperatorWithExpressionClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FacetByOperatorWithExpressionClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FacetByOperatorWithExpressionClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn forkOperatorExpression(&self) -> Option<Rc<ForkOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FacetByOperatorWithExpressionClauseContextAttrs<'input> for FacetByOperatorWithExpressionClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn facetByOperatorWithExpressionClause(&mut self,)
	-> Result<Rc<FacetByOperatorWithExpressionClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FacetByOperatorWithExpressionClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 118, RULE_facetByOperatorWithExpressionClause);
        let mut _localctx: Rc<FacetByOperatorWithExpressionClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1091);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1092);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule forkOperatorExpression*/
			recog.base.set_state(1093);
			let tmp = recog.forkOperatorExpression()?;
			 cast_mut::<_,FacetByOperatorWithExpressionClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1094);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperator ----------------
pub type FindOperatorContextAll<'input> = FindOperatorContext<'input>;


pub type FindOperatorContext<'input> = BaseParserRuleContext<'input,FindOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorContextExt<'input>{
	pub DataScopeClause: Option<Rc<DataScopeClauseContextAll<'input>>>,
	pub ParameterWhereClause: Option<Rc<FindOperatorParametersWhereClauseContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub ProjectClause: Option<Rc<FindOperatorProjectClauseContextAll<'input>>>,
	pub ProjectSmartClause: Option<Rc<FindOperatorProjectSmartClauseContextAll<'input>>>,
	pub ProjectAwayClause: Option<Rc<FindOperatorProjectAwayClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperator }
}
antlr_rust::tid!{FindOperatorContextExt<'a>}

impl<'input> FindOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorContextExt{
				DataScopeClause: None, ParameterWhereClause: None, Expression: None, ProjectClause: None, ProjectSmartClause: None, ProjectAwayClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FIND
/// Returns `None` if there is no child corresponding to token FIND
fn FIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FIND, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dataScopeClause(&self) -> Option<Rc<DataScopeClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorParametersWhereClause(&self) -> Option<Rc<FindOperatorParametersWhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorProjectClause(&self) -> Option<Rc<FindOperatorProjectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorProjectSmartClause(&self) -> Option<Rc<FindOperatorProjectSmartClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorProjectAwayClause(&self) -> Option<Rc<FindOperatorProjectAwayClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorContextAttrs<'input> for FindOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperator(&mut self,)
	-> Result<Rc<FindOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 120, RULE_findOperator);
        let mut _localctx: Rc<FindOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1096);
			recog.base.match_token(FIND,&mut recog.err_handler)?;

			recog.base.set_state(1098);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DATASCOPE {
				{
				/*InvokeRule dataScopeClause*/
				recog.base.set_state(1097);
				let tmp = recog.dataScopeClause()?;
				 cast_mut::<_,FindOperatorContext >(&mut _localctx).DataScopeClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1101);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(47,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule findOperatorParametersWhereClause*/
					recog.base.set_state(1100);
					let tmp = recog.findOperatorParametersWhereClause()?;
					 cast_mut::<_,FindOperatorContext >(&mut _localctx).ParameterWhereClause = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1103);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,FindOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1106);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(48,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule findOperatorProjectClause*/
					recog.base.set_state(1104);
					let tmp = recog.findOperatorProjectClause()?;
					 cast_mut::<_,FindOperatorContext >(&mut _localctx).ProjectClause = Some(tmp.clone());
					  

					}
				}

				x if x == 2=>{
					{
					/*InvokeRule findOperatorProjectSmartClause*/
					recog.base.set_state(1105);
					let tmp = recog.findOperatorProjectSmartClause()?;
					 cast_mut::<_,FindOperatorContext >(&mut _localctx).ProjectSmartClause = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(1109);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PROJECTAWAY_ {
				{
				/*InvokeRule findOperatorProjectAwayClause*/
				recog.base.set_state(1108);
				let tmp = recog.findOperatorProjectAwayClause()?;
				 cast_mut::<_,FindOperatorContext >(&mut _localctx).ProjectAwayClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorParametersWhereClause ----------------
pub type FindOperatorParametersWhereClauseContextAll<'input> = FindOperatorParametersWhereClauseContext<'input>;


pub type FindOperatorParametersWhereClauseContext<'input> = BaseParserRuleContext<'input,FindOperatorParametersWhereClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorParametersWhereClauseContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub InClause: Option<Rc<FindOperatorInClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorParametersWhereClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorParametersWhereClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorParametersWhereClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorParametersWhereClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorParametersWhereClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorParametersWhereClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorParametersWhereClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorParametersWhereClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorParametersWhereClause }
}
antlr_rust::tid!{FindOperatorParametersWhereClauseContextExt<'a>}

impl<'input> FindOperatorParametersWhereClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorParametersWhereClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorParametersWhereClauseContextExt{
				relaxedQueryOperatorParameter: None, InClause: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorParametersWhereClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorParametersWhereClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn findOperatorInClause(&self) -> Option<Rc<FindOperatorInClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorParametersWhereClauseContextAttrs<'input> for FindOperatorParametersWhereClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorParametersWhereClause(&mut self,)
	-> Result<Rc<FindOperatorParametersWhereClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorParametersWhereClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 122, RULE_findOperatorParametersWhereClause);
        let mut _localctx: Rc<FindOperatorParametersWhereClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1114);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1111);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,FindOperatorParametersWhereClauseContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FindOperatorParametersWhereClauseContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,FindOperatorParametersWhereClauseContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1116);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1118);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==IN {
				{
				/*InvokeRule findOperatorInClause*/
				recog.base.set_state(1117);
				let tmp = recog.findOperatorInClause()?;
				 cast_mut::<_,FindOperatorParametersWhereClauseContext >(&mut _localctx).InClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1120);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorInClause ----------------
pub type FindOperatorInClauseContextAll<'input> = FindOperatorInClauseContext<'input>;


pub type FindOperatorInClauseContext<'input> = BaseParserRuleContext<'input,FindOperatorInClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorInClauseContextExt<'input>{
	pub findOperatorSource: Option<Rc<FindOperatorSourceContextAll<'input>>>,
	pub Expressions:Vec<Rc<FindOperatorSourceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorInClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorInClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorInClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorInClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorInClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorInClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorInClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorInClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorInClause }
}
antlr_rust::tid!{FindOperatorInClauseContextExt<'a>}

impl<'input> FindOperatorInClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorInClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorInClauseContextExt{
				findOperatorSource: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorInClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorInClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn findOperatorSource_all(&self) ->  Vec<Rc<FindOperatorSourceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn findOperatorSource(&self, i: usize) -> Option<Rc<FindOperatorSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FindOperatorInClauseContextAttrs<'input> for FindOperatorInClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorInClause(&mut self,)
	-> Result<Rc<FindOperatorInClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorInClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 124, RULE_findOperatorInClause);
        let mut _localctx: Rc<FindOperatorInClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1122);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(1123);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule findOperatorSource*/
			recog.base.set_state(1124);
			let tmp = recog.findOperatorSource()?;
			 cast_mut::<_,FindOperatorInClauseContext >(&mut _localctx).findOperatorSource = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,FindOperatorInClauseContext >(&mut _localctx).findOperatorSource.clone().unwrap()
			 ;
			 cast_mut::<_,FindOperatorInClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1129);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1125);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule findOperatorSource*/
				recog.base.set_state(1126);
				let tmp = recog.findOperatorSource()?;
				 cast_mut::<_,FindOperatorInClauseContext >(&mut _localctx).findOperatorSource = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FindOperatorInClauseContext >(&mut _localctx).findOperatorSource.clone().unwrap()
				 ;
				 cast_mut::<_,FindOperatorInClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1131);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1132);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorProjectClause ----------------
pub type FindOperatorProjectClauseContextAll<'input> = FindOperatorProjectClauseContext<'input>;


pub type FindOperatorProjectClauseContext<'input> = BaseParserRuleContext<'input,FindOperatorProjectClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorProjectClauseContextExt<'input>{
	pub findOperatorProjectExpression: Option<Rc<FindOperatorProjectExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<FindOperatorProjectExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorProjectClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorProjectClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorProjectClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorProjectClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorProjectClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorProjectClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorProjectClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorProjectClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorProjectClause }
}
antlr_rust::tid!{FindOperatorProjectClauseContextExt<'a>}

impl<'input> FindOperatorProjectClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorProjectClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorProjectClauseContextExt{
				findOperatorProjectExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorProjectClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorProjectClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECT
/// Returns `None` if there is no child corresponding to token PROJECT
fn PROJECT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECT, 0)
}
fn findOperatorProjectExpression_all(&self) ->  Vec<Rc<FindOperatorProjectExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn findOperatorProjectExpression(&self, i: usize) -> Option<Rc<FindOperatorProjectExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FindOperatorProjectClauseContextAttrs<'input> for FindOperatorProjectClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorProjectClause(&mut self,)
	-> Result<Rc<FindOperatorProjectClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorProjectClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 126, RULE_findOperatorProjectClause);
        let mut _localctx: Rc<FindOperatorProjectClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1134);
			recog.base.match_token(PROJECT,&mut recog.err_handler)?;

			/*InvokeRule findOperatorProjectExpression*/
			recog.base.set_state(1135);
			let tmp = recog.findOperatorProjectExpression()?;
			 cast_mut::<_,FindOperatorProjectClauseContext >(&mut _localctx).findOperatorProjectExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,FindOperatorProjectClauseContext >(&mut _localctx).findOperatorProjectExpression.clone().unwrap()
			 ;
			 cast_mut::<_,FindOperatorProjectClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1140);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1136);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule findOperatorProjectExpression*/
				recog.base.set_state(1137);
				let tmp = recog.findOperatorProjectExpression()?;
				 cast_mut::<_,FindOperatorProjectClauseContext >(&mut _localctx).findOperatorProjectExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FindOperatorProjectClauseContext >(&mut _localctx).findOperatorProjectExpression.clone().unwrap()
				 ;
				 cast_mut::<_,FindOperatorProjectClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1142);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorProjectExpression ----------------
pub type FindOperatorProjectExpressionContextAll<'input> = FindOperatorProjectExpressionContext<'input>;


pub type FindOperatorProjectExpressionContext<'input> = BaseParserRuleContext<'input,FindOperatorProjectExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorProjectExpressionContextExt<'input>{
	pub Column: Option<Rc<FindOperatorColumnExpressionContextAll<'input>>>,
	pub Pack: Option<Rc<FindOperatorPackExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorProjectExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorProjectExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorProjectExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorProjectExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorProjectExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorProjectExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorProjectExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorProjectExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorProjectExpression }
}
antlr_rust::tid!{FindOperatorProjectExpressionContextExt<'a>}

impl<'input> FindOperatorProjectExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorProjectExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorProjectExpressionContextExt{
				Column: None, Pack: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorProjectExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorProjectExpressionContextExt<'input>>{

fn findOperatorColumnExpression(&self) -> Option<Rc<FindOperatorColumnExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorPackExpression(&self) -> Option<Rc<FindOperatorPackExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorProjectExpressionContextAttrs<'input> for FindOperatorProjectExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorProjectExpression(&mut self,)
	-> Result<Rc<FindOperatorProjectExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorProjectExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 128, RULE_findOperatorProjectExpression);
        let mut _localctx: Rc<FindOperatorProjectExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1145);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(54,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule findOperatorColumnExpression*/
					recog.base.set_state(1143);
					let tmp = recog.findOperatorColumnExpression()?;
					 cast_mut::<_,FindOperatorProjectExpressionContext >(&mut _localctx).Column = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule findOperatorPackExpression*/
					recog.base.set_state(1144);
					let tmp = recog.findOperatorPackExpression()?;
					 cast_mut::<_,FindOperatorProjectExpressionContext >(&mut _localctx).Pack = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorColumnExpression ----------------
pub type FindOperatorColumnExpressionContextAll<'input> = FindOperatorColumnExpressionContext<'input>;


pub type FindOperatorColumnExpressionContext<'input> = BaseParserRuleContext<'input,FindOperatorColumnExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorColumnExpressionContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub OptionalType: Option<Rc<FindOperatorOptionalColumnTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorColumnExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorColumnExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorColumnExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorColumnExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorColumnExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorColumnExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorColumnExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorColumnExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorColumnExpression }
}
antlr_rust::tid!{FindOperatorColumnExpressionContextExt<'a>}

impl<'input> FindOperatorColumnExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorColumnExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorColumnExpressionContextExt{
				Name: None, OptionalType: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorColumnExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorColumnExpressionContextExt<'input>>{

fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorOptionalColumnType(&self) -> Option<Rc<FindOperatorOptionalColumnTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorColumnExpressionContextAttrs<'input> for FindOperatorColumnExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorColumnExpression(&mut self,)
	-> Result<Rc<FindOperatorColumnExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorColumnExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 130, RULE_findOperatorColumnExpression);
        let mut _localctx: Rc<FindOperatorColumnExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(1147);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,FindOperatorColumnExpressionContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1149);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COLON {
				{
				/*InvokeRule findOperatorOptionalColumnType*/
				recog.base.set_state(1148);
				let tmp = recog.findOperatorOptionalColumnType()?;
				 cast_mut::<_,FindOperatorColumnExpressionContext >(&mut _localctx).OptionalType = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorOptionalColumnType ----------------
pub type FindOperatorOptionalColumnTypeContextAll<'input> = FindOperatorOptionalColumnTypeContext<'input>;


pub type FindOperatorOptionalColumnTypeContext<'input> = BaseParserRuleContext<'input,FindOperatorOptionalColumnTypeContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorOptionalColumnTypeContextExt<'input>{
	pub Type: Option<Rc<ExtendedScalarTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorOptionalColumnTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorOptionalColumnTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorOptionalColumnType(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorOptionalColumnType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorOptionalColumnTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorOptionalColumnType(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorOptionalColumnTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorOptionalColumnType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorOptionalColumnType }
}
antlr_rust::tid!{FindOperatorOptionalColumnTypeContextExt<'a>}

impl<'input> FindOperatorOptionalColumnTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorOptionalColumnTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorOptionalColumnTypeContextExt{
				Type: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorOptionalColumnTypeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorOptionalColumnTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn extendedScalarType(&self) -> Option<Rc<ExtendedScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorOptionalColumnTypeContextAttrs<'input> for FindOperatorOptionalColumnTypeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorOptionalColumnType(&mut self,)
	-> Result<Rc<FindOperatorOptionalColumnTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorOptionalColumnTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 132, RULE_findOperatorOptionalColumnType);
        let mut _localctx: Rc<FindOperatorOptionalColumnTypeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1151);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule extendedScalarType*/
			recog.base.set_state(1152);
			let tmp = recog.extendedScalarType()?;
			 cast_mut::<_,FindOperatorOptionalColumnTypeContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorPackExpression ----------------
pub type FindOperatorPackExpressionContextAll<'input> = FindOperatorPackExpressionContext<'input>;


pub type FindOperatorPackExpressionContext<'input> = BaseParserRuleContext<'input,FindOperatorPackExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorPackExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorPackExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorPackExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorPackExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorPackExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorPackExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorPackExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorPackExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorPackExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorPackExpression }
}
antlr_rust::tid!{FindOperatorPackExpressionContextExt<'a>}

impl<'input> FindOperatorPackExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorPackExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorPackExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorPackExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorPackExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PACK
/// Returns `None` if there is no child corresponding to token PACK
fn PACK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PACK, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}

}

impl<'input> FindOperatorPackExpressionContextAttrs<'input> for FindOperatorPackExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorPackExpression(&mut self,)
	-> Result<Rc<FindOperatorPackExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorPackExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 134, RULE_findOperatorPackExpression);
        let mut _localctx: Rc<FindOperatorPackExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1154);
			recog.base.match_token(PACK,&mut recog.err_handler)?;

			recog.base.set_state(1155);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1156);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			recog.base.set_state(1157);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorProjectSmartClause ----------------
pub type FindOperatorProjectSmartClauseContextAll<'input> = FindOperatorProjectSmartClauseContext<'input>;


pub type FindOperatorProjectSmartClauseContext<'input> = BaseParserRuleContext<'input,FindOperatorProjectSmartClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorProjectSmartClauseContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorProjectSmartClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorProjectSmartClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorProjectSmartClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorProjectSmartClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorProjectSmartClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorProjectSmartClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorProjectSmartClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorProjectSmartClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorProjectSmartClause }
}
antlr_rust::tid!{FindOperatorProjectSmartClauseContextExt<'a>}

impl<'input> FindOperatorProjectSmartClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorProjectSmartClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorProjectSmartClauseContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorProjectSmartClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorProjectSmartClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECTSMART
/// Returns `None` if there is no child corresponding to token PROJECTSMART
fn PROJECTSMART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECTSMART, 0)
}

}

impl<'input> FindOperatorProjectSmartClauseContextAttrs<'input> for FindOperatorProjectSmartClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorProjectSmartClause(&mut self,)
	-> Result<Rc<FindOperatorProjectSmartClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorProjectSmartClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 136, RULE_findOperatorProjectSmartClause);
        let mut _localctx: Rc<FindOperatorProjectSmartClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1159);
			recog.base.match_token(PROJECTSMART,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorProjectAwayClause ----------------
pub type FindOperatorProjectAwayClauseContextAll<'input> = FindOperatorProjectAwayClauseContext<'input>;


pub type FindOperatorProjectAwayClauseContext<'input> = BaseParserRuleContext<'input,FindOperatorProjectAwayClauseContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorProjectAwayClauseContextExt<'input>{
	pub Star: Option<Rc<FindOperatorProjectAwayStarContextAll<'input>>>,
	pub ColumnList: Option<Rc<FindOperatorProjectAwayColumnListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorProjectAwayClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorProjectAwayClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorProjectAwayClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorProjectAwayClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorProjectAwayClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorProjectAwayClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorProjectAwayClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorProjectAwayClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorProjectAwayClause }
}
antlr_rust::tid!{FindOperatorProjectAwayClauseContextExt<'a>}

impl<'input> FindOperatorProjectAwayClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorProjectAwayClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorProjectAwayClauseContextExt{
				Star: None, ColumnList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorProjectAwayClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorProjectAwayClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECTAWAY_
/// Returns `None` if there is no child corresponding to token PROJECTAWAY_
fn PROJECTAWAY_(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECTAWAY_, 0)
}
fn findOperatorProjectAwayStar(&self) -> Option<Rc<FindOperatorProjectAwayStarContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn findOperatorProjectAwayColumnList(&self) -> Option<Rc<FindOperatorProjectAwayColumnListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorProjectAwayClauseContextAttrs<'input> for FindOperatorProjectAwayClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorProjectAwayClause(&mut self,)
	-> Result<Rc<FindOperatorProjectAwayClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorProjectAwayClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 138, RULE_findOperatorProjectAwayClause);
        let mut _localctx: Rc<FindOperatorProjectAwayClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1161);
			recog.base.match_token(PROJECTAWAY_,&mut recog.err_handler)?;

			recog.base.set_state(1164);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ASTERISK 
				=> {
					{
					/*InvokeRule findOperatorProjectAwayStar*/
					recog.base.set_state(1162);
					let tmp = recog.findOperatorProjectAwayStar()?;
					 cast_mut::<_,FindOperatorProjectAwayClauseContext >(&mut _localctx).Star = Some(tmp.clone());
					  

					}
				}

			 OPENBRACKET | ACCESS | ACCUMULATE | AGGREGATIONS | ALIAS | ALL | AS |
			 AXES | BASE | BIN | BY | CLUSTER | CONSUME | CONTAINS | COUNT | DATABASE |
			 DATATABLE | DECLARE | DEFAULT | DELTA | DISTINCT | EDGES | EVALUATE |
			 EXECUTE | EXTEND | EXTERNALDATA | FACET | FILTER | FIND | FORK | FROM |
			 HAS | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | IN | INTO | INVOKE |
			 LEGEND | LET | LIMIT | LINEAR | LIST | LOOKUP | LOG | MAP | MATERIALIZE |
			 NODES | NONE | NULL | NULLS | OF | ON | OPTIONAL | OUTPUT | PACK | PARSE |
			 PARTITION | PARTITIONBY | PATTERN | PLUGIN | PRINT | QUERYPARAMETERS |
			 RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SAMPLE | SAMPLE_DISTINCT |
			 SCAN | SEARCH | SERIALIZE | SERIES | SET | SORT | STACKED | STACKED100 |
			 STEP | SUMMARIZE | TAKE | THRESHOLD | TITLE | TO | TOP | TOP_HITTERS |
			 TOP_NESTED | TOSCALAR | TOTABLE | TYPEOF | UNSTACKED | UUID | VIEW |
			 VISIBLE | WHERE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					{
					/*InvokeRule findOperatorProjectAwayColumnList*/
					recog.base.set_state(1163);
					let tmp = recog.findOperatorProjectAwayColumnList()?;
					 cast_mut::<_,FindOperatorProjectAwayClauseContext >(&mut _localctx).ColumnList = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorProjectAwayStar ----------------
pub type FindOperatorProjectAwayStarContextAll<'input> = FindOperatorProjectAwayStarContext<'input>;


pub type FindOperatorProjectAwayStarContext<'input> = BaseParserRuleContext<'input,FindOperatorProjectAwayStarContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorProjectAwayStarContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorProjectAwayStarContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorProjectAwayStarContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorProjectAwayStar(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorProjectAwayStar(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorProjectAwayStarContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorProjectAwayStar(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorProjectAwayStarContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorProjectAwayStar }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorProjectAwayStar }
}
antlr_rust::tid!{FindOperatorProjectAwayStarContextExt<'a>}

impl<'input> FindOperatorProjectAwayStarContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorProjectAwayStarContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorProjectAwayStarContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorProjectAwayStarContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorProjectAwayStarContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> FindOperatorProjectAwayStarContextAttrs<'input> for FindOperatorProjectAwayStarContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorProjectAwayStar(&mut self,)
	-> Result<Rc<FindOperatorProjectAwayStarContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorProjectAwayStarContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 140, RULE_findOperatorProjectAwayStar);
        let mut _localctx: Rc<FindOperatorProjectAwayStarContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1166);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorProjectAwayColumnList ----------------
pub type FindOperatorProjectAwayColumnListContextAll<'input> = FindOperatorProjectAwayColumnListContext<'input>;


pub type FindOperatorProjectAwayColumnListContext<'input> = BaseParserRuleContext<'input,FindOperatorProjectAwayColumnListContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorProjectAwayColumnListContextExt<'input>{
	pub findOperatorColumnExpression: Option<Rc<FindOperatorColumnExpressionContextAll<'input>>>,
	pub Columns:Vec<Rc<FindOperatorColumnExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorProjectAwayColumnListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorProjectAwayColumnListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorProjectAwayColumnList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorProjectAwayColumnList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorProjectAwayColumnListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorProjectAwayColumnList(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorProjectAwayColumnListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorProjectAwayColumnList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorProjectAwayColumnList }
}
antlr_rust::tid!{FindOperatorProjectAwayColumnListContextExt<'a>}

impl<'input> FindOperatorProjectAwayColumnListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorProjectAwayColumnListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorProjectAwayColumnListContextExt{
				findOperatorColumnExpression: None, 
				Columns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorProjectAwayColumnListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorProjectAwayColumnListContextExt<'input>>{

fn findOperatorColumnExpression_all(&self) ->  Vec<Rc<FindOperatorColumnExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn findOperatorColumnExpression(&self, i: usize) -> Option<Rc<FindOperatorColumnExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> FindOperatorProjectAwayColumnListContextAttrs<'input> for FindOperatorProjectAwayColumnListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorProjectAwayColumnList(&mut self,)
	-> Result<Rc<FindOperatorProjectAwayColumnListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorProjectAwayColumnListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 142, RULE_findOperatorProjectAwayColumnList);
        let mut _localctx: Rc<FindOperatorProjectAwayColumnListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule findOperatorColumnExpression*/
			recog.base.set_state(1168);
			let tmp = recog.findOperatorColumnExpression()?;
			 cast_mut::<_,FindOperatorProjectAwayColumnListContext >(&mut _localctx).findOperatorColumnExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,FindOperatorProjectAwayColumnListContext >(&mut _localctx).findOperatorColumnExpression.clone().unwrap()
			 ;
			 cast_mut::<_,FindOperatorProjectAwayColumnListContext >(&mut _localctx).Columns.push(temp);
			  
			recog.base.set_state(1173);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1169);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule findOperatorColumnExpression*/
				recog.base.set_state(1170);
				let tmp = recog.findOperatorColumnExpression()?;
				 cast_mut::<_,FindOperatorProjectAwayColumnListContext >(&mut _localctx).findOperatorColumnExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FindOperatorProjectAwayColumnListContext >(&mut _localctx).findOperatorColumnExpression.clone().unwrap()
				 ;
				 cast_mut::<_,FindOperatorProjectAwayColumnListContext >(&mut _localctx).Columns.push(temp);
				  
				}
				}
				recog.base.set_state(1175);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorSource ----------------
pub type FindOperatorSourceContextAll<'input> = FindOperatorSourceContext<'input>;


pub type FindOperatorSourceContext<'input> = BaseParserRuleContext<'input,FindOperatorSourceContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorSourceContextExt<'input>{
	pub Entity: Option<Rc<FindOperatorSourceEntityExpressionContextAll<'input>>>,
	pub WildcardedEntity: Option<Rc<WildcardedEntityExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorSourceContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorSourceContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorSource(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorSource(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorSourceContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorSource(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorSourceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorSource }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorSource }
}
antlr_rust::tid!{FindOperatorSourceContextExt<'a>}

impl<'input> FindOperatorSourceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorSourceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorSourceContextExt{
				Entity: None, WildcardedEntity: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorSourceContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorSourceContextExt<'input>>{

fn findOperatorSourceEntityExpression(&self) -> Option<Rc<FindOperatorSourceEntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn wildcardedEntityExpression(&self) -> Option<Rc<WildcardedEntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FindOperatorSourceContextAttrs<'input> for FindOperatorSourceContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorSource(&mut self,)
	-> Result<Rc<FindOperatorSourceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorSourceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 144, RULE_findOperatorSource);
        let mut _localctx: Rc<FindOperatorSourceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1178);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(58,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule findOperatorSourceEntityExpression*/
					recog.base.set_state(1176);
					let tmp = recog.findOperatorSourceEntityExpression()?;
					 cast_mut::<_,FindOperatorSourceContext >(&mut _localctx).Entity = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule wildcardedEntityExpression*/
					recog.base.set_state(1177);
					let tmp = recog.wildcardedEntityExpression()?;
					 cast_mut::<_,FindOperatorSourceContext >(&mut _localctx).WildcardedEntity = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- findOperatorSourceEntityExpression ----------------
pub type FindOperatorSourceEntityExpressionContextAll<'input> = FindOperatorSourceEntityExpressionContext<'input>;


pub type FindOperatorSourceEntityExpressionContext<'input> = BaseParserRuleContext<'input,FindOperatorSourceEntityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FindOperatorSourceEntityExpressionContextExt<'input>{
	pub Entity: Option<Rc<EntityNameReferenceContextAll<'input>>>,
	pub asOperator: Option<Rc<AsOperatorContextAll<'input>>>,
	pub AsOperators:Vec<Rc<AsOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FindOperatorSourceEntityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FindOperatorSourceEntityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_findOperatorSourceEntityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_findOperatorSourceEntityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FindOperatorSourceEntityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_findOperatorSourceEntityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FindOperatorSourceEntityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_findOperatorSourceEntityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_findOperatorSourceEntityExpression }
}
antlr_rust::tid!{FindOperatorSourceEntityExpressionContextExt<'a>}

impl<'input> FindOperatorSourceEntityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FindOperatorSourceEntityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FindOperatorSourceEntityExpressionContextExt{
				Entity: None, asOperator: None, 
				AsOperators: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FindOperatorSourceEntityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FindOperatorSourceEntityExpressionContextExt<'input>>{

fn entityNameReference(&self) -> Option<Rc<EntityNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token BAR in current rule
fn BAR_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token BAR, starting from 0.
/// Returns `None` if number of children corresponding to token BAR is less or equal than `i`.
fn BAR(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BAR, i)
}
fn asOperator_all(&self) ->  Vec<Rc<AsOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn asOperator(&self, i: usize) -> Option<Rc<AsOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> FindOperatorSourceEntityExpressionContextAttrs<'input> for FindOperatorSourceEntityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn findOperatorSourceEntityExpression(&mut self,)
	-> Result<Rc<FindOperatorSourceEntityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FindOperatorSourceEntityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 146, RULE_findOperatorSourceEntityExpression);
        let mut _localctx: Rc<FindOperatorSourceEntityExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule entityNameReference*/
			recog.base.set_state(1180);
			let tmp = recog.entityNameReference()?;
			 cast_mut::<_,FindOperatorSourceEntityExpressionContext >(&mut _localctx).Entity = Some(tmp.clone());
			  

			recog.base.set_state(1185);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BAR {
				{
				{
				recog.base.set_state(1181);
				recog.base.match_token(BAR,&mut recog.err_handler)?;

				/*InvokeRule asOperator*/
				recog.base.set_state(1182);
				let tmp = recog.asOperator()?;
				 cast_mut::<_,FindOperatorSourceEntityExpressionContext >(&mut _localctx).asOperator = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FindOperatorSourceEntityExpressionContext >(&mut _localctx).asOperator.clone().unwrap()
				 ;
				 cast_mut::<_,FindOperatorSourceEntityExpressionContext >(&mut _localctx).AsOperators.push(temp);
				  
				}
				}
				recog.base.set_state(1187);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forkOperator ----------------
pub type ForkOperatorContextAll<'input> = ForkOperatorContext<'input>;


pub type ForkOperatorContext<'input> = BaseParserRuleContext<'input,ForkOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ForkOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ForkOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ForkOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forkOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_forkOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ForkOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_forkOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForkOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forkOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forkOperator }
}
antlr_rust::tid!{ForkOperatorContextExt<'a>}

impl<'input> ForkOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForkOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForkOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ForkOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ForkOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FORK
/// Returns `None` if there is no child corresponding to token FORK
fn FORK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FORK, 0)
}
fn forkOperatorFork_all(&self) ->  Vec<Rc<ForkOperatorForkContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn forkOperatorFork(&self, i: usize) -> Option<Rc<ForkOperatorForkContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ForkOperatorContextAttrs<'input> for ForkOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forkOperator(&mut self,)
	-> Result<Rc<ForkOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForkOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 148, RULE_forkOperator);
        let mut _localctx: Rc<ForkOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1188);
			recog.base.match_token(FORK,&mut recog.err_handler)?;

			recog.base.set_state(1190); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule forkOperatorFork*/
				recog.base.set_state(1189);
				recog.forkOperatorFork()?;

				}
				}
				recog.base.set_state(1192); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (OPENPAREN - 30)) | (1usize << (ACCESS - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (CLUSTER - 30)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (DATABASE - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DELTA - 69)) | (1usize << (EDGES - 69)) | (1usize << (EVALUATE - 69)) | (1usize << (EXECUTE - 69)) | (1usize << (FACET - 69)) | (1usize << (FORK - 69)) | (1usize << (FROM - 69)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MAP - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 253)) & !0x3f) == 0 && ((1usize << (_la - 253)) & ((1usize << (TYPEOF - 253)) | (1usize << (UNSTACKED - 253)) | (1usize << (UUID - 253)) | (1usize << (VIEW - 253)) | (1usize << (VISIBLE - 253)) | (1usize << (WITH - 253)) | (1usize << (XAXIS - 253)) | (1usize << (XCOLUMN - 253)) | (1usize << (XMAX - 253)) | (1usize << (XMIN - 253)) | (1usize << (XTITLE - 253)) | (1usize << (YAXIS - 253)) | (1usize << (YCOLUMNS - 253)) | (1usize << (YMAX - 253)) | (1usize << (YMIN - 253)) | (1usize << (YSPLIT - 253)) | (1usize << (YTITLE - 253)) | (1usize << (BOOL - 253)))) != 0) || _la==GUID || _la==IDENTIFIER) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forkOperatorFork ----------------
pub type ForkOperatorForkContextAll<'input> = ForkOperatorForkContext<'input>;


pub type ForkOperatorForkContext<'input> = BaseParserRuleContext<'input,ForkOperatorForkContextExt<'input>>;

#[derive(Clone)]
pub struct ForkOperatorForkContextExt<'input>{
	pub Name: Option<Rc<ForkOperatorExpressionNameContextAll<'input>>>,
	pub Expression: Option<Rc<ForkOperatorExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ForkOperatorForkContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ForkOperatorForkContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forkOperatorFork(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_forkOperatorFork(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ForkOperatorForkContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_forkOperatorFork(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForkOperatorForkContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forkOperatorFork }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forkOperatorFork }
}
antlr_rust::tid!{ForkOperatorForkContextExt<'a>}

impl<'input> ForkOperatorForkContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForkOperatorForkContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForkOperatorForkContextExt{
				Name: None, Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ForkOperatorForkContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ForkOperatorForkContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn forkOperatorExpression(&self) -> Option<Rc<ForkOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn forkOperatorExpressionName(&self) -> Option<Rc<ForkOperatorExpressionNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForkOperatorForkContextAttrs<'input> for ForkOperatorForkContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forkOperatorFork(&mut self,)
	-> Result<Rc<ForkOperatorForkContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForkOperatorForkContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 150, RULE_forkOperatorFork);
        let mut _localctx: Rc<ForkOperatorForkContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1195);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (CLUSTER - 30)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (DATABASE - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DELTA - 69)) | (1usize << (EDGES - 69)) | (1usize << (EVALUATE - 69)) | (1usize << (EXECUTE - 69)) | (1usize << (FACET - 69)) | (1usize << (FORK - 69)) | (1usize << (FROM - 69)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MAP - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 253)) & !0x3f) == 0 && ((1usize << (_la - 253)) & ((1usize << (TYPEOF - 253)) | (1usize << (UNSTACKED - 253)) | (1usize << (UUID - 253)) | (1usize << (VIEW - 253)) | (1usize << (VISIBLE - 253)) | (1usize << (WITH - 253)) | (1usize << (XAXIS - 253)) | (1usize << (XCOLUMN - 253)) | (1usize << (XMAX - 253)) | (1usize << (XMIN - 253)) | (1usize << (XTITLE - 253)) | (1usize << (YAXIS - 253)) | (1usize << (YCOLUMNS - 253)) | (1usize << (YMAX - 253)) | (1usize << (YMIN - 253)) | (1usize << (YSPLIT - 253)) | (1usize << (YTITLE - 253)) | (1usize << (BOOL - 253)))) != 0) || _la==GUID || _la==IDENTIFIER {
				{
				/*InvokeRule forkOperatorExpressionName*/
				recog.base.set_state(1194);
				let tmp = recog.forkOperatorExpressionName()?;
				 cast_mut::<_,ForkOperatorForkContext >(&mut _localctx).Name = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1197);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule forkOperatorExpression*/
			recog.base.set_state(1198);
			let tmp = recog.forkOperatorExpression()?;
			 cast_mut::<_,ForkOperatorForkContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1199);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forkOperatorExpressionName ----------------
pub type ForkOperatorExpressionNameContextAll<'input> = ForkOperatorExpressionNameContext<'input>;


pub type ForkOperatorExpressionNameContext<'input> = BaseParserRuleContext<'input,ForkOperatorExpressionNameContextExt<'input>>;

#[derive(Clone)]
pub struct ForkOperatorExpressionNameContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ForkOperatorExpressionNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ForkOperatorExpressionNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forkOperatorExpressionName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_forkOperatorExpressionName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ForkOperatorExpressionNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_forkOperatorExpressionName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForkOperatorExpressionNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forkOperatorExpressionName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forkOperatorExpressionName }
}
antlr_rust::tid!{ForkOperatorExpressionNameContextExt<'a>}

impl<'input> ForkOperatorExpressionNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForkOperatorExpressionNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForkOperatorExpressionNameContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ForkOperatorExpressionNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ForkOperatorExpressionNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForkOperatorExpressionNameContextAttrs<'input> for ForkOperatorExpressionNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forkOperatorExpressionName(&mut self,)
	-> Result<Rc<ForkOperatorExpressionNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForkOperatorExpressionNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 152, RULE_forkOperatorExpressionName);
        let mut _localctx: Rc<ForkOperatorExpressionNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1201);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,ForkOperatorExpressionNameContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1202);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forkOperatorExpression ----------------
pub type ForkOperatorExpressionContextAll<'input> = ForkOperatorExpressionContext<'input>;


pub type ForkOperatorExpressionContext<'input> = BaseParserRuleContext<'input,ForkOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ForkOperatorExpressionContextExt<'input>{
	pub Operator: Option<Rc<ForkPipeOperatorContextAll<'input>>>,
	pub forkOperatorPipedOperator: Option<Rc<ForkOperatorPipedOperatorContextAll<'input>>>,
	pub PipedOperators:Vec<Rc<ForkOperatorPipedOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ForkOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ForkOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forkOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_forkOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ForkOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_forkOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForkOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forkOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forkOperatorExpression }
}
antlr_rust::tid!{ForkOperatorExpressionContextExt<'a>}

impl<'input> ForkOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForkOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForkOperatorExpressionContextExt{
				Operator: None, forkOperatorPipedOperator: None, 
				PipedOperators: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ForkOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ForkOperatorExpressionContextExt<'input>>{

fn forkPipeOperator(&self) -> Option<Rc<ForkPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn forkOperatorPipedOperator_all(&self) ->  Vec<Rc<ForkOperatorPipedOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn forkOperatorPipedOperator(&self, i: usize) -> Option<Rc<ForkOperatorPipedOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ForkOperatorExpressionContextAttrs<'input> for ForkOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forkOperatorExpression(&mut self,)
	-> Result<Rc<ForkOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForkOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 154, RULE_forkOperatorExpression);
        let mut _localctx: Rc<ForkOperatorExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule forkPipeOperator*/
			recog.base.set_state(1204);
			let tmp = recog.forkPipeOperator()?;
			 cast_mut::<_,ForkOperatorExpressionContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			recog.base.set_state(1208);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BAR {
				{
				{
				/*InvokeRule forkOperatorPipedOperator*/
				recog.base.set_state(1205);
				let tmp = recog.forkOperatorPipedOperator()?;
				 cast_mut::<_,ForkOperatorExpressionContext >(&mut _localctx).forkOperatorPipedOperator = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ForkOperatorExpressionContext >(&mut _localctx).forkOperatorPipedOperator.clone().unwrap()
				 ;
				 cast_mut::<_,ForkOperatorExpressionContext >(&mut _localctx).PipedOperators.push(temp);
				  
				}
				}
				recog.base.set_state(1210);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- forkOperatorPipedOperator ----------------
pub type ForkOperatorPipedOperatorContextAll<'input> = ForkOperatorPipedOperatorContext<'input>;


pub type ForkOperatorPipedOperatorContext<'input> = BaseParserRuleContext<'input,ForkOperatorPipedOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ForkOperatorPipedOperatorContextExt<'input>{
	pub Operator: Option<Rc<ForkPipeOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ForkOperatorPipedOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ForkOperatorPipedOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_forkOperatorPipedOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_forkOperatorPipedOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ForkOperatorPipedOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_forkOperatorPipedOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ForkOperatorPipedOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_forkOperatorPipedOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_forkOperatorPipedOperator }
}
antlr_rust::tid!{ForkOperatorPipedOperatorContextExt<'a>}

impl<'input> ForkOperatorPipedOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ForkOperatorPipedOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ForkOperatorPipedOperatorContextExt{
				Operator: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ForkOperatorPipedOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ForkOperatorPipedOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BAR
/// Returns `None` if there is no child corresponding to token BAR
fn BAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BAR, 0)
}
fn forkPipeOperator(&self) -> Option<Rc<ForkPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ForkOperatorPipedOperatorContextAttrs<'input> for ForkOperatorPipedOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn forkOperatorPipedOperator(&mut self,)
	-> Result<Rc<ForkOperatorPipedOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ForkOperatorPipedOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 156, RULE_forkOperatorPipedOperator);
        let mut _localctx: Rc<ForkOperatorPipedOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1211);
			recog.base.match_token(BAR,&mut recog.err_handler)?;

			/*InvokeRule forkPipeOperator*/
			recog.base.set_state(1212);
			let tmp = recog.forkPipeOperator()?;
			 cast_mut::<_,ForkOperatorPipedOperatorContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- getSchemaOperator ----------------
pub type GetSchemaOperatorContextAll<'input> = GetSchemaOperatorContext<'input>;


pub type GetSchemaOperatorContext<'input> = BaseParserRuleContext<'input,GetSchemaOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct GetSchemaOperatorContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GetSchemaOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GetSchemaOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_getSchemaOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_getSchemaOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GetSchemaOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_getSchemaOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for GetSchemaOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_getSchemaOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_getSchemaOperator }
}
antlr_rust::tid!{GetSchemaOperatorContextExt<'a>}

impl<'input> GetSchemaOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GetSchemaOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GetSchemaOperatorContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait GetSchemaOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GetSchemaOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GETSCHEMA
/// Returns `None` if there is no child corresponding to token GETSCHEMA
fn GETSCHEMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GETSCHEMA, 0)
}

}

impl<'input> GetSchemaOperatorContextAttrs<'input> for GetSchemaOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn getSchemaOperator(&mut self,)
	-> Result<Rc<GetSchemaOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GetSchemaOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 158, RULE_getSchemaOperator);
        let mut _localctx: Rc<GetSchemaOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1214);
			recog.base.match_token(GETSCHEMA,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMarkComponentsOperator ----------------
pub type GraphMarkComponentsOperatorContextAll<'input> = GraphMarkComponentsOperatorContext<'input>;


pub type GraphMarkComponentsOperatorContext<'input> = BaseParserRuleContext<'input,GraphMarkComponentsOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMarkComponentsOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parametems:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMarkComponentsOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMarkComponentsOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMarkComponentsOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMarkComponentsOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMarkComponentsOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMarkComponentsOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMarkComponentsOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMarkComponentsOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMarkComponentsOperator }
}
antlr_rust::tid!{GraphMarkComponentsOperatorContextExt<'a>}

impl<'input> GraphMarkComponentsOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMarkComponentsOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMarkComponentsOperatorContextExt{
				relaxedQueryOperatorParameter: None, 
				Parametems: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMarkComponentsOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMarkComponentsOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GRAPHMARKCOMPONENTS
/// Returns `None` if there is no child corresponding to token GRAPHMARKCOMPONENTS
fn GRAPHMARKCOMPONENTS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRAPHMARKCOMPONENTS, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> GraphMarkComponentsOperatorContextAttrs<'input> for GraphMarkComponentsOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMarkComponentsOperator(&mut self,)
	-> Result<Rc<GraphMarkComponentsOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMarkComponentsOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 160, RULE_graphMarkComponentsOperator);
        let mut _localctx: Rc<GraphMarkComponentsOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1216);
			recog.base.match_token(GRAPHMARKCOMPONENTS,&mut recog.err_handler)?;

			recog.base.set_state(1220);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1217);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,GraphMarkComponentsOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,GraphMarkComponentsOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,GraphMarkComponentsOperatorContext >(&mut _localctx).Parametems.push(temp);
				  
				}
				}
				recog.base.set_state(1222);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchOperator ----------------
pub type GraphMatchOperatorContextAll<'input> = GraphMatchOperatorContext<'input>;


pub type GraphMatchOperatorContext<'input> = BaseParserRuleContext<'input,GraphMatchOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub graphMatchPattern: Option<Rc<GraphMatchPatternContextAll<'input>>>,
	pub Patterns:Vec<Rc<GraphMatchPatternContextAll<'input>>>,
	pub WhereClause: Option<Rc<GraphMatchWhereClauseContextAll<'input>>>,
	pub ProjectClause: Option<Rc<GraphMatchProjectClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchOperator }
}
antlr_rust::tid!{GraphMatchOperatorContextExt<'a>}

impl<'input> GraphMatchOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchOperatorContextExt{
				relaxedQueryOperatorParameter: None, graphMatchPattern: None, WhereClause: None, ProjectClause: None, 
				Parameters: Vec::new(), Patterns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GRAPHMATCH
/// Returns `None` if there is no child corresponding to token GRAPHMATCH
fn GRAPHMATCH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRAPHMATCH, 0)
}
fn graphMatchPattern_all(&self) ->  Vec<Rc<GraphMatchPatternContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn graphMatchPattern(&self, i: usize) -> Option<Rc<GraphMatchPatternContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn graphMatchWhereClause(&self) -> Option<Rc<GraphMatchWhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMatchProjectClause(&self) -> Option<Rc<GraphMatchProjectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphMatchOperatorContextAttrs<'input> for GraphMatchOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchOperator(&mut self,)
	-> Result<Rc<GraphMatchOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 162, RULE_graphMatchOperator);
        let mut _localctx: Rc<GraphMatchOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1223);
			recog.base.match_token(GRAPHMATCH,&mut recog.err_handler)?;

			recog.base.set_state(1227);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1224);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1229);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule graphMatchPattern*/
			recog.base.set_state(1230);
			let tmp = recog.graphMatchPattern()?;
			 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).graphMatchPattern = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).graphMatchPattern.clone().unwrap()
			 ;
			 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).Patterns.push(temp);
			  
			{
			recog.base.set_state(1231);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule graphMatchPattern*/
			recog.base.set_state(1232);
			let tmp = recog.graphMatchPattern()?;
			 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).graphMatchPattern = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).graphMatchPattern.clone().unwrap()
			 ;
			 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).Patterns.push(temp);
			  
			}
			recog.base.set_state(1235);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WHERE {
				{
				/*InvokeRule graphMatchWhereClause*/
				recog.base.set_state(1234);
				let tmp = recog.graphMatchWhereClause()?;
				 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).WhereClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1238);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(66,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule graphMatchProjectClause*/
					recog.base.set_state(1237);
					let tmp = recog.graphMatchProjectClause()?;
					 cast_mut::<_,GraphMatchOperatorContext >(&mut _localctx).ProjectClause = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchPattern ----------------
pub type GraphMatchPatternContextAll<'input> = GraphMatchPatternContext<'input>;


pub type GraphMatchPatternContext<'input> = BaseParserRuleContext<'input,GraphMatchPatternContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchPatternContextExt<'input>{
	pub Node: Option<Rc<GraphMatchPatternNodeContextAll<'input>>>,
	pub UnnamedEdge: Option<Rc<GraphMatchPatternUnnamedEdgeContextAll<'input>>>,
	pub NamedEdge: Option<Rc<GraphMatchPatternNamedEdgeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchPatternContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchPatternContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchPattern(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchPattern(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchPattern }
}
antlr_rust::tid!{GraphMatchPatternContextExt<'a>}

impl<'input> GraphMatchPatternContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchPatternContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchPatternContextExt{
				Node: None, UnnamedEdge: None, NamedEdge: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchPatternContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchPatternContextExt<'input>>{

fn graphMatchPatternNode(&self) -> Option<Rc<GraphMatchPatternNodeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMatchPatternUnnamedEdge(&self) -> Option<Rc<GraphMatchPatternUnnamedEdgeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMatchPatternNamedEdge(&self) -> Option<Rc<GraphMatchPatternNamedEdgeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphMatchPatternContextAttrs<'input> for GraphMatchPatternContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchPattern(&mut self,)
	-> Result<Rc<GraphMatchPatternContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchPatternContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 164, RULE_graphMatchPattern);
        let mut _localctx: Rc<GraphMatchPatternContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1243);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 OPENPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule graphMatchPatternNode*/
					recog.base.set_state(1240);
					let tmp = recog.graphMatchPatternNode()?;
					 cast_mut::<_,GraphMatchPatternContext >(&mut _localctx).Node = Some(tmp.clone());
					  

					}
				}

			 DASHDASH | DASHDASH_GREATERTHAN | LESSTHAN_DASHDASH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule graphMatchPatternUnnamedEdge*/
					recog.base.set_state(1241);
					let tmp = recog.graphMatchPatternUnnamedEdge()?;
					 cast_mut::<_,GraphMatchPatternContext >(&mut _localctx).UnnamedEdge = Some(tmp.clone());
					  

					}
				}

			 DASH_OPENBRACKET | LESSTHAN_DASH_OPENBRACKET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule graphMatchPatternNamedEdge*/
					recog.base.set_state(1242);
					let tmp = recog.graphMatchPatternNamedEdge()?;
					 cast_mut::<_,GraphMatchPatternContext >(&mut _localctx).NamedEdge = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchPatternNode ----------------
pub type GraphMatchPatternNodeContextAll<'input> = GraphMatchPatternNodeContext<'input>;


pub type GraphMatchPatternNodeContext<'input> = BaseParserRuleContext<'input,GraphMatchPatternNodeContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchPatternNodeContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchPatternNodeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchPatternNodeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchPatternNode(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchPatternNode(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchPatternNodeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchPatternNode(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchPatternNodeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchPatternNode }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchPatternNode }
}
antlr_rust::tid!{GraphMatchPatternNodeContextExt<'a>}

impl<'input> GraphMatchPatternNodeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchPatternNodeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchPatternNodeContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchPatternNodeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchPatternNodeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphMatchPatternNodeContextAttrs<'input> for GraphMatchPatternNodeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchPatternNode(&mut self,)
	-> Result<Rc<GraphMatchPatternNodeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchPatternNodeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 166, RULE_graphMatchPatternNode);
        let mut _localctx: Rc<GraphMatchPatternNodeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1245);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1246);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,GraphMatchPatternNodeContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1247);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchPatternUnnamedEdge ----------------
pub type GraphMatchPatternUnnamedEdgeContextAll<'input> = GraphMatchPatternUnnamedEdgeContext<'input>;


pub type GraphMatchPatternUnnamedEdgeContext<'input> = BaseParserRuleContext<'input,GraphMatchPatternUnnamedEdgeContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchPatternUnnamedEdgeContextExt<'input>{
	pub Direction: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchPatternUnnamedEdgeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchPatternUnnamedEdgeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchPatternUnnamedEdge(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchPatternUnnamedEdge(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchPatternUnnamedEdgeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchPatternUnnamedEdge(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchPatternUnnamedEdgeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchPatternUnnamedEdge }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchPatternUnnamedEdge }
}
antlr_rust::tid!{GraphMatchPatternUnnamedEdgeContextExt<'a>}

impl<'input> GraphMatchPatternUnnamedEdgeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchPatternUnnamedEdgeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchPatternUnnamedEdgeContextExt{
				Direction: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchPatternUnnamedEdgeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchPatternUnnamedEdgeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DASHDASH_GREATERTHAN
/// Returns `None` if there is no child corresponding to token DASHDASH_GREATERTHAN
fn DASHDASH_GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASHDASH_GREATERTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN_DASHDASH
/// Returns `None` if there is no child corresponding to token LESSTHAN_DASHDASH
fn LESSTHAN_DASHDASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN_DASHDASH, 0)
}
/// Retrieves first TerminalNode corresponding to token DASHDASH
/// Returns `None` if there is no child corresponding to token DASHDASH
fn DASHDASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASHDASH, 0)
}

}

impl<'input> GraphMatchPatternUnnamedEdgeContextAttrs<'input> for GraphMatchPatternUnnamedEdgeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchPatternUnnamedEdge(&mut self,)
	-> Result<Rc<GraphMatchPatternUnnamedEdgeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchPatternUnnamedEdgeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 168, RULE_graphMatchPatternUnnamedEdge);
        let mut _localctx: Rc<GraphMatchPatternUnnamedEdgeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1249);
			 cast_mut::<_,GraphMatchPatternUnnamedEdgeContext >(&mut _localctx).Direction = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << DASHDASH) | (1usize << DASHDASH_GREATERTHAN) | (1usize << LESSTHAN_DASHDASH))) != 0)) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,GraphMatchPatternUnnamedEdgeContext >(&mut _localctx).Direction = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchPatternNamedEdge ----------------
pub type GraphMatchPatternNamedEdgeContextAll<'input> = GraphMatchPatternNamedEdgeContext<'input>;


pub type GraphMatchPatternNamedEdgeContext<'input> = BaseParserRuleContext<'input,GraphMatchPatternNamedEdgeContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchPatternNamedEdgeContextExt<'input>{
	pub OpenBracket: Option<TokenType<'input>>,
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub Range: Option<Rc<GraphMatchPatternRangeContextAll<'input>>>,
	pub CloseBracket: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchPatternNamedEdgeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchPatternNamedEdgeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchPatternNamedEdge(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchPatternNamedEdge(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchPatternNamedEdgeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchPatternNamedEdge(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchPatternNamedEdgeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchPatternNamedEdge }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchPatternNamedEdge }
}
antlr_rust::tid!{GraphMatchPatternNamedEdgeContextExt<'a>}

impl<'input> GraphMatchPatternNamedEdgeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchPatternNamedEdgeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchPatternNamedEdgeContextExt{
				OpenBracket: None, CloseBracket: None, 
				Name: None, Range: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchPatternNamedEdgeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchPatternNamedEdgeContextExt<'input>>{

fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token DASH_OPENBRACKET
/// Returns `None` if there is no child corresponding to token DASH_OPENBRACKET
fn DASH_OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH_OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN_DASH_OPENBRACKET
/// Returns `None` if there is no child corresponding to token LESSTHAN_DASH_OPENBRACKET
fn LESSTHAN_DASH_OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN_DASH_OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET_DASH_GREATERTHAN
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET_DASH_GREATERTHAN
fn CLOSEBRACKET_DASH_GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET_DASH_GREATERTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET_DASH
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET_DASH
fn CLOSEBRACKET_DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET_DASH, 0)
}
fn graphMatchPatternRange(&self) -> Option<Rc<GraphMatchPatternRangeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphMatchPatternNamedEdgeContextAttrs<'input> for GraphMatchPatternNamedEdgeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchPatternNamedEdge(&mut self,)
	-> Result<Rc<GraphMatchPatternNamedEdgeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchPatternNamedEdgeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 170, RULE_graphMatchPatternNamedEdge);
        let mut _localctx: Rc<GraphMatchPatternNamedEdgeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1251);
			 cast_mut::<_,GraphMatchPatternNamedEdgeContext >(&mut _localctx).OpenBracket = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==DASH_OPENBRACKET || _la==LESSTHAN_DASH_OPENBRACKET) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,GraphMatchPatternNamedEdgeContext >(&mut _localctx).OpenBracket = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1252);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,GraphMatchPatternNamedEdgeContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1254);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASTERISK {
				{
				/*InvokeRule graphMatchPatternRange*/
				recog.base.set_state(1253);
				let tmp = recog.graphMatchPatternRange()?;
				 cast_mut::<_,GraphMatchPatternNamedEdgeContext >(&mut _localctx).Range = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1256);
			 cast_mut::<_,GraphMatchPatternNamedEdgeContext >(&mut _localctx).CloseBracket = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==CLOSEBRACKET_DASH || _la==CLOSEBRACKET_DASH_GREATERTHAN) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,GraphMatchPatternNamedEdgeContext >(&mut _localctx).CloseBracket = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchPatternRange ----------------
pub type GraphMatchPatternRangeContextAll<'input> = GraphMatchPatternRangeContext<'input>;


pub type GraphMatchPatternRangeContext<'input> = BaseParserRuleContext<'input,GraphMatchPatternRangeContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchPatternRangeContextExt<'input>{
	pub LowerBound: Option<Rc<InvocationExpressionContextAll<'input>>>,
	pub UpperBound: Option<Rc<InvocationExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchPatternRangeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchPatternRangeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchPatternRange(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchPatternRange(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchPatternRangeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchPatternRange(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchPatternRangeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchPatternRange }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchPatternRange }
}
antlr_rust::tid!{GraphMatchPatternRangeContextExt<'a>}

impl<'input> GraphMatchPatternRangeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchPatternRangeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchPatternRangeContextExt{
				LowerBound: None, UpperBound: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchPatternRangeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchPatternRangeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token DOTDOT
/// Returns `None` if there is no child corresponding to token DOTDOT
fn DOTDOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOTDOT, 0)
}
fn invocationExpression_all(&self) ->  Vec<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn invocationExpression(&self, i: usize) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> GraphMatchPatternRangeContextAttrs<'input> for GraphMatchPatternRangeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchPatternRange(&mut self,)
	-> Result<Rc<GraphMatchPatternRangeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchPatternRangeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 172, RULE_graphMatchPatternRange);
        let mut _localctx: Rc<GraphMatchPatternRangeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1258);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(1259);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,GraphMatchPatternRangeContext >(&mut _localctx).LowerBound = Some(tmp.clone());
			  

			recog.base.set_state(1260);
			recog.base.match_token(DOTDOT,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(1261);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,GraphMatchPatternRangeContext >(&mut _localctx).UpperBound = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchWhereClause ----------------
pub type GraphMatchWhereClauseContextAll<'input> = GraphMatchWhereClauseContext<'input>;


pub type GraphMatchWhereClauseContext<'input> = BaseParserRuleContext<'input,GraphMatchWhereClauseContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchWhereClauseContextExt<'input>{
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchWhereClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchWhereClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchWhereClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchWhereClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchWhereClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchWhereClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchWhereClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchWhereClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchWhereClause }
}
antlr_rust::tid!{GraphMatchWhereClauseContextExt<'a>}

impl<'input> GraphMatchWhereClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchWhereClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchWhereClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchWhereClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchWhereClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphMatchWhereClauseContextAttrs<'input> for GraphMatchWhereClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchWhereClause(&mut self,)
	-> Result<Rc<GraphMatchWhereClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchWhereClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 174, RULE_graphMatchWhereClause);
        let mut _localctx: Rc<GraphMatchWhereClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1263);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(1264);
			let tmp = recog.expression()?;
			 cast_mut::<_,GraphMatchWhereClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMatchProjectClause ----------------
pub type GraphMatchProjectClauseContextAll<'input> = GraphMatchProjectClauseContext<'input>;


pub type GraphMatchProjectClauseContext<'input> = BaseParserRuleContext<'input,GraphMatchProjectClauseContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMatchProjectClauseContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMatchProjectClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMatchProjectClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMatchProjectClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMatchProjectClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMatchProjectClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMatchProjectClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMatchProjectClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMatchProjectClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMatchProjectClause }
}
antlr_rust::tid!{GraphMatchProjectClauseContextExt<'a>}

impl<'input> GraphMatchProjectClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMatchProjectClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMatchProjectClauseContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMatchProjectClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMatchProjectClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECT
/// Returns `None` if there is no child corresponding to token PROJECT
fn PROJECT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECT, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> GraphMatchProjectClauseContextAttrs<'input> for GraphMatchProjectClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMatchProjectClause(&mut self,)
	-> Result<Rc<GraphMatchProjectClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMatchProjectClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 176, RULE_graphMatchProjectClause);
        let mut _localctx: Rc<GraphMatchProjectClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1266);
			recog.base.match_token(PROJECT,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1267);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,GraphMatchProjectClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphMatchProjectClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,GraphMatchProjectClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1272);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1268);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1269);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,GraphMatchProjectClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,GraphMatchProjectClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,GraphMatchProjectClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1274);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphMergeOperator ----------------
pub type GraphMergeOperatorContextAll<'input> = GraphMergeOperatorContext<'input>;


pub type GraphMergeOperatorContext<'input> = BaseParserRuleContext<'input,GraphMergeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct GraphMergeOperatorContextExt<'input>{
	pub Graph: Option<Rc<InvocationExpressionContextAll<'input>>>,
	pub OnClause: Option<Rc<JoinOperatorOnClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphMergeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphMergeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphMergeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphMergeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphMergeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphMergeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphMergeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphMergeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphMergeOperator }
}
antlr_rust::tid!{GraphMergeOperatorContextExt<'a>}

impl<'input> GraphMergeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphMergeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphMergeOperatorContextExt{
				Graph: None, OnClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphMergeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphMergeOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GRAPHMERGE
/// Returns `None` if there is no child corresponding to token GRAPHMERGE
fn GRAPHMERGE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRAPHMERGE, 0)
}
fn invocationExpression(&self) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinOperatorOnClause(&self) -> Option<Rc<JoinOperatorOnClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphMergeOperatorContextAttrs<'input> for GraphMergeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphMergeOperator(&mut self,)
	-> Result<Rc<GraphMergeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphMergeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 178, RULE_graphMergeOperator);
        let mut _localctx: Rc<GraphMergeOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1275);
			recog.base.match_token(GRAPHMERGE,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(1276);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,GraphMergeOperatorContext >(&mut _localctx).Graph = Some(tmp.clone());
			  

			recog.base.set_state(1278);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ON {
				{
				/*InvokeRule joinOperatorOnClause*/
				recog.base.set_state(1277);
				let tmp = recog.joinOperatorOnClause()?;
				 cast_mut::<_,GraphMergeOperatorContext >(&mut _localctx).OnClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphToTableOperator ----------------
pub type GraphToTableOperatorContextAll<'input> = GraphToTableOperatorContext<'input>;


pub type GraphToTableOperatorContext<'input> = BaseParserRuleContext<'input,GraphToTableOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct GraphToTableOperatorContextExt<'input>{
	pub graphToTableOutput: Option<Rc<GraphToTableOutputContextAll<'input>>>,
	pub Outputs:Vec<Rc<GraphToTableOutputContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphToTableOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphToTableOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphToTableOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphToTableOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphToTableOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphToTableOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphToTableOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphToTableOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphToTableOperator }
}
antlr_rust::tid!{GraphToTableOperatorContextExt<'a>}

impl<'input> GraphToTableOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphToTableOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphToTableOperatorContextExt{
				graphToTableOutput: None, 
				Outputs: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphToTableOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphToTableOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GRAPHTOTABLE
/// Returns `None` if there is no child corresponding to token GRAPHTOTABLE
fn GRAPHTOTABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRAPHTOTABLE, 0)
}
fn graphToTableOutput_all(&self) ->  Vec<Rc<GraphToTableOutputContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn graphToTableOutput(&self, i: usize) -> Option<Rc<GraphToTableOutputContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}

}

impl<'input> GraphToTableOperatorContextAttrs<'input> for GraphToTableOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphToTableOperator(&mut self,)
	-> Result<Rc<GraphToTableOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphToTableOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 180, RULE_graphToTableOperator);
        let mut _localctx: Rc<GraphToTableOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1280);
			recog.base.match_token(GRAPHTOTABLE,&mut recog.err_handler)?;

			/*InvokeRule graphToTableOutput*/
			recog.base.set_state(1281);
			let tmp = recog.graphToTableOutput()?;
			 cast_mut::<_,GraphToTableOperatorContext >(&mut _localctx).graphToTableOutput = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphToTableOperatorContext >(&mut _localctx).graphToTableOutput.clone().unwrap()
			 ;
			 cast_mut::<_,GraphToTableOperatorContext >(&mut _localctx).Outputs.push(temp);
			  
			{
			recog.base.set_state(1282);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule graphToTableOutput*/
			recog.base.set_state(1283);
			let tmp = recog.graphToTableOutput()?;
			 cast_mut::<_,GraphToTableOperatorContext >(&mut _localctx).graphToTableOutput = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphToTableOperatorContext >(&mut _localctx).graphToTableOutput.clone().unwrap()
			 ;
			 cast_mut::<_,GraphToTableOperatorContext >(&mut _localctx).Outputs.push(temp);
			  
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphToTableOutput ----------------
pub type GraphToTableOutputContextAll<'input> = GraphToTableOutputContext<'input>;


pub type GraphToTableOutputContext<'input> = BaseParserRuleContext<'input,GraphToTableOutputContextExt<'input>>;

#[derive(Clone)]
pub struct GraphToTableOutputContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub AsClause: Option<Rc<GraphToTableAsClauseContextAll<'input>>>,
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphToTableOutputContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphToTableOutputContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphToTableOutput(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphToTableOutput(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphToTableOutputContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphToTableOutput(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphToTableOutputContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphToTableOutput }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphToTableOutput }
}
antlr_rust::tid!{GraphToTableOutputContextExt<'a>}

impl<'input> GraphToTableOutputContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphToTableOutputContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphToTableOutputContextExt{
				Keyword: None, 
				AsClause: None, relaxedQueryOperatorParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphToTableOutputContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphToTableOutputContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NODES
/// Returns `None` if there is no child corresponding to token NODES
fn NODES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NODES, 0)
}
/// Retrieves first TerminalNode corresponding to token EDGES
/// Returns `None` if there is no child corresponding to token EDGES
fn EDGES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EDGES, 0)
}
fn graphToTableAsClause(&self) -> Option<Rc<GraphToTableAsClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> GraphToTableOutputContextAttrs<'input> for GraphToTableOutputContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphToTableOutput(&mut self,)
	-> Result<Rc<GraphToTableOutputContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphToTableOutputContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 182, RULE_graphToTableOutput);
        let mut _localctx: Rc<GraphToTableOutputContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1285);
			 cast_mut::<_,GraphToTableOutputContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==EDGES || _la==NODES) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,GraphToTableOutputContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1287);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==AS {
				{
				/*InvokeRule graphToTableAsClause*/
				recog.base.set_state(1286);
				let tmp = recog.graphToTableAsClause()?;
				 cast_mut::<_,GraphToTableOutputContext >(&mut _localctx).AsClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1292);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1289);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,GraphToTableOutputContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,GraphToTableOutputContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,GraphToTableOutputContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1294);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphToTableAsClause ----------------
pub type GraphToTableAsClauseContextAll<'input> = GraphToTableAsClauseContext<'input>;


pub type GraphToTableAsClauseContext<'input> = BaseParserRuleContext<'input,GraphToTableAsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct GraphToTableAsClauseContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphToTableAsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphToTableAsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphToTableAsClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphToTableAsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphToTableAsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphToTableAsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphToTableAsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphToTableAsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphToTableAsClause }
}
antlr_rust::tid!{GraphToTableAsClauseContextExt<'a>}

impl<'input> GraphToTableAsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphToTableAsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphToTableAsClauseContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphToTableAsClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphToTableAsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphToTableAsClauseContextAttrs<'input> for GraphToTableAsClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphToTableAsClause(&mut self,)
	-> Result<Rc<GraphToTableAsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphToTableAsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 184, RULE_graphToTableAsClause);
        let mut _localctx: Rc<GraphToTableAsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1295);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1296);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,GraphToTableAsClauseContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- graphShortestPathsOperator ----------------
pub type GraphShortestPathsOperatorContextAll<'input> = GraphShortestPathsOperatorContext<'input>;


pub type GraphShortestPathsOperatorContext<'input> = BaseParserRuleContext<'input,GraphShortestPathsOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct GraphShortestPathsOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub graphMatchPattern: Option<Rc<GraphMatchPatternContextAll<'input>>>,
	pub Patterns:Vec<Rc<GraphMatchPatternContextAll<'input>>>,
	pub WhereClause: Option<Rc<GraphMatchWhereClauseContextAll<'input>>>,
	pub ProjectClause: Option<Rc<GraphMatchProjectClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GraphShortestPathsOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GraphShortestPathsOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_graphShortestPathsOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_graphShortestPathsOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GraphShortestPathsOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_graphShortestPathsOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for GraphShortestPathsOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_graphShortestPathsOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_graphShortestPathsOperator }
}
antlr_rust::tid!{GraphShortestPathsOperatorContextExt<'a>}

impl<'input> GraphShortestPathsOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GraphShortestPathsOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GraphShortestPathsOperatorContextExt{
				relaxedQueryOperatorParameter: None, graphMatchPattern: None, WhereClause: None, ProjectClause: None, 
				Parameters: Vec::new(), Patterns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait GraphShortestPathsOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GraphShortestPathsOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GRAPHSHORTESTPATHS
/// Returns `None` if there is no child corresponding to token GRAPHSHORTESTPATHS
fn GRAPHSHORTESTPATHS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRAPHSHORTESTPATHS, 0)
}
fn graphMatchPattern_all(&self) ->  Vec<Rc<GraphMatchPatternContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn graphMatchPattern(&self, i: usize) -> Option<Rc<GraphMatchPatternContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn graphMatchWhereClause(&self) -> Option<Rc<GraphMatchWhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn graphMatchProjectClause(&self) -> Option<Rc<GraphMatchProjectClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> GraphShortestPathsOperatorContextAttrs<'input> for GraphShortestPathsOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn graphShortestPathsOperator(&mut self,)
	-> Result<Rc<GraphShortestPathsOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GraphShortestPathsOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 186, RULE_graphShortestPathsOperator);
        let mut _localctx: Rc<GraphShortestPathsOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1298);
			recog.base.match_token(GRAPHSHORTESTPATHS,&mut recog.err_handler)?;

			recog.base.set_state(1302);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1299);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1304);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule graphMatchPattern*/
			recog.base.set_state(1305);
			let tmp = recog.graphMatchPattern()?;
			 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).graphMatchPattern = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).graphMatchPattern.clone().unwrap()
			 ;
			 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).Patterns.push(temp);
			  
			{
			recog.base.set_state(1306);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule graphMatchPattern*/
			recog.base.set_state(1307);
			let tmp = recog.graphMatchPattern()?;
			 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).graphMatchPattern = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).graphMatchPattern.clone().unwrap()
			 ;
			 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).Patterns.push(temp);
			  
			}
			recog.base.set_state(1310);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WHERE {
				{
				/*InvokeRule graphMatchWhereClause*/
				recog.base.set_state(1309);
				let tmp = recog.graphMatchWhereClause()?;
				 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).WhereClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1313);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(75,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule graphMatchProjectClause*/
					recog.base.set_state(1312);
					let tmp = recog.graphMatchProjectClause()?;
					 cast_mut::<_,GraphShortestPathsOperatorContext >(&mut _localctx).ProjectClause = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- invokeOperator ----------------
pub type InvokeOperatorContextAll<'input> = InvokeOperatorContext<'input>;


pub type InvokeOperatorContext<'input> = BaseParserRuleContext<'input,InvokeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct InvokeOperatorContextExt<'input>{
	pub FunctionCall: Option<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for InvokeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for InvokeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_invokeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_invokeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for InvokeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_invokeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for InvokeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_invokeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_invokeOperator }
}
antlr_rust::tid!{InvokeOperatorContextExt<'a>}

impl<'input> InvokeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InvokeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InvokeOperatorContextExt{
				FunctionCall: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InvokeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<InvokeOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INVOKE
/// Returns `None` if there is no child corresponding to token INVOKE
fn INVOKE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INVOKE, 0)
}
fn dotCompositeFunctionCallExpression(&self) -> Option<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> InvokeOperatorContextAttrs<'input> for InvokeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn invokeOperator(&mut self,)
	-> Result<Rc<InvokeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InvokeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 188, RULE_invokeOperator);
        let mut _localctx: Rc<InvokeOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1315);
			recog.base.match_token(INVOKE,&mut recog.err_handler)?;

			/*InvokeRule dotCompositeFunctionCallExpression*/
			recog.base.set_state(1316);
			let tmp = recog.dotCompositeFunctionCallExpression()?;
			 cast_mut::<_,InvokeOperatorContext >(&mut _localctx).FunctionCall = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinOperator ----------------
pub type JoinOperatorContextAll<'input> = JoinOperatorContext<'input>;


pub type JoinOperatorContext<'input> = BaseParserRuleContext<'input,JoinOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct JoinOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Table: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub OnClause: Option<Rc<JoinOperatorOnClauseContextAll<'input>>>,
	pub WhereClause: Option<Rc<JoinOperatorWhereClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JoinOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JoinOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_joinOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JoinOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_joinOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinOperator }
}
antlr_rust::tid!{JoinOperatorContextExt<'a>}

impl<'input> JoinOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinOperatorContextExt{
				relaxedQueryOperatorParameter: None, Table: None, OnClause: None, WhereClause: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JoinOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token JOIN
/// Returns `None` if there is no child corresponding to token JOIN
fn JOIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(JOIN, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn joinOperatorOnClause(&self) -> Option<Rc<JoinOperatorOnClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinOperatorWhereClause(&self) -> Option<Rc<JoinOperatorWhereClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JoinOperatorContextAttrs<'input> for JoinOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinOperator(&mut self,)
	-> Result<Rc<JoinOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 190, RULE_joinOperator);
        let mut _localctx: Rc<JoinOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1318);
			recog.base.match_token(JOIN,&mut recog.err_handler)?;

			recog.base.set_state(1322);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(76,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1319);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,JoinOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,JoinOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,JoinOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1324);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(76,&mut recog.base)?;
			}
			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1325);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,JoinOperatorContext >(&mut _localctx).Table = Some(tmp.clone());
			  

			recog.base.set_state(1328);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ON 
				=> {
			    	{
			    	/*InvokeRule joinOperatorOnClause*/
			    	recog.base.set_state(1326);
			    	let tmp = recog.joinOperatorOnClause()?;
			    	 cast_mut::<_,JoinOperatorContext >(&mut _localctx).OnClause = Some(tmp.clone());
			    	  

			    	}
			    }

			 WHERE 
				=> {
			    	{
			    	/*InvokeRule joinOperatorWhereClause*/
			    	recog.base.set_state(1327);
			    	let tmp = recog.joinOperatorWhereClause()?;
			    	 cast_mut::<_,JoinOperatorContext >(&mut _localctx).WhereClause = Some(tmp.clone());
			    	  

			    	}
			    }

			 EOF | BAR | CLOSEBRACE | CLOSEPAREN | SEMICOLON | PROJECT 
				=> {
			    }

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinOperatorOnClause ----------------
pub type JoinOperatorOnClauseContextAll<'input> = JoinOperatorOnClauseContext<'input>;


pub type JoinOperatorOnClauseContext<'input> = BaseParserRuleContext<'input,JoinOperatorOnClauseContextExt<'input>>;

#[derive(Clone)]
pub struct JoinOperatorOnClauseContextExt<'input>{
	pub unnamedExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JoinOperatorOnClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JoinOperatorOnClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinOperatorOnClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_joinOperatorOnClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JoinOperatorOnClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_joinOperatorOnClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinOperatorOnClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinOperatorOnClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinOperatorOnClause }
}
antlr_rust::tid!{JoinOperatorOnClauseContextExt<'a>}

impl<'input> JoinOperatorOnClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinOperatorOnClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinOperatorOnClauseContextExt{
				unnamedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinOperatorOnClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JoinOperatorOnClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn unnamedExpression_all(&self) ->  Vec<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unnamedExpression(&self, i: usize) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> JoinOperatorOnClauseContextAttrs<'input> for JoinOperatorOnClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinOperatorOnClause(&mut self,)
	-> Result<Rc<JoinOperatorOnClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinOperatorOnClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 192, RULE_joinOperatorOnClause);
        let mut _localctx: Rc<JoinOperatorOnClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1330);
			recog.base.match_token(ON,&mut recog.err_handler)?;

			recog.base.set_state(1339);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ASTERISK) | (1usize << DASH) | (1usize << OPENBRACKET) | (1usize << OPENPAREN))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (PLUS - 33)) | (1usize << (ACCESS - 33)) | (1usize << (AGGREGATIONS - 33)) | (1usize << (ALIAS - 33)) | (1usize << (ALL - 33)) | (1usize << (AXES - 33)) | (1usize << (BASE - 33)) | (1usize << (BIN - 33)) | (1usize << (CLUSTER - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (CONTEXTUAL_DATATABLE - 65)) | (1usize << (COUNT - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATATABLE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DELTA - 65)) | (1usize << (EDGES - 65)) | (1usize << (EVALUATE - 65)) | (1usize << (EXECUTE - 65)) | (1usize << (EXTERNALDATA - 65)) | (1usize << (EXTERNAL_DATA - 65)) | (1usize << (FACET - 65)) | (1usize << (FORK - 65)) | (1usize << (FROM - 65)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MAP - 145)) | (1usize << (MATERIALIZED_VIEW_COMBINE - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 250)) & !0x3f) == 0 && ((1usize << (_la - 250)) & ((1usize << (TOSCALAR - 250)) | (1usize << (TOTABLE - 250)) | (1usize << (TYPEOF - 250)) | (1usize << (UNSTACKED - 250)) | (1usize << (UUID - 250)) | (1usize << (VIEW - 250)) | (1usize << (VISIBLE - 250)) | (1usize << (WITH - 250)) | (1usize << (XAXIS - 250)) | (1usize << (XCOLUMN - 250)) | (1usize << (XMAX - 250)) | (1usize << (XMIN - 250)) | (1usize << (XTITLE - 250)) | (1usize << (YAXIS - 250)) | (1usize << (YCOLUMNS - 250)) | (1usize << (YMAX - 250)) | (1usize << (YMIN - 250)) | (1usize << (YSPLIT - 250)) | (1usize << (YTITLE - 250)) | (1usize << (BOOL - 250)))) != 0) || ((((_la - 285)) & !0x3f) == 0 && ((1usize << (_la - 285)) & ((1usize << (DYNAMIC - 285)) | (1usize << (GUID - 285)) | (1usize << (LONGLITERAL - 285)) | (1usize << (INTLITERAL - 285)) | (1usize << (REALLITERAL - 285)) | (1usize << (DECIMALLITERAL - 285)) | (1usize << (STRINGLITERAL - 285)) | (1usize << (BOOLEANLITERAL - 285)) | (1usize << (DATETIMELITERAL - 285)) | (1usize << (TIMESPANLITERAL - 285)) | (1usize << (TYPELITERAL - 285)) | (1usize << (GUIDLITERAL - 285)) | (1usize << (IDENTIFIER - 285)))) != 0) {
				{
				/*InvokeRule unnamedExpression*/
				recog.base.set_state(1331);
				let tmp = recog.unnamedExpression()?;
				 cast_mut::<_,JoinOperatorOnClauseContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,JoinOperatorOnClauseContext >(&mut _localctx).unnamedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,JoinOperatorOnClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				recog.base.set_state(1336);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1332);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule unnamedExpression*/
					recog.base.set_state(1333);
					let tmp = recog.unnamedExpression()?;
					 cast_mut::<_,JoinOperatorOnClauseContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,JoinOperatorOnClauseContext >(&mut _localctx).unnamedExpression.clone().unwrap()
					 ;
					 cast_mut::<_,JoinOperatorOnClauseContext >(&mut _localctx).Expressions.push(temp);
					  
					}
					}
					recog.base.set_state(1338);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- joinOperatorWhereClause ----------------
pub type JoinOperatorWhereClauseContextAll<'input> = JoinOperatorWhereClauseContext<'input>;


pub type JoinOperatorWhereClauseContext<'input> = BaseParserRuleContext<'input,JoinOperatorWhereClauseContextExt<'input>>;

#[derive(Clone)]
pub struct JoinOperatorWhereClauseContextExt<'input>{
	pub Predicate: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JoinOperatorWhereClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JoinOperatorWhereClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_joinOperatorWhereClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_joinOperatorWhereClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JoinOperatorWhereClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_joinOperatorWhereClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for JoinOperatorWhereClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_joinOperatorWhereClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_joinOperatorWhereClause }
}
antlr_rust::tid!{JoinOperatorWhereClauseContextExt<'a>}

impl<'input> JoinOperatorWhereClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JoinOperatorWhereClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JoinOperatorWhereClauseContextExt{
				Predicate: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JoinOperatorWhereClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JoinOperatorWhereClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JoinOperatorWhereClauseContextAttrs<'input> for JoinOperatorWhereClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn joinOperatorWhereClause(&mut self,)
	-> Result<Rc<JoinOperatorWhereClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JoinOperatorWhereClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 194, RULE_joinOperatorWhereClause);
        let mut _localctx: Rc<JoinOperatorWhereClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1341);
			recog.base.match_token(WHERE,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1342);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,JoinOperatorWhereClauseContext >(&mut _localctx).Predicate = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- lookupOperator ----------------
pub type LookupOperatorContextAll<'input> = LookupOperatorContext<'input>;


pub type LookupOperatorContext<'input> = BaseParserRuleContext<'input,LookupOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct LookupOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Table: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub OnClause: Option<Rc<JoinOperatorOnClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LookupOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LookupOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_lookupOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_lookupOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LookupOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_lookupOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for LookupOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_lookupOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_lookupOperator }
}
antlr_rust::tid!{LookupOperatorContextExt<'a>}

impl<'input> LookupOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LookupOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LookupOperatorContextExt{
				relaxedQueryOperatorParameter: None, Table: None, OnClause: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LookupOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LookupOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LOOKUP
/// Returns `None` if there is no child corresponding to token LOOKUP
fn LOOKUP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LOOKUP, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn joinOperatorOnClause(&self) -> Option<Rc<JoinOperatorOnClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> LookupOperatorContextAttrs<'input> for LookupOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn lookupOperator(&mut self,)
	-> Result<Rc<LookupOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LookupOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 196, RULE_lookupOperator);
        let mut _localctx: Rc<LookupOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1344);
			recog.base.match_token(LOOKUP,&mut recog.err_handler)?;

			recog.base.set_state(1348);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(80,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1345);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,LookupOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,LookupOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,LookupOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1350);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(80,&mut recog.base)?;
			}
			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1351);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,LookupOperatorContext >(&mut _localctx).Table = Some(tmp.clone());
			  

			/*InvokeRule joinOperatorOnClause*/
			recog.base.set_state(1352);
			let tmp = recog.joinOperatorOnClause()?;
			 cast_mut::<_,LookupOperatorContext >(&mut _localctx).OnClause = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- macroExpandOperator ----------------
pub type MacroExpandOperatorContextAll<'input> = MacroExpandOperatorContext<'input>;


pub type MacroExpandOperatorContext<'input> = BaseParserRuleContext<'input,MacroExpandOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct MacroExpandOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub EntityGroup: Option<Rc<MacroExpandEntityGroupContextAll<'input>>>,
	pub ScopeName: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
	pub statement: Option<Rc<StatementContextAll<'input>>>,
	pub Statements:Vec<Rc<StatementContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MacroExpandOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MacroExpandOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_macroExpandOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_macroExpandOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MacroExpandOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_macroExpandOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for MacroExpandOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_macroExpandOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_macroExpandOperator }
}
antlr_rust::tid!{MacroExpandOperatorContextExt<'a>}

impl<'input> MacroExpandOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MacroExpandOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MacroExpandOperatorContextExt{
				relaxedQueryOperatorParameter: None, EntityGroup: None, ScopeName: None, statement: None, 
				Parameters: Vec::new(), Statements: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MacroExpandOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MacroExpandOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token MACROEXPAND
/// Returns `None` if there is no child corresponding to token MACROEXPAND
fn MACROEXPAND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MACROEXPAND, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn macroExpandEntityGroup(&self) -> Option<Rc<MacroExpandEntityGroupContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn statement_all(&self) ->  Vec<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn statement(&self, i: usize) -> Option<Rc<StatementContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token SEMICOLON in current rule
fn SEMICOLON_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token SEMICOLON, starting from 0.
/// Returns `None` if number of children corresponding to token SEMICOLON is less or equal than `i`.
fn SEMICOLON(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, i)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> MacroExpandOperatorContextAttrs<'input> for MacroExpandOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn macroExpandOperator(&mut self,)
	-> Result<Rc<MacroExpandOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MacroExpandOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 198, RULE_macroExpandOperator);
        let mut _localctx: Rc<MacroExpandOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1354);
			recog.base.match_token(MACROEXPAND,&mut recog.err_handler)?;

			recog.base.set_state(1358);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(81,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1355);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1360);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(81,&mut recog.base)?;
			}
			/*InvokeRule macroExpandEntityGroup*/
			recog.base.set_state(1361);
			let tmp = recog.macroExpandEntityGroup()?;
			 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).EntityGroup = Some(tmp.clone());
			  

			recog.base.set_state(1362);
			recog.base.match_token(AS,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1363);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).ScopeName = Some(tmp.clone());
			  

			recog.base.set_state(1364);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule statement*/
			recog.base.set_state(1365);
			let tmp = recog.statement()?;
			 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).statement = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).statement.clone().unwrap()
			 ;
			 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).Statements.push(temp);
			  
			recog.base.set_state(1370);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(82,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1366);
					recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

					/*InvokeRule statement*/
					recog.base.set_state(1367);
					let tmp = recog.statement()?;
					 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).statement = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).statement.clone().unwrap()
					 ;
					 cast_mut::<_,MacroExpandOperatorContext >(&mut _localctx).Statements.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1372);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(82,&mut recog.base)?;
			}
			recog.base.set_state(1374);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==SEMICOLON {
				{
				recog.base.set_state(1373);
				recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1376);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- macroExpandEntityGroup ----------------
pub type MacroExpandEntityGroupContextAll<'input> = MacroExpandEntityGroupContext<'input>;


pub type MacroExpandEntityGroupContext<'input> = BaseParserRuleContext<'input,MacroExpandEntityGroupContextExt<'input>>;

#[derive(Clone)]
pub struct MacroExpandEntityGroupContextExt<'input>{
	pub EntityGroup: Option<Rc<EntityGroupExpressionContextAll<'input>>>,
	pub Name: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub Entity: Option<Rc<EntityExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MacroExpandEntityGroupContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MacroExpandEntityGroupContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_macroExpandEntityGroup(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_macroExpandEntityGroup(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MacroExpandEntityGroupContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_macroExpandEntityGroup(self);
	}
}

impl<'input> CustomRuleContext<'input> for MacroExpandEntityGroupContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_macroExpandEntityGroup }
	//fn type_rule_index() -> usize where Self: Sized { RULE_macroExpandEntityGroup }
}
antlr_rust::tid!{MacroExpandEntityGroupContextExt<'a>}

impl<'input> MacroExpandEntityGroupContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MacroExpandEntityGroupContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MacroExpandEntityGroupContextExt{
				EntityGroup: None, Name: None, Entity: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MacroExpandEntityGroupContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MacroExpandEntityGroupContextExt<'input>>{

fn entityGroupExpression(&self) -> Option<Rc<EntityGroupExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn entityExpression(&self) -> Option<Rc<EntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MacroExpandEntityGroupContextAttrs<'input> for MacroExpandEntityGroupContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn macroExpandEntityGroup(&mut self,)
	-> Result<Rc<MacroExpandEntityGroupContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MacroExpandEntityGroupContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 200, RULE_macroExpandEntityGroup);
        let mut _localctx: Rc<MacroExpandEntityGroupContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1381);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(84,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule entityGroupExpression*/
					recog.base.set_state(1378);
					let tmp = recog.entityGroupExpression()?;
					 cast_mut::<_,MacroExpandEntityGroupContext >(&mut _localctx).EntityGroup = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule simpleNameReference*/
					recog.base.set_state(1379);
					let tmp = recog.simpleNameReference()?;
					 cast_mut::<_,MacroExpandEntityGroupContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule entityExpression*/
					recog.base.set_state(1380);
					let tmp = recog.entityExpression()?;
					 cast_mut::<_,MacroExpandEntityGroupContext >(&mut _localctx).Entity = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityGroupExpression ----------------
pub type EntityGroupExpressionContextAll<'input> = EntityGroupExpressionContext<'input>;


pub type EntityGroupExpressionContext<'input> = BaseParserRuleContext<'input,EntityGroupExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct EntityGroupExpressionContextExt<'input>{
	pub unnamedExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityGroupExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityGroupExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityGroupExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityGroupExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityGroupExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityGroupExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityGroupExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityGroupExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityGroupExpression }
}
antlr_rust::tid!{EntityGroupExpressionContextExt<'a>}

impl<'input> EntityGroupExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityGroupExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityGroupExpressionContextExt{
				unnamedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityGroupExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityGroupExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ENTITYGROUP
/// Returns `None` if there is no child corresponding to token ENTITYGROUP
fn ENTITYGROUP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ENTITYGROUP, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn unnamedExpression_all(&self) ->  Vec<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unnamedExpression(&self, i: usize) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> EntityGroupExpressionContextAttrs<'input> for EntityGroupExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityGroupExpression(&mut self,)
	-> Result<Rc<EntityGroupExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityGroupExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 202, RULE_entityGroupExpression);
        let mut _localctx: Rc<EntityGroupExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1383);
			recog.base.match_token(ENTITYGROUP,&mut recog.err_handler)?;

			recog.base.set_state(1384);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1385);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,EntityGroupExpressionContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,EntityGroupExpressionContext >(&mut _localctx).unnamedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,EntityGroupExpressionContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1390);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1386);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unnamedExpression*/
				recog.base.set_state(1387);
				let tmp = recog.unnamedExpression()?;
				 cast_mut::<_,EntityGroupExpressionContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,EntityGroupExpressionContext >(&mut _localctx).unnamedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,EntityGroupExpressionContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1392);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1393);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeGraphOperator ----------------
pub type MakeGraphOperatorContextAll<'input> = MakeGraphOperatorContext<'input>;


pub type MakeGraphOperatorContext<'input> = BaseParserRuleContext<'input,MakeGraphOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct MakeGraphOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub SourceColumn: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub Direction: Option<TokenType<'input>>,
	pub TargetColumn: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub IdClause: Option<Rc<MakeGraphIdClauseContextAll<'input>>>,
	pub TablesAndKeysClause: Option<Rc<MakeGraphTablesAndKeysClauseContextAll<'input>>>,
	pub PartitionedByClause: Option<Rc<MakeGraphPartitionedByClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeGraphOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeGraphOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeGraphOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeGraphOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeGraphOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeGraphOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeGraphOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeGraphOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeGraphOperator }
}
antlr_rust::tid!{MakeGraphOperatorContextExt<'a>}

impl<'input> MakeGraphOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeGraphOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeGraphOperatorContextExt{
				Direction: None, 
				relaxedQueryOperatorParameter: None, SourceColumn: None, TargetColumn: None, IdClause: None, TablesAndKeysClause: None, PartitionedByClause: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeGraphOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeGraphOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token MAKEGRAPH
/// Returns `None` if there is no child corresponding to token MAKEGRAPH
fn MAKEGRAPH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MAKEGRAPH, 0)
}
fn simpleNameReference_all(&self) ->  Vec<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn simpleNameReference(&self, i: usize) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token DASHDASH_GREATERTHAN
/// Returns `None` if there is no child corresponding to token DASHDASH_GREATERTHAN
fn DASHDASH_GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASHDASH_GREATERTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token DASHDASH
/// Returns `None` if there is no child corresponding to token DASHDASH
fn DASHDASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASHDASH, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn makeGraphIdClause(&self) -> Option<Rc<MakeGraphIdClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn makeGraphTablesAndKeysClause(&self) -> Option<Rc<MakeGraphTablesAndKeysClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn makeGraphPartitionedByClause(&self) -> Option<Rc<MakeGraphPartitionedByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeGraphOperatorContextAttrs<'input> for MakeGraphOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeGraphOperator(&mut self,)
	-> Result<Rc<MakeGraphOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeGraphOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 204, RULE_makeGraphOperator);
        let mut _localctx: Rc<MakeGraphOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1395);
			recog.base.match_token(MAKEGRAPH,&mut recog.err_handler)?;

			recog.base.set_state(1399);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(86,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1396);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1401);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(86,&mut recog.base)?;
			}
			/*InvokeRule simpleNameReference*/
			recog.base.set_state(1402);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).SourceColumn = Some(tmp.clone());
			  

			recog.base.set_state(1403);
			 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).Direction = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==DASHDASH || _la==DASHDASH_GREATERTHAN) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).Direction = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule simpleNameReference*/
			recog.base.set_state(1404);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).TargetColumn = Some(tmp.clone());
			  

			recog.base.set_state(1407);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 WITH_NODE_ID 
				=> {
			    	{
			    	/*InvokeRule makeGraphIdClause*/
			    	recog.base.set_state(1405);
			    	let tmp = recog.makeGraphIdClause()?;
			    	 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).IdClause = Some(tmp.clone());
			    	  

			    	}
			    }

			 WITH 
				=> {
			    	{
			    	/*InvokeRule makeGraphTablesAndKeysClause*/
			    	recog.base.set_state(1406);
			    	let tmp = recog.makeGraphTablesAndKeysClause()?;
			    	 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).TablesAndKeysClause = Some(tmp.clone());
			    	  

			    	}
			    }

			 EOF | BAR | CLOSEBRACE | CLOSEPAREN | SEMICOLON | PARTITIONEDBY | PROJECT 
				=> {
			    }

				_ => {}
			}
			recog.base.set_state(1410);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITIONEDBY {
				{
				/*InvokeRule makeGraphPartitionedByClause*/
				recog.base.set_state(1409);
				let tmp = recog.makeGraphPartitionedByClause()?;
				 cast_mut::<_,MakeGraphOperatorContext >(&mut _localctx).PartitionedByClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeGraphIdClause ----------------
pub type MakeGraphIdClauseContextAll<'input> = MakeGraphIdClauseContext<'input>;


pub type MakeGraphIdClauseContext<'input> = BaseParserRuleContext<'input,MakeGraphIdClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeGraphIdClauseContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeGraphIdClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeGraphIdClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeGraphIdClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeGraphIdClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeGraphIdClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeGraphIdClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeGraphIdClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeGraphIdClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeGraphIdClause }
}
antlr_rust::tid!{MakeGraphIdClauseContextExt<'a>}

impl<'input> MakeGraphIdClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeGraphIdClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeGraphIdClauseContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeGraphIdClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeGraphIdClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH_NODE_ID
/// Returns `None` if there is no child corresponding to token WITH_NODE_ID
fn WITH_NODE_ID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_NODE_ID, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeGraphIdClauseContextAttrs<'input> for MakeGraphIdClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeGraphIdClause(&mut self,)
	-> Result<Rc<MakeGraphIdClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeGraphIdClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 206, RULE_makeGraphIdClause);
        let mut _localctx: Rc<MakeGraphIdClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1412);
			recog.base.match_token(WITH_NODE_ID,&mut recog.err_handler)?;

			recog.base.set_state(1413);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(1414);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,MakeGraphIdClauseContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeGraphTablesAndKeysClause ----------------
pub type MakeGraphTablesAndKeysClauseContextAll<'input> = MakeGraphTablesAndKeysClauseContext<'input>;


pub type MakeGraphTablesAndKeysClauseContext<'input> = BaseParserRuleContext<'input,MakeGraphTablesAndKeysClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeGraphTablesAndKeysClauseContextExt<'input>{
	pub Table: Option<Rc<InvocationExpressionContextAll<'input>>>,
	pub Column: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeGraphTablesAndKeysClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeGraphTablesAndKeysClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeGraphTablesAndKeysClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeGraphTablesAndKeysClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeGraphTablesAndKeysClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeGraphTablesAndKeysClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeGraphTablesAndKeysClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeGraphTablesAndKeysClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeGraphTablesAndKeysClause }
}
antlr_rust::tid!{MakeGraphTablesAndKeysClauseContextExt<'a>}

impl<'input> MakeGraphTablesAndKeysClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeGraphTablesAndKeysClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeGraphTablesAndKeysClauseContextExt{
				Table: None, Column: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeGraphTablesAndKeysClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeGraphTablesAndKeysClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn invocationExpression(&self) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeGraphTablesAndKeysClauseContextAttrs<'input> for MakeGraphTablesAndKeysClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeGraphTablesAndKeysClause(&mut self,)
	-> Result<Rc<MakeGraphTablesAndKeysClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeGraphTablesAndKeysClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 208, RULE_makeGraphTablesAndKeysClause);
        let mut _localctx: Rc<MakeGraphTablesAndKeysClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1416);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(1417);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,MakeGraphTablesAndKeysClauseContext >(&mut _localctx).Table = Some(tmp.clone());
			  

			recog.base.set_state(1418);
			recog.base.match_token(ON,&mut recog.err_handler)?;

			/*InvokeRule simpleNameReference*/
			recog.base.set_state(1419);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,MakeGraphTablesAndKeysClauseContext >(&mut _localctx).Column = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeGraphPartitionedByClause ----------------
pub type MakeGraphPartitionedByClauseContextAll<'input> = MakeGraphPartitionedByClauseContext<'input>;


pub type MakeGraphPartitionedByClauseContext<'input> = BaseParserRuleContext<'input,MakeGraphPartitionedByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeGraphPartitionedByClauseContextExt<'input>{
	pub Entity: Option<Rc<EntityPathOrElementExpressionContextAll<'input>>>,
	pub SubQuery: Option<Rc<ContextualSubExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeGraphPartitionedByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeGraphPartitionedByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeGraphPartitionedByClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeGraphPartitionedByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeGraphPartitionedByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeGraphPartitionedByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeGraphPartitionedByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeGraphPartitionedByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeGraphPartitionedByClause }
}
antlr_rust::tid!{MakeGraphPartitionedByClauseContextExt<'a>}

impl<'input> MakeGraphPartitionedByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeGraphPartitionedByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeGraphPartitionedByClauseContextExt{
				Entity: None, SubQuery: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeGraphPartitionedByClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeGraphPartitionedByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITIONEDBY
/// Returns `None` if there is no child corresponding to token PARTITIONEDBY
fn PARTITIONEDBY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONEDBY, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn entityPathOrElementExpression(&self) -> Option<Rc<EntityPathOrElementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn contextualSubExpression(&self) -> Option<Rc<ContextualSubExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeGraphPartitionedByClauseContextAttrs<'input> for MakeGraphPartitionedByClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeGraphPartitionedByClause(&mut self,)
	-> Result<Rc<MakeGraphPartitionedByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeGraphPartitionedByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 210, RULE_makeGraphPartitionedByClause);
        let mut _localctx: Rc<MakeGraphPartitionedByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1421);
			recog.base.match_token(PARTITIONEDBY,&mut recog.err_handler)?;

			/*InvokeRule entityPathOrElementExpression*/
			recog.base.set_state(1422);
			let tmp = recog.entityPathOrElementExpression()?;
			 cast_mut::<_,MakeGraphPartitionedByClauseContext >(&mut _localctx).Entity = Some(tmp.clone());
			  

			recog.base.set_state(1423);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule contextualSubExpression*/
			recog.base.set_state(1424);
			let tmp = recog.contextualSubExpression()?;
			 cast_mut::<_,MakeGraphPartitionedByClauseContext >(&mut _localctx).SubQuery = Some(tmp.clone());
			  

			recog.base.set_state(1425);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperator ----------------
pub type MakeSeriesOperatorContextAll<'input> = MakeSeriesOperatorContext<'input>;


pub type MakeSeriesOperatorContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub makeSeriesOperatorAggregation: Option<Rc<MakeSeriesOperatorAggregationContextAll<'input>>>,
	pub Aggregations:Vec<Rc<MakeSeriesOperatorAggregationContextAll<'input>>>,
	pub OnClause: Option<Rc<MakeSeriesOperatorOnClauseContextAll<'input>>>,
	pub InRangeClause: Option<Rc<MakeSeriesOperatorInRangeClauseContextAll<'input>>>,
	pub FromToStepClause: Option<Rc<MakeSeriesOperatorFromToStepClauseContextAll<'input>>>,
	pub ByClause: Option<Rc<MakeSeriesOperatorByClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperator }
}
antlr_rust::tid!{MakeSeriesOperatorContextExt<'a>}

impl<'input> MakeSeriesOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorContextExt{
				relaxedQueryOperatorParameter: None, makeSeriesOperatorAggregation: None, OnClause: None, InRangeClause: None, FromToStepClause: None, ByClause: None, 
				Parameters: Vec::new(), Aggregations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token MAKESERIES
/// Returns `None` if there is no child corresponding to token MAKESERIES
fn MAKESERIES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MAKESERIES, 0)
}
fn makeSeriesOperatorAggregation_all(&self) ->  Vec<Rc<MakeSeriesOperatorAggregationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn makeSeriesOperatorAggregation(&self, i: usize) -> Option<Rc<MakeSeriesOperatorAggregationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn makeSeriesOperatorOnClause(&self) -> Option<Rc<MakeSeriesOperatorOnClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn makeSeriesOperatorInRangeClause(&self) -> Option<Rc<MakeSeriesOperatorInRangeClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn makeSeriesOperatorFromToStepClause(&self) -> Option<Rc<MakeSeriesOperatorFromToStepClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn makeSeriesOperatorByClause(&self) -> Option<Rc<MakeSeriesOperatorByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeSeriesOperatorContextAttrs<'input> for MakeSeriesOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperator(&mut self,)
	-> Result<Rc<MakeSeriesOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 212, RULE_makeSeriesOperator);
        let mut _localctx: Rc<MakeSeriesOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1427);
			recog.base.match_token(MAKESERIES,&mut recog.err_handler)?;

			recog.base.set_state(1431);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(89,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1428);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1433);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(89,&mut recog.base)?;
			}
			/*InvokeRule makeSeriesOperatorAggregation*/
			recog.base.set_state(1434);
			let tmp = recog.makeSeriesOperatorAggregation()?;
			 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).makeSeriesOperatorAggregation = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).makeSeriesOperatorAggregation.clone().unwrap()
			 ;
			 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).Aggregations.push(temp);
			  
			recog.base.set_state(1439);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1435);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule makeSeriesOperatorAggregation*/
				recog.base.set_state(1436);
				let tmp = recog.makeSeriesOperatorAggregation()?;
				 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).makeSeriesOperatorAggregation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).makeSeriesOperatorAggregation.clone().unwrap()
				 ;
				 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).Aggregations.push(temp);
				  
				}
				}
				recog.base.set_state(1441);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule makeSeriesOperatorOnClause*/
			recog.base.set_state(1442);
			let tmp = recog.makeSeriesOperatorOnClause()?;
			 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).OnClause = Some(tmp.clone());
			  

			recog.base.set_state(1445);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IN 
				=> {
					{
					/*InvokeRule makeSeriesOperatorInRangeClause*/
					recog.base.set_state(1443);
					let tmp = recog.makeSeriesOperatorInRangeClause()?;
					 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).InRangeClause = Some(tmp.clone());
					  

					}
				}

			 FROM | STEP | TO 
				=> {
					{
					/*InvokeRule makeSeriesOperatorFromToStepClause*/
					recog.base.set_state(1444);
					let tmp = recog.makeSeriesOperatorFromToStepClause()?;
					 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).FromToStepClause = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(1448);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BY {
				{
				/*InvokeRule makeSeriesOperatorByClause*/
				recog.base.set_state(1447);
				let tmp = recog.makeSeriesOperatorByClause()?;
				 cast_mut::<_,MakeSeriesOperatorContext >(&mut _localctx).ByClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperatorOnClause ----------------
pub type MakeSeriesOperatorOnClauseContextAll<'input> = MakeSeriesOperatorOnClauseContext<'input>;


pub type MakeSeriesOperatorOnClauseContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorOnClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorOnClauseContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorOnClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorOnClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperatorOnClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperatorOnClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorOnClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperatorOnClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorOnClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperatorOnClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperatorOnClause }
}
antlr_rust::tid!{MakeSeriesOperatorOnClauseContextExt<'a>}

impl<'input> MakeSeriesOperatorOnClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorOnClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorOnClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorOnClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorOnClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeSeriesOperatorOnClauseContextAttrs<'input> for MakeSeriesOperatorOnClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperatorOnClause(&mut self,)
	-> Result<Rc<MakeSeriesOperatorOnClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorOnClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 214, RULE_makeSeriesOperatorOnClause);
        let mut _localctx: Rc<MakeSeriesOperatorOnClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1450);
			recog.base.match_token(ON,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1451);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorOnClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperatorAggregation ----------------
pub type MakeSeriesOperatorAggregationContextAll<'input> = MakeSeriesOperatorAggregationContext<'input>;


pub type MakeSeriesOperatorAggregationContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorAggregationContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorAggregationContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Default: Option<Rc<MakeSeriesOperatorExpressionDefaultClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorAggregationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorAggregationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperatorAggregation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperatorAggregation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorAggregationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperatorAggregation(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorAggregationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperatorAggregation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperatorAggregation }
}
antlr_rust::tid!{MakeSeriesOperatorAggregationContextExt<'a>}

impl<'input> MakeSeriesOperatorAggregationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorAggregationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorAggregationContextExt{
				Expression: None, Default: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorAggregationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorAggregationContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn makeSeriesOperatorExpressionDefaultClause(&self) -> Option<Rc<MakeSeriesOperatorExpressionDefaultClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeSeriesOperatorAggregationContextAttrs<'input> for MakeSeriesOperatorAggregationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperatorAggregation(&mut self,)
	-> Result<Rc<MakeSeriesOperatorAggregationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorAggregationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 216, RULE_makeSeriesOperatorAggregation);
        let mut _localctx: Rc<MakeSeriesOperatorAggregationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(1453);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorAggregationContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1455);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DEFAULT {
				{
				/*InvokeRule makeSeriesOperatorExpressionDefaultClause*/
				recog.base.set_state(1454);
				let tmp = recog.makeSeriesOperatorExpressionDefaultClause()?;
				 cast_mut::<_,MakeSeriesOperatorAggregationContext >(&mut _localctx).Default = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperatorExpressionDefaultClause ----------------
pub type MakeSeriesOperatorExpressionDefaultClauseContextAll<'input> = MakeSeriesOperatorExpressionDefaultClauseContext<'input>;


pub type MakeSeriesOperatorExpressionDefaultClauseContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorExpressionDefaultClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorExpressionDefaultClauseContextExt<'input>{
	pub Value: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorExpressionDefaultClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorExpressionDefaultClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperatorExpressionDefaultClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperatorExpressionDefaultClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorExpressionDefaultClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperatorExpressionDefaultClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorExpressionDefaultClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperatorExpressionDefaultClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperatorExpressionDefaultClause }
}
antlr_rust::tid!{MakeSeriesOperatorExpressionDefaultClauseContextExt<'a>}

impl<'input> MakeSeriesOperatorExpressionDefaultClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorExpressionDefaultClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorExpressionDefaultClauseContextExt{
				Value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorExpressionDefaultClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorExpressionDefaultClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MakeSeriesOperatorExpressionDefaultClauseContextAttrs<'input> for MakeSeriesOperatorExpressionDefaultClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperatorExpressionDefaultClause(&mut self,)
	-> Result<Rc<MakeSeriesOperatorExpressionDefaultClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorExpressionDefaultClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 218, RULE_makeSeriesOperatorExpressionDefaultClause);
        let mut _localctx: Rc<MakeSeriesOperatorExpressionDefaultClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1457);
			recog.base.match_token(DEFAULT,&mut recog.err_handler)?;

			recog.base.set_state(1458);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1459);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorExpressionDefaultClauseContext >(&mut _localctx).Value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperatorInRangeClause ----------------
pub type MakeSeriesOperatorInRangeClauseContextAll<'input> = MakeSeriesOperatorInRangeClauseContext<'input>;


pub type MakeSeriesOperatorInRangeClauseContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorInRangeClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorInRangeClauseContextExt<'input>{
	pub FromExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub ToComma: Option<TokenType<'input>>,
	pub ToExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub StepComma: Option<TokenType<'input>>,
	pub StepExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorInRangeClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorInRangeClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperatorInRangeClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperatorInRangeClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorInRangeClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperatorInRangeClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorInRangeClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperatorInRangeClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperatorInRangeClause }
}
antlr_rust::tid!{MakeSeriesOperatorInRangeClauseContextExt<'a>}

impl<'input> MakeSeriesOperatorInRangeClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorInRangeClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorInRangeClauseContextExt{
				ToComma: None, StepComma: None, 
				FromExpression: None, ToExpression: None, StepExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorInRangeClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorInRangeClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MakeSeriesOperatorInRangeClauseContextAttrs<'input> for MakeSeriesOperatorInRangeClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperatorInRangeClause(&mut self,)
	-> Result<Rc<MakeSeriesOperatorInRangeClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorInRangeClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 220, RULE_makeSeriesOperatorInRangeClause);
        let mut _localctx: Rc<MakeSeriesOperatorInRangeClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1461);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(1462);
			recog.base.match_token(RANGE,&mut recog.err_handler)?;

			recog.base.set_state(1463);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1464);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorInRangeClauseContext >(&mut _localctx).FromExpression = Some(tmp.clone());
			  

			recog.base.set_state(1465);
			let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
			 cast_mut::<_,MakeSeriesOperatorInRangeClauseContext >(&mut _localctx).ToComma = Some(tmp.clone());
			  

			/*InvokeRule namedExpression*/
			recog.base.set_state(1466);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorInRangeClauseContext >(&mut _localctx).ToExpression = Some(tmp.clone());
			  

			recog.base.set_state(1467);
			let tmp = recog.base.match_token(COMMA,&mut recog.err_handler)?;
			 cast_mut::<_,MakeSeriesOperatorInRangeClauseContext >(&mut _localctx).StepComma = Some(tmp.clone());
			  

			/*InvokeRule namedExpression*/
			recog.base.set_state(1468);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorInRangeClauseContext >(&mut _localctx).StepExpression = Some(tmp.clone());
			  

			recog.base.set_state(1469);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperatorFromToStepClause ----------------
pub type MakeSeriesOperatorFromToStepClauseContextAll<'input> = MakeSeriesOperatorFromToStepClauseContext<'input>;


pub type MakeSeriesOperatorFromToStepClauseContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorFromToStepClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorFromToStepClauseContextExt<'input>{
	pub FromExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub ToExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub StepExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorFromToStepClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorFromToStepClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperatorFromToStepClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperatorFromToStepClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorFromToStepClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperatorFromToStepClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorFromToStepClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperatorFromToStepClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperatorFromToStepClause }
}
antlr_rust::tid!{MakeSeriesOperatorFromToStepClauseContextExt<'a>}

impl<'input> MakeSeriesOperatorFromToStepClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorFromToStepClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorFromToStepClauseContextExt{
				FromExpression: None, ToExpression: None, StepExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorFromToStepClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorFromToStepClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STEP
/// Returns `None` if there is no child corresponding to token STEP
fn STEP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STEP, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}

}

impl<'input> MakeSeriesOperatorFromToStepClauseContextAttrs<'input> for MakeSeriesOperatorFromToStepClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperatorFromToStepClause(&mut self,)
	-> Result<Rc<MakeSeriesOperatorFromToStepClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorFromToStepClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 222, RULE_makeSeriesOperatorFromToStepClause);
        let mut _localctx: Rc<MakeSeriesOperatorFromToStepClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1473);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FROM {
				{
				recog.base.set_state(1471);
				recog.base.match_token(FROM,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1472);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,MakeSeriesOperatorFromToStepClauseContext >(&mut _localctx).FromExpression = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1477);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==TO {
				{
				recog.base.set_state(1475);
				recog.base.match_token(TO,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1476);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,MakeSeriesOperatorFromToStepClauseContext >(&mut _localctx).ToExpression = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1479);
			recog.base.match_token(STEP,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1480);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorFromToStepClauseContext >(&mut _localctx).StepExpression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- makeSeriesOperatorByClause ----------------
pub type MakeSeriesOperatorByClauseContextAll<'input> = MakeSeriesOperatorByClauseContext<'input>;


pub type MakeSeriesOperatorByClauseContext<'input> = BaseParserRuleContext<'input,MakeSeriesOperatorByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MakeSeriesOperatorByClauseContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MakeSeriesOperatorByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MakeSeriesOperatorByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_makeSeriesOperatorByClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_makeSeriesOperatorByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MakeSeriesOperatorByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_makeSeriesOperatorByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MakeSeriesOperatorByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_makeSeriesOperatorByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_makeSeriesOperatorByClause }
}
antlr_rust::tid!{MakeSeriesOperatorByClauseContextExt<'a>}

impl<'input> MakeSeriesOperatorByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MakeSeriesOperatorByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MakeSeriesOperatorByClauseContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MakeSeriesOperatorByClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MakeSeriesOperatorByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> MakeSeriesOperatorByClauseContextAttrs<'input> for MakeSeriesOperatorByClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn makeSeriesOperatorByClause(&mut self,)
	-> Result<Rc<MakeSeriesOperatorByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MakeSeriesOperatorByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 224, RULE_makeSeriesOperatorByClause);
        let mut _localctx: Rc<MakeSeriesOperatorByClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1482);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1483);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MakeSeriesOperatorByClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MakeSeriesOperatorByClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,MakeSeriesOperatorByClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1488);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1484);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1485);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,MakeSeriesOperatorByClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MakeSeriesOperatorByClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,MakeSeriesOperatorByClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1490);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvapplyOperator ----------------
pub type MvapplyOperatorContextAll<'input> = MvapplyOperatorContext<'input>;


pub type MvapplyOperatorContext<'input> = BaseParserRuleContext<'input,MvapplyOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct MvapplyOperatorContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub mvapplyOperatorExpression: Option<Rc<MvapplyOperatorExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<MvapplyOperatorExpressionContextAll<'input>>>,
	pub LimitClause: Option<Rc<MvapplyOperatorLimitClauseContextAll<'input>>>,
	pub IdClause: Option<Rc<MvapplyOperatorIdClauseContextAll<'input>>>,
	pub OnExpression: Option<Rc<ContextualSubExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvapplyOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvapplyOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvapplyOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvapplyOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvapplyOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvapplyOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvapplyOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvapplyOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvapplyOperator }
}
antlr_rust::tid!{MvapplyOperatorContextExt<'a>}

impl<'input> MvapplyOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvapplyOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvapplyOperatorContextExt{
				Keyword: None, 
				strictQueryOperatorParameter: None, mvapplyOperatorExpression: None, LimitClause: None, IdClause: None, OnExpression: None, 
				Parameters: Vec::new(), Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvapplyOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvapplyOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn mvapplyOperatorExpression_all(&self) ->  Vec<Rc<MvapplyOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn mvapplyOperatorExpression(&self, i: usize) -> Option<Rc<MvapplyOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn contextualSubExpression(&self) -> Option<Rc<ContextualSubExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token MVAPPLY
/// Returns `None` if there is no child corresponding to token MVAPPLY
fn MVAPPLY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MVAPPLY, 0)
}
/// Retrieves first TerminalNode corresponding to token MV_APPLY
/// Returns `None` if there is no child corresponding to token MV_APPLY
fn MV_APPLY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MV_APPLY, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn mvapplyOperatorLimitClause(&self) -> Option<Rc<MvapplyOperatorLimitClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mvapplyOperatorIdClause(&self) -> Option<Rc<MvapplyOperatorIdClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MvapplyOperatorContextAttrs<'input> for MvapplyOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvapplyOperator(&mut self,)
	-> Result<Rc<MvapplyOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvapplyOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 226, RULE_mvapplyOperator);
        let mut _localctx: Rc<MvapplyOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1491);
			 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==MV_APPLY || _la==MVAPPLY) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1495);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(1492);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1497);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule mvapplyOperatorExpression*/
			recog.base.set_state(1498);
			let tmp = recog.mvapplyOperatorExpression()?;
			 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).mvapplyOperatorExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).mvapplyOperatorExpression.clone().unwrap()
			 ;
			 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1503);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1499);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule mvapplyOperatorExpression*/
				recog.base.set_state(1500);
				let tmp = recog.mvapplyOperatorExpression()?;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).mvapplyOperatorExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).mvapplyOperatorExpression.clone().unwrap()
				 ;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1505);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1507);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				/*InvokeRule mvapplyOperatorLimitClause*/
				recog.base.set_state(1506);
				let tmp = recog.mvapplyOperatorLimitClause()?;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).LimitClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1510);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ID {
				{
				/*InvokeRule mvapplyOperatorIdClause*/
				recog.base.set_state(1509);
				let tmp = recog.mvapplyOperatorIdClause()?;
				 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).IdClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1512);
			recog.base.match_token(ON,&mut recog.err_handler)?;

			recog.base.set_state(1513);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule contextualSubExpression*/
			recog.base.set_state(1514);
			let tmp = recog.contextualSubExpression()?;
			 cast_mut::<_,MvapplyOperatorContext >(&mut _localctx).OnExpression = Some(tmp.clone());
			  

			recog.base.set_state(1515);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvapplyOperatorLimitClause ----------------
pub type MvapplyOperatorLimitClauseContextAll<'input> = MvapplyOperatorLimitClauseContext<'input>;


pub type MvapplyOperatorLimitClauseContext<'input> = BaseParserRuleContext<'input,MvapplyOperatorLimitClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MvapplyOperatorLimitClauseContextExt<'input>{
	pub LimitValue: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvapplyOperatorLimitClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvapplyOperatorLimitClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvapplyOperatorLimitClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvapplyOperatorLimitClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvapplyOperatorLimitClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvapplyOperatorLimitClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvapplyOperatorLimitClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvapplyOperatorLimitClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvapplyOperatorLimitClause }
}
antlr_rust::tid!{MvapplyOperatorLimitClauseContextExt<'a>}

impl<'input> MvapplyOperatorLimitClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvapplyOperatorLimitClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvapplyOperatorLimitClauseContextExt{
				LimitValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvapplyOperatorLimitClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvapplyOperatorLimitClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token LONGLITERAL
/// Returns `None` if there is no child corresponding to token LONGLITERAL
fn LONGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONGLITERAL, 0)
}

}

impl<'input> MvapplyOperatorLimitClauseContextAttrs<'input> for MvapplyOperatorLimitClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvapplyOperatorLimitClause(&mut self,)
	-> Result<Rc<MvapplyOperatorLimitClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvapplyOperatorLimitClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 228, RULE_mvapplyOperatorLimitClause);
        let mut _localctx: Rc<MvapplyOperatorLimitClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1517);
			recog.base.match_token(LIMIT,&mut recog.err_handler)?;

			recog.base.set_state(1518);
			let tmp = recog.base.match_token(LONGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,MvapplyOperatorLimitClauseContext >(&mut _localctx).LimitValue = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvapplyOperatorIdClause ----------------
pub type MvapplyOperatorIdClauseContextAll<'input> = MvapplyOperatorIdClauseContext<'input>;


pub type MvapplyOperatorIdClauseContext<'input> = BaseParserRuleContext<'input,MvapplyOperatorIdClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MvapplyOperatorIdClauseContextExt<'input>{
	pub IdValue: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvapplyOperatorIdClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvapplyOperatorIdClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvapplyOperatorIdClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvapplyOperatorIdClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvapplyOperatorIdClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvapplyOperatorIdClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvapplyOperatorIdClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvapplyOperatorIdClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvapplyOperatorIdClause }
}
antlr_rust::tid!{MvapplyOperatorIdClauseContextExt<'a>}

impl<'input> MvapplyOperatorIdClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvapplyOperatorIdClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvapplyOperatorIdClauseContextExt{
				IdValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvapplyOperatorIdClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvapplyOperatorIdClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ID
/// Returns `None` if there is no child corresponding to token ID
fn ID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ID, 0)
}
/// Retrieves first TerminalNode corresponding to token GUIDLITERAL
/// Returns `None` if there is no child corresponding to token GUIDLITERAL
fn GUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUIDLITERAL, 0)
}

}

impl<'input> MvapplyOperatorIdClauseContextAttrs<'input> for MvapplyOperatorIdClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvapplyOperatorIdClause(&mut self,)
	-> Result<Rc<MvapplyOperatorIdClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvapplyOperatorIdClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 230, RULE_mvapplyOperatorIdClause);
        let mut _localctx: Rc<MvapplyOperatorIdClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1520);
			recog.base.match_token(ID,&mut recog.err_handler)?;

			recog.base.set_state(1521);
			let tmp = recog.base.match_token(GUIDLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,MvapplyOperatorIdClauseContext >(&mut _localctx).IdValue = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvapplyOperatorExpression ----------------
pub type MvapplyOperatorExpressionContextAll<'input> = MvapplyOperatorExpressionContext<'input>;


pub type MvapplyOperatorExpressionContext<'input> = BaseParserRuleContext<'input,MvapplyOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct MvapplyOperatorExpressionContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub ToClause: Option<Rc<MvapplyOperatorExpressionToClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvapplyOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvapplyOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvapplyOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvapplyOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvapplyOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvapplyOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvapplyOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvapplyOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvapplyOperatorExpression }
}
antlr_rust::tid!{MvapplyOperatorExpressionContextExt<'a>}

impl<'input> MvapplyOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvapplyOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvapplyOperatorExpressionContextExt{
				Expression: None, ToClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvapplyOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvapplyOperatorExpressionContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mvapplyOperatorExpressionToClause(&self) -> Option<Rc<MvapplyOperatorExpressionToClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MvapplyOperatorExpressionContextAttrs<'input> for MvapplyOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvapplyOperatorExpression(&mut self,)
	-> Result<Rc<MvapplyOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvapplyOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 232, RULE_mvapplyOperatorExpression);
        let mut _localctx: Rc<MvapplyOperatorExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(1523);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MvapplyOperatorExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1525);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==TO {
				{
				/*InvokeRule mvapplyOperatorExpressionToClause*/
				recog.base.set_state(1524);
				let tmp = recog.mvapplyOperatorExpressionToClause()?;
				 cast_mut::<_,MvapplyOperatorExpressionContext >(&mut _localctx).ToClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvapplyOperatorExpressionToClause ----------------
pub type MvapplyOperatorExpressionToClauseContextAll<'input> = MvapplyOperatorExpressionToClauseContext<'input>;


pub type MvapplyOperatorExpressionToClauseContext<'input> = BaseParserRuleContext<'input,MvapplyOperatorExpressionToClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MvapplyOperatorExpressionToClauseContextExt<'input>{
	pub Type: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvapplyOperatorExpressionToClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvapplyOperatorExpressionToClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvapplyOperatorExpressionToClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvapplyOperatorExpressionToClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvapplyOperatorExpressionToClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvapplyOperatorExpressionToClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvapplyOperatorExpressionToClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvapplyOperatorExpressionToClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvapplyOperatorExpressionToClause }
}
antlr_rust::tid!{MvapplyOperatorExpressionToClauseContextExt<'a>}

impl<'input> MvapplyOperatorExpressionToClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvapplyOperatorExpressionToClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvapplyOperatorExpressionToClauseContextExt{
				Type: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvapplyOperatorExpressionToClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvapplyOperatorExpressionToClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPELITERAL
/// Returns `None` if there is no child corresponding to token TYPELITERAL
fn TYPELITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TYPELITERAL, 0)
}

}

impl<'input> MvapplyOperatorExpressionToClauseContextAttrs<'input> for MvapplyOperatorExpressionToClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvapplyOperatorExpressionToClause(&mut self,)
	-> Result<Rc<MvapplyOperatorExpressionToClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvapplyOperatorExpressionToClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 234, RULE_mvapplyOperatorExpressionToClause);
        let mut _localctx: Rc<MvapplyOperatorExpressionToClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1527);
			recog.base.match_token(TO,&mut recog.err_handler)?;

			recog.base.set_state(1528);
			let tmp = recog.base.match_token(TYPELITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,MvapplyOperatorExpressionToClauseContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvexpandOperator ----------------
pub type MvexpandOperatorContextAll<'input> = MvexpandOperatorContext<'input>;


pub type MvexpandOperatorContext<'input> = BaseParserRuleContext<'input,MvexpandOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct MvexpandOperatorContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub mvexpandOperatorExpression: Option<Rc<MvexpandOperatorExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<MvexpandOperatorExpressionContextAll<'input>>>,
	pub LimitClause: Option<Rc<MvapplyOperatorLimitClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvexpandOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvexpandOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvexpandOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvexpandOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvexpandOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvexpandOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvexpandOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvexpandOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvexpandOperator }
}
antlr_rust::tid!{MvexpandOperatorContextExt<'a>}

impl<'input> MvexpandOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvexpandOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvexpandOperatorContextExt{
				Keyword: None, 
				strictQueryOperatorParameter: None, mvexpandOperatorExpression: None, LimitClause: None, 
				Parameters: Vec::new(), Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvexpandOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvexpandOperatorContextExt<'input>>{

fn mvexpandOperatorExpression_all(&self) ->  Vec<Rc<MvexpandOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn mvexpandOperatorExpression(&self, i: usize) -> Option<Rc<MvexpandOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token MVEXPAND
/// Returns `None` if there is no child corresponding to token MVEXPAND
fn MVEXPAND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MVEXPAND, 0)
}
/// Retrieves first TerminalNode corresponding to token MV_EXPAND
/// Returns `None` if there is no child corresponding to token MV_EXPAND
fn MV_EXPAND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MV_EXPAND, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn mvapplyOperatorLimitClause(&self) -> Option<Rc<MvapplyOperatorLimitClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MvexpandOperatorContextAttrs<'input> for MvexpandOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvexpandOperator(&mut self,)
	-> Result<Rc<MvexpandOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvexpandOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 236, RULE_mvexpandOperator);
        let mut _localctx: Rc<MvexpandOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1530);
			 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==MV_EXPAND || _la==MVEXPAND) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1534);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(1531);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1536);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule mvexpandOperatorExpression*/
			recog.base.set_state(1537);
			let tmp = recog.mvexpandOperatorExpression()?;
			 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).mvexpandOperatorExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).mvexpandOperatorExpression.clone().unwrap()
			 ;
			 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1542);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1538);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule mvexpandOperatorExpression*/
				recog.base.set_state(1539);
				let tmp = recog.mvexpandOperatorExpression()?;
				 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).mvexpandOperatorExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).mvexpandOperatorExpression.clone().unwrap()
				 ;
				 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1544);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1546);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==LIMIT {
				{
				/*InvokeRule mvapplyOperatorLimitClause*/
				recog.base.set_state(1545);
				let tmp = recog.mvapplyOperatorLimitClause()?;
				 cast_mut::<_,MvexpandOperatorContext >(&mut _localctx).LimitClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- mvexpandOperatorExpression ----------------
pub type MvexpandOperatorExpressionContextAll<'input> = MvexpandOperatorExpressionContext<'input>;


pub type MvexpandOperatorExpressionContext<'input> = BaseParserRuleContext<'input,MvexpandOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct MvexpandOperatorExpressionContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub ToClause: Option<Rc<MvapplyOperatorExpressionToClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MvexpandOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MvexpandOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_mvexpandOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_mvexpandOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MvexpandOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_mvexpandOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for MvexpandOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_mvexpandOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_mvexpandOperatorExpression }
}
antlr_rust::tid!{MvexpandOperatorExpressionContextExt<'a>}

impl<'input> MvexpandOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MvexpandOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MvexpandOperatorExpressionContextExt{
				Expression: None, ToClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MvexpandOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MvexpandOperatorExpressionContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn mvapplyOperatorExpressionToClause(&self) -> Option<Rc<MvapplyOperatorExpressionToClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MvexpandOperatorExpressionContextAttrs<'input> for MvexpandOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn mvexpandOperatorExpression(&mut self,)
	-> Result<Rc<MvexpandOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MvexpandOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 238, RULE_mvexpandOperatorExpression);
        let mut _localctx: Rc<MvexpandOperatorExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(1548);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,MvexpandOperatorExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1550);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==TO {
				{
				/*InvokeRule mvapplyOperatorExpressionToClause*/
				recog.base.set_state(1549);
				let tmp = recog.mvapplyOperatorExpressionToClause()?;
				 cast_mut::<_,MvexpandOperatorExpressionContext >(&mut _localctx).ToClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseOperator ----------------
pub type ParseOperatorContextAll<'input> = ParseOperatorContext<'input>;


pub type ParseOperatorContext<'input> = BaseParserRuleContext<'input,ParseOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ParseOperatorContextExt<'input>{
	pub KindClause: Option<Rc<ParseOperatorKindClauseContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Pattern: Option<Rc<ParseOperatorPatternContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseOperator }
}
antlr_rust::tid!{ParseOperatorContextExt<'a>}

impl<'input> ParseOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseOperatorContextExt{
				KindClause: None, Expression: None, Pattern: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARSE
/// Returns `None` if there is no child corresponding to token PARSE
fn PARSE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARSE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperatorPattern(&self) -> Option<Rc<ParseOperatorPatternContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperatorKindClause(&self) -> Option<Rc<ParseOperatorKindClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParseOperatorContextAttrs<'input> for ParseOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseOperator(&mut self,)
	-> Result<Rc<ParseOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 240, RULE_parseOperator);
        let mut _localctx: Rc<ParseOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1552);
			recog.base.match_token(PARSE,&mut recog.err_handler)?;

			recog.base.set_state(1554);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KIND {
				{
				/*InvokeRule parseOperatorKindClause*/
				recog.base.set_state(1553);
				let tmp = recog.parseOperatorKindClause()?;
				 cast_mut::<_,ParseOperatorContext >(&mut _localctx).KindClause = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1556);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,ParseOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1557);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule parseOperatorPattern*/
			recog.base.set_state(1558);
			let tmp = recog.parseOperatorPattern()?;
			 cast_mut::<_,ParseOperatorContext >(&mut _localctx).Pattern = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseOperatorKindClause ----------------
pub type ParseOperatorKindClauseContextAll<'input> = ParseOperatorKindClauseContext<'input>;


pub type ParseOperatorKindClauseContext<'input> = BaseParserRuleContext<'input,ParseOperatorKindClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ParseOperatorKindClauseContextExt<'input>{
	pub Kind: Option<TokenType<'input>>,
	pub FlagsClause: Option<Rc<ParseOperatorFlagsClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseOperatorKindClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseOperatorKindClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseOperatorKindClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseOperatorKindClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseOperatorKindClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseOperatorKindClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseOperatorKindClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseOperatorKindClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseOperatorKindClause }
}
antlr_rust::tid!{ParseOperatorKindClauseContextExt<'a>}

impl<'input> ParseOperatorKindClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseOperatorKindClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseOperatorKindClauseContextExt{
				Kind: None, 
				FlagsClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseOperatorKindClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseOperatorKindClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token SIMPLE
/// Returns `None` if there is no child corresponding to token SIMPLE
fn SIMPLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SIMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token REGEX
/// Returns `None` if there is no child corresponding to token REGEX
fn REGEX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REGEX, 0)
}
/// Retrieves first TerminalNode corresponding to token RELAXED
/// Returns `None` if there is no child corresponding to token RELAXED
fn RELAXED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RELAXED, 0)
}
fn parseOperatorFlagsClause(&self) -> Option<Rc<ParseOperatorFlagsClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParseOperatorKindClauseContextAttrs<'input> for ParseOperatorKindClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseOperatorKindClause(&mut self,)
	-> Result<Rc<ParseOperatorKindClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseOperatorKindClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 242, RULE_parseOperatorKindClause);
        let mut _localctx: Rc<ParseOperatorKindClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1560);
			recog.base.match_token(KIND,&mut recog.err_handler)?;

			recog.base.set_state(1561);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(1562);
			 cast_mut::<_,ParseOperatorKindClauseContext >(&mut _localctx).Kind = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 216)) & !0x3f) == 0 && ((1usize << (_la - 216)) & ((1usize << (REGEX - 216)) | (1usize << (RELAXED - 216)) | (1usize << (SIMPLE - 216)))) != 0)) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ParseOperatorKindClauseContext >(&mut _localctx).Kind = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1564);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==FLAGS {
				{
				/*InvokeRule parseOperatorFlagsClause*/
				recog.base.set_state(1563);
				let tmp = recog.parseOperatorFlagsClause()?;
				 cast_mut::<_,ParseOperatorKindClauseContext >(&mut _localctx).FlagsClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseOperatorFlagsClause ----------------
pub type ParseOperatorFlagsClauseContextAll<'input> = ParseOperatorFlagsClauseContext<'input>;


pub type ParseOperatorFlagsClauseContext<'input> = BaseParserRuleContext<'input,ParseOperatorFlagsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ParseOperatorFlagsClauseContextExt<'input>{
	pub Flags: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseOperatorFlagsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseOperatorFlagsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseOperatorFlagsClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseOperatorFlagsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseOperatorFlagsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseOperatorFlagsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseOperatorFlagsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseOperatorFlagsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseOperatorFlagsClause }
}
antlr_rust::tid!{ParseOperatorFlagsClauseContextExt<'a>}

impl<'input> ParseOperatorFlagsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseOperatorFlagsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseOperatorFlagsClauseContextExt{
				Flags: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseOperatorFlagsClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseOperatorFlagsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token FLAGS
/// Returns `None` if there is no child corresponding to token FLAGS
fn FLAGS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FLAGS, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}

}

impl<'input> ParseOperatorFlagsClauseContextAttrs<'input> for ParseOperatorFlagsClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseOperatorFlagsClause(&mut self,)
	-> Result<Rc<ParseOperatorFlagsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseOperatorFlagsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 244, RULE_parseOperatorFlagsClause);
        let mut _localctx: Rc<ParseOperatorFlagsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1566);
			recog.base.match_token(FLAGS,&mut recog.err_handler)?;

			recog.base.set_state(1567);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(1568);
			let tmp = recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;
			 cast_mut::<_,ParseOperatorFlagsClauseContext >(&mut _localctx).Flags = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseOperatorNameAndOptionalType ----------------
pub type ParseOperatorNameAndOptionalTypeContextAll<'input> = ParseOperatorNameAndOptionalTypeContext<'input>;


pub type ParseOperatorNameAndOptionalTypeContext<'input> = BaseParserRuleContext<'input,ParseOperatorNameAndOptionalTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ParseOperatorNameAndOptionalTypeContextExt<'input>{
	pub Name: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub Type: Option<Rc<ScalarTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseOperatorNameAndOptionalTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseOperatorNameAndOptionalTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseOperatorNameAndOptionalType(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseOperatorNameAndOptionalType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseOperatorNameAndOptionalTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseOperatorNameAndOptionalType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseOperatorNameAndOptionalTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseOperatorNameAndOptionalType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseOperatorNameAndOptionalType }
}
antlr_rust::tid!{ParseOperatorNameAndOptionalTypeContextExt<'a>}

impl<'input> ParseOperatorNameAndOptionalTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseOperatorNameAndOptionalTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseOperatorNameAndOptionalTypeContextExt{
				Name: None, Type: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseOperatorNameAndOptionalTypeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseOperatorNameAndOptionalTypeContextExt<'input>>{

fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn scalarType(&self) -> Option<Rc<ScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParseOperatorNameAndOptionalTypeContextAttrs<'input> for ParseOperatorNameAndOptionalTypeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseOperatorNameAndOptionalType(&mut self,)
	-> Result<Rc<ParseOperatorNameAndOptionalTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseOperatorNameAndOptionalTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 246, RULE_parseOperatorNameAndOptionalType);
        let mut _localctx: Rc<ParseOperatorNameAndOptionalTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule simpleNameReference*/
			recog.base.set_state(1570);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,ParseOperatorNameAndOptionalTypeContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1573);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COLON {
				{
				recog.base.set_state(1571);
				recog.base.match_token(COLON,&mut recog.err_handler)?;

				/*InvokeRule scalarType*/
				recog.base.set_state(1572);
				let tmp = recog.scalarType()?;
				 cast_mut::<_,ParseOperatorNameAndOptionalTypeContext >(&mut _localctx).Type = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseOperatorPattern ----------------
pub type ParseOperatorPatternContextAll<'input> = ParseOperatorPatternContext<'input>;


pub type ParseOperatorPatternContext<'input> = BaseParserRuleContext<'input,ParseOperatorPatternContextExt<'input>>;

#[derive(Clone)]
pub struct ParseOperatorPatternContextExt<'input>{
	pub LeadingColumn: Option<Rc<ParseOperatorNameAndOptionalTypeContextAll<'input>>>,
	pub parseOperatorPatternSegment: Option<Rc<ParseOperatorPatternSegmentContextAll<'input>>>,
	pub Segments:Vec<Rc<ParseOperatorPatternSegmentContextAll<'input>>>,
	pub TrailingStar: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseOperatorPatternContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseOperatorPatternContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseOperatorPattern(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseOperatorPattern(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseOperatorPatternContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseOperatorPattern(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseOperatorPatternContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseOperatorPattern }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseOperatorPattern }
}
antlr_rust::tid!{ParseOperatorPatternContextExt<'a>}

impl<'input> ParseOperatorPatternContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseOperatorPatternContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseOperatorPatternContextExt{
				TrailingStar: None, 
				LeadingColumn: None, parseOperatorPatternSegment: None, 
				Segments: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseOperatorPatternContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseOperatorPatternContextExt<'input>>{

fn parseOperatorNameAndOptionalType(&self) -> Option<Rc<ParseOperatorNameAndOptionalTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperatorPatternSegment_all(&self) ->  Vec<Rc<ParseOperatorPatternSegmentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn parseOperatorPatternSegment(&self, i: usize) -> Option<Rc<ParseOperatorPatternSegmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> ParseOperatorPatternContextAttrs<'input> for ParseOperatorPatternContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseOperatorPattern(&mut self,)
	-> Result<Rc<ParseOperatorPatternContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseOperatorPatternContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 248, RULE_parseOperatorPattern);
        let mut _localctx: Rc<ParseOperatorPatternContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1576);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (CLUSTER - 30)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (DATABASE - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DELTA - 69)) | (1usize << (EDGES - 69)) | (1usize << (EVALUATE - 69)) | (1usize << (EXECUTE - 69)) | (1usize << (FACET - 69)) | (1usize << (FORK - 69)) | (1usize << (FROM - 69)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MAP - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 253)) & !0x3f) == 0 && ((1usize << (_la - 253)) & ((1usize << (TYPEOF - 253)) | (1usize << (UNSTACKED - 253)) | (1usize << (UUID - 253)) | (1usize << (VIEW - 253)) | (1usize << (VISIBLE - 253)) | (1usize << (WITH - 253)) | (1usize << (XAXIS - 253)) | (1usize << (XCOLUMN - 253)) | (1usize << (XMAX - 253)) | (1usize << (XMIN - 253)) | (1usize << (XTITLE - 253)) | (1usize << (YAXIS - 253)) | (1usize << (YCOLUMNS - 253)) | (1usize << (YMAX - 253)) | (1usize << (YMIN - 253)) | (1usize << (YSPLIT - 253)) | (1usize << (YTITLE - 253)) | (1usize << (BOOL - 253)))) != 0) || _la==GUID || _la==IDENTIFIER {
				{
				/*InvokeRule parseOperatorNameAndOptionalType*/
				recog.base.set_state(1575);
				let tmp = recog.parseOperatorNameAndOptionalType()?;
				 cast_mut::<_,ParseOperatorPatternContext >(&mut _localctx).LeadingColumn = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1581);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(110,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule parseOperatorPatternSegment*/
					recog.base.set_state(1578);
					let tmp = recog.parseOperatorPatternSegment()?;
					 cast_mut::<_,ParseOperatorPatternContext >(&mut _localctx).parseOperatorPatternSegment = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ParseOperatorPatternContext >(&mut _localctx).parseOperatorPatternSegment.clone().unwrap()
					 ;
					 cast_mut::<_,ParseOperatorPatternContext >(&mut _localctx).Segments.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1583);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(110,&mut recog.base)?;
			}
			recog.base.set_state(1585);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASTERISK {
				{
				recog.base.set_state(1584);
				let tmp = recog.base.match_token(ASTERISK,&mut recog.err_handler)?;
				 cast_mut::<_,ParseOperatorPatternContext >(&mut _localctx).TrailingStar = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseOperatorPatternSegment ----------------
pub type ParseOperatorPatternSegmentContextAll<'input> = ParseOperatorPatternSegmentContext<'input>;


pub type ParseOperatorPatternSegmentContext<'input> = BaseParserRuleContext<'input,ParseOperatorPatternSegmentContextExt<'input>>;

#[derive(Clone)]
pub struct ParseOperatorPatternSegmentContextExt<'input>{
	pub Text: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub Column: Option<Rc<ParseOperatorNameAndOptionalTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseOperatorPatternSegmentContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseOperatorPatternSegmentContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseOperatorPatternSegment(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseOperatorPatternSegment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseOperatorPatternSegmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseOperatorPatternSegment(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseOperatorPatternSegmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseOperatorPatternSegment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseOperatorPatternSegment }
}
antlr_rust::tid!{ParseOperatorPatternSegmentContextExt<'a>}

impl<'input> ParseOperatorPatternSegmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseOperatorPatternSegmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseOperatorPatternSegmentContextExt{
				Text: None, Column: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseOperatorPatternSegmentContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseOperatorPatternSegmentContextExt<'input>>{

fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
fn parseOperatorNameAndOptionalType(&self) -> Option<Rc<ParseOperatorNameAndOptionalTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParseOperatorPatternSegmentContextAttrs<'input> for ParseOperatorPatternSegmentContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseOperatorPatternSegment(&mut self,)
	-> Result<Rc<ParseOperatorPatternSegmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseOperatorPatternSegmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 250, RULE_parseOperatorPatternSegment);
        let mut _localctx: Rc<ParseOperatorPatternSegmentContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1588);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASTERISK {
				{
				recog.base.set_state(1587);
				recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

				}
			}

			/*InvokeRule stringLiteralExpression*/
			recog.base.set_state(1590);
			let tmp = recog.stringLiteralExpression()?;
			 cast_mut::<_,ParseOperatorPatternSegmentContext >(&mut _localctx).Text = Some(tmp.clone());
			  

			recog.base.set_state(1592);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (CLUSTER - 30)))) != 0) || ((((_la - 69)) & !0x3f) == 0 && ((1usize << (_la - 69)) & ((1usize << (DATABASE - 69)) | (1usize << (DECLARE - 69)) | (1usize << (DEFAULT - 69)) | (1usize << (DELTA - 69)) | (1usize << (EDGES - 69)) | (1usize << (EVALUATE - 69)) | (1usize << (EXECUTE - 69)) | (1usize << (FACET - 69)) | (1usize << (FORK - 69)) | (1usize << (FROM - 69)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MAP - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 253)) & !0x3f) == 0 && ((1usize << (_la - 253)) & ((1usize << (TYPEOF - 253)) | (1usize << (UNSTACKED - 253)) | (1usize << (UUID - 253)) | (1usize << (VIEW - 253)) | (1usize << (VISIBLE - 253)) | (1usize << (WITH - 253)) | (1usize << (XAXIS - 253)) | (1usize << (XCOLUMN - 253)) | (1usize << (XMAX - 253)) | (1usize << (XMIN - 253)) | (1usize << (XTITLE - 253)) | (1usize << (YAXIS - 253)) | (1usize << (YCOLUMNS - 253)) | (1usize << (YMAX - 253)) | (1usize << (YMIN - 253)) | (1usize << (YSPLIT - 253)) | (1usize << (YTITLE - 253)) | (1usize << (BOOL - 253)))) != 0) || _la==GUID || _la==IDENTIFIER {
				{
				/*InvokeRule parseOperatorNameAndOptionalType*/
				recog.base.set_state(1591);
				let tmp = recog.parseOperatorNameAndOptionalType()?;
				 cast_mut::<_,ParseOperatorPatternSegmentContext >(&mut _localctx).Column = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseWhereOperator ----------------
pub type ParseWhereOperatorContextAll<'input> = ParseWhereOperatorContext<'input>;


pub type ParseWhereOperatorContext<'input> = BaseParserRuleContext<'input,ParseWhereOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ParseWhereOperatorContextExt<'input>{
	pub KindClause: Option<Rc<ParseOperatorKindClauseContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Pattern: Option<Rc<ParseOperatorPatternContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseWhereOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseWhereOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseWhereOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseWhereOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseWhereOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseWhereOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseWhereOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseWhereOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseWhereOperator }
}
antlr_rust::tid!{ParseWhereOperatorContextExt<'a>}

impl<'input> ParseWhereOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseWhereOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseWhereOperatorContextExt{
				KindClause: None, Expression: None, Pattern: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseWhereOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseWhereOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARSEWHERE
/// Returns `None` if there is no child corresponding to token PARSEWHERE
fn PARSEWHERE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARSEWHERE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperatorPattern(&self) -> Option<Rc<ParseOperatorPatternContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseOperatorKindClause(&self) -> Option<Rc<ParseOperatorKindClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParseWhereOperatorContextAttrs<'input> for ParseWhereOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseWhereOperator(&mut self,)
	-> Result<Rc<ParseWhereOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseWhereOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 252, RULE_parseWhereOperator);
        let mut _localctx: Rc<ParseWhereOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1594);
			recog.base.match_token(PARSEWHERE,&mut recog.err_handler)?;

			recog.base.set_state(1596);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KIND {
				{
				/*InvokeRule parseOperatorKindClause*/
				recog.base.set_state(1595);
				let tmp = recog.parseOperatorKindClause()?;
				 cast_mut::<_,ParseWhereOperatorContext >(&mut _localctx).KindClause = Some(tmp.clone());
				  

				}
			}

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1598);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,ParseWhereOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1599);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule parseOperatorPattern*/
			recog.base.set_state(1600);
			let tmp = recog.parseOperatorPattern()?;
			 cast_mut::<_,ParseWhereOperatorContext >(&mut _localctx).Pattern = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseKvOperator ----------------
pub type ParseKvOperatorContextAll<'input> = ParseKvOperatorContext<'input>;


pub type ParseKvOperatorContext<'input> = BaseParserRuleContext<'input,ParseKvOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ParseKvOperatorContextExt<'input>{
	pub Expressions: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Keys: Option<Rc<RowSchemaContextAll<'input>>>,
	pub WithClause: Option<Rc<ParseKvWithClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseKvOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseKvOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseKvOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseKvOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseKvOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseKvOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseKvOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseKvOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseKvOperator }
}
antlr_rust::tid!{ParseKvOperatorContextExt<'a>}

impl<'input> ParseKvOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseKvOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseKvOperatorContextExt{
				Expressions: None, Keys: None, WithClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseKvOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseKvOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARSEKV
/// Returns `None` if there is no child corresponding to token PARSEKV
fn PARSEKV(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARSEKV, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn rowSchema(&self) -> Option<Rc<RowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parseKvWithClause(&self) -> Option<Rc<ParseKvWithClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParseKvOperatorContextAttrs<'input> for ParseKvOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseKvOperator(&mut self,)
	-> Result<Rc<ParseKvOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseKvOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 254, RULE_parseKvOperator);
        let mut _localctx: Rc<ParseKvOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1602);
			recog.base.match_token(PARSEKV,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1603);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,ParseKvOperatorContext >(&mut _localctx).Expressions = Some(tmp.clone());
			  

			/*InvokeRule rowSchema*/
			recog.base.set_state(1604);
			let tmp = recog.rowSchema()?;
			 cast_mut::<_,ParseKvOperatorContext >(&mut _localctx).Keys = Some(tmp.clone());
			  

			recog.base.set_state(1606);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule parseKvWithClause*/
				recog.base.set_state(1605);
				let tmp = recog.parseKvWithClause()?;
				 cast_mut::<_,ParseKvOperatorContext >(&mut _localctx).WithClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parseKvWithClause ----------------
pub type ParseKvWithClauseContextAll<'input> = ParseKvWithClauseContext<'input>;


pub type ParseKvWithClauseContext<'input> = BaseParserRuleContext<'input,ParseKvWithClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ParseKvWithClauseContextExt<'input>{
	pub queryOperatorProperty: Option<Rc<QueryOperatorPropertyContextAll<'input>>>,
	pub Properties:Vec<Rc<QueryOperatorPropertyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParseKvWithClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParseKvWithClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parseKvWithClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parseKvWithClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParseKvWithClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parseKvWithClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParseKvWithClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parseKvWithClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parseKvWithClause }
}
antlr_rust::tid!{ParseKvWithClauseContextExt<'a>}

impl<'input> ParseKvWithClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParseKvWithClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParseKvWithClauseContextExt{
				queryOperatorProperty: None, 
				Properties: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParseKvWithClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParseKvWithClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn queryOperatorProperty_all(&self) ->  Vec<Rc<QueryOperatorPropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn queryOperatorProperty(&self, i: usize) -> Option<Rc<QueryOperatorPropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ParseKvWithClauseContextAttrs<'input> for ParseKvWithClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parseKvWithClause(&mut self,)
	-> Result<Rc<ParseKvWithClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParseKvWithClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 256, RULE_parseKvWithClause);
        let mut _localctx: Rc<ParseKvWithClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1608);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1609);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule queryOperatorProperty*/
			recog.base.set_state(1610);
			let tmp = recog.queryOperatorProperty()?;
			 cast_mut::<_,ParseKvWithClauseContext >(&mut _localctx).queryOperatorProperty = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ParseKvWithClauseContext >(&mut _localctx).queryOperatorProperty.clone().unwrap()
			 ;
			 cast_mut::<_,ParseKvWithClauseContext >(&mut _localctx).Properties.push(temp);
			  
			recog.base.set_state(1615);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1611);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule queryOperatorProperty*/
				recog.base.set_state(1612);
				let tmp = recog.queryOperatorProperty()?;
				 cast_mut::<_,ParseKvWithClauseContext >(&mut _localctx).queryOperatorProperty = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ParseKvWithClauseContext >(&mut _localctx).queryOperatorProperty.clone().unwrap()
				 ;
				 cast_mut::<_,ParseKvWithClauseContext >(&mut _localctx).Properties.push(temp);
				  
				}
				}
				recog.base.set_state(1617);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1618);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionOperator ----------------
pub type PartitionOperatorContextAll<'input> = PartitionOperatorContext<'input>;


pub type PartitionOperatorContext<'input> = BaseParserRuleContext<'input,PartitionOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub ByExpression: Option<Rc<EntityExpressionContextAll<'input>>>,
	pub InClause: Option<Rc<PartitionOperatorInClauseContextAll<'input>>>,
	pub SubExpressionBody: Option<Rc<PartitionOperatorSubExpressionBodyContextAll<'input>>>,
	pub FullExpressionBody: Option<Rc<PartitionOperatorFullExpressionBodyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PartitionOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PartitionOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_partitionOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PartitionOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_partitionOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionOperator }
}
antlr_rust::tid!{PartitionOperatorContextExt<'a>}

impl<'input> PartitionOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionOperatorContextExt{
				relaxedQueryOperatorParameter: None, ByExpression: None, InClause: None, SubExpressionBody: None, FullExpressionBody: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PartitionOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn entityExpression(&self) -> Option<Rc<EntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionOperatorSubExpressionBody(&self) -> Option<Rc<PartitionOperatorSubExpressionBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn partitionOperatorFullExpressionBody(&self) -> Option<Rc<PartitionOperatorFullExpressionBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionOperatorInClause(&self) -> Option<Rc<PartitionOperatorInClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionOperatorContextAttrs<'input> for PartitionOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionOperator(&mut self,)
	-> Result<Rc<PartitionOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 258, RULE_partitionOperator);
        let mut _localctx: Rc<PartitionOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1620);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(1624);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1621);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,PartitionOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,PartitionOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,PartitionOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1626);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1627);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule entityExpression*/
			recog.base.set_state(1628);
			let tmp = recog.entityExpression()?;
			 cast_mut::<_,PartitionOperatorContext >(&mut _localctx).ByExpression = Some(tmp.clone());
			  

			recog.base.set_state(1630);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==IN {
				{
				/*InvokeRule partitionOperatorInClause*/
				recog.base.set_state(1629);
				let tmp = recog.partitionOperatorInClause()?;
				 cast_mut::<_,PartitionOperatorContext >(&mut _localctx).InClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1634);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 OPENPAREN 
				=> {
					{
					/*InvokeRule partitionOperatorSubExpressionBody*/
					recog.base.set_state(1632);
					let tmp = recog.partitionOperatorSubExpressionBody()?;
					 cast_mut::<_,PartitionOperatorContext >(&mut _localctx).SubExpressionBody = Some(tmp.clone());
					  

					}
				}

			 OPENBRACE 
				=> {
					{
					/*InvokeRule partitionOperatorFullExpressionBody*/
					recog.base.set_state(1633);
					let tmp = recog.partitionOperatorFullExpressionBody()?;
					 cast_mut::<_,PartitionOperatorContext >(&mut _localctx).FullExpressionBody = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionOperatorInClause ----------------
pub type PartitionOperatorInClauseContextAll<'input> = PartitionOperatorInClauseContext<'input>;


pub type PartitionOperatorInClauseContext<'input> = BaseParserRuleContext<'input,PartitionOperatorInClauseContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionOperatorInClauseContextExt<'input>{
	pub FunctionCall: Option<Rc<FunctionCallExpressionContextAll<'input>>>,
	pub Literal: Option<Rc<DynamicLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PartitionOperatorInClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PartitionOperatorInClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionOperatorInClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_partitionOperatorInClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PartitionOperatorInClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_partitionOperatorInClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionOperatorInClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionOperatorInClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionOperatorInClause }
}
antlr_rust::tid!{PartitionOperatorInClauseContextExt<'a>}

impl<'input> PartitionOperatorInClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionOperatorInClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionOperatorInClauseContextExt{
				FunctionCall: None, Literal: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionOperatorInClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PartitionOperatorInClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
fn functionCallExpression(&self) -> Option<Rc<FunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dynamicLiteralExpression(&self) -> Option<Rc<DynamicLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionOperatorInClauseContextAttrs<'input> for PartitionOperatorInClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionOperatorInClause(&mut self,)
	-> Result<Rc<PartitionOperatorInClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionOperatorInClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 260, RULE_partitionOperatorInClause);
        let mut _localctx: Rc<PartitionOperatorInClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1636);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(1639);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 OPENBRACKET | ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN |
			 CLUSTER | COUNT | DATABASE | DECLARE | DEFAULT | DELTA | EDGES | EVALUATE |
			 EXECUTE | FACET | FORK | FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX |
			 ID | INTO | LEGEND | LET | LINEAR | LIST | LOOKUP | LOG | MAP | NODES |
			 NONE | NULL | NULLS | ON | OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY |
			 PATTERN | PLUGIN | QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE |
			 RESTRICT | SERIES | STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF |
			 UNSTACKED | UUID | VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN |
			 XTITLE | YAXIS | YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID |
			 IDENTIFIER 
				=> {
					{
					/*InvokeRule functionCallExpression*/
					recog.base.set_state(1637);
					let tmp = recog.functionCallExpression()?;
					 cast_mut::<_,PartitionOperatorInClauseContext >(&mut _localctx).FunctionCall = Some(tmp.clone());
					  

					}
				}

			 DYNAMIC 
				=> {
					{
					/*InvokeRule dynamicLiteralExpression*/
					recog.base.set_state(1638);
					let tmp = recog.dynamicLiteralExpression()?;
					 cast_mut::<_,PartitionOperatorInClauseContext >(&mut _localctx).Literal = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionOperatorSubExpressionBody ----------------
pub type PartitionOperatorSubExpressionBodyContextAll<'input> = PartitionOperatorSubExpressionBodyContext<'input>;


pub type PartitionOperatorSubExpressionBodyContext<'input> = BaseParserRuleContext<'input,PartitionOperatorSubExpressionBodyContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionOperatorSubExpressionBodyContextExt<'input>{
	pub SubExpression: Option<Rc<PipeSubExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PartitionOperatorSubExpressionBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PartitionOperatorSubExpressionBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionOperatorSubExpressionBody(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_partitionOperatorSubExpressionBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PartitionOperatorSubExpressionBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_partitionOperatorSubExpressionBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionOperatorSubExpressionBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionOperatorSubExpressionBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionOperatorSubExpressionBody }
}
antlr_rust::tid!{PartitionOperatorSubExpressionBodyContextExt<'a>}

impl<'input> PartitionOperatorSubExpressionBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionOperatorSubExpressionBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionOperatorSubExpressionBodyContextExt{
				SubExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionOperatorSubExpressionBodyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PartitionOperatorSubExpressionBodyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn pipeSubExpression(&self) -> Option<Rc<PipeSubExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionOperatorSubExpressionBodyContextAttrs<'input> for PartitionOperatorSubExpressionBodyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionOperatorSubExpressionBody(&mut self,)
	-> Result<Rc<PartitionOperatorSubExpressionBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionOperatorSubExpressionBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 262, RULE_partitionOperatorSubExpressionBody);
        let mut _localctx: Rc<PartitionOperatorSubExpressionBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1641);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule pipeSubExpression*/
			recog.base.set_state(1642);
			let tmp = recog.pipeSubExpression()?;
			 cast_mut::<_,PartitionOperatorSubExpressionBodyContext >(&mut _localctx).SubExpression = Some(tmp.clone());
			  

			recog.base.set_state(1643);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionOperatorFullExpressionBody ----------------
pub type PartitionOperatorFullExpressionBodyContextAll<'input> = PartitionOperatorFullExpressionBodyContext<'input>;


pub type PartitionOperatorFullExpressionBodyContext<'input> = BaseParserRuleContext<'input,PartitionOperatorFullExpressionBodyContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionOperatorFullExpressionBodyContextExt<'input>{
	pub Expression: Option<Rc<PipeExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PartitionOperatorFullExpressionBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PartitionOperatorFullExpressionBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionOperatorFullExpressionBody(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_partitionOperatorFullExpressionBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PartitionOperatorFullExpressionBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_partitionOperatorFullExpressionBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionOperatorFullExpressionBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionOperatorFullExpressionBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionOperatorFullExpressionBody }
}
antlr_rust::tid!{PartitionOperatorFullExpressionBodyContextExt<'a>}

impl<'input> PartitionOperatorFullExpressionBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionOperatorFullExpressionBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionOperatorFullExpressionBodyContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionOperatorFullExpressionBodyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PartitionOperatorFullExpressionBodyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACE
/// Returns `None` if there is no child corresponding to token OPENBRACE
fn OPENBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACE
/// Returns `None` if there is no child corresponding to token CLOSEBRACE
fn CLOSEBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACE, 0)
}
fn pipeExpression(&self) -> Option<Rc<PipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionOperatorFullExpressionBodyContextAttrs<'input> for PartitionOperatorFullExpressionBodyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionOperatorFullExpressionBody(&mut self,)
	-> Result<Rc<PartitionOperatorFullExpressionBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionOperatorFullExpressionBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 264, RULE_partitionOperatorFullExpressionBody);
        let mut _localctx: Rc<PartitionOperatorFullExpressionBodyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1645);
			recog.base.match_token(OPENBRACE,&mut recog.err_handler)?;

			/*InvokeRule pipeExpression*/
			recog.base.set_state(1646);
			let tmp = recog.pipeExpression()?;
			 cast_mut::<_,PartitionOperatorFullExpressionBodyContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1647);
			recog.base.match_token(CLOSEBRACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionByOperator ----------------
pub type PartitionByOperatorContextAll<'input> = PartitionByOperatorContext<'input>;


pub type PartitionByOperatorContext<'input> = BaseParserRuleContext<'input,PartitionByOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionByOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Column: Option<Rc<EntityExpressionContextAll<'input>>>,
	pub IdClause: Option<Rc<PartitionByOperatorIdClauseContextAll<'input>>>,
	pub SubExpression: Option<Rc<ContextualSubExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PartitionByOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PartitionByOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionByOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_partitionByOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PartitionByOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_partitionByOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionByOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionByOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionByOperator }
}
antlr_rust::tid!{PartitionByOperatorContextExt<'a>}

impl<'input> PartitionByOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionByOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionByOperatorContextExt{
				relaxedQueryOperatorParameter: None, Column: None, IdClause: None, SubExpression: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionByOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PartitionByOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITIONBY
/// Returns `None` if there is no child corresponding to token PARTITIONBY
fn PARTITIONBY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONBY, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn entityExpression(&self) -> Option<Rc<EntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn contextualSubExpression(&self) -> Option<Rc<ContextualSubExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn partitionByOperatorIdClause(&self) -> Option<Rc<PartitionByOperatorIdClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PartitionByOperatorContextAttrs<'input> for PartitionByOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionByOperator(&mut self,)
	-> Result<Rc<PartitionByOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionByOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 266, RULE_partitionByOperator);
        let mut _localctx: Rc<PartitionByOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1649);
			recog.base.match_token(PARTITIONBY,&mut recog.err_handler)?;

			recog.base.set_state(1653);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(121,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1650);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,PartitionByOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,PartitionByOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,PartitionByOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1655);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(121,&mut recog.base)?;
			}
			/*InvokeRule entityExpression*/
			recog.base.set_state(1656);
			let tmp = recog.entityExpression()?;
			 cast_mut::<_,PartitionByOperatorContext >(&mut _localctx).Column = Some(tmp.clone());
			  

			recog.base.set_state(1658);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ID {
				{
				/*InvokeRule partitionByOperatorIdClause*/
				recog.base.set_state(1657);
				let tmp = recog.partitionByOperatorIdClause()?;
				 cast_mut::<_,PartitionByOperatorContext >(&mut _localctx).IdClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1660);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule contextualSubExpression*/
			recog.base.set_state(1661);
			let tmp = recog.contextualSubExpression()?;
			 cast_mut::<_,PartitionByOperatorContext >(&mut _localctx).SubExpression = Some(tmp.clone());
			  

			recog.base.set_state(1662);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- partitionByOperatorIdClause ----------------
pub type PartitionByOperatorIdClauseContextAll<'input> = PartitionByOperatorIdClauseContext<'input>;


pub type PartitionByOperatorIdClauseContext<'input> = BaseParserRuleContext<'input,PartitionByOperatorIdClauseContextExt<'input>>;

#[derive(Clone)]
pub struct PartitionByOperatorIdClauseContextExt<'input>{
	pub IdValue: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PartitionByOperatorIdClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PartitionByOperatorIdClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_partitionByOperatorIdClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_partitionByOperatorIdClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PartitionByOperatorIdClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_partitionByOperatorIdClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for PartitionByOperatorIdClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_partitionByOperatorIdClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_partitionByOperatorIdClause }
}
antlr_rust::tid!{PartitionByOperatorIdClauseContextExt<'a>}

impl<'input> PartitionByOperatorIdClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PartitionByOperatorIdClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PartitionByOperatorIdClauseContextExt{
				IdValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait PartitionByOperatorIdClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PartitionByOperatorIdClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ID
/// Returns `None` if there is no child corresponding to token ID
fn ID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ID, 0)
}
/// Retrieves first TerminalNode corresponding to token GUIDLITERAL
/// Returns `None` if there is no child corresponding to token GUIDLITERAL
fn GUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUIDLITERAL, 0)
}

}

impl<'input> PartitionByOperatorIdClauseContextAttrs<'input> for PartitionByOperatorIdClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn partitionByOperatorIdClause(&mut self,)
	-> Result<Rc<PartitionByOperatorIdClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PartitionByOperatorIdClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 268, RULE_partitionByOperatorIdClause);
        let mut _localctx: Rc<PartitionByOperatorIdClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1664);
			recog.base.match_token(ID,&mut recog.err_handler)?;

			recog.base.set_state(1665);
			let tmp = recog.base.match_token(GUIDLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,PartitionByOperatorIdClauseContext >(&mut _localctx).IdValue = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- printOperator ----------------
pub type PrintOperatorContextAll<'input> = PrintOperatorContext<'input>;


pub type PrintOperatorContext<'input> = BaseParserRuleContext<'input,PrintOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct PrintOperatorContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PrintOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PrintOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_printOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_printOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PrintOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_printOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrintOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_printOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_printOperator }
}
antlr_rust::tid!{PrintOperatorContextExt<'a>}

impl<'input> PrintOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrintOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrintOperatorContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait PrintOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PrintOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PRINT
/// Returns `None` if there is no child corresponding to token PRINT
fn PRINT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PRINT, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> PrintOperatorContextAttrs<'input> for PrintOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn printOperator(&mut self,)
	-> Result<Rc<PrintOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrintOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 270, RULE_printOperator);
        let mut _localctx: Rc<PrintOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1667);
			recog.base.match_token(PRINT,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1668);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,PrintOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,PrintOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,PrintOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1673);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1669);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1670);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,PrintOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,PrintOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,PrintOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1675);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- projectAwayOperator ----------------
pub type ProjectAwayOperatorContextAll<'input> = ProjectAwayOperatorContext<'input>;


pub type ProjectAwayOperatorContext<'input> = BaseParserRuleContext<'input,ProjectAwayOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ProjectAwayOperatorContextExt<'input>{
	pub simpleOrWildcardedNameReference: Option<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>>,
	pub Columns:Vec<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ProjectAwayOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ProjectAwayOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_projectAwayOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_projectAwayOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ProjectAwayOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_projectAwayOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProjectAwayOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_projectAwayOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_projectAwayOperator }
}
antlr_rust::tid!{ProjectAwayOperatorContextExt<'a>}

impl<'input> ProjectAwayOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProjectAwayOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProjectAwayOperatorContextExt{
				simpleOrWildcardedNameReference: None, 
				Columns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ProjectAwayOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ProjectAwayOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECTAWAY
/// Returns `None` if there is no child corresponding to token PROJECTAWAY
fn PROJECTAWAY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECTAWAY, 0)
}
fn simpleOrWildcardedNameReference_all(&self) ->  Vec<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn simpleOrWildcardedNameReference(&self, i: usize) -> Option<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ProjectAwayOperatorContextAttrs<'input> for ProjectAwayOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn projectAwayOperator(&mut self,)
	-> Result<Rc<ProjectAwayOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProjectAwayOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 272, RULE_projectAwayOperator);
        let mut _localctx: Rc<ProjectAwayOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1676);
			recog.base.match_token(PROJECTAWAY,&mut recog.err_handler)?;

			recog.base.set_state(1685);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASTERISK || _la==OPENBRACKET || ((((_la - 38)) & !0x3f) == 0 && ((1usize << (_la - 38)) & ((1usize << (ACCESS - 38)) | (1usize << (ACCUMULATE - 38)) | (1usize << (AGGREGATIONS - 38)) | (1usize << (ALIAS - 38)) | (1usize << (ALL - 38)) | (1usize << (AS - 38)) | (1usize << (AXES - 38)) | (1usize << (BASE - 38)) | (1usize << (BIN - 38)) | (1usize << (BY - 38)) | (1usize << (CLUSTER - 38)) | (1usize << (CONSUME - 38)) | (1usize << (CONTAINS - 38)) | (1usize << (COUNT - 38)) | (1usize << (DATABASE - 38)))) != 0) || ((((_la - 71)) & !0x3f) == 0 && ((1usize << (_la - 71)) & ((1usize << (DATATABLE - 71)) | (1usize << (DECLARE - 71)) | (1usize << (DEFAULT - 71)) | (1usize << (DELTA - 71)) | (1usize << (DISTINCT - 71)) | (1usize << (EDGES - 71)) | (1usize << (EVALUATE - 71)) | (1usize << (EXECUTE - 71)) | (1usize << (EXTEND - 71)) | (1usize << (EXTERNALDATA - 71)) | (1usize << (FACET - 71)) | (1usize << (FILTER - 71)) | (1usize << (FIND - 71)) | (1usize << (FORK - 71)) | (1usize << (FROM - 71)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || _la==BOOL || _la==GUID || _la==IDENTIFIER {
				{
				/*InvokeRule simpleOrWildcardedNameReference*/
				recog.base.set_state(1677);
				let tmp = recog.simpleOrWildcardedNameReference()?;
				 cast_mut::<_,ProjectAwayOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ProjectAwayOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference.clone().unwrap()
				 ;
				 cast_mut::<_,ProjectAwayOperatorContext >(&mut _localctx).Columns.push(temp);
				  
				recog.base.set_state(1682);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1678);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule simpleOrWildcardedNameReference*/
					recog.base.set_state(1679);
					let tmp = recog.simpleOrWildcardedNameReference()?;
					 cast_mut::<_,ProjectAwayOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ProjectAwayOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference.clone().unwrap()
					 ;
					 cast_mut::<_,ProjectAwayOperatorContext >(&mut _localctx).Columns.push(temp);
					  
					}
					}
					recog.base.set_state(1684);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- projectKeepOperator ----------------
pub type ProjectKeepOperatorContextAll<'input> = ProjectKeepOperatorContext<'input>;


pub type ProjectKeepOperatorContext<'input> = BaseParserRuleContext<'input,ProjectKeepOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ProjectKeepOperatorContextExt<'input>{
	pub simpleOrWildcardedNameReference: Option<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>>,
	pub Columns:Vec<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ProjectKeepOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ProjectKeepOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_projectKeepOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_projectKeepOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ProjectKeepOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_projectKeepOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProjectKeepOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_projectKeepOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_projectKeepOperator }
}
antlr_rust::tid!{ProjectKeepOperatorContextExt<'a>}

impl<'input> ProjectKeepOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProjectKeepOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProjectKeepOperatorContextExt{
				simpleOrWildcardedNameReference: None, 
				Columns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ProjectKeepOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ProjectKeepOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECTKEEP
/// Returns `None` if there is no child corresponding to token PROJECTKEEP
fn PROJECTKEEP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECTKEEP, 0)
}
fn simpleOrWildcardedNameReference_all(&self) ->  Vec<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn simpleOrWildcardedNameReference(&self, i: usize) -> Option<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ProjectKeepOperatorContextAttrs<'input> for ProjectKeepOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn projectKeepOperator(&mut self,)
	-> Result<Rc<ProjectKeepOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProjectKeepOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 274, RULE_projectKeepOperator);
        let mut _localctx: Rc<ProjectKeepOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1687);
			recog.base.match_token(PROJECTKEEP,&mut recog.err_handler)?;

			/*InvokeRule simpleOrWildcardedNameReference*/
			recog.base.set_state(1688);
			let tmp = recog.simpleOrWildcardedNameReference()?;
			 cast_mut::<_,ProjectKeepOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ProjectKeepOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference.clone().unwrap()
			 ;
			 cast_mut::<_,ProjectKeepOperatorContext >(&mut _localctx).Columns.push(temp);
			  
			recog.base.set_state(1693);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1689);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule simpleOrWildcardedNameReference*/
				recog.base.set_state(1690);
				let tmp = recog.simpleOrWildcardedNameReference()?;
				 cast_mut::<_,ProjectKeepOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ProjectKeepOperatorContext >(&mut _localctx).simpleOrWildcardedNameReference.clone().unwrap()
				 ;
				 cast_mut::<_,ProjectKeepOperatorContext >(&mut _localctx).Columns.push(temp);
				  
				}
				}
				recog.base.set_state(1695);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- projectOperator ----------------
pub type ProjectOperatorContextAll<'input> = ProjectOperatorContext<'input>;


pub type ProjectOperatorContext<'input> = BaseParserRuleContext<'input,ProjectOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ProjectOperatorContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ProjectOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ProjectOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_projectOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_projectOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ProjectOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_projectOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProjectOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_projectOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_projectOperator }
}
antlr_rust::tid!{ProjectOperatorContextExt<'a>}

impl<'input> ProjectOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProjectOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProjectOperatorContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ProjectOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ProjectOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECT
/// Returns `None` if there is no child corresponding to token PROJECT
fn PROJECT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECT, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ProjectOperatorContextAttrs<'input> for ProjectOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn projectOperator(&mut self,)
	-> Result<Rc<ProjectOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProjectOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 276, RULE_projectOperator);
        let mut _localctx: Rc<ProjectOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1696);
			recog.base.match_token(PROJECT,&mut recog.err_handler)?;

			recog.base.set_state(1705);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ASTERISK) | (1usize << DASH) | (1usize << OPENBRACKET) | (1usize << OPENPAREN))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (PLUS - 33)) | (1usize << (ACCESS - 33)) | (1usize << (ACCUMULATE - 33)) | (1usize << (AGGREGATIONS - 33)) | (1usize << (ALIAS - 33)) | (1usize << (ALL - 33)) | (1usize << (AS - 33)) | (1usize << (AXES - 33)) | (1usize << (BASE - 33)) | (1usize << (BIN - 33)) | (1usize << (BY - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (CONSUME - 33)) | (1usize << (CONTAINS - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (CONTEXTUAL_DATATABLE - 65)) | (1usize << (COUNT - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATATABLE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DELTA - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (EDGES - 65)) | (1usize << (EVALUATE - 65)) | (1usize << (EXECUTE - 65)) | (1usize << (EXTEND - 65)) | (1usize << (EXTERNALDATA - 65)) | (1usize << (EXTERNAL_DATA - 65)) | (1usize << (FACET - 65)) | (1usize << (FILTER - 65)) | (1usize << (FIND - 65)) | (1usize << (FORK - 65)) | (1usize << (FROM - 65)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (MATERIALIZED_VIEW_COMBINE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || ((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (DYNAMIC - 279)) | (1usize << (GUID - 279)) | (1usize << (LONGLITERAL - 279)) | (1usize << (INTLITERAL - 279)) | (1usize << (REALLITERAL - 279)) | (1usize << (DECIMALLITERAL - 279)) | (1usize << (STRINGLITERAL - 279)) | (1usize << (BOOLEANLITERAL - 279)))) != 0) || ((((_la - 311)) & !0x3f) == 0 && ((1usize << (_la - 311)) & ((1usize << (DATETIMELITERAL - 311)) | (1usize << (TIMESPANLITERAL - 311)) | (1usize << (TYPELITERAL - 311)) | (1usize << (GUIDLITERAL - 311)) | (1usize << (IDENTIFIER - 311)))) != 0) {
				{
				/*InvokeRule namedExpression*/
				recog.base.set_state(1697);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,ProjectOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ProjectOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ProjectOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				recog.base.set_state(1702);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1698);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule namedExpression*/
					recog.base.set_state(1699);
					let tmp = recog.namedExpression()?;
					 cast_mut::<_,ProjectOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ProjectOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
					 ;
					 cast_mut::<_,ProjectOperatorContext >(&mut _localctx).Expressions.push(temp);
					  
					}
					}
					recog.base.set_state(1704);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- projectRenameOperator ----------------
pub type ProjectRenameOperatorContextAll<'input> = ProjectRenameOperatorContext<'input>;


pub type ProjectRenameOperatorContext<'input> = BaseParserRuleContext<'input,ProjectRenameOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ProjectRenameOperatorContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ProjectRenameOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ProjectRenameOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_projectRenameOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_projectRenameOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ProjectRenameOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_projectRenameOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProjectRenameOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_projectRenameOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_projectRenameOperator }
}
antlr_rust::tid!{ProjectRenameOperatorContextExt<'a>}

impl<'input> ProjectRenameOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProjectRenameOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProjectRenameOperatorContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ProjectRenameOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ProjectRenameOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECTRENAME
/// Returns `None` if there is no child corresponding to token PROJECTRENAME
fn PROJECTRENAME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECTRENAME, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ProjectRenameOperatorContextAttrs<'input> for ProjectRenameOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn projectRenameOperator(&mut self,)
	-> Result<Rc<ProjectRenameOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProjectRenameOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 278, RULE_projectRenameOperator);
        let mut _localctx: Rc<ProjectRenameOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1707);
			recog.base.match_token(PROJECTRENAME,&mut recog.err_handler)?;

			recog.base.set_state(1716);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ASTERISK) | (1usize << DASH) | (1usize << OPENBRACKET) | (1usize << OPENPAREN))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (PLUS - 33)) | (1usize << (ACCESS - 33)) | (1usize << (ACCUMULATE - 33)) | (1usize << (AGGREGATIONS - 33)) | (1usize << (ALIAS - 33)) | (1usize << (ALL - 33)) | (1usize << (AS - 33)) | (1usize << (AXES - 33)) | (1usize << (BASE - 33)) | (1usize << (BIN - 33)) | (1usize << (BY - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (CONSUME - 33)) | (1usize << (CONTAINS - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (CONTEXTUAL_DATATABLE - 65)) | (1usize << (COUNT - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATATABLE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DELTA - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (EDGES - 65)) | (1usize << (EVALUATE - 65)) | (1usize << (EXECUTE - 65)) | (1usize << (EXTEND - 65)) | (1usize << (EXTERNALDATA - 65)) | (1usize << (EXTERNAL_DATA - 65)) | (1usize << (FACET - 65)) | (1usize << (FILTER - 65)) | (1usize << (FIND - 65)) | (1usize << (FORK - 65)) | (1usize << (FROM - 65)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (MATERIALIZED_VIEW_COMBINE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || ((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (DYNAMIC - 279)) | (1usize << (GUID - 279)) | (1usize << (LONGLITERAL - 279)) | (1usize << (INTLITERAL - 279)) | (1usize << (REALLITERAL - 279)) | (1usize << (DECIMALLITERAL - 279)) | (1usize << (STRINGLITERAL - 279)) | (1usize << (BOOLEANLITERAL - 279)))) != 0) || ((((_la - 311)) & !0x3f) == 0 && ((1usize << (_la - 311)) & ((1usize << (DATETIMELITERAL - 311)) | (1usize << (TIMESPANLITERAL - 311)) | (1usize << (TYPELITERAL - 311)) | (1usize << (GUIDLITERAL - 311)) | (1usize << (IDENTIFIER - 311)))) != 0) {
				{
				/*InvokeRule namedExpression*/
				recog.base.set_state(1708);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,ProjectRenameOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ProjectRenameOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ProjectRenameOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				recog.base.set_state(1713);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1709);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule namedExpression*/
					recog.base.set_state(1710);
					let tmp = recog.namedExpression()?;
					 cast_mut::<_,ProjectRenameOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ProjectRenameOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
					 ;
					 cast_mut::<_,ProjectRenameOperatorContext >(&mut _localctx).Expressions.push(temp);
					  
					}
					}
					recog.base.set_state(1715);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- projectReorderOperator ----------------
pub type ProjectReorderOperatorContextAll<'input> = ProjectReorderOperatorContext<'input>;


pub type ProjectReorderOperatorContext<'input> = BaseParserRuleContext<'input,ProjectReorderOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ProjectReorderOperatorContextExt<'input>{
	pub projectReorderExpression: Option<Rc<ProjectReorderExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<ProjectReorderExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ProjectReorderOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ProjectReorderOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_projectReorderOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_projectReorderOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ProjectReorderOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_projectReorderOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProjectReorderOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_projectReorderOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_projectReorderOperator }
}
antlr_rust::tid!{ProjectReorderOperatorContextExt<'a>}

impl<'input> ProjectReorderOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProjectReorderOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProjectReorderOperatorContextExt{
				projectReorderExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ProjectReorderOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ProjectReorderOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PROJECTREORDER
/// Returns `None` if there is no child corresponding to token PROJECTREORDER
fn PROJECTREORDER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PROJECTREORDER, 0)
}
fn projectReorderExpression_all(&self) ->  Vec<Rc<ProjectReorderExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn projectReorderExpression(&self, i: usize) -> Option<Rc<ProjectReorderExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ProjectReorderOperatorContextAttrs<'input> for ProjectReorderOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn projectReorderOperator(&mut self,)
	-> Result<Rc<ProjectReorderOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProjectReorderOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 280, RULE_projectReorderOperator);
        let mut _localctx: Rc<ProjectReorderOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1718);
			recog.base.match_token(PROJECTREORDER,&mut recog.err_handler)?;

			recog.base.set_state(1727);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASTERISK || _la==OPENBRACKET || ((((_la - 38)) & !0x3f) == 0 && ((1usize << (_la - 38)) & ((1usize << (ACCESS - 38)) | (1usize << (ACCUMULATE - 38)) | (1usize << (AGGREGATIONS - 38)) | (1usize << (ALIAS - 38)) | (1usize << (ALL - 38)) | (1usize << (AS - 38)) | (1usize << (AXES - 38)) | (1usize << (BASE - 38)) | (1usize << (BIN - 38)) | (1usize << (BY - 38)) | (1usize << (CLUSTER - 38)) | (1usize << (CONSUME - 38)) | (1usize << (CONTAINS - 38)) | (1usize << (COUNT - 38)) | (1usize << (DATABASE - 38)))) != 0) || ((((_la - 71)) & !0x3f) == 0 && ((1usize << (_la - 71)) & ((1usize << (DATATABLE - 71)) | (1usize << (DECLARE - 71)) | (1usize << (DEFAULT - 71)) | (1usize << (DELTA - 71)) | (1usize << (DISTINCT - 71)) | (1usize << (EDGES - 71)) | (1usize << (EVALUATE - 71)) | (1usize << (EXECUTE - 71)) | (1usize << (EXTEND - 71)) | (1usize << (EXTERNALDATA - 71)) | (1usize << (FACET - 71)) | (1usize << (FILTER - 71)) | (1usize << (FIND - 71)) | (1usize << (FORK - 71)) | (1usize << (FROM - 71)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || _la==BOOL || _la==GUID || _la==IDENTIFIER {
				{
				/*InvokeRule projectReorderExpression*/
				recog.base.set_state(1719);
				let tmp = recog.projectReorderExpression()?;
				 cast_mut::<_,ProjectReorderOperatorContext >(&mut _localctx).projectReorderExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ProjectReorderOperatorContext >(&mut _localctx).projectReorderExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ProjectReorderOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				recog.base.set_state(1724);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1720);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule projectReorderExpression*/
					recog.base.set_state(1721);
					let tmp = recog.projectReorderExpression()?;
					 cast_mut::<_,ProjectReorderOperatorContext >(&mut _localctx).projectReorderExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,ProjectReorderOperatorContext >(&mut _localctx).projectReorderExpression.clone().unwrap()
					 ;
					 cast_mut::<_,ProjectReorderOperatorContext >(&mut _localctx).Expressions.push(temp);
					  
					}
					}
					recog.base.set_state(1726);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- projectReorderExpression ----------------
pub type ProjectReorderExpressionContextAll<'input> = ProjectReorderExpressionContext<'input>;


pub type ProjectReorderExpressionContext<'input> = BaseParserRuleContext<'input,ProjectReorderExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ProjectReorderExpressionContextExt<'input>{
	pub Expression: Option<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>>,
	pub Order: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ProjectReorderExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ProjectReorderExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_projectReorderExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_projectReorderExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ProjectReorderExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_projectReorderExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ProjectReorderExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_projectReorderExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_projectReorderExpression }
}
antlr_rust::tid!{ProjectReorderExpressionContextExt<'a>}

impl<'input> ProjectReorderExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ProjectReorderExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ProjectReorderExpressionContextExt{
				Order: None, 
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ProjectReorderExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ProjectReorderExpressionContextExt<'input>>{

fn simpleOrWildcardedNameReference(&self) -> Option<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANNYASC
/// Returns `None` if there is no child corresponding to token GRANNYASC
fn GRANNYASC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRANNYASC, 0)
}
/// Retrieves first TerminalNode corresponding to token GRANNYDESC
/// Returns `None` if there is no child corresponding to token GRANNYDESC
fn GRANNYDESC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GRANNYDESC, 0)
}

}

impl<'input> ProjectReorderExpressionContextAttrs<'input> for ProjectReorderExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn projectReorderExpression(&mut self,)
	-> Result<Rc<ProjectReorderExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ProjectReorderExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 282, RULE_projectReorderExpression);
        let mut _localctx: Rc<ProjectReorderExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule simpleOrWildcardedNameReference*/
			recog.base.set_state(1729);
			let tmp = recog.simpleOrWildcardedNameReference()?;
			 cast_mut::<_,ProjectReorderExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1731);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASC || _la==DESC || _la==GRANNYASC || _la==GRANNYDESC {
				{
				recog.base.set_state(1730);
				 cast_mut::<_,ProjectReorderExpressionContext >(&mut _localctx).Order = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==ASC || _la==DESC || _la==GRANNYASC || _la==GRANNYDESC) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,ProjectReorderExpressionContext >(&mut _localctx).Order = Some(tmp.clone());
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- reduceByOperator ----------------
pub type ReduceByOperatorContextAll<'input> = ReduceByOperatorContext<'input>;


pub type ReduceByOperatorContext<'input> = BaseParserRuleContext<'input,ReduceByOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ReduceByOperatorContextExt<'input>{
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub ByExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub WithClause: Option<Rc<ReduceByWithClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ReduceByOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ReduceByOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_reduceByOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_reduceByOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ReduceByOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_reduceByOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReduceByOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_reduceByOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_reduceByOperator }
}
antlr_rust::tid!{ReduceByOperatorContextExt<'a>}

impl<'input> ReduceByOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReduceByOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReduceByOperatorContextExt{
				strictQueryOperatorParameter: None, ByExpression: None, WithClause: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReduceByOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ReduceByOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn reduceByWithClause(&self) -> Option<Rc<ReduceByWithClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ReduceByOperatorContextAttrs<'input> for ReduceByOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn reduceByOperator(&mut self,)
	-> Result<Rc<ReduceByOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReduceByOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 284, RULE_reduceByOperator);
        let mut _localctx: Rc<ReduceByOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1733);
			recog.base.match_token(REDUCE,&mut recog.err_handler)?;

			recog.base.set_state(1737);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(1734);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,ReduceByOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ReduceByOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,ReduceByOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1739);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1740);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1741);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,ReduceByOperatorContext >(&mut _localctx).ByExpression = Some(tmp.clone());
			  

			recog.base.set_state(1743);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule reduceByWithClause*/
				recog.base.set_state(1742);
				let tmp = recog.reduceByWithClause()?;
				 cast_mut::<_,ReduceByOperatorContext >(&mut _localctx).WithClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- reduceByWithClause ----------------
pub type ReduceByWithClauseContextAll<'input> = ReduceByWithClauseContext<'input>;


pub type ReduceByWithClauseContext<'input> = BaseParserRuleContext<'input,ReduceByWithClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ReduceByWithClauseContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ReduceByWithClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ReduceByWithClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_reduceByWithClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_reduceByWithClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ReduceByWithClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_reduceByWithClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ReduceByWithClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_reduceByWithClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_reduceByWithClause }
}
antlr_rust::tid!{ReduceByWithClauseContextExt<'a>}

impl<'input> ReduceByWithClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ReduceByWithClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ReduceByWithClauseContextExt{
				namedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ReduceByWithClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ReduceByWithClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ReduceByWithClauseContextAttrs<'input> for ReduceByWithClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn reduceByWithClause(&mut self,)
	-> Result<Rc<ReduceByWithClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ReduceByWithClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 286, RULE_reduceByWithClause);
        let mut _localctx: Rc<ReduceByWithClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1745);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1746);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,ReduceByWithClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ReduceByWithClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ReduceByWithClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1751);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1747);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(1748);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,ReduceByWithClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ReduceByWithClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ReduceByWithClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1753);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- renderOperator ----------------
pub type RenderOperatorContextAll<'input> = RenderOperatorContext<'input>;


pub type RenderOperatorContext<'input> = BaseParserRuleContext<'input,RenderOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct RenderOperatorContextExt<'input>{
	pub CharType: Option<TokenType<'input>>,
	pub WithClause: Option<Rc<RenderOperatorWithClauseContextAll<'input>>>,
	pub LegacyPropertyList: Option<Rc<RenderOperatorLegacyPropertyListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RenderOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RenderOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_renderOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_renderOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RenderOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_renderOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenderOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_renderOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_renderOperator }
}
antlr_rust::tid!{RenderOperatorContextExt<'a>}

impl<'input> RenderOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RenderOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RenderOperatorContextExt{
				CharType: None, 
				WithClause: None, LegacyPropertyList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RenderOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RenderOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RENDER
/// Returns `None` if there is no child corresponding to token RENDER
fn RENDER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RENDER, 0)
}
/// Retrieves first TerminalNode corresponding to token TABLE
/// Returns `None` if there is no child corresponding to token TABLE
fn TABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIST
/// Returns `None` if there is no child corresponding to token LIST
fn LIST(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIST, 0)
}
/// Retrieves first TerminalNode corresponding to token BARCHART
/// Returns `None` if there is no child corresponding to token BARCHART
fn BARCHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BARCHART, 0)
}
/// Retrieves first TerminalNode corresponding to token PIECHART
/// Returns `None` if there is no child corresponding to token PIECHART
fn PIECHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PIECHART, 0)
}
/// Retrieves first TerminalNode corresponding to token LADDERCHART
/// Returns `None` if there is no child corresponding to token LADDERCHART
fn LADDERCHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LADDERCHART, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMECHART
/// Returns `None` if there is no child corresponding to token TIMECHART
fn TIMECHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMECHART, 0)
}
/// Retrieves first TerminalNode corresponding to token LINECHART
/// Returns `None` if there is no child corresponding to token LINECHART
fn LINECHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LINECHART, 0)
}
/// Retrieves first TerminalNode corresponding to token ANOMALYCHART
/// Returns `None` if there is no child corresponding to token ANOMALYCHART
fn ANOMALYCHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ANOMALYCHART, 0)
}
/// Retrieves first TerminalNode corresponding to token PIVOTCHART
/// Returns `None` if there is no child corresponding to token PIVOTCHART
fn PIVOTCHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PIVOTCHART, 0)
}
/// Retrieves first TerminalNode corresponding to token AREACHART
/// Returns `None` if there is no child corresponding to token AREACHART
fn AREACHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AREACHART, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKEDAREACHART
/// Returns `None` if there is no child corresponding to token STACKEDAREACHART
fn STACKEDAREACHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKEDAREACHART, 0)
}
/// Retrieves first TerminalNode corresponding to token SCATTERCHART
/// Returns `None` if there is no child corresponding to token SCATTERCHART
fn SCATTERCHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SCATTERCHART, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMEPIVOT
/// Returns `None` if there is no child corresponding to token TIMEPIVOT
fn TIMEPIVOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMEPIVOT, 0)
}
/// Retrieves first TerminalNode corresponding to token COLUMNCHART
/// Returns `None` if there is no child corresponding to token COLUMNCHART
fn COLUMNCHART(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLUMNCHART, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMELINE
/// Returns `None` if there is no child corresponding to token TIMELINE
fn TIMELINE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMELINE, 0)
}
/// Retrieves first TerminalNode corresponding to token CHART3D_
/// Returns `None` if there is no child corresponding to token CHART3D_
fn CHART3D_(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CHART3D_, 0)
}
/// Retrieves first TerminalNode corresponding to token CARD
/// Returns `None` if there is no child corresponding to token CARD
fn CARD(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CARD, 0)
}
/// Retrieves first TerminalNode corresponding to token TREEMAP
/// Returns `None` if there is no child corresponding to token TREEMAP
fn TREEMAP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TREEMAP, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}
fn renderOperatorWithClause(&self) -> Option<Rc<RenderOperatorWithClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn renderOperatorLegacyPropertyList(&self) -> Option<Rc<RenderOperatorLegacyPropertyListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RenderOperatorContextAttrs<'input> for RenderOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn renderOperator(&mut self,)
	-> Result<Rc<RenderOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RenderOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 288, RULE_renderOperator);
        let mut _localctx: Rc<RenderOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1754);
			recog.base.match_token(RENDER,&mut recog.err_handler)?;

			recog.base.set_state(1755);
			 cast_mut::<_,RenderOperatorContext >(&mut _localctx).CharType = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 37)) & !0x3f) == 0 && ((1usize << (_la - 37)) & ((1usize << (CHART3D_ - 37)) | (1usize << (ANOMALYCHART - 37)) | (1usize << (AREACHART - 37)) | (1usize << (BARCHART - 37)) | (1usize << (CARD - 37)) | (1usize << (COLUMNCHART - 37)))) != 0) || ((((_la - 138)) & !0x3f) == 0 && ((1usize << (_la - 138)) & ((1usize << (LADDERCHART - 138)) | (1usize << (LINECHART - 138)) | (1usize << (LIST - 138)))) != 0) || ((((_la - 202)) & !0x3f) == 0 && ((1usize << (_la - 202)) & ((1usize << (PIECHART - 202)) | (1usize << (PIVOTCHART - 202)) | (1usize << (SCATTERCHART - 202)))) != 0) || ((((_la - 234)) & !0x3f) == 0 && ((1usize << (_la - 234)) & ((1usize << (STACKEDAREACHART - 234)) | (1usize << (TABLE - 234)) | (1usize << (TIMECHART - 234)) | (1usize << (TIMELINE - 234)) | (1usize << (TIMEPIVOT - 234)) | (1usize << (TREEMAP - 234)))) != 0) || _la==IDENTIFIER) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,RenderOperatorContext >(&mut _localctx).CharType = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(1758);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(137,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule renderOperatorWithClause*/
					recog.base.set_state(1756);
					let tmp = recog.renderOperatorWithClause()?;
					 cast_mut::<_,RenderOperatorContext >(&mut _localctx).WithClause = Some(tmp.clone());
					  

					}
				}

				x if x == 2=>{
					{
					/*InvokeRule renderOperatorLegacyPropertyList*/
					recog.base.set_state(1757);
					let tmp = recog.renderOperatorLegacyPropertyList()?;
					 cast_mut::<_,RenderOperatorContext >(&mut _localctx).LegacyPropertyList = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- renderOperatorWithClause ----------------
pub type RenderOperatorWithClauseContextAll<'input> = RenderOperatorWithClauseContext<'input>;


pub type RenderOperatorWithClauseContext<'input> = BaseParserRuleContext<'input,RenderOperatorWithClauseContextExt<'input>>;

#[derive(Clone)]
pub struct RenderOperatorWithClauseContextExt<'input>{
	pub renderOperatorProperty: Option<Rc<RenderOperatorPropertyContextAll<'input>>>,
	pub Properties:Vec<Rc<RenderOperatorPropertyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RenderOperatorWithClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RenderOperatorWithClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_renderOperatorWithClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_renderOperatorWithClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RenderOperatorWithClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_renderOperatorWithClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenderOperatorWithClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_renderOperatorWithClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_renderOperatorWithClause }
}
antlr_rust::tid!{RenderOperatorWithClauseContextExt<'a>}

impl<'input> RenderOperatorWithClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RenderOperatorWithClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RenderOperatorWithClauseContextExt{
				renderOperatorProperty: None, 
				Properties: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait RenderOperatorWithClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RenderOperatorWithClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn renderOperatorProperty_all(&self) ->  Vec<Rc<RenderOperatorPropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn renderOperatorProperty(&self, i: usize) -> Option<Rc<RenderOperatorPropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RenderOperatorWithClauseContextAttrs<'input> for RenderOperatorWithClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn renderOperatorWithClause(&mut self,)
	-> Result<Rc<RenderOperatorWithClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RenderOperatorWithClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 290, RULE_renderOperatorWithClause);
        let mut _localctx: Rc<RenderOperatorWithClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1760);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1761);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1770);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ACCUMULATE || _la==ANOMALYCOLUMNS || _la==KIND || _la==LEGEND || _la==SERIES || _la==TITLE || ((((_la - 268)) & !0x3f) == 0 && ((1usize << (_la - 268)) & ((1usize << (XAXIS - 268)) | (1usize << (XCOLUMN - 268)) | (1usize << (XMAX - 268)) | (1usize << (XMIN - 268)) | (1usize << (XTITLE - 268)) | (1usize << (YAXIS - 268)) | (1usize << (YCOLUMNS - 268)) | (1usize << (YMAX - 268)) | (1usize << (YMIN - 268)) | (1usize << (YSPLIT - 268)) | (1usize << (YTITLE - 268)))) != 0) {
				{
				/*InvokeRule renderOperatorProperty*/
				recog.base.set_state(1762);
				let tmp = recog.renderOperatorProperty()?;
				 cast_mut::<_,RenderOperatorWithClauseContext >(&mut _localctx).renderOperatorProperty = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,RenderOperatorWithClauseContext >(&mut _localctx).renderOperatorProperty.clone().unwrap()
				 ;
				 cast_mut::<_,RenderOperatorWithClauseContext >(&mut _localctx).Properties.push(temp);
				  
				recog.base.set_state(1767);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(1763);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule renderOperatorProperty*/
					recog.base.set_state(1764);
					let tmp = recog.renderOperatorProperty()?;
					 cast_mut::<_,RenderOperatorWithClauseContext >(&mut _localctx).renderOperatorProperty = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,RenderOperatorWithClauseContext >(&mut _localctx).renderOperatorProperty.clone().unwrap()
					 ;
					 cast_mut::<_,RenderOperatorWithClauseContext >(&mut _localctx).Properties.push(temp);
					  
					}
					}
					recog.base.set_state(1769);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(1772);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- renderOperatorLegacyPropertyList ----------------
pub type RenderOperatorLegacyPropertyListContextAll<'input> = RenderOperatorLegacyPropertyListContext<'input>;


pub type RenderOperatorLegacyPropertyListContext<'input> = BaseParserRuleContext<'input,RenderOperatorLegacyPropertyListContextExt<'input>>;

#[derive(Clone)]
pub struct RenderOperatorLegacyPropertyListContextExt<'input>{
	pub renderOperatorLegacyProperty: Option<Rc<RenderOperatorLegacyPropertyContextAll<'input>>>,
	pub Properties:Vec<Rc<RenderOperatorLegacyPropertyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RenderOperatorLegacyPropertyListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RenderOperatorLegacyPropertyListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_renderOperatorLegacyPropertyList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_renderOperatorLegacyPropertyList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RenderOperatorLegacyPropertyListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_renderOperatorLegacyPropertyList(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenderOperatorLegacyPropertyListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_renderOperatorLegacyPropertyList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_renderOperatorLegacyPropertyList }
}
antlr_rust::tid!{RenderOperatorLegacyPropertyListContextExt<'a>}

impl<'input> RenderOperatorLegacyPropertyListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RenderOperatorLegacyPropertyListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RenderOperatorLegacyPropertyListContextExt{
				renderOperatorLegacyProperty: None, 
				Properties: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait RenderOperatorLegacyPropertyListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RenderOperatorLegacyPropertyListContextExt<'input>>{

fn renderOperatorLegacyProperty_all(&self) ->  Vec<Rc<RenderOperatorLegacyPropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn renderOperatorLegacyProperty(&self, i: usize) -> Option<Rc<RenderOperatorLegacyPropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RenderOperatorLegacyPropertyListContextAttrs<'input> for RenderOperatorLegacyPropertyListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn renderOperatorLegacyPropertyList(&mut self,)
	-> Result<Rc<RenderOperatorLegacyPropertyListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RenderOperatorLegacyPropertyListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 292, RULE_renderOperatorLegacyPropertyList);
        let mut _localctx: Rc<RenderOperatorLegacyPropertyListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1775); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule renderOperatorLegacyProperty*/
				recog.base.set_state(1774);
				let tmp = recog.renderOperatorLegacyProperty()?;
				 cast_mut::<_,RenderOperatorLegacyPropertyListContext >(&mut _localctx).renderOperatorLegacyProperty = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,RenderOperatorLegacyPropertyListContext >(&mut _localctx).renderOperatorLegacyProperty.clone().unwrap()
				 ;
				 cast_mut::<_,RenderOperatorLegacyPropertyListContext >(&mut _localctx).Properties.push(temp);
				  
				}
				}
				recog.base.set_state(1777); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==ACCUMULATE || _la==BY || _la==KIND || _la==TITLE || _la==WITH) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- renderOperatorProperty ----------------
pub type RenderOperatorPropertyContextAll<'input> = RenderOperatorPropertyContext<'input>;


pub type RenderOperatorPropertyContext<'input> = BaseParserRuleContext<'input,RenderOperatorPropertyContextExt<'input>>;

#[derive(Clone)]
pub struct RenderOperatorPropertyContextExt<'input>{
	pub Name: Option<TokenType<'input>>,
	pub ExpressionValue: Option<Rc<FunctionCallOrPathExpressionContextAll<'input>>>,
	pub NameValue: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub NameListValue: Option<Rc<RenderPropertyNameListContextAll<'input>>>,
	pub TokenValue: Option<TokenType<'input>>,
	pub BoolValue: Option<TokenType<'input>>,
	pub NumberValue: Option<Rc<NumericLiteralExpressionContextAll<'input>>>,
	pub LiteralValue: Option<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RenderOperatorPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RenderOperatorPropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_renderOperatorProperty(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_renderOperatorProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RenderOperatorPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_renderOperatorProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenderOperatorPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_renderOperatorProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_renderOperatorProperty }
}
antlr_rust::tid!{RenderOperatorPropertyContextExt<'a>}

impl<'input> RenderOperatorPropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RenderOperatorPropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RenderOperatorPropertyContextExt{
				Name: None, TokenValue: None, BoolValue: None, 
				ExpressionValue: None, NameValue: None, NameListValue: None, NumberValue: None, LiteralValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RenderOperatorPropertyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RenderOperatorPropertyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token TITLE
/// Returns `None` if there is no child corresponding to token TITLE
fn TITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TITLE, 0)
}
fn functionCallOrPathExpression(&self) -> Option<Rc<FunctionCallOrPathExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token XCOLUMN
/// Returns `None` if there is no child corresponding to token XCOLUMN
fn XCOLUMN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XCOLUMN, 0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token SERIES
/// Returns `None` if there is no child corresponding to token SERIES
fn SERIES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SERIES, 0)
}
fn renderPropertyNameList(&self) -> Option<Rc<RenderPropertyNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token YCOLUMNS
/// Returns `None` if there is no child corresponding to token YCOLUMNS
fn YCOLUMNS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YCOLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token ANOMALYCOLUMNS
/// Returns `None` if there is no child corresponding to token ANOMALYCOLUMNS
fn ANOMALYCOLUMNS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ANOMALYCOLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSTACKED
/// Returns `None` if there is no child corresponding to token UNSTACKED
fn UNSTACKED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UNSTACKED, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKED
/// Returns `None` if there is no child corresponding to token STACKED
fn STACKED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKED, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKED100
/// Returns `None` if there is no child corresponding to token STACKED100
fn STACKED100(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKED100, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token XTITLE
/// Returns `None` if there is no child corresponding to token XTITLE
fn XTITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XTITLE, 0)
}
/// Retrieves first TerminalNode corresponding to token YTITLE
/// Returns `None` if there is no child corresponding to token YTITLE
fn YTITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YTITLE, 0)
}
/// Retrieves first TerminalNode corresponding to token XAXIS
/// Returns `None` if there is no child corresponding to token XAXIS
fn XAXIS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XAXIS, 0)
}
/// Retrieves first TerminalNode corresponding to token LINEAR
/// Returns `None` if there is no child corresponding to token LINEAR
fn LINEAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LINEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token LOG
/// Returns `None` if there is no child corresponding to token LOG
fn LOG(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LOG, 0)
}
/// Retrieves first TerminalNode corresponding to token YAXIS
/// Returns `None` if there is no child corresponding to token YAXIS
fn YAXIS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YAXIS, 0)
}
/// Retrieves first TerminalNode corresponding to token LEGEND
/// Returns `None` if there is no child corresponding to token LEGEND
fn LEGEND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LEGEND, 0)
}
/// Retrieves first TerminalNode corresponding to token VISIBLE
/// Returns `None` if there is no child corresponding to token VISIBLE
fn VISIBLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(VISIBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token HIDDEN_
/// Returns `None` if there is no child corresponding to token HIDDEN_
fn HIDDEN_(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HIDDEN_, 0)
}
/// Retrieves first TerminalNode corresponding to token YSPLIT
/// Returns `None` if there is no child corresponding to token YSPLIT
fn YSPLIT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YSPLIT, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token AXES
/// Returns `None` if there is no child corresponding to token AXES
fn AXES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AXES, 0)
}
/// Retrieves first TerminalNode corresponding to token PANELS
/// Returns `None` if there is no child corresponding to token PANELS
fn PANELS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PANELS, 0)
}
/// Retrieves first TerminalNode corresponding to token ACCUMULATE
/// Returns `None` if there is no child corresponding to token ACCUMULATE
fn ACCUMULATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ACCUMULATE, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEANLITERAL
/// Returns `None` if there is no child corresponding to token BOOLEANLITERAL
fn BOOLEANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEANLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token YMIN
/// Returns `None` if there is no child corresponding to token YMIN
fn YMIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YMIN, 0)
}
fn numericLiteralExpression(&self) -> Option<Rc<NumericLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token YMAX
/// Returns `None` if there is no child corresponding to token YMAX
fn YMAX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YMAX, 0)
}
/// Retrieves first TerminalNode corresponding to token XMIN
/// Returns `None` if there is no child corresponding to token XMIN
fn XMIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XMIN, 0)
}
fn literalExpression(&self) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token XMAX
/// Returns `None` if there is no child corresponding to token XMAX
fn XMAX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XMAX, 0)
}

}

impl<'input> RenderOperatorPropertyContextAttrs<'input> for RenderOperatorPropertyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn renderOperatorProperty(&mut self,)
	-> Result<Rc<RenderOperatorPropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RenderOperatorPropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 294, RULE_renderOperatorProperty);
        let mut _localctx: Rc<RenderOperatorPropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1830);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 TITLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					{
					recog.base.set_state(1779);
					let tmp = recog.base.match_token(TITLE,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1780);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule functionCallOrPathExpression*/
					recog.base.set_state(1781);
					let tmp = recog.functionCallOrPathExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).ExpressionValue = Some(tmp.clone());
					  

					}
					}
				}

			 XCOLUMN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					{
					recog.base.set_state(1782);
					let tmp = recog.base.match_token(XCOLUMN,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1783);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule simpleNameReference*/
					recog.base.set_state(1784);
					let tmp = recog.simpleNameReference()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).NameValue = Some(tmp.clone());
					  

					}
					}
				}

			 SERIES 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					{
					recog.base.set_state(1785);
					let tmp = recog.base.match_token(SERIES,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1786);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule renderPropertyNameList*/
					recog.base.set_state(1787);
					let tmp = recog.renderPropertyNameList()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).NameListValue = Some(tmp.clone());
					  

					}
					}
				}

			 YCOLUMNS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					{
					recog.base.set_state(1788);
					let tmp = recog.base.match_token(YCOLUMNS,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1789);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule renderPropertyNameList*/
					recog.base.set_state(1790);
					let tmp = recog.renderPropertyNameList()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).NameListValue = Some(tmp.clone());
					  

					}
					}
				}

			 ANOMALYCOLUMNS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					{
					recog.base.set_state(1791);
					let tmp = recog.base.match_token(ANOMALYCOLUMNS,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1792);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule renderPropertyNameList*/
					recog.base.set_state(1793);
					let tmp = recog.renderPropertyNameList()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).NameListValue = Some(tmp.clone());
					  

					}
					}
				}

			 KIND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					{
					recog.base.set_state(1794);
					let tmp = recog.base.match_token(KIND,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1795);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1796);
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==DEFAULT || _la==MAP || ((((_la - 232)) & !0x3f) == 0 && ((1usize << (_la - 232)) & ((1usize << (STACKED - 232)) | (1usize << (STACKED100 - 232)) | (1usize << (UNSTACKED - 232)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
					}
				}

			 XTITLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					{
					recog.base.set_state(1797);
					let tmp = recog.base.match_token(XTITLE,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1798);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule functionCallOrPathExpression*/
					recog.base.set_state(1799);
					let tmp = recog.functionCallOrPathExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).ExpressionValue = Some(tmp.clone());
					  

					}
					}
				}

			 YTITLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					{
					recog.base.set_state(1800);
					let tmp = recog.base.match_token(YTITLE,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1801);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule functionCallOrPathExpression*/
					recog.base.set_state(1802);
					let tmp = recog.functionCallOrPathExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).ExpressionValue = Some(tmp.clone());
					  

					}
					}
				}

			 XAXIS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					{
					recog.base.set_state(1803);
					let tmp = recog.base.match_token(XAXIS,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1804);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1805);
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==LINEAR || _la==LOG) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
					}
				}

			 YAXIS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					{
					recog.base.set_state(1806);
					let tmp = recog.base.match_token(YAXIS,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1807);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1808);
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==LINEAR || _la==LOG) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
					}
				}

			 LEGEND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					{
					recog.base.set_state(1809);
					let tmp = recog.base.match_token(LEGEND,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1810);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1811);
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==HIDDEN_ || _la==VISIBLE) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
					}
				}

			 YSPLIT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 12);
					recog.base.enter_outer_alt(None, 12);
					{
					{
					recog.base.set_state(1812);
					let tmp = recog.base.match_token(YSPLIT,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1813);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1814);
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==AXES || _la==NONE || _la==PANELS) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
					}
				}

			 ACCUMULATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 13);
					recog.base.enter_outer_alt(None, 13);
					{
					{
					recog.base.set_state(1815);
					let tmp = recog.base.match_token(ACCUMULATE,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1816);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1817);
					let tmp = recog.base.match_token(BOOLEANLITERAL,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).BoolValue = Some(tmp.clone());
					  

					}
					}
				}

			 YMIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 14);
					recog.base.enter_outer_alt(None, 14);
					{
					{
					recog.base.set_state(1818);
					let tmp = recog.base.match_token(YMIN,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1819);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule numericLiteralExpression*/
					recog.base.set_state(1820);
					let tmp = recog.numericLiteralExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).NumberValue = Some(tmp.clone());
					  

					}
					}
				}

			 YMAX 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 15);
					recog.base.enter_outer_alt(None, 15);
					{
					{
					recog.base.set_state(1821);
					let tmp = recog.base.match_token(YMAX,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1822);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule numericLiteralExpression*/
					recog.base.set_state(1823);
					let tmp = recog.numericLiteralExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).NumberValue = Some(tmp.clone());
					  

					}
					}
				}

			 XMIN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 16);
					recog.base.enter_outer_alt(None, 16);
					{
					{
					recog.base.set_state(1824);
					let tmp = recog.base.match_token(XMIN,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1825);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule literalExpression*/
					recog.base.set_state(1826);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).LiteralValue = Some(tmp.clone());
					  

					}
					}
				}

			 XMAX 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 17);
					recog.base.enter_outer_alt(None, 17);
					{
					{
					recog.base.set_state(1827);
					let tmp = recog.base.match_token(XMAX,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1828);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule literalExpression*/
					recog.base.set_state(1829);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,RenderOperatorPropertyContext >(&mut _localctx).LiteralValue = Some(tmp.clone());
					  

					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- renderPropertyNameList ----------------
pub type RenderPropertyNameListContextAll<'input> = RenderPropertyNameListContext<'input>;


pub type RenderPropertyNameListContext<'input> = BaseParserRuleContext<'input,RenderPropertyNameListContextExt<'input>>;

#[derive(Clone)]
pub struct RenderPropertyNameListContextExt<'input>{
	pub extendedNameReference: Option<Rc<ExtendedNameReferenceContextAll<'input>>>,
	pub Names:Vec<Rc<ExtendedNameReferenceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RenderPropertyNameListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RenderPropertyNameListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_renderPropertyNameList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_renderPropertyNameList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RenderPropertyNameListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_renderPropertyNameList(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenderPropertyNameListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_renderPropertyNameList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_renderPropertyNameList }
}
antlr_rust::tid!{RenderPropertyNameListContextExt<'a>}

impl<'input> RenderPropertyNameListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RenderPropertyNameListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RenderPropertyNameListContextExt{
				extendedNameReference: None, 
				Names: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait RenderPropertyNameListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RenderPropertyNameListContextExt<'input>>{

fn extendedNameReference_all(&self) ->  Vec<Rc<ExtendedNameReferenceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn extendedNameReference(&self, i: usize) -> Option<Rc<ExtendedNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> RenderPropertyNameListContextAttrs<'input> for RenderPropertyNameListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn renderPropertyNameList(&mut self,)
	-> Result<Rc<RenderPropertyNameListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RenderPropertyNameListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 296, RULE_renderPropertyNameList);
        let mut _localctx: Rc<RenderPropertyNameListContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule extendedNameReference*/
			recog.base.set_state(1832);
			let tmp = recog.extendedNameReference()?;
			 cast_mut::<_,RenderPropertyNameListContext >(&mut _localctx).extendedNameReference = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,RenderPropertyNameListContext >(&mut _localctx).extendedNameReference.clone().unwrap()
			 ;
			 cast_mut::<_,RenderPropertyNameListContext >(&mut _localctx).Names.push(temp);
			  
			recog.base.set_state(1837);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(142,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(1833);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule extendedNameReference*/
					recog.base.set_state(1834);
					let tmp = recog.extendedNameReference()?;
					 cast_mut::<_,RenderPropertyNameListContext >(&mut _localctx).extendedNameReference = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,RenderPropertyNameListContext >(&mut _localctx).extendedNameReference.clone().unwrap()
					 ;
					 cast_mut::<_,RenderPropertyNameListContext >(&mut _localctx).Names.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1839);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(142,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- renderOperatorLegacyProperty ----------------
pub type RenderOperatorLegacyPropertyContextAll<'input> = RenderOperatorLegacyPropertyContext<'input>;


pub type RenderOperatorLegacyPropertyContext<'input> = BaseParserRuleContext<'input,RenderOperatorLegacyPropertyContextExt<'input>>;

#[derive(Clone)]
pub struct RenderOperatorLegacyPropertyContextExt<'input>{
	pub Name: Option<TokenType<'input>>,
	pub StringValue: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub TokenValue: Option<TokenType<'input>>,
	pub NameListValue: Option<Rc<RenderPropertyNameListContextAll<'input>>>,
	pub BoolValue: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RenderOperatorLegacyPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RenderOperatorLegacyPropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_renderOperatorLegacyProperty(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_renderOperatorLegacyProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RenderOperatorLegacyPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_renderOperatorLegacyProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for RenderOperatorLegacyPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_renderOperatorLegacyProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_renderOperatorLegacyProperty }
}
antlr_rust::tid!{RenderOperatorLegacyPropertyContextExt<'a>}

impl<'input> RenderOperatorLegacyPropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RenderOperatorLegacyPropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RenderOperatorLegacyPropertyContextExt{
				Name: None, TokenValue: None, BoolValue: None, 
				StringValue: None, NameListValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RenderOperatorLegacyPropertyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RenderOperatorLegacyPropertyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token TITLE
/// Returns `None` if there is no child corresponding to token TITLE
fn TITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TITLE, 0)
}
fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSTACKED
/// Returns `None` if there is no child corresponding to token UNSTACKED
fn UNSTACKED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UNSTACKED, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKED
/// Returns `None` if there is no child corresponding to token STACKED
fn STACKED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKED, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKED100
/// Returns `None` if there is no child corresponding to token STACKED100
fn STACKED100(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKED100, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn renderPropertyNameList(&self) -> Option<Rc<RenderPropertyNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ACCUMULATE
/// Returns `None` if there is no child corresponding to token ACCUMULATE
fn ACCUMULATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ACCUMULATE, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEANLITERAL
/// Returns `None` if there is no child corresponding to token BOOLEANLITERAL
fn BOOLEANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEANLITERAL, 0)
}

}

impl<'input> RenderOperatorLegacyPropertyContextAttrs<'input> for RenderOperatorLegacyPropertyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn renderOperatorLegacyProperty(&mut self,)
	-> Result<Rc<RenderOperatorLegacyPropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RenderOperatorLegacyPropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 298, RULE_renderOperatorLegacyProperty);
        let mut _localctx: Rc<RenderOperatorLegacyPropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(1853);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 TITLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					{
					recog.base.set_state(1840);
					let tmp = recog.base.match_token(TITLE,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1841);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					/*InvokeRule stringLiteralExpression*/
					recog.base.set_state(1842);
					let tmp = recog.stringLiteralExpression()?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).StringValue = Some(tmp.clone());
					  

					}
					}
				}

			 KIND 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					{
					recog.base.set_state(1843);
					let tmp = recog.base.match_token(KIND,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1844);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1845);
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(_la==DEFAULT || _la==MAP || ((((_la - 232)) & !0x3f) == 0 && ((1usize << (_la - 232)) & ((1usize << (STACKED - 232)) | (1usize << (STACKED100 - 232)) | (1usize << (UNSTACKED - 232)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
					}
				}

			 WITH 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					{
					recog.base.set_state(1846);
					let tmp = recog.base.match_token(WITH,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					/*InvokeRule stringLiteralExpression*/
					recog.base.set_state(1847);
					let tmp = recog.stringLiteralExpression()?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).StringValue = Some(tmp.clone());
					  

					}
					}
				}

			 BY 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					{
					recog.base.set_state(1848);
					let tmp = recog.base.match_token(BY,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					/*InvokeRule renderPropertyNameList*/
					recog.base.set_state(1849);
					let tmp = recog.renderPropertyNameList()?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).NameListValue = Some(tmp.clone());
					  

					}
					}
				}

			 ACCUMULATE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					{
					recog.base.set_state(1850);
					let tmp = recog.base.match_token(ACCUMULATE,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					recog.base.set_state(1851);
					recog.base.match_token(EQUAL,&mut recog.err_handler)?;

					recog.base.set_state(1852);
					let tmp = recog.base.match_token(BOOLEANLITERAL,&mut recog.err_handler)?;
					 cast_mut::<_,RenderOperatorLegacyPropertyContext >(&mut _localctx).BoolValue = Some(tmp.clone());
					  

					}
					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleDistinctOperator ----------------
pub type SampleDistinctOperatorContextAll<'input> = SampleDistinctOperatorContext<'input>;


pub type SampleDistinctOperatorContext<'input> = BaseParserRuleContext<'input,SampleDistinctOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SampleDistinctOperatorContextExt<'input>{
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub OfExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SampleDistinctOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SampleDistinctOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampleDistinctOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_sampleDistinctOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SampleDistinctOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_sampleDistinctOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleDistinctOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleDistinctOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleDistinctOperator }
}
antlr_rust::tid!{SampleDistinctOperatorContextExt<'a>}

impl<'input> SampleDistinctOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleDistinctOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleDistinctOperatorContextExt{
				strictQueryOperatorParameter: None, Expression: None, OfExpression: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleDistinctOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SampleDistinctOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SAMPLE_DISTINCT
/// Returns `None` if there is no child corresponding to token SAMPLE_DISTINCT
fn SAMPLE_DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SAMPLE_DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SampleDistinctOperatorContextAttrs<'input> for SampleDistinctOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleDistinctOperator(&mut self,)
	-> Result<Rc<SampleDistinctOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleDistinctOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 300, RULE_sampleDistinctOperator);
        let mut _localctx: Rc<SampleDistinctOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1855);
			recog.base.match_token(SAMPLE_DISTINCT,&mut recog.err_handler)?;

			recog.base.set_state(1859);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(1856);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,SampleDistinctOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SampleDistinctOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,SampleDistinctOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1861);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule namedExpression*/
			recog.base.set_state(1862);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,SampleDistinctOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1863);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(1864);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,SampleDistinctOperatorContext >(&mut _localctx).OfExpression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sampleOperator ----------------
pub type SampleOperatorContextAll<'input> = SampleOperatorContext<'input>;


pub type SampleOperatorContext<'input> = BaseParserRuleContext<'input,SampleOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SampleOperatorContextExt<'input>{
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SampleOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SampleOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sampleOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_sampleOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SampleOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_sampleOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SampleOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sampleOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sampleOperator }
}
antlr_rust::tid!{SampleOperatorContextExt<'a>}

impl<'input> SampleOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SampleOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SampleOperatorContextExt{
				strictQueryOperatorParameter: None, Expression: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SampleOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SampleOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SAMPLE
/// Returns `None` if there is no child corresponding to token SAMPLE
fn SAMPLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SAMPLE, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SampleOperatorContextAttrs<'input> for SampleOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sampleOperator(&mut self,)
	-> Result<Rc<SampleOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SampleOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 302, RULE_sampleOperator);
        let mut _localctx: Rc<SampleOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1866);
			recog.base.match_token(SAMPLE,&mut recog.err_handler)?;

			recog.base.set_state(1870);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(1867);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,SampleOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SampleOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,SampleOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1872);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule namedExpression*/
			recog.base.set_state(1873);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,SampleOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperator ----------------
pub type ScanOperatorContextAll<'input> = ScanOperatorContext<'input>;


pub type ScanOperatorContext<'input> = BaseParserRuleContext<'input,ScanOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub OrderByClause: Option<Rc<ScanOperatorOrderByClauseContextAll<'input>>>,
	pub PartitionByClause: Option<Rc<ScanOperatorPartitionByClauseContextAll<'input>>>,
	pub DeclareClause: Option<Rc<ScanOperatorDeclareClauseContextAll<'input>>>,
	pub scanOperatorStep: Option<Rc<ScanOperatorStepContextAll<'input>>>,
	pub Steps:Vec<Rc<ScanOperatorStepContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperator }
}
antlr_rust::tid!{ScanOperatorContextExt<'a>}

impl<'input> ScanOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorContextExt{
				relaxedQueryOperatorParameter: None, OrderByClause: None, PartitionByClause: None, DeclareClause: None, scanOperatorStep: None, 
				Parameters: Vec::new(), Steps: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SCAN
/// Returns `None` if there is no child corresponding to token SCAN
fn SCAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SCAN, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn scanOperatorOrderByClause(&self) -> Option<Rc<ScanOperatorOrderByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scanOperatorPartitionByClause(&self) -> Option<Rc<ScanOperatorPartitionByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scanOperatorDeclareClause(&self) -> Option<Rc<ScanOperatorDeclareClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scanOperatorStep_all(&self) ->  Vec<Rc<ScanOperatorStepContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn scanOperatorStep(&self, i: usize) -> Option<Rc<ScanOperatorStepContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ScanOperatorContextAttrs<'input> for ScanOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperator(&mut self,)
	-> Result<Rc<ScanOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 304, RULE_scanOperator);
        let mut _localctx: Rc<ScanOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1875);
			recog.base.match_token(SCAN,&mut recog.err_handler)?;

			recog.base.set_state(1879);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(1876);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ScanOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1881);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1883);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ORDER {
				{
				/*InvokeRule scanOperatorOrderByClause*/
				recog.base.set_state(1882);
				let tmp = recog.scanOperatorOrderByClause()?;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).OrderByClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1886);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==PARTITION {
				{
				/*InvokeRule scanOperatorPartitionByClause*/
				recog.base.set_state(1885);
				let tmp = recog.scanOperatorPartitionByClause()?;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).PartitionByClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1889);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DECLARE {
				{
				/*InvokeRule scanOperatorDeclareClause*/
				recog.base.set_state(1888);
				let tmp = recog.scanOperatorDeclareClause()?;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).DeclareClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1891);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(1892);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(1894); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule scanOperatorStep*/
				recog.base.set_state(1893);
				let tmp = recog.scanOperatorStep()?;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).scanOperatorStep = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ScanOperatorContext >(&mut _localctx).scanOperatorStep.clone().unwrap()
				 ;
				 cast_mut::<_,ScanOperatorContext >(&mut _localctx).Steps.push(temp);
				  
				}
				}
				recog.base.set_state(1896); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==STEP) {break}
			}
			recog.base.set_state(1898);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorOrderByClause ----------------
pub type ScanOperatorOrderByClauseContextAll<'input> = ScanOperatorOrderByClauseContext<'input>;


pub type ScanOperatorOrderByClauseContext<'input> = BaseParserRuleContext<'input,ScanOperatorOrderByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorOrderByClauseContextExt<'input>{
	pub orderedExpression: Option<Rc<OrderedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<OrderedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorOrderByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorOrderByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorOrderByClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorOrderByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorOrderByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorOrderByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorOrderByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorOrderByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorOrderByClause }
}
antlr_rust::tid!{ScanOperatorOrderByClauseContextExt<'a>}

impl<'input> ScanOperatorOrderByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorOrderByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorOrderByClauseContextExt{
				orderedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorOrderByClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorOrderByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn orderedExpression_all(&self) ->  Vec<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn orderedExpression(&self, i: usize) -> Option<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}

}

impl<'input> ScanOperatorOrderByClauseContextAttrs<'input> for ScanOperatorOrderByClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorOrderByClause(&mut self,)
	-> Result<Rc<ScanOperatorOrderByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorOrderByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 306, RULE_scanOperatorOrderByClause);
        let mut _localctx: Rc<ScanOperatorOrderByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1900);
			recog.base.match_token(ORDER,&mut recog.err_handler)?;

			recog.base.set_state(1901);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule orderedExpression*/
			recog.base.set_state(1902);
			let tmp = recog.orderedExpression()?;
			 cast_mut::<_,ScanOperatorOrderByClauseContext >(&mut _localctx).orderedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ScanOperatorOrderByClauseContext >(&mut _localctx).orderedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ScanOperatorOrderByClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			{
			recog.base.set_state(1903);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule orderedExpression*/
			recog.base.set_state(1904);
			let tmp = recog.orderedExpression()?;
			 cast_mut::<_,ScanOperatorOrderByClauseContext >(&mut _localctx).orderedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ScanOperatorOrderByClauseContext >(&mut _localctx).orderedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ScanOperatorOrderByClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorPartitionByClause ----------------
pub type ScanOperatorPartitionByClauseContextAll<'input> = ScanOperatorPartitionByClauseContext<'input>;


pub type ScanOperatorPartitionByClauseContext<'input> = BaseParserRuleContext<'input,ScanOperatorPartitionByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorPartitionByClauseContextExt<'input>{
	pub unnamedExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorPartitionByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorPartitionByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorPartitionByClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorPartitionByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorPartitionByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorPartitionByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorPartitionByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorPartitionByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorPartitionByClause }
}
antlr_rust::tid!{ScanOperatorPartitionByClauseContextExt<'a>}

impl<'input> ScanOperatorPartitionByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorPartitionByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorPartitionByClauseContextExt{
				unnamedExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorPartitionByClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorPartitionByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn unnamedExpression_all(&self) ->  Vec<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unnamedExpression(&self, i: usize) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ScanOperatorPartitionByClauseContextAttrs<'input> for ScanOperatorPartitionByClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorPartitionByClause(&mut self,)
	-> Result<Rc<ScanOperatorPartitionByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorPartitionByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 308, RULE_scanOperatorPartitionByClause);
        let mut _localctx: Rc<ScanOperatorPartitionByClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1906);
			recog.base.match_token(PARTITION,&mut recog.err_handler)?;

			recog.base.set_state(1907);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1908);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,ScanOperatorPartitionByClauseContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ScanOperatorPartitionByClauseContext >(&mut _localctx).unnamedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ScanOperatorPartitionByClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1913);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1909);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unnamedExpression*/
				recog.base.set_state(1910);
				let tmp = recog.unnamedExpression()?;
				 cast_mut::<_,ScanOperatorPartitionByClauseContext >(&mut _localctx).unnamedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ScanOperatorPartitionByClauseContext >(&mut _localctx).unnamedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ScanOperatorPartitionByClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1915);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorDeclareClause ----------------
pub type ScanOperatorDeclareClauseContextAll<'input> = ScanOperatorDeclareClauseContext<'input>;


pub type ScanOperatorDeclareClauseContext<'input> = BaseParserRuleContext<'input,ScanOperatorDeclareClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorDeclareClauseContextExt<'input>{
	pub scalarParameter: Option<Rc<ScalarParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<ScalarParameterContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorDeclareClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorDeclareClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorDeclareClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorDeclareClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorDeclareClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorDeclareClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorDeclareClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorDeclareClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorDeclareClause }
}
antlr_rust::tid!{ScanOperatorDeclareClauseContextExt<'a>}

impl<'input> ScanOperatorDeclareClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorDeclareClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorDeclareClauseContextExt{
				scalarParameter: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorDeclareClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorDeclareClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn scalarParameter_all(&self) ->  Vec<Rc<ScalarParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn scalarParameter(&self, i: usize) -> Option<Rc<ScalarParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ScanOperatorDeclareClauseContextAttrs<'input> for ScanOperatorDeclareClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorDeclareClause(&mut self,)
	-> Result<Rc<ScanOperatorDeclareClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorDeclareClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 310, RULE_scanOperatorDeclareClause);
        let mut _localctx: Rc<ScanOperatorDeclareClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1916);
			recog.base.match_token(DECLARE,&mut recog.err_handler)?;

			recog.base.set_state(1917);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule scalarParameter*/
			recog.base.set_state(1918);
			let tmp = recog.scalarParameter()?;
			 cast_mut::<_,ScanOperatorDeclareClauseContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ScanOperatorDeclareClauseContext >(&mut _localctx).scalarParameter.clone().unwrap()
			 ;
			 cast_mut::<_,ScanOperatorDeclareClauseContext >(&mut _localctx).Parameters.push(temp);
			  
			recog.base.set_state(1923);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1919);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule scalarParameter*/
				recog.base.set_state(1920);
				let tmp = recog.scalarParameter()?;
				 cast_mut::<_,ScanOperatorDeclareClauseContext >(&mut _localctx).scalarParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ScanOperatorDeclareClauseContext >(&mut _localctx).scalarParameter.clone().unwrap()
				 ;
				 cast_mut::<_,ScanOperatorDeclareClauseContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(1925);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1926);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorStep ----------------
pub type ScanOperatorStepContextAll<'input> = ScanOperatorStepContext<'input>;


pub type ScanOperatorStepContext<'input> = BaseParserRuleContext<'input,ScanOperatorStepContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorStepContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub OutputClause: Option<Rc<ScanOperatorStepOutputClauseContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Body: Option<Rc<ScanOperatorBodyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorStepContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorStepContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorStep(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorStep(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorStepContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorStep(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorStepContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorStep }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorStep }
}
antlr_rust::tid!{ScanOperatorStepContextExt<'a>}

impl<'input> ScanOperatorStepContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorStepContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorStepContextExt{
				Name: None, OutputClause: None, Expression: None, Body: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorStepContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorStepContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token STEP
/// Returns `None` if there is no child corresponding to token STEP
fn STEP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STEP, 0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
/// Retrieves first TerminalNode corresponding to token SEMICOLON
/// Returns `None` if there is no child corresponding to token SEMICOLON
fn SEMICOLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEMICOLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONAL
/// Returns `None` if there is no child corresponding to token OPTIONAL
fn OPTIONAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPTIONAL, 0)
}
fn scanOperatorStepOutputClause(&self) -> Option<Rc<ScanOperatorStepOutputClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scanOperatorBody(&self) -> Option<Rc<ScanOperatorBodyContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ScanOperatorStepContextAttrs<'input> for ScanOperatorStepContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorStep(&mut self,)
	-> Result<Rc<ScanOperatorStepContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorStepContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 312, RULE_scanOperatorStep);
        let mut _localctx: Rc<ScanOperatorStepContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1928);
			recog.base.match_token(STEP,&mut recog.err_handler)?;

			/*InvokeRule parameterName*/
			recog.base.set_state(1929);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,ScanOperatorStepContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1931);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OPTIONAL {
				{
				recog.base.set_state(1930);
				recog.base.match_token(OPTIONAL,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(1934);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==OUTPUT {
				{
				/*InvokeRule scanOperatorStepOutputClause*/
				recog.base.set_state(1933);
				let tmp = recog.scanOperatorStepOutputClause()?;
				 cast_mut::<_,ScanOperatorStepContext >(&mut _localctx).OutputClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1936);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1937);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,ScanOperatorStepContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(1939);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==EQUAL_GREATERTHAN {
				{
				/*InvokeRule scanOperatorBody*/
				recog.base.set_state(1938);
				let tmp = recog.scanOperatorBody()?;
				 cast_mut::<_,ScanOperatorStepContext >(&mut _localctx).Body = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1941);
			recog.base.match_token(SEMICOLON,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorStepOutputClause ----------------
pub type ScanOperatorStepOutputClauseContextAll<'input> = ScanOperatorStepOutputClauseContext<'input>;


pub type ScanOperatorStepOutputClauseContext<'input> = BaseParserRuleContext<'input,ScanOperatorStepOutputClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorStepOutputClauseContextExt<'input>{
	pub OutputKind: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorStepOutputClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorStepOutputClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorStepOutputClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorStepOutputClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorStepOutputClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorStepOutputClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorStepOutputClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorStepOutputClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorStepOutputClause }
}
antlr_rust::tid!{ScanOperatorStepOutputClauseContextExt<'a>}

impl<'input> ScanOperatorStepOutputClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorStepOutputClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorStepOutputClauseContextExt{
				OutputKind: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorStepOutputClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorStepOutputClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OUTPUT
/// Returns `None` if there is no child corresponding to token OUTPUT
fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OUTPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}

}

impl<'input> ScanOperatorStepOutputClauseContextAttrs<'input> for ScanOperatorStepOutputClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorStepOutputClause(&mut self,)
	-> Result<Rc<ScanOperatorStepOutputClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorStepOutputClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 314, RULE_scanOperatorStepOutputClause);
        let mut _localctx: Rc<ScanOperatorStepOutputClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1943);
			recog.base.match_token(OUTPUT,&mut recog.err_handler)?;

			recog.base.set_state(1944);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(1945);
			 cast_mut::<_,ScanOperatorStepOutputClauseContext >(&mut _localctx).OutputKind = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==LAST || _la==NONE) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ScanOperatorStepOutputClauseContext >(&mut _localctx).OutputKind = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorBody ----------------
pub type ScanOperatorBodyContextAll<'input> = ScanOperatorBodyContext<'input>;


pub type ScanOperatorBodyContext<'input> = BaseParserRuleContext<'input,ScanOperatorBodyContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorBodyContextExt<'input>{
	pub scanOperatorAssignment: Option<Rc<ScanOperatorAssignmentContextAll<'input>>>,
	pub Assignments:Vec<Rc<ScanOperatorAssignmentContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorBodyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorBodyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorBody(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorBody(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorBodyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorBody(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorBodyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorBody }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorBody }
}
antlr_rust::tid!{ScanOperatorBodyContextExt<'a>}

impl<'input> ScanOperatorBodyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorBodyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorBodyContextExt{
				scanOperatorAssignment: None, 
				Assignments: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorBodyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorBodyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL_GREATERTHAN
/// Returns `None` if there is no child corresponding to token EQUAL_GREATERTHAN
fn EQUAL_GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL_GREATERTHAN, 0)
}
fn scanOperatorAssignment_all(&self) ->  Vec<Rc<ScanOperatorAssignmentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn scanOperatorAssignment(&self, i: usize) -> Option<Rc<ScanOperatorAssignmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ScanOperatorBodyContextAttrs<'input> for ScanOperatorBodyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorBody(&mut self,)
	-> Result<Rc<ScanOperatorBodyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorBodyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 316, RULE_scanOperatorBody);
        let mut _localctx: Rc<ScanOperatorBodyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1947);
			recog.base.match_token(EQUAL_GREATERTHAN,&mut recog.err_handler)?;

			/*InvokeRule scanOperatorAssignment*/
			recog.base.set_state(1948);
			let tmp = recog.scanOperatorAssignment()?;
			 cast_mut::<_,ScanOperatorBodyContext >(&mut _localctx).scanOperatorAssignment = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ScanOperatorBodyContext >(&mut _localctx).scanOperatorAssignment.clone().unwrap()
			 ;
			 cast_mut::<_,ScanOperatorBodyContext >(&mut _localctx).Assignments.push(temp);
			  
			recog.base.set_state(1953);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1949);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule scanOperatorAssignment*/
				recog.base.set_state(1950);
				let tmp = recog.scanOperatorAssignment()?;
				 cast_mut::<_,ScanOperatorBodyContext >(&mut _localctx).scanOperatorAssignment = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ScanOperatorBodyContext >(&mut _localctx).scanOperatorAssignment.clone().unwrap()
				 ;
				 cast_mut::<_,ScanOperatorBodyContext >(&mut _localctx).Assignments.push(temp);
				  
				}
				}
				recog.base.set_state(1955);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scanOperatorAssignment ----------------
pub type ScanOperatorAssignmentContextAll<'input> = ScanOperatorAssignmentContext<'input>;


pub type ScanOperatorAssignmentContext<'input> = BaseParserRuleContext<'input,ScanOperatorAssignmentContextExt<'input>>;

#[derive(Clone)]
pub struct ScanOperatorAssignmentContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScanOperatorAssignmentContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScanOperatorAssignmentContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scanOperatorAssignment(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scanOperatorAssignment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScanOperatorAssignmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scanOperatorAssignment(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScanOperatorAssignmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scanOperatorAssignment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scanOperatorAssignment }
}
antlr_rust::tid!{ScanOperatorAssignmentContextExt<'a>}

impl<'input> ScanOperatorAssignmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScanOperatorAssignmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScanOperatorAssignmentContextExt{
				Name: None, Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScanOperatorAssignmentContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScanOperatorAssignmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ScanOperatorAssignmentContextAttrs<'input> for ScanOperatorAssignmentContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scanOperatorAssignment(&mut self,)
	-> Result<Rc<ScanOperatorAssignmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScanOperatorAssignmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 318, RULE_scanOperatorAssignment);
        let mut _localctx: Rc<ScanOperatorAssignmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(1956);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,ScanOperatorAssignmentContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(1957);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1958);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,ScanOperatorAssignmentContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- searchOperator ----------------
pub type SearchOperatorContextAll<'input> = SearchOperatorContext<'input>;


pub type SearchOperatorContext<'input> = BaseParserRuleContext<'input,SearchOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SearchOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub DataScope: Option<Rc<DataScopeClauseContextAll<'input>>>,
	pub InClause: Option<Rc<SearchOperatorInClauseContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub Star: Option<Rc<StarExpressionContextAll<'input>>>,
	pub StarAndExpression: Option<Rc<SearchOperatorStarAndExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SearchOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SearchOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_searchOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_searchOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SearchOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_searchOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_searchOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_searchOperator }
}
antlr_rust::tid!{SearchOperatorContextExt<'a>}

impl<'input> SearchOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SearchOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SearchOperatorContextExt{
				relaxedQueryOperatorParameter: None, DataScope: None, InClause: None, Expression: None, Star: None, StarAndExpression: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SearchOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SearchOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SEARCH
/// Returns `None` if there is no child corresponding to token SEARCH
fn SEARCH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEARCH, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn starExpression(&self) -> Option<Rc<StarExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn searchOperatorStarAndExpression(&self) -> Option<Rc<SearchOperatorStarAndExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn dataScopeClause(&self) -> Option<Rc<DataScopeClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn searchOperatorInClause(&self) -> Option<Rc<SearchOperatorInClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SearchOperatorContextAttrs<'input> for SearchOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn searchOperator(&mut self,)
	-> Result<Rc<SearchOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SearchOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 320, RULE_searchOperator);
        let mut _localctx: Rc<SearchOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1960);
			recog.base.match_token(SEARCH,&mut recog.err_handler)?;

			recog.base.set_state(1964);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(157,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(1961);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,SearchOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,SearchOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,SearchOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(1966);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(157,&mut recog.base)?;
			}
			recog.base.set_state(1968);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DATASCOPE {
				{
				/*InvokeRule dataScopeClause*/
				recog.base.set_state(1967);
				let tmp = recog.dataScopeClause()?;
				 cast_mut::<_,SearchOperatorContext >(&mut _localctx).DataScope = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1971);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==IN {
				{
				/*InvokeRule searchOperatorInClause*/
				recog.base.set_state(1970);
				let tmp = recog.searchOperatorInClause()?;
				 cast_mut::<_,SearchOperatorContext >(&mut _localctx).InClause = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(1976);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(160,&mut recog.base)? {
				1 =>{
					{
					/*InvokeRule unnamedExpression*/
					recog.base.set_state(1973);
					let tmp = recog.unnamedExpression()?;
					 cast_mut::<_,SearchOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					{
					/*InvokeRule starExpression*/
					recog.base.set_state(1974);
					let tmp = recog.starExpression()?;
					 cast_mut::<_,SearchOperatorContext >(&mut _localctx).Star = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					{
					/*InvokeRule searchOperatorStarAndExpression*/
					recog.base.set_state(1975);
					let tmp = recog.searchOperatorStarAndExpression()?;
					 cast_mut::<_,SearchOperatorContext >(&mut _localctx).StarAndExpression = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- searchOperatorStarAndExpression ----------------
pub type SearchOperatorStarAndExpressionContextAll<'input> = SearchOperatorStarAndExpressionContext<'input>;


pub type SearchOperatorStarAndExpressionContext<'input> = BaseParserRuleContext<'input,SearchOperatorStarAndExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SearchOperatorStarAndExpressionContextExt<'input>{
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SearchOperatorStarAndExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SearchOperatorStarAndExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_searchOperatorStarAndExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_searchOperatorStarAndExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SearchOperatorStarAndExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_searchOperatorStarAndExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchOperatorStarAndExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_searchOperatorStarAndExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_searchOperatorStarAndExpression }
}
antlr_rust::tid!{SearchOperatorStarAndExpressionContextExt<'a>}

impl<'input> SearchOperatorStarAndExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SearchOperatorStarAndExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SearchOperatorStarAndExpressionContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SearchOperatorStarAndExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SearchOperatorStarAndExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SearchOperatorStarAndExpressionContextAttrs<'input> for SearchOperatorStarAndExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn searchOperatorStarAndExpression(&mut self,)
	-> Result<Rc<SearchOperatorStarAndExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SearchOperatorStarAndExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 322, RULE_searchOperatorStarAndExpression);
        let mut _localctx: Rc<SearchOperatorStarAndExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1978);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			recog.base.set_state(1979);
			recog.base.match_token(AND,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(1980);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,SearchOperatorStarAndExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- searchOperatorInClause ----------------
pub type SearchOperatorInClauseContextAll<'input> = SearchOperatorInClauseContext<'input>;


pub type SearchOperatorInClauseContext<'input> = BaseParserRuleContext<'input,SearchOperatorInClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SearchOperatorInClauseContextExt<'input>{
	pub findOperatorSource: Option<Rc<FindOperatorSourceContextAll<'input>>>,
	pub Expressions:Vec<Rc<FindOperatorSourceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SearchOperatorInClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SearchOperatorInClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_searchOperatorInClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_searchOperatorInClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SearchOperatorInClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_searchOperatorInClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SearchOperatorInClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_searchOperatorInClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_searchOperatorInClause }
}
antlr_rust::tid!{SearchOperatorInClauseContextExt<'a>}

impl<'input> SearchOperatorInClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SearchOperatorInClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SearchOperatorInClauseContextExt{
				findOperatorSource: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SearchOperatorInClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SearchOperatorInClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn findOperatorSource_all(&self) ->  Vec<Rc<FindOperatorSourceContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn findOperatorSource(&self, i: usize) -> Option<Rc<FindOperatorSourceContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SearchOperatorInClauseContextAttrs<'input> for SearchOperatorInClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn searchOperatorInClause(&mut self,)
	-> Result<Rc<SearchOperatorInClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SearchOperatorInClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 324, RULE_searchOperatorInClause);
        let mut _localctx: Rc<SearchOperatorInClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1982);
			recog.base.match_token(IN,&mut recog.err_handler)?;

			recog.base.set_state(1983);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule findOperatorSource*/
			recog.base.set_state(1984);
			let tmp = recog.findOperatorSource()?;
			 cast_mut::<_,SearchOperatorInClauseContext >(&mut _localctx).findOperatorSource = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,SearchOperatorInClauseContext >(&mut _localctx).findOperatorSource.clone().unwrap()
			 ;
			 cast_mut::<_,SearchOperatorInClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(1989);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(1985);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule findOperatorSource*/
				recog.base.set_state(1986);
				let tmp = recog.findOperatorSource()?;
				 cast_mut::<_,SearchOperatorInClauseContext >(&mut _localctx).findOperatorSource = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SearchOperatorInClauseContext >(&mut _localctx).findOperatorSource.clone().unwrap()
				 ;
				 cast_mut::<_,SearchOperatorInClauseContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(1991);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(1992);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- serializeOperator ----------------
pub type SerializeOperatorContextAll<'input> = SerializeOperatorContext<'input>;


pub type SerializeOperatorContext<'input> = BaseParserRuleContext<'input,SerializeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SerializeOperatorContextExt<'input>{
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SerializeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SerializeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_serializeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_serializeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SerializeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_serializeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SerializeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_serializeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_serializeOperator }
}
antlr_rust::tid!{SerializeOperatorContextExt<'a>}

impl<'input> SerializeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SerializeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SerializeOperatorContextExt{
				strictQueryOperatorParameter: None, namedExpression: None, 
				Parameters: Vec::new(), Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SerializeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SerializeOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SERIALIZE
/// Returns `None` if there is no child corresponding to token SERIALIZE
fn SERIALIZE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SERIALIZE, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SerializeOperatorContextAttrs<'input> for SerializeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn serializeOperator(&mut self,)
	-> Result<Rc<SerializeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SerializeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 326, RULE_serializeOperator);
        let mut _localctx: Rc<SerializeOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(1994);
			recog.base.match_token(SERIALIZE,&mut recog.err_handler)?;

			recog.base.set_state(1998);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(1995);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,SerializeOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SerializeOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,SerializeOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2000);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule namedExpression*/
			recog.base.set_state(2001);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,SerializeOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,SerializeOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,SerializeOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(2006);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2002);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule namedExpression*/
				recog.base.set_state(2003);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,SerializeOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SerializeOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,SerializeOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(2008);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortOperator ----------------
pub type SortOperatorContextAll<'input> = SortOperatorContext<'input>;


pub type SortOperatorContext<'input> = BaseParserRuleContext<'input,SortOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SortOperatorContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub orderedExpression: Option<Rc<OrderedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<OrderedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SortOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SortOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_sortOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SortOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_sortOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SortOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortOperator }
}
antlr_rust::tid!{SortOperatorContextExt<'a>}

impl<'input> SortOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortOperatorContextExt{
				Keyword: None, 
				relaxedQueryOperatorParameter: None, orderedExpression: None, 
				Parameters: Vec::new(), Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SortOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SortOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn orderedExpression_all(&self) ->  Vec<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn orderedExpression(&self, i: usize) -> Option<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token ORDER
/// Returns `None` if there is no child corresponding to token ORDER
fn ORDER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ORDER, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> SortOperatorContextAttrs<'input> for SortOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortOperator(&mut self,)
	-> Result<Rc<SortOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 328, RULE_sortOperator);
        let mut _localctx: Rc<SortOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2009);
			 cast_mut::<_,SortOperatorContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==ORDER || _la==SORT) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,SortOperatorContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2013);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(2010);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,SortOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SortOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,SortOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2015);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2016);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule orderedExpression*/
			recog.base.set_state(2017);
			let tmp = recog.orderedExpression()?;
			 cast_mut::<_,SortOperatorContext >(&mut _localctx).orderedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,SortOperatorContext >(&mut _localctx).orderedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,SortOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(2022);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2018);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule orderedExpression*/
				recog.base.set_state(2019);
				let tmp = recog.orderedExpression()?;
				 cast_mut::<_,SortOperatorContext >(&mut _localctx).orderedExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SortOperatorContext >(&mut _localctx).orderedExpression.clone().unwrap()
				 ;
				 cast_mut::<_,SortOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(2024);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- orderedExpression ----------------
pub type OrderedExpressionContextAll<'input> = OrderedExpressionContext<'input>;


pub type OrderedExpressionContext<'input> = BaseParserRuleContext<'input,OrderedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct OrderedExpressionContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Ordering: Option<Rc<SortOrderingContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for OrderedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for OrderedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_orderedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_orderedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for OrderedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_orderedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for OrderedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_orderedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_orderedExpression }
}
antlr_rust::tid!{OrderedExpressionContextExt<'a>}

impl<'input> OrderedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<OrderedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,OrderedExpressionContextExt{
				Expression: None, Ordering: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait OrderedExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<OrderedExpressionContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn sortOrdering(&self) -> Option<Rc<SortOrderingContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> OrderedExpressionContextAttrs<'input> for OrderedExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn orderedExpression(&mut self,)
	-> Result<Rc<OrderedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = OrderedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 330, RULE_orderedExpression);
        let mut _localctx: Rc<OrderedExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule namedExpression*/
			recog.base.set_state(2025);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,OrderedExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			/*InvokeRule sortOrdering*/
			recog.base.set_state(2026);
			let tmp = recog.sortOrdering()?;
			 cast_mut::<_,OrderedExpressionContext >(&mut _localctx).Ordering = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- sortOrdering ----------------
pub type SortOrderingContextAll<'input> = SortOrderingContext<'input>;


pub type SortOrderingContext<'input> = BaseParserRuleContext<'input,SortOrderingContextExt<'input>>;

#[derive(Clone)]
pub struct SortOrderingContextExt<'input>{
	pub OrderKind: Option<TokenType<'input>>,
	pub NullsKind: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SortOrderingContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SortOrderingContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_sortOrdering(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_sortOrdering(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SortOrderingContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_sortOrdering(self);
	}
}

impl<'input> CustomRuleContext<'input> for SortOrderingContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_sortOrdering }
	//fn type_rule_index() -> usize where Self: Sized { RULE_sortOrdering }
}
antlr_rust::tid!{SortOrderingContextExt<'a>}

impl<'input> SortOrderingContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SortOrderingContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SortOrderingContextExt{
				OrderKind: None, NullsKind: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SortOrderingContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SortOrderingContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ASC
/// Returns `None` if there is no child corresponding to token ASC
fn ASC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASC, 0)
}
/// Retrieves first TerminalNode corresponding to token DESC
/// Returns `None` if there is no child corresponding to token DESC
fn DESC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DESC, 0)
}
/// Retrieves first TerminalNode corresponding to token FIRST
/// Returns `None` if there is no child corresponding to token FIRST
fn FIRST(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FIRST, 0)
}
/// Retrieves first TerminalNode corresponding to token LAST
/// Returns `None` if there is no child corresponding to token LAST
fn LAST(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LAST, 0)
}

}

impl<'input> SortOrderingContextAttrs<'input> for SortOrderingContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn sortOrdering(&mut self,)
	-> Result<Rc<SortOrderingContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SortOrderingContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 332, RULE_sortOrdering);
        let mut _localctx: Rc<SortOrderingContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2029);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==ASC || _la==DESC {
				{
				recog.base.set_state(2028);
				 cast_mut::<_,SortOrderingContext >(&mut _localctx).OrderKind = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==ASC || _la==DESC) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortOrderingContext >(&mut _localctx).OrderKind = Some(tmp.clone());
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			recog.base.set_state(2033);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==NULLS {
				{
				recog.base.set_state(2031);
				recog.base.match_token(NULLS,&mut recog.err_handler)?;

				recog.base.set_state(2032);
				 cast_mut::<_,SortOrderingContext >(&mut _localctx).NullsKind = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==FIRST || _la==LAST) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,SortOrderingContext >(&mut _localctx).NullsKind = Some(tmp.clone());
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- summarizeOperator ----------------
pub type SummarizeOperatorContextAll<'input> = SummarizeOperatorContext<'input>;


pub type SummarizeOperatorContext<'input> = BaseParserRuleContext<'input,SummarizeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct SummarizeOperatorContextExt<'input>{
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
	pub ByClause: Option<Rc<SummarizeOperatorByClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SummarizeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SummarizeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_summarizeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_summarizeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SummarizeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_summarizeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for SummarizeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_summarizeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_summarizeOperator }
}
antlr_rust::tid!{SummarizeOperatorContextExt<'a>}

impl<'input> SummarizeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SummarizeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SummarizeOperatorContextExt{
				strictQueryOperatorParameter: None, namedExpression: None, ByClause: None, 
				Parameters: Vec::new(), Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SummarizeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SummarizeOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token SUMMARIZE
/// Returns `None` if there is no child corresponding to token SUMMARIZE
fn SUMMARIZE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SUMMARIZE, 0)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn summarizeOperatorByClause(&self) -> Option<Rc<SummarizeOperatorByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> SummarizeOperatorContextAttrs<'input> for SummarizeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn summarizeOperator(&mut self,)
	-> Result<Rc<SummarizeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SummarizeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 334, RULE_summarizeOperator);
        let mut _localctx: Rc<SummarizeOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2035);
			recog.base.match_token(SUMMARIZE,&mut recog.err_handler)?;

			recog.base.set_state(2039);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(2036);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2041);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2050);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(170,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule namedExpression*/
					recog.base.set_state(2042);
					let tmp = recog.namedExpression()?;
					 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
					 ;
					 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).Expressions.push(temp);
					  
					recog.base.set_state(2047);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
					while _la==COMMA {
						{
						{
						recog.base.set_state(2043);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule namedExpression*/
						recog.base.set_state(2044);
						let tmp = recog.namedExpression()?;
						 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).namedExpression = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).namedExpression.clone().unwrap()
						 ;
						 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).Expressions.push(temp);
						  
						}
						}
						recog.base.set_state(2049);
						recog.err_handler.sync(&mut recog.base)?;
						_la = recog.base.input.la(1);
					}
					}
				}

				_ => {}
			}
			recog.base.set_state(2053);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BY {
				{
				/*InvokeRule summarizeOperatorByClause*/
				recog.base.set_state(2052);
				let tmp = recog.summarizeOperatorByClause()?;
				 cast_mut::<_,SummarizeOperatorContext >(&mut _localctx).ByClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- summarizeOperatorByClause ----------------
pub type SummarizeOperatorByClauseContextAll<'input> = SummarizeOperatorByClauseContext<'input>;


pub type SummarizeOperatorByClauseContext<'input> = BaseParserRuleContext<'input,SummarizeOperatorByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SummarizeOperatorByClauseContextExt<'input>{
	pub namedExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<NamedExpressionContextAll<'input>>>,
	pub BinClause: Option<Rc<SummarizeOperatorLegacyBinClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SummarizeOperatorByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SummarizeOperatorByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_summarizeOperatorByClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_summarizeOperatorByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SummarizeOperatorByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_summarizeOperatorByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SummarizeOperatorByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_summarizeOperatorByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_summarizeOperatorByClause }
}
antlr_rust::tid!{SummarizeOperatorByClauseContextExt<'a>}

impl<'input> SummarizeOperatorByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SummarizeOperatorByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SummarizeOperatorByClauseContextExt{
				namedExpression: None, BinClause: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait SummarizeOperatorByClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SummarizeOperatorByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token COMMA
/// Returns `None` if there is no child corresponding to token COMMA
fn COMMA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, 0)
}
fn summarizeOperatorLegacyBinClause(&self) -> Option<Rc<SummarizeOperatorLegacyBinClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SummarizeOperatorByClauseContextAttrs<'input> for SummarizeOperatorByClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn summarizeOperatorByClause(&mut self,)
	-> Result<Rc<SummarizeOperatorByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SummarizeOperatorByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 336, RULE_summarizeOperatorByClause);
        let mut _localctx: Rc<SummarizeOperatorByClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2055);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(2056);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			{
			recog.base.set_state(2057);
			recog.base.match_token(COMMA,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(2058);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).namedExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).namedExpression.clone().unwrap()
			 ;
			 cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).Expressions.push(temp);
			  
			}
			recog.base.set_state(2061);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BIN {
				{
				/*InvokeRule summarizeOperatorLegacyBinClause*/
				recog.base.set_state(2060);
				let tmp = recog.summarizeOperatorLegacyBinClause()?;
				 cast_mut::<_,SummarizeOperatorByClauseContext >(&mut _localctx).BinClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- summarizeOperatorLegacyBinClause ----------------
pub type SummarizeOperatorLegacyBinClauseContextAll<'input> = SummarizeOperatorLegacyBinClauseContext<'input>;


pub type SummarizeOperatorLegacyBinClauseContext<'input> = BaseParserRuleContext<'input,SummarizeOperatorLegacyBinClauseContextExt<'input>>;

#[derive(Clone)]
pub struct SummarizeOperatorLegacyBinClauseContextExt<'input>{
	pub Expression: Option<Rc<NumberLikeLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SummarizeOperatorLegacyBinClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SummarizeOperatorLegacyBinClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_summarizeOperatorLegacyBinClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_summarizeOperatorLegacyBinClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SummarizeOperatorLegacyBinClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_summarizeOperatorLegacyBinClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for SummarizeOperatorLegacyBinClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_summarizeOperatorLegacyBinClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_summarizeOperatorLegacyBinClause }
}
antlr_rust::tid!{SummarizeOperatorLegacyBinClauseContextExt<'a>}

impl<'input> SummarizeOperatorLegacyBinClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SummarizeOperatorLegacyBinClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SummarizeOperatorLegacyBinClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SummarizeOperatorLegacyBinClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SummarizeOperatorLegacyBinClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BIN
/// Returns `None` if there is no child corresponding to token BIN
fn BIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BIN, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn numberLikeLiteralExpression(&self) -> Option<Rc<NumberLikeLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SummarizeOperatorLegacyBinClauseContextAttrs<'input> for SummarizeOperatorLegacyBinClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn summarizeOperatorLegacyBinClause(&mut self,)
	-> Result<Rc<SummarizeOperatorLegacyBinClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SummarizeOperatorLegacyBinClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 338, RULE_summarizeOperatorLegacyBinClause);
        let mut _localctx: Rc<SummarizeOperatorLegacyBinClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2063);
			recog.base.match_token(BIN,&mut recog.err_handler)?;

			recog.base.set_state(2064);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule numberLikeLiteralExpression*/
			recog.base.set_state(2065);
			let tmp = recog.numberLikeLiteralExpression()?;
			 cast_mut::<_,SummarizeOperatorLegacyBinClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- takeOperator ----------------
pub type TakeOperatorContextAll<'input> = TakeOperatorContext<'input>;


pub type TakeOperatorContext<'input> = BaseParserRuleContext<'input,TakeOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct TakeOperatorContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TakeOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TakeOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_takeOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_takeOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TakeOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_takeOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for TakeOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_takeOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_takeOperator }
}
antlr_rust::tid!{TakeOperatorContextExt<'a>}

impl<'input> TakeOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TakeOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TakeOperatorContextExt{
				Keyword: None, 
				strictQueryOperatorParameter: None, Expression: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TakeOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TakeOperatorContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token TAKE
/// Returns `None` if there is no child corresponding to token TAKE
fn TAKE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TAKE, 0)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> TakeOperatorContextAttrs<'input> for TakeOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn takeOperator(&mut self,)
	-> Result<Rc<TakeOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TakeOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 340, RULE_takeOperator);
        let mut _localctx: Rc<TakeOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2067);
			 cast_mut::<_,TakeOperatorContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==LIMIT || _la==TAKE) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,TakeOperatorContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2071);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(2068);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,TakeOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,TakeOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,TakeOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2073);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule namedExpression*/
			recog.base.set_state(2074);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,TakeOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- topOperator ----------------
pub type TopOperatorContextAll<'input> = TopOperatorContext<'input>;


pub type TopOperatorContext<'input> = BaseParserRuleContext<'input,TopOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct TopOperatorContextExt<'input>{
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub ByExpression: Option<Rc<OrderedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_topOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_topOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_topOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_topOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_topOperator }
}
antlr_rust::tid!{TopOperatorContextExt<'a>}

impl<'input> TopOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopOperatorContextExt{
				strictQueryOperatorParameter: None, Expression: None, ByExpression: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TopOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TOP
/// Returns `None` if there is no child corresponding to token TOP
fn TOP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOP, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn orderedExpression(&self) -> Option<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> TopOperatorContextAttrs<'input> for TopOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn topOperator(&mut self,)
	-> Result<Rc<TopOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 342, RULE_topOperator);
        let mut _localctx: Rc<TopOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2076);
			recog.base.match_token(TOP,&mut recog.err_handler)?;

			recog.base.set_state(2080);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(2077);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,TopOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,TopOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,TopOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2082);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule namedExpression*/
			recog.base.set_state(2083);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,TopOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2084);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule orderedExpression*/
			recog.base.set_state(2085);
			let tmp = recog.orderedExpression()?;
			 cast_mut::<_,TopOperatorContext >(&mut _localctx).ByExpression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- topHittersOperator ----------------
pub type TopHittersOperatorContextAll<'input> = TopHittersOperatorContext<'input>;


pub type TopHittersOperatorContext<'input> = BaseParserRuleContext<'input,TopHittersOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct TopHittersOperatorContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub OfExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub ByClause: Option<Rc<TopHittersOperatorByClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopHittersOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopHittersOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_topHittersOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_topHittersOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopHittersOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_topHittersOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopHittersOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_topHittersOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_topHittersOperator }
}
antlr_rust::tid!{TopHittersOperatorContextExt<'a>}

impl<'input> TopHittersOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopHittersOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopHittersOperatorContextExt{
				Expression: None, OfExpression: None, ByClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TopHittersOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopHittersOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TOP_HITTERS
/// Returns `None` if there is no child corresponding to token TOP_HITTERS
fn TOP_HITTERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOP_HITTERS, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn topHittersOperatorByClause(&self) -> Option<Rc<TopHittersOperatorByClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TopHittersOperatorContextAttrs<'input> for TopHittersOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn topHittersOperator(&mut self,)
	-> Result<Rc<TopHittersOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopHittersOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 344, RULE_topHittersOperator);
        let mut _localctx: Rc<TopHittersOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2087);
			recog.base.match_token(TOP_HITTERS,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(2088);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,TopHittersOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2089);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(2090);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,TopHittersOperatorContext >(&mut _localctx).OfExpression = Some(tmp.clone());
			  

			recog.base.set_state(2092);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==BY {
				{
				/*InvokeRule topHittersOperatorByClause*/
				recog.base.set_state(2091);
				let tmp = recog.topHittersOperatorByClause()?;
				 cast_mut::<_,TopHittersOperatorContext >(&mut _localctx).ByClause = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- topHittersOperatorByClause ----------------
pub type TopHittersOperatorByClauseContextAll<'input> = TopHittersOperatorByClauseContext<'input>;


pub type TopHittersOperatorByClauseContext<'input> = BaseParserRuleContext<'input,TopHittersOperatorByClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TopHittersOperatorByClauseContextExt<'input>{
	pub ByExpression: Option<Rc<OrderedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopHittersOperatorByClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopHittersOperatorByClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_topHittersOperatorByClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_topHittersOperatorByClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopHittersOperatorByClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_topHittersOperatorByClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopHittersOperatorByClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_topHittersOperatorByClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_topHittersOperatorByClause }
}
antlr_rust::tid!{TopHittersOperatorByClauseContextExt<'a>}

impl<'input> TopHittersOperatorByClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopHittersOperatorByClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopHittersOperatorByClauseContextExt{
				ByExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TopHittersOperatorByClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopHittersOperatorByClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn orderedExpression(&self) -> Option<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TopHittersOperatorByClauseContextAttrs<'input> for TopHittersOperatorByClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn topHittersOperatorByClause(&mut self,)
	-> Result<Rc<TopHittersOperatorByClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopHittersOperatorByClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 346, RULE_topHittersOperatorByClause);
        let mut _localctx: Rc<TopHittersOperatorByClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2094);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule orderedExpression*/
			recog.base.set_state(2095);
			let tmp = recog.orderedExpression()?;
			 cast_mut::<_,TopHittersOperatorByClauseContext >(&mut _localctx).ByExpression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- topNestedOperator ----------------
pub type TopNestedOperatorContextAll<'input> = TopNestedOperatorContext<'input>;


pub type TopNestedOperatorContext<'input> = BaseParserRuleContext<'input,TopNestedOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct TopNestedOperatorContextExt<'input>{
	pub topNestedOperatorPart: Option<Rc<TopNestedOperatorPartContextAll<'input>>>,
	pub Segments:Vec<Rc<TopNestedOperatorPartContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopNestedOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopNestedOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_topNestedOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_topNestedOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopNestedOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_topNestedOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopNestedOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_topNestedOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_topNestedOperator }
}
antlr_rust::tid!{TopNestedOperatorContextExt<'a>}

impl<'input> TopNestedOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopNestedOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopNestedOperatorContextExt{
				topNestedOperatorPart: None, 
				Segments: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait TopNestedOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopNestedOperatorContextExt<'input>>{

fn topNestedOperatorPart_all(&self) ->  Vec<Rc<TopNestedOperatorPartContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn topNestedOperatorPart(&self, i: usize) -> Option<Rc<TopNestedOperatorPartContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> TopNestedOperatorContextAttrs<'input> for TopNestedOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn topNestedOperator(&mut self,)
	-> Result<Rc<TopNestedOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopNestedOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 348, RULE_topNestedOperator);
        let mut _localctx: Rc<TopNestedOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule topNestedOperatorPart*/
			recog.base.set_state(2097);
			let tmp = recog.topNestedOperatorPart()?;
			 cast_mut::<_,TopNestedOperatorContext >(&mut _localctx).topNestedOperatorPart = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,TopNestedOperatorContext >(&mut _localctx).topNestedOperatorPart.clone().unwrap()
			 ;
			 cast_mut::<_,TopNestedOperatorContext >(&mut _localctx).Segments.push(temp);
			  
			recog.base.set_state(2102);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2098);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule topNestedOperatorPart*/
				recog.base.set_state(2099);
				let tmp = recog.topNestedOperatorPart()?;
				 cast_mut::<_,TopNestedOperatorContext >(&mut _localctx).topNestedOperatorPart = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,TopNestedOperatorContext >(&mut _localctx).topNestedOperatorPart.clone().unwrap()
				 ;
				 cast_mut::<_,TopNestedOperatorContext >(&mut _localctx).Segments.push(temp);
				  
				}
				}
				recog.base.set_state(2104);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- topNestedOperatorPart ----------------
pub type TopNestedOperatorPartContextAll<'input> = TopNestedOperatorPartContext<'input>;


pub type TopNestedOperatorPartContext<'input> = BaseParserRuleContext<'input,TopNestedOperatorPartContextExt<'input>>;

#[derive(Clone)]
pub struct TopNestedOperatorPartContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub OfExpression: Option<Rc<NamedExpressionContextAll<'input>>>,
	pub WithOthers: Option<Rc<TopNestedOperatorWithOthersClauseContextAll<'input>>>,
	pub ByExpression: Option<Rc<OrderedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopNestedOperatorPartContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopNestedOperatorPartContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_topNestedOperatorPart(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_topNestedOperatorPart(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopNestedOperatorPartContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_topNestedOperatorPart(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopNestedOperatorPartContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_topNestedOperatorPart }
	//fn type_rule_index() -> usize where Self: Sized { RULE_topNestedOperatorPart }
}
antlr_rust::tid!{TopNestedOperatorPartContextExt<'a>}

impl<'input> TopNestedOperatorPartContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopNestedOperatorPartContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopNestedOperatorPartContextExt{
				Expression: None, OfExpression: None, WithOthers: None, ByExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TopNestedOperatorPartContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopNestedOperatorPartContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TOP_NESTED
/// Returns `None` if there is no child corresponding to token TOP_NESTED
fn TOP_NESTED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOP_NESTED, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
fn namedExpression_all(&self) ->  Vec<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn namedExpression(&self, i: usize) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn orderedExpression(&self) -> Option<Rc<OrderedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn topNestedOperatorWithOthersClause(&self) -> Option<Rc<TopNestedOperatorWithOthersClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TopNestedOperatorPartContextAttrs<'input> for TopNestedOperatorPartContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn topNestedOperatorPart(&mut self,)
	-> Result<Rc<TopNestedOperatorPartContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopNestedOperatorPartContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 350, RULE_topNestedOperatorPart);
        let mut _localctx: Rc<TopNestedOperatorPartContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2105);
			recog.base.match_token(TOP_NESTED,&mut recog.err_handler)?;

			recog.base.set_state(2107);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(177,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule namedExpression*/
					recog.base.set_state(2106);
					let tmp = recog.namedExpression()?;
					 cast_mut::<_,TopNestedOperatorPartContext >(&mut _localctx).Expression = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			recog.base.set_state(2109);
			recog.base.match_token(OF,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(2110);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,TopNestedOperatorPartContext >(&mut _localctx).OfExpression = Some(tmp.clone());
			  

			recog.base.set_state(2112);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==WITH {
				{
				/*InvokeRule topNestedOperatorWithOthersClause*/
				recog.base.set_state(2111);
				let tmp = recog.topNestedOperatorWithOthersClause()?;
				 cast_mut::<_,TopNestedOperatorPartContext >(&mut _localctx).WithOthers = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2114);
			recog.base.match_token(BY,&mut recog.err_handler)?;

			/*InvokeRule orderedExpression*/
			recog.base.set_state(2115);
			let tmp = recog.orderedExpression()?;
			 cast_mut::<_,TopNestedOperatorPartContext >(&mut _localctx).ByExpression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- topNestedOperatorWithOthersClause ----------------
pub type TopNestedOperatorWithOthersClauseContextAll<'input> = TopNestedOperatorWithOthersClauseContext<'input>;


pub type TopNestedOperatorWithOthersClauseContext<'input> = BaseParserRuleContext<'input,TopNestedOperatorWithOthersClauseContextExt<'input>>;

#[derive(Clone)]
pub struct TopNestedOperatorWithOthersClauseContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TopNestedOperatorWithOthersClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TopNestedOperatorWithOthersClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_topNestedOperatorWithOthersClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_topNestedOperatorWithOthersClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TopNestedOperatorWithOthersClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_topNestedOperatorWithOthersClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for TopNestedOperatorWithOthersClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_topNestedOperatorWithOthersClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_topNestedOperatorWithOthersClause }
}
antlr_rust::tid!{TopNestedOperatorWithOthersClauseContextExt<'a>}

impl<'input> TopNestedOperatorWithOthersClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TopNestedOperatorWithOthersClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TopNestedOperatorWithOthersClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TopNestedOperatorWithOthersClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TopNestedOperatorWithOthersClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token OTHERS
/// Returns `None` if there is no child corresponding to token OTHERS
fn OTHERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OTHERS, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> TopNestedOperatorWithOthersClauseContextAttrs<'input> for TopNestedOperatorWithOthersClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn topNestedOperatorWithOthersClause(&mut self,)
	-> Result<Rc<TopNestedOperatorWithOthersClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TopNestedOperatorWithOthersClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 352, RULE_topNestedOperatorWithOthersClause);
        let mut _localctx: Rc<TopNestedOperatorWithOthersClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2117);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(2118);
			recog.base.match_token(OTHERS,&mut recog.err_handler)?;

			recog.base.set_state(2119);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			/*InvokeRule namedExpression*/
			recog.base.set_state(2120);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,TopNestedOperatorWithOthersClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unionOperator ----------------
pub type UnionOperatorContextAll<'input> = UnionOperatorContext<'input>;


pub type UnionOperatorContext<'input> = BaseParserRuleContext<'input,UnionOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct UnionOperatorContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub unionOperatorExpression: Option<Rc<UnionOperatorExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<UnionOperatorExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for UnionOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for UnionOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unionOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_unionOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for UnionOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_unionOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnionOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unionOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unionOperator }
}
antlr_rust::tid!{UnionOperatorContextExt<'a>}

impl<'input> UnionOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnionOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnionOperatorContextExt{
				relaxedQueryOperatorParameter: None, unionOperatorExpression: None, 
				Parameters: Vec::new(), Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnionOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<UnionOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token UNION
/// Returns `None` if there is no child corresponding to token UNION
fn UNION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UNION, 0)
}
fn unionOperatorExpression_all(&self) ->  Vec<Rc<UnionOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unionOperatorExpression(&self, i: usize) -> Option<Rc<UnionOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> UnionOperatorContextAttrs<'input> for UnionOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unionOperator(&mut self,)
	-> Result<Rc<UnionOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnionOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 354, RULE_unionOperator);
        let mut _localctx: Rc<UnionOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2122);
			recog.base.match_token(UNION,&mut recog.err_handler)?;

			recog.base.set_state(2126);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(179,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule relaxedQueryOperatorParameter*/
					recog.base.set_state(2123);
					let tmp = recog.relaxedQueryOperatorParameter()?;
					 cast_mut::<_,UnionOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,UnionOperatorContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
					 ;
					 cast_mut::<_,UnionOperatorContext >(&mut _localctx).Parameters.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2128);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(179,&mut recog.base)?;
			}
			/*InvokeRule unionOperatorExpression*/
			recog.base.set_state(2129);
			let tmp = recog.unionOperatorExpression()?;
			 cast_mut::<_,UnionOperatorContext >(&mut _localctx).unionOperatorExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,UnionOperatorContext >(&mut _localctx).unionOperatorExpression.clone().unwrap()
			 ;
			 cast_mut::<_,UnionOperatorContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(2134);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2130);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule unionOperatorExpression*/
				recog.base.set_state(2131);
				let tmp = recog.unionOperatorExpression()?;
				 cast_mut::<_,UnionOperatorContext >(&mut _localctx).unionOperatorExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,UnionOperatorContext >(&mut _localctx).unionOperatorExpression.clone().unwrap()
				 ;
				 cast_mut::<_,UnionOperatorContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(2136);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unionOperatorExpression ----------------
pub type UnionOperatorExpressionContextAll<'input> = UnionOperatorExpressionContext<'input>;


pub type UnionOperatorExpressionContext<'input> = BaseParserRuleContext<'input,UnionOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct UnionOperatorExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for UnionOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for UnionOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unionOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_unionOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for UnionOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_unionOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnionOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unionOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unionOperatorExpression }
}
antlr_rust::tid!{UnionOperatorExpressionContextExt<'a>}

impl<'input> UnionOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnionOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnionOperatorExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnionOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<UnionOperatorExpressionContextExt<'input>>{

fn wildcardedEntityExpression(&self) -> Option<Rc<WildcardedEntityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn entityNameReference(&self) -> Option<Rc<EntityNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parenthesizedExpression(&self) -> Option<Rc<ParenthesizedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnionOperatorExpressionContextAttrs<'input> for UnionOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unionOperatorExpression(&mut self,)
	-> Result<Rc<UnionOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnionOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 356, RULE_unionOperatorExpression);
        let mut _localctx: Rc<UnionOperatorExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2140);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(181,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule wildcardedEntityExpression*/
					recog.base.set_state(2137);
					recog.wildcardedEntityExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule entityNameReference*/
					recog.base.set_state(2138);
					recog.entityNameReference()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule parenthesizedExpression*/
					recog.base.set_state(2139);
					recog.parenthesizedExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- whereOperator ----------------
pub type WhereOperatorContextAll<'input> = WhereOperatorContext<'input>;


pub type WhereOperatorContext<'input> = BaseParserRuleContext<'input,WhereOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct WhereOperatorContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub strictQueryOperatorParameter: Option<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>>,
	pub Predicate: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WhereOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WhereOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_whereOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_whereOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WhereOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_whereOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for WhereOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_whereOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_whereOperator }
}
antlr_rust::tid!{WhereOperatorContextExt<'a>}

impl<'input> WhereOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WhereOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WhereOperatorContextExt{
				Keyword: None, 
				strictQueryOperatorParameter: None, Predicate: None, 
				Parameters: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait WhereOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WhereOperatorContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}
fn strictQueryOperatorParameter_all(&self) ->  Vec<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn strictQueryOperatorParameter(&self, i: usize) -> Option<Rc<StrictQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> WhereOperatorContextAttrs<'input> for WhereOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn whereOperator(&mut self,)
	-> Result<Rc<WhereOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WhereOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 358, RULE_whereOperator);
        let mut _localctx: Rc<WhereOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2142);
			 cast_mut::<_,WhereOperatorContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==FILTER || _la==WHERE) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,WhereOperatorContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2146);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) {
				{
				{
				/*InvokeRule strictQueryOperatorParameter*/
				recog.base.set_state(2143);
				let tmp = recog.strictQueryOperatorParameter()?;
				 cast_mut::<_,WhereOperatorContext >(&mut _localctx).strictQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,WhereOperatorContext >(&mut _localctx).strictQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,WhereOperatorContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2148);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule namedExpression*/
			recog.base.set_state(2149);
			let tmp = recog.namedExpression()?;
			 cast_mut::<_,WhereOperatorContext >(&mut _localctx).Predicate = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- contextualSubExpression ----------------
pub type ContextualSubExpressionContextAll<'input> = ContextualSubExpressionContext<'input>;


pub type ContextualSubExpressionContext<'input> = BaseParserRuleContext<'input,ContextualSubExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ContextualSubExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ContextualSubExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ContextualSubExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_contextualSubExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_contextualSubExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ContextualSubExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_contextualSubExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ContextualSubExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_contextualSubExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_contextualSubExpression }
}
antlr_rust::tid!{ContextualSubExpressionContextExt<'a>}

impl<'input> ContextualSubExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ContextualSubExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ContextualSubExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ContextualSubExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ContextualSubExpressionContextExt<'input>>{

fn pipeSubExpression(&self) -> Option<Rc<PipeSubExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn contextualPipeExpression(&self) -> Option<Rc<ContextualPipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ContextualSubExpressionContextAttrs<'input> for ContextualSubExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn contextualSubExpression(&mut self,)
	-> Result<Rc<ContextualSubExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ContextualSubExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 360, RULE_contextualSubExpression);
        let mut _localctx: Rc<ContextualSubExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2153);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 AS | ASSERTSCHEMA | CONSUME | COUNT | DISTINCT | EVALUATE | EXECUTE_AND_CACHE |
			 EXTEND | FACET | FILTER | FIND | FORK | GETSCHEMA | GRAPHMARKCOMPONENTS |
			 GRAPHMATCH | GRAPHMERGE | GRAPHSHORTESTPATHS | GRAPHTOTABLE | INVOKE |
			 JOIN | LIMIT | LOOKUP | MAKEGRAPH | MAKESERIES | MV_APPLY | MV_EXPAND |
			 MVAPPLY | MVEXPAND | ORDER | PARSE | PARSEKV | PARSEWHERE | PARTITION |
			 PARTITIONBY | PROJECT | PROJECTAWAY | PROJECTKEEP | PROJECTRENAME | PROJECTREORDER |
			 REDUCE | RENDER | SAMPLE | SAMPLE_DISTINCT | SCAN | SEARCH | SERIALIZE |
			 SORT | SUMMARIZE | TAKE | TOP | TOP_HITTERS | TOP_NESTED | UNION | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule pipeSubExpression*/
					recog.base.set_state(2151);
					recog.pipeSubExpression()?;

					}
				}

			 CONTEXTUAL_DATATABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule contextualPipeExpression*/
					recog.base.set_state(2152);
					recog.contextualPipeExpression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- contextualPipeExpression ----------------
pub type ContextualPipeExpressionContextAll<'input> = ContextualPipeExpressionContext<'input>;


pub type ContextualPipeExpressionContext<'input> = BaseParserRuleContext<'input,ContextualPipeExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ContextualPipeExpressionContextExt<'input>{
	pub Expression: Option<Rc<ContextualDataTableExpressionContextAll<'input>>>,
	pub contextualPipeExpressionPipedOperator: Option<Rc<ContextualPipeExpressionPipedOperatorContextAll<'input>>>,
	pub PipedOperators:Vec<Rc<ContextualPipeExpressionPipedOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ContextualPipeExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ContextualPipeExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_contextualPipeExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_contextualPipeExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ContextualPipeExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_contextualPipeExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ContextualPipeExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_contextualPipeExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_contextualPipeExpression }
}
antlr_rust::tid!{ContextualPipeExpressionContextExt<'a>}

impl<'input> ContextualPipeExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ContextualPipeExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ContextualPipeExpressionContextExt{
				Expression: None, contextualPipeExpressionPipedOperator: None, 
				PipedOperators: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ContextualPipeExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ContextualPipeExpressionContextExt<'input>>{

fn contextualDataTableExpression(&self) -> Option<Rc<ContextualDataTableExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn contextualPipeExpressionPipedOperator_all(&self) ->  Vec<Rc<ContextualPipeExpressionPipedOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn contextualPipeExpressionPipedOperator(&self, i: usize) -> Option<Rc<ContextualPipeExpressionPipedOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ContextualPipeExpressionContextAttrs<'input> for ContextualPipeExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn contextualPipeExpression(&mut self,)
	-> Result<Rc<ContextualPipeExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ContextualPipeExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 362, RULE_contextualPipeExpression);
        let mut _localctx: Rc<ContextualPipeExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule contextualDataTableExpression*/
			recog.base.set_state(2155);
			let tmp = recog.contextualDataTableExpression()?;
			 cast_mut::<_,ContextualPipeExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2159);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==BAR {
				{
				{
				/*InvokeRule contextualPipeExpressionPipedOperator*/
				recog.base.set_state(2156);
				let tmp = recog.contextualPipeExpressionPipedOperator()?;
				 cast_mut::<_,ContextualPipeExpressionContext >(&mut _localctx).contextualPipeExpressionPipedOperator = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ContextualPipeExpressionContext >(&mut _localctx).contextualPipeExpressionPipedOperator.clone().unwrap()
				 ;
				 cast_mut::<_,ContextualPipeExpressionContext >(&mut _localctx).PipedOperators.push(temp);
				  
				}
				}
				recog.base.set_state(2161);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- contextualPipeExpressionPipedOperator ----------------
pub type ContextualPipeExpressionPipedOperatorContextAll<'input> = ContextualPipeExpressionPipedOperatorContext<'input>;


pub type ContextualPipeExpressionPipedOperatorContext<'input> = BaseParserRuleContext<'input,ContextualPipeExpressionPipedOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct ContextualPipeExpressionPipedOperatorContextExt<'input>{
	pub Operator: Option<Rc<AfterPipeOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ContextualPipeExpressionPipedOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ContextualPipeExpressionPipedOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_contextualPipeExpressionPipedOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_contextualPipeExpressionPipedOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ContextualPipeExpressionPipedOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_contextualPipeExpressionPipedOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for ContextualPipeExpressionPipedOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_contextualPipeExpressionPipedOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_contextualPipeExpressionPipedOperator }
}
antlr_rust::tid!{ContextualPipeExpressionPipedOperatorContextExt<'a>}

impl<'input> ContextualPipeExpressionPipedOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ContextualPipeExpressionPipedOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ContextualPipeExpressionPipedOperatorContextExt{
				Operator: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ContextualPipeExpressionPipedOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ContextualPipeExpressionPipedOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BAR
/// Returns `None` if there is no child corresponding to token BAR
fn BAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BAR, 0)
}
fn afterPipeOperator(&self) -> Option<Rc<AfterPipeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ContextualPipeExpressionPipedOperatorContextAttrs<'input> for ContextualPipeExpressionPipedOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn contextualPipeExpressionPipedOperator(&mut self,)
	-> Result<Rc<ContextualPipeExpressionPipedOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ContextualPipeExpressionPipedOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 364, RULE_contextualPipeExpressionPipedOperator);
        let mut _localctx: Rc<ContextualPipeExpressionPipedOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2162);
			recog.base.match_token(BAR,&mut recog.err_handler)?;

			/*InvokeRule afterPipeOperator*/
			recog.base.set_state(2163);
			let tmp = recog.afterPipeOperator()?;
			 cast_mut::<_,ContextualPipeExpressionPipedOperatorContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- strictQueryOperatorParameter ----------------
pub type StrictQueryOperatorParameterContextAll<'input> = StrictQueryOperatorParameterContext<'input>;


pub type StrictQueryOperatorParameterContext<'input> = BaseParserRuleContext<'input,StrictQueryOperatorParameterContextExt<'input>>;

#[derive(Clone)]
pub struct StrictQueryOperatorParameterContextExt<'input>{
	pub NameToken: Option<TokenType<'input>>,
	pub NameValue: Option<Rc<IdentifierOrKeywordNameContextAll<'input>>>,
	pub LiteralValue: Option<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StrictQueryOperatorParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StrictQueryOperatorParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_strictQueryOperatorParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_strictQueryOperatorParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StrictQueryOperatorParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_strictQueryOperatorParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for StrictQueryOperatorParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_strictQueryOperatorParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_strictQueryOperatorParameter }
}
antlr_rust::tid!{StrictQueryOperatorParameterContextExt<'a>}

impl<'input> StrictQueryOperatorParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StrictQueryOperatorParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StrictQueryOperatorParameterContextExt{
				NameToken: None, 
				NameValue: None, LiteralValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait StrictQueryOperatorParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StrictQueryOperatorParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token BAGEXPANSION
/// Returns `None` if there is no child corresponding to token BAGEXPANSION
fn BAGEXPANSION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BAGEXPANSION, 0)
}
/// Retrieves first TerminalNode corresponding to token BIN_LEGACY
/// Returns `None` if there is no child corresponding to token BIN_LEGACY
fn BIN_LEGACY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BIN_LEGACY, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSSCLUSTER__
/// Returns `None` if there is no child corresponding to token CROSSCLUSTER__
fn CROSSCLUSTER__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CROSSCLUSTER__, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSSDB__
/// Returns `None` if there is no child corresponding to token CROSSDB__
fn CROSSDB__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CROSSDB__, 0)
}
/// Retrieves first TerminalNode corresponding to token DECODEBLOCKS
/// Returns `None` if there is no child corresponding to token DECODEBLOCKS
fn DECODEBLOCKS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECODEBLOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPANDOUTPUT
/// Returns `None` if there is no child corresponding to token EXPANDOUTPUT
fn EXPANDOUTPUT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXPANDOUTPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_CONCURRENCY
/// Returns `None` if there is no child corresponding to token HINT_CONCURRENCY
fn HINT_CONCURRENCY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_CONCURRENCY, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_DISTRIBUTION
/// Returns `None` if there is no child corresponding to token HINT_DISTRIBUTION
fn HINT_DISTRIBUTION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_DISTRIBUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_MATERIALIZED
/// Returns `None` if there is no child corresponding to token HINT_MATERIALIZED
fn HINT_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_NUM_PARTITIONS
/// Returns `None` if there is no child corresponding to token HINT_NUM_PARTITIONS
fn HINT_NUM_PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_NUM_PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_PASS_FILTERS
/// Returns `None` if there is no child corresponding to token HINT_PASS_FILTERS
fn HINT_PASS_FILTERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_PASS_FILTERS, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_PASS_FILTERS_COLUMN
/// Returns `None` if there is no child corresponding to token HINT_PASS_FILTERS_COLUMN
fn HINT_PASS_FILTERS_COLUMN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_PASS_FILTERS_COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_PROGRESSIVE_TOP
/// Returns `None` if there is no child corresponding to token HINT_PROGRESSIVE_TOP
fn HINT_PROGRESSIVE_TOP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_PROGRESSIVE_TOP, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_REMOTE
/// Returns `None` if there is no child corresponding to token HINT_REMOTE
fn HINT_REMOTE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_REMOTE, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_SUFFLEKEY
/// Returns `None` if there is no child corresponding to token HINT_SUFFLEKEY
fn HINT_SUFFLEKEY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_SUFFLEKEY, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_SPREAD
/// Returns `None` if there is no child corresponding to token HINT_SPREAD
fn HINT_SPREAD(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_SPREAD, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_STRATEGY
/// Returns `None` if there is no child corresponding to token HINT_STRATEGY
fn HINT_STRATEGY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_STRATEGY, 0)
}
/// Retrieves first TerminalNode corresponding to token ISFUZZY
/// Returns `None` if there is no child corresponding to token ISFUZZY
fn ISFUZZY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ISFUZZY, 0)
}
/// Retrieves first TerminalNode corresponding to token ISFUZZY__
/// Returns `None` if there is no child corresponding to token ISFUZZY__
fn ISFUZZY__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ISFUZZY__, 0)
}
/// Retrieves first TerminalNode corresponding to token ID__
/// Returns `None` if there is no child corresponding to token ID__
fn ID__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ID__, 0)
}
/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token PACKEDCOLUMN__
/// Returns `None` if there is no child corresponding to token PACKEDCOLUMN__
fn PACKEDCOLUMN__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PACKEDCOLUMN__, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCECOLUMNINDEX__
/// Returns `None` if there is no child corresponding to token SOURCECOLUMNINDEX__
fn SOURCECOLUMNINDEX__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SOURCECOLUMNINDEX__, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_ITEM_INDEX
/// Returns `None` if there is no child corresponding to token WITH_ITEM_INDEX
fn WITH_ITEM_INDEX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_ITEM_INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_MATCH_ID
/// Returns `None` if there is no child corresponding to token WITH_MATCH_ID
fn WITH_MATCH_ID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_MATCH_ID, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_STEP_NAME
/// Returns `None` if there is no child corresponding to token WITH_STEP_NAME
fn WITH_STEP_NAME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_STEP_NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHSOURCE
/// Returns `None` if there is no child corresponding to token WITHSOURCE
fn WITHSOURCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITHSOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_SOURCE
/// Returns `None` if there is no child corresponding to token WITH_SOURCE
fn WITH_SOURCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHNOSOURCE__
/// Returns `None` if there is no child corresponding to token WITHNOSOURCE__
fn WITHNOSOURCE__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITHNOSOURCE__, 0)
}
fn identifierOrKeywordName(&self) -> Option<Rc<IdentifierOrKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn literalExpression(&self) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StrictQueryOperatorParameterContextAttrs<'input> for StrictQueryOperatorParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn strictQueryOperatorParameter(&mut self,)
	-> Result<Rc<StrictQueryOperatorParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StrictQueryOperatorParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 366, RULE_strictQueryOperatorParameter);
        let mut _localctx: Rc<StrictQueryOperatorParameterContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2165);
			 cast_mut::<_,StrictQueryOperatorParameterContext >(&mut _localctx).NameToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0)) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,StrictQueryOperatorParameterContext >(&mut _localctx).NameToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2166);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2169);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					{
					/*InvokeRule identifierOrKeywordName*/
					recog.base.set_state(2167);
					let tmp = recog.identifierOrKeywordName()?;
					 cast_mut::<_,StrictQueryOperatorParameterContext >(&mut _localctx).NameValue = Some(tmp.clone());
					  

					}
				}

			 DASH | PLUS | DYNAMIC | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL |
			 STRINGLITERAL | BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL |
			 TYPELITERAL | GUIDLITERAL 
				=> {
					{
					/*InvokeRule literalExpression*/
					recog.base.set_state(2168);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,StrictQueryOperatorParameterContext >(&mut _localctx).LiteralValue = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relaxedQueryOperatorParameter ----------------
pub type RelaxedQueryOperatorParameterContextAll<'input> = RelaxedQueryOperatorParameterContext<'input>;


pub type RelaxedQueryOperatorParameterContext<'input> = BaseParserRuleContext<'input,RelaxedQueryOperatorParameterContextExt<'input>>;

#[derive(Clone)]
pub struct RelaxedQueryOperatorParameterContextExt<'input>{
	pub NameToken: Option<TokenType<'input>>,
	pub NameValue: Option<Rc<IdentifierOrKeywordNameContextAll<'input>>>,
	pub LiteralValue: Option<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RelaxedQueryOperatorParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RelaxedQueryOperatorParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relaxedQueryOperatorParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_relaxedQueryOperatorParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RelaxedQueryOperatorParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_relaxedQueryOperatorParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelaxedQueryOperatorParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relaxedQueryOperatorParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relaxedQueryOperatorParameter }
}
antlr_rust::tid!{RelaxedQueryOperatorParameterContextExt<'a>}

impl<'input> RelaxedQueryOperatorParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelaxedQueryOperatorParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelaxedQueryOperatorParameterContextExt{
				NameToken: None, 
				NameValue: None, LiteralValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RelaxedQueryOperatorParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RelaxedQueryOperatorParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}
/// Retrieves first TerminalNode corresponding to token BAGEXPANSION
/// Returns `None` if there is no child corresponding to token BAGEXPANSION
fn BAGEXPANSION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BAGEXPANSION, 0)
}
/// Retrieves first TerminalNode corresponding to token BIN_LEGACY
/// Returns `None` if there is no child corresponding to token BIN_LEGACY
fn BIN_LEGACY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BIN_LEGACY, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSSCLUSTER__
/// Returns `None` if there is no child corresponding to token CROSSCLUSTER__
fn CROSSCLUSTER__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CROSSCLUSTER__, 0)
}
/// Retrieves first TerminalNode corresponding to token CROSSDB__
/// Returns `None` if there is no child corresponding to token CROSSDB__
fn CROSSDB__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CROSSDB__, 0)
}
/// Retrieves first TerminalNode corresponding to token DECODEBLOCKS
/// Returns `None` if there is no child corresponding to token DECODEBLOCKS
fn DECODEBLOCKS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECODEBLOCKS, 0)
}
/// Retrieves first TerminalNode corresponding to token EXPANDOUTPUT
/// Returns `None` if there is no child corresponding to token EXPANDOUTPUT
fn EXPANDOUTPUT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXPANDOUTPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_CONCURRENCY
/// Returns `None` if there is no child corresponding to token HINT_CONCURRENCY
fn HINT_CONCURRENCY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_CONCURRENCY, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_DISTRIBUTION
/// Returns `None` if there is no child corresponding to token HINT_DISTRIBUTION
fn HINT_DISTRIBUTION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_DISTRIBUTION, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_MATERIALIZED
/// Returns `None` if there is no child corresponding to token HINT_MATERIALIZED
fn HINT_MATERIALIZED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_MATERIALIZED, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_NUM_PARTITIONS
/// Returns `None` if there is no child corresponding to token HINT_NUM_PARTITIONS
fn HINT_NUM_PARTITIONS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_NUM_PARTITIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_PASS_FILTERS
/// Returns `None` if there is no child corresponding to token HINT_PASS_FILTERS
fn HINT_PASS_FILTERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_PASS_FILTERS, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_PASS_FILTERS_COLUMN
/// Returns `None` if there is no child corresponding to token HINT_PASS_FILTERS_COLUMN
fn HINT_PASS_FILTERS_COLUMN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_PASS_FILTERS_COLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_PROGRESSIVE_TOP
/// Returns `None` if there is no child corresponding to token HINT_PROGRESSIVE_TOP
fn HINT_PROGRESSIVE_TOP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_PROGRESSIVE_TOP, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_REMOTE
/// Returns `None` if there is no child corresponding to token HINT_REMOTE
fn HINT_REMOTE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_REMOTE, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_SUFFLEKEY
/// Returns `None` if there is no child corresponding to token HINT_SUFFLEKEY
fn HINT_SUFFLEKEY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_SUFFLEKEY, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_SPREAD
/// Returns `None` if there is no child corresponding to token HINT_SPREAD
fn HINT_SPREAD(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_SPREAD, 0)
}
/// Retrieves first TerminalNode corresponding to token HINT_STRATEGY
/// Returns `None` if there is no child corresponding to token HINT_STRATEGY
fn HINT_STRATEGY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HINT_STRATEGY, 0)
}
/// Retrieves first TerminalNode corresponding to token ISFUZZY
/// Returns `None` if there is no child corresponding to token ISFUZZY
fn ISFUZZY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ISFUZZY, 0)
}
/// Retrieves first TerminalNode corresponding to token ISFUZZY__
/// Returns `None` if there is no child corresponding to token ISFUZZY__
fn ISFUZZY__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ISFUZZY__, 0)
}
/// Retrieves first TerminalNode corresponding to token ID__
/// Returns `None` if there is no child corresponding to token ID__
fn ID__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ID__, 0)
}
/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token PACKEDCOLUMN__
/// Returns `None` if there is no child corresponding to token PACKEDCOLUMN__
fn PACKEDCOLUMN__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PACKEDCOLUMN__, 0)
}
/// Retrieves first TerminalNode corresponding to token SOURCECOLUMNINDEX__
/// Returns `None` if there is no child corresponding to token SOURCECOLUMNINDEX__
fn SOURCECOLUMNINDEX__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SOURCECOLUMNINDEX__, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_ITEM_INDEX
/// Returns `None` if there is no child corresponding to token WITH_ITEM_INDEX
fn WITH_ITEM_INDEX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_ITEM_INDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_MATCH_ID
/// Returns `None` if there is no child corresponding to token WITH_MATCH_ID
fn WITH_MATCH_ID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_MATCH_ID, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_STEP_NAME
/// Returns `None` if there is no child corresponding to token WITH_STEP_NAME
fn WITH_STEP_NAME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_STEP_NAME, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHSOURCE
/// Returns `None` if there is no child corresponding to token WITHSOURCE
fn WITHSOURCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITHSOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_SOURCE
/// Returns `None` if there is no child corresponding to token WITH_SOURCE
fn WITH_SOURCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_SOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHNOSOURCE__
/// Returns `None` if there is no child corresponding to token WITHNOSOURCE__
fn WITHNOSOURCE__(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITHNOSOURCE__, 0)
}
fn identifierOrKeywordName(&self) -> Option<Rc<IdentifierOrKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn literalExpression(&self) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RelaxedQueryOperatorParameterContextAttrs<'input> for RelaxedQueryOperatorParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relaxedQueryOperatorParameter(&mut self,)
	-> Result<Rc<RelaxedQueryOperatorParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelaxedQueryOperatorParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 368, RULE_relaxedQueryOperatorParameter);
        let mut _localctx: Rc<RelaxedQueryOperatorParameterContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2171);
			 cast_mut::<_,RelaxedQueryOperatorParameterContext >(&mut _localctx).NameToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,RelaxedQueryOperatorParameterContext >(&mut _localctx).NameToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2172);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2175);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					{
					/*InvokeRule identifierOrKeywordName*/
					recog.base.set_state(2173);
					let tmp = recog.identifierOrKeywordName()?;
					 cast_mut::<_,RelaxedQueryOperatorParameterContext >(&mut _localctx).NameValue = Some(tmp.clone());
					  

					}
				}

			 DASH | PLUS | DYNAMIC | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL |
			 STRINGLITERAL | BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL |
			 TYPELITERAL | GUIDLITERAL 
				=> {
					{
					/*InvokeRule literalExpression*/
					recog.base.set_state(2174);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,RelaxedQueryOperatorParameterContext >(&mut _localctx).LiteralValue = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- queryOperatorProperty ----------------
pub type QueryOperatorPropertyContextAll<'input> = QueryOperatorPropertyContext<'input>;


pub type QueryOperatorPropertyContext<'input> = BaseParserRuleContext<'input,QueryOperatorPropertyContextExt<'input>>;

#[derive(Clone)]
pub struct QueryOperatorPropertyContextExt<'input>{
	pub Name: Option<TokenType<'input>>,
	pub NameValue: Option<Rc<IdentifierOrKeywordNameContextAll<'input>>>,
	pub LiteralValue: Option<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for QueryOperatorPropertyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for QueryOperatorPropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_queryOperatorProperty(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_queryOperatorProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for QueryOperatorPropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_queryOperatorProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for QueryOperatorPropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_queryOperatorProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_queryOperatorProperty }
}
antlr_rust::tid!{QueryOperatorPropertyContextExt<'a>}

impl<'input> QueryOperatorPropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<QueryOperatorPropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,QueryOperatorPropertyContextExt{
				Name: None, 
				NameValue: None, LiteralValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait QueryOperatorPropertyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<QueryOperatorPropertyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}
fn identifierOrKeywordName(&self) -> Option<Rc<IdentifierOrKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn literalExpression(&self) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> QueryOperatorPropertyContextAttrs<'input> for QueryOperatorPropertyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn queryOperatorProperty(&mut self,)
	-> Result<Rc<QueryOperatorPropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = QueryOperatorPropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 370, RULE_queryOperatorProperty);
        let mut _localctx: Rc<QueryOperatorPropertyContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2177);
			let tmp = recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;
			 cast_mut::<_,QueryOperatorPropertyContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2178);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2181);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					{
					/*InvokeRule identifierOrKeywordName*/
					recog.base.set_state(2179);
					let tmp = recog.identifierOrKeywordName()?;
					 cast_mut::<_,QueryOperatorPropertyContext >(&mut _localctx).NameValue = Some(tmp.clone());
					  

					}
				}

			 DASH | PLUS | DYNAMIC | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL |
			 STRINGLITERAL | BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL |
			 TYPELITERAL | GUIDLITERAL 
				=> {
					{
					/*InvokeRule literalExpression*/
					recog.base.set_state(2180);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,QueryOperatorPropertyContext >(&mut _localctx).LiteralValue = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpression ----------------
pub type NamedExpressionContextAll<'input> = NamedExpressionContext<'input>;


pub type NamedExpressionContext<'input> = BaseParserRuleContext<'input,NamedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionContextExt<'input>{
	pub Name: Option<Rc<NamedExpressionNameClauseContextAll<'input>>>,
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NamedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_namedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_namedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpression }
}
antlr_rust::tid!{NamedExpressionContextExt<'a>}

impl<'input> NamedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionContextExt{
				Name: None, Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NamedExpressionContextExt<'input>>{

fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn namedExpressionNameClause(&self) -> Option<Rc<NamedExpressionNameClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedExpressionContextAttrs<'input> for NamedExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpression(&mut self,)
	-> Result<Rc<NamedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 372, RULE_namedExpression);
        let mut _localctx: Rc<NamedExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2184);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(188,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule namedExpressionNameClause*/
					recog.base.set_state(2183);
					let tmp = recog.namedExpressionNameClause()?;
					 cast_mut::<_,NamedExpressionContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2186);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,NamedExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpressionNameClause ----------------
pub type NamedExpressionNameClauseContextAll<'input> = NamedExpressionNameClauseContext<'input>;


pub type NamedExpressionNameClauseContext<'input> = BaseParserRuleContext<'input,NamedExpressionNameClauseContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionNameClauseContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>>,
	pub NameList: Option<Rc<NamedExpressionNameListContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NamedExpressionNameClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NamedExpressionNameClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpressionNameClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_namedExpressionNameClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NamedExpressionNameClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_namedExpressionNameClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionNameClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpressionNameClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpressionNameClause }
}
antlr_rust::tid!{NamedExpressionNameClauseContextExt<'a>}

impl<'input> NamedExpressionNameClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionNameClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionNameClauseContextExt{
				Name: None, NameList: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionNameClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NamedExpressionNameClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn identifierOrExtendedKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn namedExpressionNameList(&self) -> Option<Rc<NamedExpressionNameListContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NamedExpressionNameClauseContextAttrs<'input> for NamedExpressionNameClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpressionNameClause(&mut self,)
	-> Result<Rc<NamedExpressionNameClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionNameClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 374, RULE_namedExpressionNameClause);
        let mut _localctx: Rc<NamedExpressionNameClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2190);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 OPENBRACKET | ACCESS | ACCUMULATE | AGGREGATIONS | ALIAS | ALL | AS |
			 AXES | BASE | BIN | BY | CLUSTER | CONSUME | CONTAINS | COUNT | DATABASE |
			 DATATABLE | DECLARE | DEFAULT | DELTA | DISTINCT | EDGES | EVALUATE |
			 EXECUTE | EXTEND | EXTERNALDATA | FACET | FILTER | FIND | FORK | FROM |
			 HAS | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | IN | INTO | INVOKE |
			 LEGEND | LET | LIMIT | LINEAR | LIST | LOOKUP | LOG | MAP | MATERIALIZE |
			 NODES | NONE | NULL | NULLS | OF | ON | OPTIONAL | OUTPUT | PACK | PARSE |
			 PARTITION | PARTITIONBY | PATTERN | PLUGIN | PRINT | QUERYPARAMETERS |
			 RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SAMPLE | SAMPLE_DISTINCT |
			 SCAN | SEARCH | SERIALIZE | SERIES | SET | SORT | STACKED | STACKED100 |
			 STEP | SUMMARIZE | TAKE | THRESHOLD | TITLE | TO | TOP | TOP_HITTERS |
			 TOP_NESTED | TOSCALAR | TOTABLE | TYPEOF | UNSTACKED | UUID | VIEW |
			 VISIBLE | WHERE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					{
					/*InvokeRule identifierOrExtendedKeywordOrEscapedName*/
					recog.base.set_state(2188);
					let tmp = recog.identifierOrExtendedKeywordOrEscapedName()?;
					 cast_mut::<_,NamedExpressionNameClauseContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					}
				}

			 OPENPAREN 
				=> {
					{
					/*InvokeRule namedExpressionNameList*/
					recog.base.set_state(2189);
					let tmp = recog.namedExpressionNameList()?;
					 cast_mut::<_,NamedExpressionNameClauseContext >(&mut _localctx).NameList = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			recog.base.set_state(2192);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedExpressionNameList ----------------
pub type NamedExpressionNameListContextAll<'input> = NamedExpressionNameListContext<'input>;


pub type NamedExpressionNameListContext<'input> = BaseParserRuleContext<'input,NamedExpressionNameListContextExt<'input>>;

#[derive(Clone)]
pub struct NamedExpressionNameListContextExt<'input>{
	pub identifierOrExtendedKeywordOrEscapedName: Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>>,
	pub Names:Vec<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NamedExpressionNameListContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NamedExpressionNameListContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedExpressionNameList(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_namedExpressionNameList(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NamedExpressionNameListContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_namedExpressionNameList(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedExpressionNameListContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedExpressionNameList }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedExpressionNameList }
}
antlr_rust::tid!{NamedExpressionNameListContextExt<'a>}

impl<'input> NamedExpressionNameListContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedExpressionNameListContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedExpressionNameListContextExt{
				identifierOrExtendedKeywordOrEscapedName: None, 
				Names: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedExpressionNameListContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NamedExpressionNameListContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn identifierOrExtendedKeywordOrEscapedName_all(&self) ->  Vec<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn identifierOrExtendedKeywordOrEscapedName(&self, i: usize) -> Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NamedExpressionNameListContextAttrs<'input> for NamedExpressionNameListContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedExpressionNameList(&mut self,)
	-> Result<Rc<NamedExpressionNameListContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedExpressionNameListContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 376, RULE_namedExpressionNameList);
        let mut _localctx: Rc<NamedExpressionNameListContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2194);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule identifierOrExtendedKeywordOrEscapedName*/
			recog.base.set_state(2195);
			let tmp = recog.identifierOrExtendedKeywordOrEscapedName()?;
			 cast_mut::<_,NamedExpressionNameListContext >(&mut _localctx).identifierOrExtendedKeywordOrEscapedName = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,NamedExpressionNameListContext >(&mut _localctx).identifierOrExtendedKeywordOrEscapedName.clone().unwrap()
			 ;
			 cast_mut::<_,NamedExpressionNameListContext >(&mut _localctx).Names.push(temp);
			  
			recog.base.set_state(2200);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2196);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule identifierOrExtendedKeywordOrEscapedName*/
				recog.base.set_state(2197);
				let tmp = recog.identifierOrExtendedKeywordOrEscapedName()?;
				 cast_mut::<_,NamedExpressionNameListContext >(&mut _localctx).identifierOrExtendedKeywordOrEscapedName = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,NamedExpressionNameListContext >(&mut _localctx).identifierOrExtendedKeywordOrEscapedName.clone().unwrap()
				 ;
				 cast_mut::<_,NamedExpressionNameListContext >(&mut _localctx).Names.push(temp);
				  
				}
				}
				recog.base.set_state(2202);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2203);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scopedFunctionCallExpression ----------------
pub type ScopedFunctionCallExpressionContextAll<'input> = ScopedFunctionCallExpressionContext<'input>;


pub type ScopedFunctionCallExpressionContext<'input> = BaseParserRuleContext<'input,ScopedFunctionCallExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ScopedFunctionCallExpressionContextExt<'input>{
	pub Scope: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub FunctionCall: Option<Rc<FunctionCallExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScopedFunctionCallExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScopedFunctionCallExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scopedFunctionCallExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scopedFunctionCallExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScopedFunctionCallExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scopedFunctionCallExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScopedFunctionCallExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scopedFunctionCallExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scopedFunctionCallExpression }
}
antlr_rust::tid!{ScopedFunctionCallExpressionContextExt<'a>}

impl<'input> ScopedFunctionCallExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScopedFunctionCallExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScopedFunctionCallExpressionContextExt{
				Scope: None, FunctionCall: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScopedFunctionCallExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScopedFunctionCallExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionCallExpression(&self) -> Option<Rc<FunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ScopedFunctionCallExpressionContextAttrs<'input> for ScopedFunctionCallExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scopedFunctionCallExpression(&mut self,)
	-> Result<Rc<ScopedFunctionCallExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScopedFunctionCallExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 378, RULE_scopedFunctionCallExpression);
        let mut _localctx: Rc<ScopedFunctionCallExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule simpleNameReference*/
			recog.base.set_state(2205);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,ScopedFunctionCallExpressionContext >(&mut _localctx).Scope = Some(tmp.clone());
			  

			recog.base.set_state(2206);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule functionCallExpression*/
			recog.base.set_state(2207);
			let tmp = recog.functionCallExpression()?;
			 cast_mut::<_,ScopedFunctionCallExpressionContext >(&mut _localctx).FunctionCall = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unnamedExpression ----------------
pub type UnnamedExpressionContextAll<'input> = UnnamedExpressionContext<'input>;


pub type UnnamedExpressionContext<'input> = BaseParserRuleContext<'input,UnnamedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct UnnamedExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for UnnamedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for UnnamedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unnamedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_unnamedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for UnnamedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_unnamedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnnamedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unnamedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unnamedExpression }
}
antlr_rust::tid!{UnnamedExpressionContextExt<'a>}

impl<'input> UnnamedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnnamedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnnamedExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait UnnamedExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<UnnamedExpressionContextExt<'input>>{

fn logicalOrExpression(&self) -> Option<Rc<LogicalOrExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnnamedExpressionContextAttrs<'input> for UnnamedExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unnamedExpression(&mut self,)
	-> Result<Rc<UnnamedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnnamedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 380, RULE_unnamedExpression);
        let mut _localctx: Rc<UnnamedExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule logicalOrExpression*/
			recog.base.set_state(2209);
			recog.logicalOrExpression()?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- logicalOrExpression ----------------
pub type LogicalOrExpressionContextAll<'input> = LogicalOrExpressionContext<'input>;


pub type LogicalOrExpressionContext<'input> = BaseParserRuleContext<'input,LogicalOrExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct LogicalOrExpressionContextExt<'input>{
	pub Left: Option<Rc<LogicalAndExpressionContextAll<'input>>>,
	pub logicalOrOperation: Option<Rc<LogicalOrOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<LogicalOrOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LogicalOrExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LogicalOrExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_logicalOrExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_logicalOrExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LogicalOrExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_logicalOrExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalOrExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_logicalOrExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_logicalOrExpression }
}
antlr_rust::tid!{LogicalOrExpressionContextExt<'a>}

impl<'input> LogicalOrExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LogicalOrExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LogicalOrExpressionContextExt{
				Left: None, logicalOrOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LogicalOrExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LogicalOrExpressionContextExt<'input>>{

fn logicalAndExpression(&self) -> Option<Rc<LogicalAndExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn logicalOrOperation_all(&self) ->  Vec<Rc<LogicalOrOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn logicalOrOperation(&self, i: usize) -> Option<Rc<LogicalOrOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> LogicalOrExpressionContextAttrs<'input> for LogicalOrExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn logicalOrExpression(&mut self,)
	-> Result<Rc<LogicalOrExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LogicalOrExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 382, RULE_logicalOrExpression);
        let mut _localctx: Rc<LogicalOrExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule logicalAndExpression*/
			recog.base.set_state(2211);
			let tmp = recog.logicalAndExpression()?;
			 cast_mut::<_,LogicalOrExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2215);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==OR {
				{
				{
				/*InvokeRule logicalOrOperation*/
				recog.base.set_state(2212);
				let tmp = recog.logicalOrOperation()?;
				 cast_mut::<_,LogicalOrExpressionContext >(&mut _localctx).logicalOrOperation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,LogicalOrExpressionContext >(&mut _localctx).logicalOrOperation.clone().unwrap()
				 ;
				 cast_mut::<_,LogicalOrExpressionContext >(&mut _localctx).Operations.push(temp);
				  
				}
				}
				recog.base.set_state(2217);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- logicalOrOperation ----------------
pub type LogicalOrOperationContextAll<'input> = LogicalOrOperationContext<'input>;


pub type LogicalOrOperationContext<'input> = BaseParserRuleContext<'input,LogicalOrOperationContextExt<'input>>;

#[derive(Clone)]
pub struct LogicalOrOperationContextExt<'input>{
	pub Right: Option<Rc<LogicalAndExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LogicalOrOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LogicalOrOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_logicalOrOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_logicalOrOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LogicalOrOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_logicalOrOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalOrOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_logicalOrOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_logicalOrOperation }
}
antlr_rust::tid!{LogicalOrOperationContextExt<'a>}

impl<'input> LogicalOrOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LogicalOrOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LogicalOrOperationContextExt{
				Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LogicalOrOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LogicalOrOperationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OR
/// Returns `None` if there is no child corresponding to token OR
fn OR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OR, 0)
}
fn logicalAndExpression(&self) -> Option<Rc<LogicalAndExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LogicalOrOperationContextAttrs<'input> for LogicalOrOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn logicalOrOperation(&mut self,)
	-> Result<Rc<LogicalOrOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LogicalOrOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 384, RULE_logicalOrOperation);
        let mut _localctx: Rc<LogicalOrOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2218);
			recog.base.match_token(OR,&mut recog.err_handler)?;

			/*InvokeRule logicalAndExpression*/
			recog.base.set_state(2219);
			let tmp = recog.logicalAndExpression()?;
			 cast_mut::<_,LogicalOrOperationContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- logicalAndExpression ----------------
pub type LogicalAndExpressionContextAll<'input> = LogicalAndExpressionContext<'input>;


pub type LogicalAndExpressionContext<'input> = BaseParserRuleContext<'input,LogicalAndExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct LogicalAndExpressionContextExt<'input>{
	pub Left: Option<Rc<EqualityExpressionContextAll<'input>>>,
	pub logicalAndOperation: Option<Rc<LogicalAndOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<LogicalAndOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LogicalAndExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LogicalAndExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_logicalAndExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_logicalAndExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LogicalAndExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_logicalAndExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalAndExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_logicalAndExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_logicalAndExpression }
}
antlr_rust::tid!{LogicalAndExpressionContextExt<'a>}

impl<'input> LogicalAndExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LogicalAndExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LogicalAndExpressionContextExt{
				Left: None, logicalAndOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait LogicalAndExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LogicalAndExpressionContextExt<'input>>{

fn equalityExpression(&self) -> Option<Rc<EqualityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn logicalAndOperation_all(&self) ->  Vec<Rc<LogicalAndOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn logicalAndOperation(&self, i: usize) -> Option<Rc<LogicalAndOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> LogicalAndExpressionContextAttrs<'input> for LogicalAndExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn logicalAndExpression(&mut self,)
	-> Result<Rc<LogicalAndExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LogicalAndExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 386, RULE_logicalAndExpression);
        let mut _localctx: Rc<LogicalAndExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule equalityExpression*/
			recog.base.set_state(2221);
			let tmp = recog.equalityExpression()?;
			 cast_mut::<_,LogicalAndExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2225);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==AND {
				{
				{
				/*InvokeRule logicalAndOperation*/
				recog.base.set_state(2222);
				let tmp = recog.logicalAndOperation()?;
				 cast_mut::<_,LogicalAndExpressionContext >(&mut _localctx).logicalAndOperation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,LogicalAndExpressionContext >(&mut _localctx).logicalAndOperation.clone().unwrap()
				 ;
				 cast_mut::<_,LogicalAndExpressionContext >(&mut _localctx).Operations.push(temp);
				  
				}
				}
				recog.base.set_state(2227);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- logicalAndOperation ----------------
pub type LogicalAndOperationContextAll<'input> = LogicalAndOperationContext<'input>;


pub type LogicalAndOperationContext<'input> = BaseParserRuleContext<'input,LogicalAndOperationContextExt<'input>>;

#[derive(Clone)]
pub struct LogicalAndOperationContextExt<'input>{
	pub Right: Option<Rc<EqualityExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LogicalAndOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LogicalAndOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_logicalAndOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_logicalAndOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LogicalAndOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_logicalAndOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for LogicalAndOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_logicalAndOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_logicalAndOperation }
}
antlr_rust::tid!{LogicalAndOperationContextExt<'a>}

impl<'input> LogicalAndOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LogicalAndOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LogicalAndOperationContextExt{
				Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LogicalAndOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LogicalAndOperationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AND
/// Returns `None` if there is no child corresponding to token AND
fn AND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AND, 0)
}
fn equalityExpression(&self) -> Option<Rc<EqualityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LogicalAndOperationContextAttrs<'input> for LogicalAndOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn logicalAndOperation(&mut self,)
	-> Result<Rc<LogicalAndOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LogicalAndOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 388, RULE_logicalAndOperation);
        let mut _localctx: Rc<LogicalAndOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2228);
			recog.base.match_token(AND,&mut recog.err_handler)?;

			/*InvokeRule equalityExpression*/
			recog.base.set_state(2229);
			let tmp = recog.equalityExpression()?;
			 cast_mut::<_,LogicalAndOperationContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- equalityExpression ----------------
pub type EqualityExpressionContextAll<'input> = EqualityExpressionContext<'input>;


pub type EqualityExpressionContext<'input> = BaseParserRuleContext<'input,EqualityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct EqualityExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EqualityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EqualityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_equalityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_equalityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EqualityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_equalityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for EqualityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_equalityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_equalityExpression }
}
antlr_rust::tid!{EqualityExpressionContextExt<'a>}

impl<'input> EqualityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EqualityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EqualityExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EqualityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EqualityExpressionContextExt<'input>>{

fn relationalExpression(&self) -> Option<Rc<RelationalExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn equalsEqualityExpression(&self) -> Option<Rc<EqualsEqualityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn listEqualityExpression(&self) -> Option<Rc<ListEqualityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn betweenEqualityExpression(&self) -> Option<Rc<BetweenEqualityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn starEqualityExpression(&self) -> Option<Rc<StarEqualityExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EqualityExpressionContextAttrs<'input> for EqualityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn equalityExpression(&mut self,)
	-> Result<Rc<EqualityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EqualityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 390, RULE_equalityExpression);
        let mut _localctx: Rc<EqualityExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2236);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(193,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule relationalExpression*/
					recog.base.set_state(2231);
					recog.relationalExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule equalsEqualityExpression*/
					recog.base.set_state(2232);
					recog.equalsEqualityExpression()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule listEqualityExpression*/
					recog.base.set_state(2233);
					recog.listEqualityExpression()?;

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule betweenEqualityExpression*/
					recog.base.set_state(2234);
					recog.betweenEqualityExpression()?;

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule starEqualityExpression*/
					recog.base.set_state(2235);
					recog.starEqualityExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- equalsEqualityExpression ----------------
pub type EqualsEqualityExpressionContextAll<'input> = EqualsEqualityExpressionContext<'input>;


pub type EqualsEqualityExpressionContext<'input> = BaseParserRuleContext<'input,EqualsEqualityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct EqualsEqualityExpressionContextExt<'input>{
	pub Left: Option<Rc<RelationalExpressionContextAll<'input>>>,
	pub OperatorToken: Option<TokenType<'input>>,
	pub Right: Option<Rc<RelationalExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EqualsEqualityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EqualsEqualityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_equalsEqualityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_equalsEqualityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EqualsEqualityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_equalsEqualityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for EqualsEqualityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_equalsEqualityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_equalsEqualityExpression }
}
antlr_rust::tid!{EqualsEqualityExpressionContextExt<'a>}

impl<'input> EqualsEqualityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EqualsEqualityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EqualsEqualityExpressionContextExt{
				OperatorToken: None, 
				Left: None, Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EqualsEqualityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EqualsEqualityExpressionContextExt<'input>>{

fn relationalExpression_all(&self) ->  Vec<Rc<RelationalExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relationalExpression(&self, i: usize) -> Option<Rc<RelationalExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token EQUALEQUAL
/// Returns `None` if there is no child corresponding to token EQUALEQUAL
fn EQUALEQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUALEQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN_GREATERTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN_GREATERTHAN
fn LESSTHAN_GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN_GREATERTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLAIMATIONPOINT_EQUAL
/// Returns `None` if there is no child corresponding to token EXCLAIMATIONPOINT_EQUAL
fn EXCLAIMATIONPOINT_EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXCLAIMATIONPOINT_EQUAL, 0)
}

}

impl<'input> EqualsEqualityExpressionContextAttrs<'input> for EqualsEqualityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn equalsEqualityExpression(&mut self,)
	-> Result<Rc<EqualsEqualityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EqualsEqualityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 392, RULE_equalsEqualityExpression);
        let mut _localctx: Rc<EqualsEqualityExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule relationalExpression*/
			recog.base.set_state(2238);
			let tmp = recog.relationalExpression()?;
			 cast_mut::<_,EqualsEqualityExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2239);
			 cast_mut::<_,EqualsEqualityExpressionContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << EQUALEQUAL) | (1usize << EXCLAIMATIONPOINT_EQUAL) | (1usize << LESSTHAN_GREATERTHAN))) != 0)) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,EqualsEqualityExpressionContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule relationalExpression*/
			recog.base.set_state(2240);
			let tmp = recog.relationalExpression()?;
			 cast_mut::<_,EqualsEqualityExpressionContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- listEqualityExpression ----------------
pub type ListEqualityExpressionContextAll<'input> = ListEqualityExpressionContext<'input>;


pub type ListEqualityExpressionContext<'input> = BaseParserRuleContext<'input,ListEqualityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ListEqualityExpressionContextExt<'input>{
	pub Left: Option<Rc<RelationalExpressionContextAll<'input>>>,
	pub OperatorToken: Option<TokenType<'input>>,
	pub invocationExpression: Option<Rc<InvocationExpressionContextAll<'input>>>,
	pub Expressions:Vec<Rc<InvocationExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ListEqualityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ListEqualityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_listEqualityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_listEqualityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ListEqualityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_listEqualityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ListEqualityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_listEqualityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_listEqualityExpression }
}
antlr_rust::tid!{ListEqualityExpressionContextExt<'a>}

impl<'input> ListEqualityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ListEqualityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ListEqualityExpressionContextExt{
				OperatorToken: None, 
				Left: None, invocationExpression: None, 
				Expressions: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ListEqualityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ListEqualityExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn relationalExpression(&self) -> Option<Rc<RelationalExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn invocationExpression_all(&self) ->  Vec<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn invocationExpression(&self, i: usize) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_IN
/// Returns `None` if there is no child corresponding to token NOT_IN
fn NOT_IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_IN, 0)
}
/// Retrieves first TerminalNode corresponding to token IN_CI
/// Returns `None` if there is no child corresponding to token IN_CI
fn IN_CI(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN_CI, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_IN_CI
/// Returns `None` if there is no child corresponding to token NOT_IN_CI
fn NOT_IN_CI(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_IN_CI, 0)
}
/// Retrieves first TerminalNode corresponding to token HAS_ANY
/// Returns `None` if there is no child corresponding to token HAS_ANY
fn HAS_ANY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HAS_ANY, 0)
}
/// Retrieves first TerminalNode corresponding to token HAS_ALL
/// Returns `None` if there is no child corresponding to token HAS_ALL
fn HAS_ALL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HAS_ALL, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ListEqualityExpressionContextAttrs<'input> for ListEqualityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn listEqualityExpression(&mut self,)
	-> Result<Rc<ListEqualityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ListEqualityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 394, RULE_listEqualityExpression);
        let mut _localctx: Rc<ListEqualityExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule relationalExpression*/
			recog.base.set_state(2242);
			let tmp = recog.relationalExpression()?;
			 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2243);
			 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 105)) & !0x3f) == 0 && ((1usize << (_la - 105)) & ((1usize << (HAS_ALL - 105)) | (1usize << (HAS_ANY - 105)) | (1usize << (IN - 105)) | (1usize << (IN_CI - 105)))) != 0) || _la==NOT_IN || _la==NOT_IN_CI) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2244);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(2245);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).invocationExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).invocationExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).Expressions.push(temp);
			  
			recog.base.set_state(2250);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2246);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule invocationExpression*/
				recog.base.set_state(2247);
				let tmp = recog.invocationExpression()?;
				 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).invocationExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).invocationExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ListEqualityExpressionContext >(&mut _localctx).Expressions.push(temp);
				  
				}
				}
				recog.base.set_state(2252);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2253);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- betweenEqualityExpression ----------------
pub type BetweenEqualityExpressionContextAll<'input> = BetweenEqualityExpressionContext<'input>;


pub type BetweenEqualityExpressionContext<'input> = BaseParserRuleContext<'input,BetweenEqualityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BetweenEqualityExpressionContextExt<'input>{
	pub Left: Option<Rc<RelationalExpressionContextAll<'input>>>,
	pub OperatorToken: Option<TokenType<'input>>,
	pub StartExpression: Option<Rc<InvocationExpressionContextAll<'input>>>,
	pub EndExpression: Option<Rc<InvocationExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for BetweenEqualityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for BetweenEqualityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_betweenEqualityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_betweenEqualityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for BetweenEqualityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_betweenEqualityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for BetweenEqualityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_betweenEqualityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_betweenEqualityExpression }
}
antlr_rust::tid!{BetweenEqualityExpressionContextExt<'a>}

impl<'input> BetweenEqualityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BetweenEqualityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BetweenEqualityExpressionContextExt{
				OperatorToken: None, 
				Left: None, StartExpression: None, EndExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait BetweenEqualityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<BetweenEqualityExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token DOTDOT
/// Returns `None` if there is no child corresponding to token DOTDOT
fn DOTDOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOTDOT, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn relationalExpression(&self) -> Option<Rc<RelationalExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn invocationExpression_all(&self) ->  Vec<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn invocationExpression(&self, i: usize) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token BETWEEN
/// Returns `None` if there is no child corresponding to token BETWEEN
fn BETWEEN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BETWEEN, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_BETWEEN
/// Returns `None` if there is no child corresponding to token NOT_BETWEEN
fn NOT_BETWEEN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_BETWEEN, 0)
}

}

impl<'input> BetweenEqualityExpressionContextAttrs<'input> for BetweenEqualityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn betweenEqualityExpression(&mut self,)
	-> Result<Rc<BetweenEqualityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BetweenEqualityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 396, RULE_betweenEqualityExpression);
        let mut _localctx: Rc<BetweenEqualityExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule relationalExpression*/
			recog.base.set_state(2255);
			let tmp = recog.relationalExpression()?;
			 cast_mut::<_,BetweenEqualityExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2256);
			 cast_mut::<_,BetweenEqualityExpressionContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==BETWEEN || _la==NOT_BETWEEN) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,BetweenEqualityExpressionContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2257);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(2258);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,BetweenEqualityExpressionContext >(&mut _localctx).StartExpression = Some(tmp.clone());
			  

			recog.base.set_state(2259);
			recog.base.match_token(DOTDOT,&mut recog.err_handler)?;

			/*InvokeRule invocationExpression*/
			recog.base.set_state(2260);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,BetweenEqualityExpressionContext >(&mut _localctx).EndExpression = Some(tmp.clone());
			  

			recog.base.set_state(2261);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- starEqualityExpression ----------------
pub type StarEqualityExpressionContextAll<'input> = StarEqualityExpressionContext<'input>;


pub type StarEqualityExpressionContext<'input> = BaseParserRuleContext<'input,StarEqualityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StarEqualityExpressionContextExt<'input>{
	pub Expression: Option<Rc<RelationalExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StarEqualityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StarEqualityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_starEqualityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_starEqualityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StarEqualityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_starEqualityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StarEqualityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_starEqualityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_starEqualityExpression }
}
antlr_rust::tid!{StarEqualityExpressionContextExt<'a>}

impl<'input> StarEqualityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StarEqualityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StarEqualityExpressionContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait StarEqualityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StarEqualityExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUALEQUAL
/// Returns `None` if there is no child corresponding to token EQUALEQUAL
fn EQUALEQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUALEQUAL, 0)
}
fn relationalExpression(&self) -> Option<Rc<RelationalExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StarEqualityExpressionContextAttrs<'input> for StarEqualityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn starEqualityExpression(&mut self,)
	-> Result<Rc<StarEqualityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StarEqualityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 398, RULE_starEqualityExpression);
        let mut _localctx: Rc<StarEqualityExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2263);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			recog.base.set_state(2264);
			recog.base.match_token(EQUALEQUAL,&mut recog.err_handler)?;

			/*InvokeRule relationalExpression*/
			recog.base.set_state(2265);
			let tmp = recog.relationalExpression()?;
			 cast_mut::<_,StarEqualityExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- relationalExpression ----------------
pub type RelationalExpressionContextAll<'input> = RelationalExpressionContext<'input>;


pub type RelationalExpressionContext<'input> = BaseParserRuleContext<'input,RelationalExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct RelationalExpressionContextExt<'input>{
	pub Left: Option<Rc<AdditiveExpressionContextAll<'input>>>,
	pub OperatorToken: Option<TokenType<'input>>,
	pub Right: Option<Rc<AdditiveExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RelationalExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RelationalExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_relationalExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_relationalExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RelationalExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_relationalExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for RelationalExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_relationalExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_relationalExpression }
}
antlr_rust::tid!{RelationalExpressionContextExt<'a>}

impl<'input> RelationalExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RelationalExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RelationalExpressionContextExt{
				OperatorToken: None, 
				Left: None, Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RelationalExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RelationalExpressionContextExt<'input>>{

fn additiveExpression_all(&self) ->  Vec<Rc<AdditiveExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn additiveExpression(&self, i: usize) -> Option<Rc<AdditiveExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN
/// Returns `None` if there is no child corresponding to token LESSTHAN
fn LESSTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN
/// Returns `None` if there is no child corresponding to token GREATERTHAN
fn GREATERTHAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN, 0)
}
/// Retrieves first TerminalNode corresponding to token LESSTHAN_EQUAL
/// Returns `None` if there is no child corresponding to token LESSTHAN_EQUAL
fn LESSTHAN_EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LESSTHAN_EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token GREATERTHAN_EQUAL
/// Returns `None` if there is no child corresponding to token GREATERTHAN_EQUAL
fn GREATERTHAN_EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GREATERTHAN_EQUAL, 0)
}

}

impl<'input> RelationalExpressionContextAttrs<'input> for RelationalExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn relationalExpression(&mut self,)
	-> Result<Rc<RelationalExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RelationalExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 400, RULE_relationalExpression);
        let mut _localctx: Rc<RelationalExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule additiveExpression*/
			recog.base.set_state(2267);
			let tmp = recog.additiveExpression()?;
			 cast_mut::<_,RelationalExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2270);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << GREATERTHAN) | (1usize << GREATERTHAN_EQUAL) | (1usize << LESSTHAN) | (1usize << LESSTHAN_EQUAL))) != 0) {
				{
				recog.base.set_state(2268);
				 cast_mut::<_,RelationalExpressionContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !((((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << GREATERTHAN) | (1usize << GREATERTHAN_EQUAL) | (1usize << LESSTHAN) | (1usize << LESSTHAN_EQUAL))) != 0)) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,RelationalExpressionContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				/*InvokeRule additiveExpression*/
				recog.base.set_state(2269);
				let tmp = recog.additiveExpression()?;
				 cast_mut::<_,RelationalExpressionContext >(&mut _localctx).Right = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- additiveExpression ----------------
pub type AdditiveExpressionContextAll<'input> = AdditiveExpressionContext<'input>;


pub type AdditiveExpressionContext<'input> = BaseParserRuleContext<'input,AdditiveExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct AdditiveExpressionContextExt<'input>{
	pub Left: Option<Rc<MultiplicativeExpressionContextAll<'input>>>,
	pub additiveOperation: Option<Rc<AdditiveOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<AdditiveOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AdditiveExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AdditiveExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_additiveExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_additiveExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AdditiveExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_additiveExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for AdditiveExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_additiveExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_additiveExpression }
}
antlr_rust::tid!{AdditiveExpressionContextExt<'a>}

impl<'input> AdditiveExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AdditiveExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AdditiveExpressionContextExt{
				Left: None, additiveOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait AdditiveExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AdditiveExpressionContextExt<'input>>{

fn multiplicativeExpression(&self) -> Option<Rc<MultiplicativeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn additiveOperation_all(&self) ->  Vec<Rc<AdditiveOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn additiveOperation(&self, i: usize) -> Option<Rc<AdditiveOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> AdditiveExpressionContextAttrs<'input> for AdditiveExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn additiveExpression(&mut self,)
	-> Result<Rc<AdditiveExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AdditiveExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 402, RULE_additiveExpression);
        let mut _localctx: Rc<AdditiveExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule multiplicativeExpression*/
			recog.base.set_state(2272);
			let tmp = recog.multiplicativeExpression()?;
			 cast_mut::<_,AdditiveExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2276);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==DASH || _la==PLUS {
				{
				{
				/*InvokeRule additiveOperation*/
				recog.base.set_state(2273);
				let tmp = recog.additiveOperation()?;
				 cast_mut::<_,AdditiveExpressionContext >(&mut _localctx).additiveOperation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,AdditiveExpressionContext >(&mut _localctx).additiveOperation.clone().unwrap()
				 ;
				 cast_mut::<_,AdditiveExpressionContext >(&mut _localctx).Operations.push(temp);
				  
				}
				}
				recog.base.set_state(2278);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- additiveOperation ----------------
pub type AdditiveOperationContextAll<'input> = AdditiveOperationContext<'input>;


pub type AdditiveOperationContext<'input> = BaseParserRuleContext<'input,AdditiveOperationContextExt<'input>>;

#[derive(Clone)]
pub struct AdditiveOperationContextExt<'input>{
	pub OperatorToken: Option<TokenType<'input>>,
	pub Right: Option<Rc<MultiplicativeExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AdditiveOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AdditiveOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_additiveOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_additiveOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AdditiveOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_additiveOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for AdditiveOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_additiveOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_additiveOperation }
}
antlr_rust::tid!{AdditiveOperationContextExt<'a>}

impl<'input> AdditiveOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AdditiveOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AdditiveOperationContextExt{
				OperatorToken: None, 
				Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AdditiveOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AdditiveOperationContextExt<'input>>{

fn multiplicativeExpression(&self) -> Option<Rc<MultiplicativeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token DASH
/// Returns `None` if there is no child corresponding to token DASH
fn DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH, 0)
}

}

impl<'input> AdditiveOperationContextAttrs<'input> for AdditiveOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn additiveOperation(&mut self,)
	-> Result<Rc<AdditiveOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AdditiveOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 404, RULE_additiveOperation);
        let mut _localctx: Rc<AdditiveOperationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2279);
			 cast_mut::<_,AdditiveOperationContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==DASH || _la==PLUS) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,AdditiveOperationContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule multiplicativeExpression*/
			recog.base.set_state(2280);
			let tmp = recog.multiplicativeExpression()?;
			 cast_mut::<_,AdditiveOperationContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiplicativeExpression ----------------
pub type MultiplicativeExpressionContextAll<'input> = MultiplicativeExpressionContext<'input>;


pub type MultiplicativeExpressionContext<'input> = BaseParserRuleContext<'input,MultiplicativeExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct MultiplicativeExpressionContextExt<'input>{
	pub Left: Option<Rc<StringOperatorExpressionContextAll<'input>>>,
	pub multiplicativeOperation: Option<Rc<MultiplicativeOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<MultiplicativeOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MultiplicativeExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MultiplicativeExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiplicativeExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_multiplicativeExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MultiplicativeExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_multiplicativeExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiplicativeExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiplicativeExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiplicativeExpression }
}
antlr_rust::tid!{MultiplicativeExpressionContextExt<'a>}

impl<'input> MultiplicativeExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiplicativeExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiplicativeExpressionContextExt{
				Left: None, multiplicativeOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiplicativeExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MultiplicativeExpressionContextExt<'input>>{

fn stringOperatorExpression(&self) -> Option<Rc<StringOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn multiplicativeOperation_all(&self) ->  Vec<Rc<MultiplicativeOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn multiplicativeOperation(&self, i: usize) -> Option<Rc<MultiplicativeOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> MultiplicativeExpressionContextAttrs<'input> for MultiplicativeExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiplicativeExpression(&mut self,)
	-> Result<Rc<MultiplicativeExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiplicativeExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 406, RULE_multiplicativeExpression);
        let mut _localctx: Rc<MultiplicativeExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule stringOperatorExpression*/
			recog.base.set_state(2282);
			let tmp = recog.stringOperatorExpression()?;
			 cast_mut::<_,MultiplicativeExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2286);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==ASTERISK || _la==PERCENTSIGN || _la==SLASH {
				{
				{
				/*InvokeRule multiplicativeOperation*/
				recog.base.set_state(2283);
				let tmp = recog.multiplicativeOperation()?;
				 cast_mut::<_,MultiplicativeExpressionContext >(&mut _localctx).multiplicativeOperation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,MultiplicativeExpressionContext >(&mut _localctx).multiplicativeOperation.clone().unwrap()
				 ;
				 cast_mut::<_,MultiplicativeExpressionContext >(&mut _localctx).Operations.push(temp);
				  
				}
				}
				recog.base.set_state(2288);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- multiplicativeOperation ----------------
pub type MultiplicativeOperationContextAll<'input> = MultiplicativeOperationContext<'input>;


pub type MultiplicativeOperationContext<'input> = BaseParserRuleContext<'input,MultiplicativeOperationContextExt<'input>>;

#[derive(Clone)]
pub struct MultiplicativeOperationContextExt<'input>{
	pub OperatorToken: Option<TokenType<'input>>,
	pub Right: Option<Rc<StringOperatorExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MultiplicativeOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MultiplicativeOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_multiplicativeOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_multiplicativeOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MultiplicativeOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_multiplicativeOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for MultiplicativeOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_multiplicativeOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_multiplicativeOperation }
}
antlr_rust::tid!{MultiplicativeOperationContextExt<'a>}

impl<'input> MultiplicativeOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MultiplicativeOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MultiplicativeOperationContextExt{
				OperatorToken: None, 
				Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MultiplicativeOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MultiplicativeOperationContextExt<'input>>{

fn stringOperatorExpression(&self) -> Option<Rc<StringOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
/// Retrieves first TerminalNode corresponding to token SLASH
/// Returns `None` if there is no child corresponding to token SLASH
fn SLASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SLASH, 0)
}
/// Retrieves first TerminalNode corresponding to token PERCENTSIGN
/// Returns `None` if there is no child corresponding to token PERCENTSIGN
fn PERCENTSIGN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PERCENTSIGN, 0)
}

}

impl<'input> MultiplicativeOperationContextAttrs<'input> for MultiplicativeOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn multiplicativeOperation(&mut self,)
	-> Result<Rc<MultiplicativeOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MultiplicativeOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 408, RULE_multiplicativeOperation);
        let mut _localctx: Rc<MultiplicativeOperationContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2289);
			 cast_mut::<_,MultiplicativeOperationContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==ASTERISK || _la==PERCENTSIGN || _la==SLASH) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,MultiplicativeOperationContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			/*InvokeRule stringOperatorExpression*/
			recog.base.set_state(2290);
			let tmp = recog.stringOperatorExpression()?;
			 cast_mut::<_,MultiplicativeOperationContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringOperatorExpression ----------------
pub type StringOperatorExpressionContextAll<'input> = StringOperatorExpressionContext<'input>;


pub type StringOperatorExpressionContext<'input> = BaseParserRuleContext<'input,StringOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StringOperatorExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StringOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StringOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_stringOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StringOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_stringOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringOperatorExpression }
}
antlr_rust::tid!{StringOperatorExpressionContextExt<'a>}

impl<'input> StringOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringOperatorExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StringOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StringOperatorExpressionContextExt<'input>>{

fn stringBinaryOperatorExpression(&self) -> Option<Rc<StringBinaryOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringStarOperatorExpression(&self) -> Option<Rc<StringStarOperatorExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StringOperatorExpressionContextAttrs<'input> for StringOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringOperatorExpression(&mut self,)
	-> Result<Rc<StringOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 410, RULE_stringOperatorExpression);
        let mut _localctx: Rc<StringOperatorExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2294);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DASH | OPENBRACKET | OPENPAREN | PLUS | ACCESS | AGGREGATIONS | ALIAS |
			 ALL | AXES | BASE | BIN | CLUSTER | CONTEXTUAL_DATATABLE | COUNT | DATABASE |
			 DATATABLE | DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE |
			 EXTERNALDATA | EXTERNAL_DATA | FACET | FORK | FROM | HIDDEN_ | HOT |
			 HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET | LINEAR | LIST | LOOKUP |
			 LOG | MAP | MATERIALIZED_VIEW_COMBINE | NODES | NONE | NULL | NULLS |
			 ON | OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TOSCALAR | TOTABLE | TYPEOF |
			 UNSTACKED | UUID | VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN |
			 XTITLE | YAXIS | YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | DYNAMIC |
			 GUID | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL | STRINGLITERAL |
			 BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL | TYPELITERAL | GUIDLITERAL |
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule stringBinaryOperatorExpression*/
					recog.base.set_state(2292);
					recog.stringBinaryOperatorExpression()?;

					}
				}

			 ASTERISK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule stringStarOperatorExpression*/
					recog.base.set_state(2293);
					recog.stringStarOperatorExpression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringBinaryOperatorExpression ----------------
pub type StringBinaryOperatorExpressionContextAll<'input> = StringBinaryOperatorExpressionContext<'input>;


pub type StringBinaryOperatorExpressionContext<'input> = BaseParserRuleContext<'input,StringBinaryOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StringBinaryOperatorExpressionContextExt<'input>{
	pub Left: Option<Rc<InvocationExpressionContextAll<'input>>>,
	pub stringBinaryOperation: Option<Rc<StringBinaryOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<StringBinaryOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StringBinaryOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StringBinaryOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringBinaryOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_stringBinaryOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StringBinaryOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_stringBinaryOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringBinaryOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringBinaryOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringBinaryOperatorExpression }
}
antlr_rust::tid!{StringBinaryOperatorExpressionContextExt<'a>}

impl<'input> StringBinaryOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringBinaryOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringBinaryOperatorExpressionContextExt{
				Left: None, stringBinaryOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait StringBinaryOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StringBinaryOperatorExpressionContextExt<'input>>{

fn invocationExpression(&self) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringBinaryOperation_all(&self) ->  Vec<Rc<StringBinaryOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn stringBinaryOperation(&self, i: usize) -> Option<Rc<StringBinaryOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> StringBinaryOperatorExpressionContextAttrs<'input> for StringBinaryOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringBinaryOperatorExpression(&mut self,)
	-> Result<Rc<StringBinaryOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringBinaryOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 412, RULE_stringBinaryOperatorExpression);
        let mut _localctx: Rc<StringBinaryOperatorExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule invocationExpression*/
			recog.base.set_state(2296);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,StringBinaryOperatorExpressionContext >(&mut _localctx).Left = Some(tmp.clone());
			  

			recog.base.set_state(2300);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << COLON) | (1usize << EQUALTILDE) | (1usize << EXCLAIMATIONPOINT_TILDE))) != 0) || ((((_la - 62)) & !0x3f) == 0 && ((1usize << (_la - 62)) & ((1usize << (CONTAINS - 62)) | (1usize << (CONTAINSCS - 62)) | (1usize << (CONTAINS_CS - 62)) | (1usize << (ENDSWITH - 62)) | (1usize << (ENDSWITH_CS - 62)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HAS_CS - 104)) | (1usize << (HASPREFIX - 104)) | (1usize << (HASPREFIX_CS - 104)) | (1usize << (HASSUFFIX - 104)) | (1usize << (HASSUFFIX_CS - 104)))) != 0) || ((((_la - 142)) & !0x3f) == 0 && ((1usize << (_la - 142)) & ((1usize << (LIKE - 142)) | (1usize << (LIKECS - 142)) | (1usize << (MATCHES_REGEX - 142)) | (1usize << (NOT_CONTAINS - 142)) | (1usize << (NOT_CONTAINS_CS - 142)) | (1usize << (NOT_ENDSWITH_CS - 142)) | (1usize << (NOT_ENDSWITH - 142)) | (1usize << (NOT_HAS - 142)) | (1usize << (NOT_HAS_CS - 142)) | (1usize << (NOT_HASPREFIX - 142)) | (1usize << (NOT_HASPREFIX_CS - 142)) | (1usize << (NOT_HASSUFFIX - 142)))) != 0) || ((((_la - 174)) & !0x3f) == 0 && ((1usize << (_la - 174)) & ((1usize << (NOT_HASSUFFIX_CS - 174)) | (1usize << (NOT_STARTSWITH - 174)) | (1usize << (NOT_STARTSWITH_CS - 174)) | (1usize << (NOTCONTAINS - 174)) | (1usize << (NOTCONTAINSCS - 174)) | (1usize << (NOTLIKE - 174)) | (1usize << (NOTLIKECS - 174)))) != 0) || _la==STARTSWITH || _la==STARTSWITH_CS {
				{
				{
				/*InvokeRule stringBinaryOperation*/
				recog.base.set_state(2297);
				let tmp = recog.stringBinaryOperation()?;
				 cast_mut::<_,StringBinaryOperatorExpressionContext >(&mut _localctx).stringBinaryOperation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,StringBinaryOperatorExpressionContext >(&mut _localctx).stringBinaryOperation.clone().unwrap()
				 ;
				 cast_mut::<_,StringBinaryOperatorExpressionContext >(&mut _localctx).Operations.push(temp);
				  
				}
				}
				recog.base.set_state(2302);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringBinaryOperation ----------------
pub type StringBinaryOperationContextAll<'input> = StringBinaryOperationContext<'input>;


pub type StringBinaryOperationContext<'input> = BaseParserRuleContext<'input,StringBinaryOperationContextExt<'input>>;

#[derive(Clone)]
pub struct StringBinaryOperationContextExt<'input>{
	pub Operator: Option<Rc<StringBinaryOperatorContextAll<'input>>>,
	pub HasOperator: Option<TokenType<'input>>,
	pub Right: Option<Rc<InvocationExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StringBinaryOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StringBinaryOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringBinaryOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_stringBinaryOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StringBinaryOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_stringBinaryOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringBinaryOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringBinaryOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringBinaryOperation }
}
antlr_rust::tid!{StringBinaryOperationContextExt<'a>}

impl<'input> StringBinaryOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringBinaryOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringBinaryOperationContextExt{
				HasOperator: None, 
				Operator: None, Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait StringBinaryOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StringBinaryOperationContextExt<'input>>{

fn invocationExpression(&self) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringBinaryOperator(&self) -> Option<Rc<StringBinaryOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}

}

impl<'input> StringBinaryOperationContextAttrs<'input> for StringBinaryOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringBinaryOperation(&mut self,)
	-> Result<Rc<StringBinaryOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringBinaryOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 414, RULE_stringBinaryOperation);
        let mut _localctx: Rc<StringBinaryOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2305);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 EQUALTILDE | EXCLAIMATIONPOINT_TILDE | CONTAINS | CONTAINSCS | CONTAINS_CS |
			 ENDSWITH | ENDSWITH_CS | HAS | HAS_CS | HASPREFIX | HASPREFIX_CS | HASSUFFIX |
			 HASSUFFIX_CS | LIKE | LIKECS | MATCHES_REGEX | NOT_CONTAINS | NOT_CONTAINS_CS |
			 NOT_ENDSWITH_CS | NOT_ENDSWITH | NOT_HAS | NOT_HAS_CS | NOT_HASPREFIX |
			 NOT_HASPREFIX_CS | NOT_HASSUFFIX | NOT_HASSUFFIX_CS | NOT_STARTSWITH |
			 NOT_STARTSWITH_CS | NOTCONTAINS | NOTCONTAINSCS | NOTLIKE | NOTLIKECS |
			 STARTSWITH | STARTSWITH_CS 
				=> {
					{
					/*InvokeRule stringBinaryOperator*/
					recog.base.set_state(2303);
					let tmp = recog.stringBinaryOperator()?;
					 cast_mut::<_,StringBinaryOperationContext >(&mut _localctx).Operator = Some(tmp.clone());
					  

					}
				}

			 COLON 
				=> {
					{
					recog.base.set_state(2304);
					let tmp = recog.base.match_token(COLON,&mut recog.err_handler)?;
					 cast_mut::<_,StringBinaryOperationContext >(&mut _localctx).HasOperator = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			/*InvokeRule invocationExpression*/
			recog.base.set_state(2307);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,StringBinaryOperationContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringBinaryOperator ----------------
pub type StringBinaryOperatorContextAll<'input> = StringBinaryOperatorContext<'input>;


pub type StringBinaryOperatorContext<'input> = BaseParserRuleContext<'input,StringBinaryOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct StringBinaryOperatorContextExt<'input>{
	pub OperatorToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StringBinaryOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StringBinaryOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringBinaryOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_stringBinaryOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StringBinaryOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_stringBinaryOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringBinaryOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringBinaryOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringBinaryOperator }
}
antlr_rust::tid!{StringBinaryOperatorContextExt<'a>}

impl<'input> StringBinaryOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringBinaryOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringBinaryOperatorContextExt{
				OperatorToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait StringBinaryOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StringBinaryOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUALTILDE
/// Returns `None` if there is no child corresponding to token EQUALTILDE
fn EQUALTILDE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUALTILDE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXCLAIMATIONPOINT_TILDE
/// Returns `None` if there is no child corresponding to token EXCLAIMATIONPOINT_TILDE
fn EXCLAIMATIONPOINT_TILDE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXCLAIMATIONPOINT_TILDE, 0)
}
/// Retrieves first TerminalNode corresponding to token HAS
/// Returns `None` if there is no child corresponding to token HAS
fn HAS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HAS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_HAS
/// Returns `None` if there is no child corresponding to token NOT_HAS
fn NOT_HAS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_HAS, 0)
}
/// Retrieves first TerminalNode corresponding to token HAS_CS
/// Returns `None` if there is no child corresponding to token HAS_CS
fn HAS_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HAS_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_HAS_CS
/// Returns `None` if there is no child corresponding to token NOT_HAS_CS
fn NOT_HAS_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_HAS_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token HASPREFIX
/// Returns `None` if there is no child corresponding to token HASPREFIX
fn HASPREFIX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HASPREFIX, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_HASPREFIX
/// Returns `None` if there is no child corresponding to token NOT_HASPREFIX
fn NOT_HASPREFIX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_HASPREFIX, 0)
}
/// Retrieves first TerminalNode corresponding to token HASPREFIX_CS
/// Returns `None` if there is no child corresponding to token HASPREFIX_CS
fn HASPREFIX_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HASPREFIX_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_HASPREFIX_CS
/// Returns `None` if there is no child corresponding to token NOT_HASPREFIX_CS
fn NOT_HASPREFIX_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_HASPREFIX_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token HASSUFFIX
/// Returns `None` if there is no child corresponding to token HASSUFFIX
fn HASSUFFIX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HASSUFFIX, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_HASSUFFIX
/// Returns `None` if there is no child corresponding to token NOT_HASSUFFIX
fn NOT_HASSUFFIX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_HASSUFFIX, 0)
}
/// Retrieves first TerminalNode corresponding to token HASSUFFIX_CS
/// Returns `None` if there is no child corresponding to token HASSUFFIX_CS
fn HASSUFFIX_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HASSUFFIX_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_HASSUFFIX_CS
/// Returns `None` if there is no child corresponding to token NOT_HASSUFFIX_CS
fn NOT_HASSUFFIX_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_HASSUFFIX_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKE
/// Returns `None` if there is no child corresponding to token LIKE
fn LIKE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTLIKE
/// Returns `None` if there is no child corresponding to token NOTLIKE
fn NOTLIKE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOTLIKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIKECS
/// Returns `None` if there is no child corresponding to token LIKECS
fn LIKECS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIKECS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTLIKECS
/// Returns `None` if there is no child corresponding to token NOTLIKECS
fn NOTLIKECS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOTLIKECS, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS
/// Returns `None` if there is no child corresponding to token CONTAINS
fn CONTAINS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTCONTAINS
/// Returns `None` if there is no child corresponding to token NOTCONTAINS
fn NOTCONTAINS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOTCONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINSCS
/// Returns `None` if there is no child corresponding to token CONTAINSCS
fn CONTAINSCS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONTAINSCS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOTCONTAINSCS
/// Returns `None` if there is no child corresponding to token NOTCONTAINSCS
fn NOTCONTAINSCS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOTCONTAINSCS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_CONTAINS
/// Returns `None` if there is no child corresponding to token NOT_CONTAINS
fn NOT_CONTAINS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS_CS
/// Returns `None` if there is no child corresponding to token CONTAINS_CS
fn CONTAINS_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_CONTAINS_CS
/// Returns `None` if there is no child corresponding to token NOT_CONTAINS_CS
fn NOT_CONTAINS_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_CONTAINS_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token STARTSWITH
/// Returns `None` if there is no child corresponding to token STARTSWITH
fn STARTSWITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STARTSWITH, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_STARTSWITH
/// Returns `None` if there is no child corresponding to token NOT_STARTSWITH
fn NOT_STARTSWITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_STARTSWITH, 0)
}
/// Retrieves first TerminalNode corresponding to token STARTSWITH_CS
/// Returns `None` if there is no child corresponding to token STARTSWITH_CS
fn STARTSWITH_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STARTSWITH_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_STARTSWITH_CS
/// Returns `None` if there is no child corresponding to token NOT_STARTSWITH_CS
fn NOT_STARTSWITH_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_STARTSWITH_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token ENDSWITH
/// Returns `None` if there is no child corresponding to token ENDSWITH
fn ENDSWITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ENDSWITH, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_ENDSWITH
/// Returns `None` if there is no child corresponding to token NOT_ENDSWITH
fn NOT_ENDSWITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_ENDSWITH, 0)
}
/// Retrieves first TerminalNode corresponding to token ENDSWITH_CS
/// Returns `None` if there is no child corresponding to token ENDSWITH_CS
fn ENDSWITH_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ENDSWITH_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token NOT_ENDSWITH_CS
/// Returns `None` if there is no child corresponding to token NOT_ENDSWITH_CS
fn NOT_ENDSWITH_CS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOT_ENDSWITH_CS, 0)
}
/// Retrieves first TerminalNode corresponding to token MATCHES_REGEX
/// Returns `None` if there is no child corresponding to token MATCHES_REGEX
fn MATCHES_REGEX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MATCHES_REGEX, 0)
}

}

impl<'input> StringBinaryOperatorContextAttrs<'input> for StringBinaryOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringBinaryOperator(&mut self,)
	-> Result<Rc<StringBinaryOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringBinaryOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 416, RULE_stringBinaryOperator);
        let mut _localctx: Rc<StringBinaryOperatorContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2309);
			 cast_mut::<_,StringBinaryOperatorContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==EQUALTILDE || _la==EXCLAIMATIONPOINT_TILDE || ((((_la - 62)) & !0x3f) == 0 && ((1usize << (_la - 62)) & ((1usize << (CONTAINS - 62)) | (1usize << (CONTAINSCS - 62)) | (1usize << (CONTAINS_CS - 62)) | (1usize << (ENDSWITH - 62)) | (1usize << (ENDSWITH_CS - 62)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HAS_CS - 104)) | (1usize << (HASPREFIX - 104)) | (1usize << (HASPREFIX_CS - 104)) | (1usize << (HASSUFFIX - 104)) | (1usize << (HASSUFFIX_CS - 104)))) != 0) || ((((_la - 142)) & !0x3f) == 0 && ((1usize << (_la - 142)) & ((1usize << (LIKE - 142)) | (1usize << (LIKECS - 142)) | (1usize << (MATCHES_REGEX - 142)) | (1usize << (NOT_CONTAINS - 142)) | (1usize << (NOT_CONTAINS_CS - 142)) | (1usize << (NOT_ENDSWITH_CS - 142)) | (1usize << (NOT_ENDSWITH - 142)) | (1usize << (NOT_HAS - 142)) | (1usize << (NOT_HAS_CS - 142)) | (1usize << (NOT_HASPREFIX - 142)) | (1usize << (NOT_HASPREFIX_CS - 142)) | (1usize << (NOT_HASSUFFIX - 142)))) != 0) || ((((_la - 174)) & !0x3f) == 0 && ((1usize << (_la - 174)) & ((1usize << (NOT_HASSUFFIX_CS - 174)) | (1usize << (NOT_STARTSWITH - 174)) | (1usize << (NOT_STARTSWITH_CS - 174)) | (1usize << (NOTCONTAINS - 174)) | (1usize << (NOTCONTAINSCS - 174)) | (1usize << (NOTLIKE - 174)) | (1usize << (NOTLIKECS - 174)))) != 0) || _la==STARTSWITH || _la==STARTSWITH_CS) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,StringBinaryOperatorContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringStarOperatorExpression ----------------
pub type StringStarOperatorExpressionContextAll<'input> = StringStarOperatorExpressionContext<'input>;


pub type StringStarOperatorExpressionContext<'input> = BaseParserRuleContext<'input,StringStarOperatorExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StringStarOperatorExpressionContextExt<'input>{
	pub LeftStarToken: Option<TokenType<'input>>,
	pub Operator: Option<Rc<StringBinaryOperatorContextAll<'input>>>,
	pub Right: Option<Rc<InvocationExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StringStarOperatorExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StringStarOperatorExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringStarOperatorExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_stringStarOperatorExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StringStarOperatorExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_stringStarOperatorExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringStarOperatorExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringStarOperatorExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringStarOperatorExpression }
}
antlr_rust::tid!{StringStarOperatorExpressionContextExt<'a>}

impl<'input> StringStarOperatorExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringStarOperatorExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringStarOperatorExpressionContextExt{
				LeftStarToken: None, 
				Operator: None, Right: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait StringStarOperatorExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StringStarOperatorExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
fn stringBinaryOperator(&self) -> Option<Rc<StringBinaryOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn invocationExpression(&self) -> Option<Rc<InvocationExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StringStarOperatorExpressionContextAttrs<'input> for StringStarOperatorExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringStarOperatorExpression(&mut self,)
	-> Result<Rc<StringStarOperatorExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringStarOperatorExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 418, RULE_stringStarOperatorExpression);
        let mut _localctx: Rc<StringStarOperatorExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2311);
			let tmp = recog.base.match_token(ASTERISK,&mut recog.err_handler)?;
			 cast_mut::<_,StringStarOperatorExpressionContext >(&mut _localctx).LeftStarToken = Some(tmp.clone());
			  

			/*InvokeRule stringBinaryOperator*/
			recog.base.set_state(2312);
			let tmp = recog.stringBinaryOperator()?;
			 cast_mut::<_,StringStarOperatorExpressionContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			/*InvokeRule invocationExpression*/
			recog.base.set_state(2313);
			let tmp = recog.invocationExpression()?;
			 cast_mut::<_,StringStarOperatorExpressionContext >(&mut _localctx).Right = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- invocationExpression ----------------
pub type InvocationExpressionContextAll<'input> = InvocationExpressionContext<'input>;


pub type InvocationExpressionContext<'input> = BaseParserRuleContext<'input,InvocationExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct InvocationExpressionContextExt<'input>{
	pub OperatorToken: Option<TokenType<'input>>,
	pub Expression: Option<Rc<FunctionCallOrPathExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for InvocationExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for InvocationExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_invocationExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_invocationExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for InvocationExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_invocationExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for InvocationExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_invocationExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_invocationExpression }
}
antlr_rust::tid!{InvocationExpressionContextExt<'a>}

impl<'input> InvocationExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<InvocationExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,InvocationExpressionContextExt{
				OperatorToken: None, 
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait InvocationExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<InvocationExpressionContextExt<'input>>{

fn functionCallOrPathExpression(&self) -> Option<Rc<FunctionCallOrPathExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token DASH
/// Returns `None` if there is no child corresponding to token DASH
fn DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH, 0)
}

}

impl<'input> InvocationExpressionContextAttrs<'input> for InvocationExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn invocationExpression(&mut self,)
	-> Result<Rc<InvocationExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = InvocationExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 420, RULE_invocationExpression);
        let mut _localctx: Rc<InvocationExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2316);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DASH || _la==PLUS {
				{
				recog.base.set_state(2315);
				 cast_mut::<_,InvocationExpressionContext >(&mut _localctx).OperatorToken = recog.base.input.lt(1).cloned();
				 
				_la = recog.base.input.la(1);
				if { !(_la==DASH || _la==PLUS) } {
					let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
					 cast_mut::<_,InvocationExpressionContext >(&mut _localctx).OperatorToken = Some(tmp.clone());
					  

				}
				else {
					if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
					recog.err_handler.report_match(&mut recog.base);
					recog.base.consume(&mut recog.err_handler);
				}
				}
			}

			/*InvokeRule functionCallOrPathExpression*/
			recog.base.set_state(2318);
			let tmp = recog.functionCallOrPathExpression()?;
			 cast_mut::<_,InvocationExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallOrPathExpression ----------------
pub type FunctionCallOrPathExpressionContextAll<'input> = FunctionCallOrPathExpressionContext<'input>;


pub type FunctionCallOrPathExpressionContext<'input> = BaseParserRuleContext<'input,FunctionCallOrPathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallOrPathExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionCallOrPathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionCallOrPathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallOrPathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionCallOrPathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionCallOrPathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionCallOrPathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallOrPathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallOrPathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallOrPathExpression }
}
antlr_rust::tid!{FunctionCallOrPathExpressionContextExt<'a>}

impl<'input> FunctionCallOrPathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallOrPathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallOrPathExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallOrPathExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionCallOrPathExpressionContextExt<'input>>{

fn functionCallOrPathRoot(&self) -> Option<Rc<FunctionCallOrPathRootContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionCallOrPathPathExpression(&self) -> Option<Rc<FunctionCallOrPathPathExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn toTableExpression(&self) -> Option<Rc<ToTableExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallOrPathExpressionContextAttrs<'input> for FunctionCallOrPathExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallOrPathExpression(&mut self,)
	-> Result<Rc<FunctionCallOrPathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallOrPathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 422, RULE_functionCallOrPathExpression);
        let mut _localctx: Rc<FunctionCallOrPathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2323);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(202,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule functionCallOrPathRoot*/
					recog.base.set_state(2320);
					recog.functionCallOrPathRoot()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule functionCallOrPathPathExpression*/
					recog.base.set_state(2321);
					recog.functionCallOrPathPathExpression()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule toTableExpression*/
					recog.base.set_state(2322);
					recog.toTableExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallOrPathRoot ----------------
pub type FunctionCallOrPathRootContextAll<'input> = FunctionCallOrPathRootContext<'input>;


pub type FunctionCallOrPathRootContext<'input> = BaseParserRuleContext<'input,FunctionCallOrPathRootContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallOrPathRootContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionCallOrPathRootContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionCallOrPathRootContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallOrPathRoot(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionCallOrPathRoot(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionCallOrPathRootContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionCallOrPathRoot(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallOrPathRootContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallOrPathRoot }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallOrPathRoot }
}
antlr_rust::tid!{FunctionCallOrPathRootContextExt<'a>}

impl<'input> FunctionCallOrPathRootContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallOrPathRootContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallOrPathRootContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallOrPathRootContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionCallOrPathRootContextExt<'input>>{

fn dotCompositeFunctionCallExpression(&self) -> Option<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn primaryExpression(&self) -> Option<Rc<PrimaryExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn toScalarExpression(&self) -> Option<Rc<ToScalarExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallOrPathRootContextAttrs<'input> for FunctionCallOrPathRootContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallOrPathRoot(&mut self,)
	-> Result<Rc<FunctionCallOrPathRootContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallOrPathRootContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 424, RULE_functionCallOrPathRoot);
        let mut _localctx: Rc<FunctionCallOrPathRootContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2328);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(203,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule dotCompositeFunctionCallExpression*/
					recog.base.set_state(2325);
					recog.dotCompositeFunctionCallExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule primaryExpression*/
					recog.base.set_state(2326);
					recog.primaryExpression()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule toScalarExpression*/
					recog.base.set_state(2327);
					recog.toScalarExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallOrPathPathExpression ----------------
pub type FunctionCallOrPathPathExpressionContextAll<'input> = FunctionCallOrPathPathExpressionContext<'input>;


pub type FunctionCallOrPathPathExpressionContext<'input> = BaseParserRuleContext<'input,FunctionCallOrPathPathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallOrPathPathExpressionContextExt<'input>{
	pub Expression: Option<Rc<FunctionCallOrPathRootContextAll<'input>>>,
	pub functionCallOrPathOperation: Option<Rc<FunctionCallOrPathOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<FunctionCallOrPathOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionCallOrPathPathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionCallOrPathPathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallOrPathPathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionCallOrPathPathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionCallOrPathPathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionCallOrPathPathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallOrPathPathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallOrPathPathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallOrPathPathExpression }
}
antlr_rust::tid!{FunctionCallOrPathPathExpressionContextExt<'a>}

impl<'input> FunctionCallOrPathPathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallOrPathPathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallOrPathPathExpressionContextExt{
				Expression: None, functionCallOrPathOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallOrPathPathExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionCallOrPathPathExpressionContextExt<'input>>{

fn functionCallOrPathRoot(&self) -> Option<Rc<FunctionCallOrPathRootContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionCallOrPathOperation_all(&self) ->  Vec<Rc<FunctionCallOrPathOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn functionCallOrPathOperation(&self, i: usize) -> Option<Rc<FunctionCallOrPathOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> FunctionCallOrPathPathExpressionContextAttrs<'input> for FunctionCallOrPathPathExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallOrPathPathExpression(&mut self,)
	-> Result<Rc<FunctionCallOrPathPathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallOrPathPathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 426, RULE_functionCallOrPathPathExpression);
        let mut _localctx: Rc<FunctionCallOrPathPathExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule functionCallOrPathRoot*/
			recog.base.set_state(2330);
			let tmp = recog.functionCallOrPathRoot()?;
			 cast_mut::<_,FunctionCallOrPathPathExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2332); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule functionCallOrPathOperation*/
				recog.base.set_state(2331);
				let tmp = recog.functionCallOrPathOperation()?;
				 cast_mut::<_,FunctionCallOrPathPathExpressionContext >(&mut _localctx).functionCallOrPathOperation = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,FunctionCallOrPathPathExpressionContext >(&mut _localctx).functionCallOrPathOperation.clone().unwrap()
				 ;
				 cast_mut::<_,FunctionCallOrPathPathExpressionContext >(&mut _localctx).Operations.push(temp);
				  
				}
				}
				recog.base.set_state(2334); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==DOT || _la==OPENBRACKET) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallOrPathOperation ----------------
pub type FunctionCallOrPathOperationContextAll<'input> = FunctionCallOrPathOperationContext<'input>;


pub type FunctionCallOrPathOperationContext<'input> = BaseParserRuleContext<'input,FunctionCallOrPathOperationContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallOrPathOperationContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionCallOrPathOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionCallOrPathOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallOrPathOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionCallOrPathOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionCallOrPathOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionCallOrPathOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallOrPathOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallOrPathOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallOrPathOperation }
}
antlr_rust::tid!{FunctionCallOrPathOperationContextExt<'a>}

impl<'input> FunctionCallOrPathOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallOrPathOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallOrPathOperationContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallOrPathOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionCallOrPathOperationContextExt<'input>>{

fn functionalCallOrPathPathOperation(&self) -> Option<Rc<FunctionalCallOrPathPathOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn functionCallOrPathElementOperation(&self) -> Option<Rc<FunctionCallOrPathElementOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn legacyFunctionCallOrPathElementOperation(&self) -> Option<Rc<LegacyFunctionCallOrPathElementOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallOrPathOperationContextAttrs<'input> for FunctionCallOrPathOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallOrPathOperation(&mut self,)
	-> Result<Rc<FunctionCallOrPathOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallOrPathOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 428, RULE_functionCallOrPathOperation);
        let mut _localctx: Rc<FunctionCallOrPathOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2339);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(205,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule functionalCallOrPathPathOperation*/
					recog.base.set_state(2336);
					recog.functionalCallOrPathPathOperation()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule functionCallOrPathElementOperation*/
					recog.base.set_state(2337);
					recog.functionCallOrPathElementOperation()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule legacyFunctionCallOrPathElementOperation*/
					recog.base.set_state(2338);
					recog.legacyFunctionCallOrPathElementOperation()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionalCallOrPathPathOperation ----------------
pub type FunctionalCallOrPathPathOperationContextAll<'input> = FunctionalCallOrPathPathOperationContext<'input>;


pub type FunctionalCallOrPathPathOperationContext<'input> = BaseParserRuleContext<'input,FunctionalCallOrPathPathOperationContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionalCallOrPathPathOperationContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionalCallOrPathPathOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionalCallOrPathPathOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionalCallOrPathPathOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionalCallOrPathPathOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionalCallOrPathPathOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionalCallOrPathPathOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionalCallOrPathPathOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionalCallOrPathPathOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionalCallOrPathPathOperation }
}
antlr_rust::tid!{FunctionalCallOrPathPathOperationContextExt<'a>}

impl<'input> FunctionalCallOrPathPathOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionalCallOrPathPathOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionalCallOrPathPathOperationContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionalCallOrPathPathOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionalCallOrPathPathOperationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionalCallOrPathPathOperationContextAttrs<'input> for FunctionalCallOrPathPathOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionalCallOrPathPathOperation(&mut self,)
	-> Result<Rc<FunctionalCallOrPathPathOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionalCallOrPathPathOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 430, RULE_functionalCallOrPathPathOperation);
        let mut _localctx: Rc<FunctionalCallOrPathPathOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2341);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(2342);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,FunctionalCallOrPathPathOperationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallOrPathElementOperation ----------------
pub type FunctionCallOrPathElementOperationContextAll<'input> = FunctionCallOrPathElementOperationContext<'input>;


pub type FunctionCallOrPathElementOperationContext<'input> = BaseParserRuleContext<'input,FunctionCallOrPathElementOperationContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallOrPathElementOperationContextExt<'input>{
	pub Element: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionCallOrPathElementOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionCallOrPathElementOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallOrPathElementOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionCallOrPathElementOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionCallOrPathElementOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionCallOrPathElementOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallOrPathElementOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallOrPathElementOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallOrPathElementOperation }
}
antlr_rust::tid!{FunctionCallOrPathElementOperationContextExt<'a>}

impl<'input> FunctionCallOrPathElementOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallOrPathElementOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallOrPathElementOperationContextExt{
				Element: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallOrPathElementOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionCallOrPathElementOperationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallOrPathElementOperationContextAttrs<'input> for FunctionCallOrPathElementOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallOrPathElementOperation(&mut self,)
	-> Result<Rc<FunctionCallOrPathElementOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallOrPathElementOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 432, RULE_functionCallOrPathElementOperation);
        let mut _localctx: Rc<FunctionCallOrPathElementOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2344);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2345);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,FunctionCallOrPathElementOperationContext >(&mut _localctx).Element = Some(tmp.clone());
			  

			recog.base.set_state(2346);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- legacyFunctionCallOrPathElementOperation ----------------
pub type LegacyFunctionCallOrPathElementOperationContextAll<'input> = LegacyFunctionCallOrPathElementOperationContext<'input>;


pub type LegacyFunctionCallOrPathElementOperationContext<'input> = BaseParserRuleContext<'input,LegacyFunctionCallOrPathElementOperationContextExt<'input>>;

#[derive(Clone)]
pub struct LegacyFunctionCallOrPathElementOperationContextExt<'input>{
	pub Element: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LegacyFunctionCallOrPathElementOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LegacyFunctionCallOrPathElementOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_legacyFunctionCallOrPathElementOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_legacyFunctionCallOrPathElementOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LegacyFunctionCallOrPathElementOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_legacyFunctionCallOrPathElementOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyFunctionCallOrPathElementOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_legacyFunctionCallOrPathElementOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_legacyFunctionCallOrPathElementOperation }
}
antlr_rust::tid!{LegacyFunctionCallOrPathElementOperationContextExt<'a>}

impl<'input> LegacyFunctionCallOrPathElementOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LegacyFunctionCallOrPathElementOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LegacyFunctionCallOrPathElementOperationContextExt{
				Element: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LegacyFunctionCallOrPathElementOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LegacyFunctionCallOrPathElementOperationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LegacyFunctionCallOrPathElementOperationContextAttrs<'input> for LegacyFunctionCallOrPathElementOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn legacyFunctionCallOrPathElementOperation(&mut self,)
	-> Result<Rc<LegacyFunctionCallOrPathElementOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LegacyFunctionCallOrPathElementOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 434, RULE_legacyFunctionCallOrPathElementOperation);
        let mut _localctx: Rc<LegacyFunctionCallOrPathElementOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2348);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			recog.base.set_state(2349);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2350);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,LegacyFunctionCallOrPathElementOperationContext >(&mut _localctx).Element = Some(tmp.clone());
			  

			recog.base.set_state(2351);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- toScalarExpression ----------------
pub type ToScalarExpressionContextAll<'input> = ToScalarExpressionContext<'input>;


pub type ToScalarExpressionContext<'input> = BaseParserRuleContext<'input,ToScalarExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ToScalarExpressionContextExt<'input>{
	pub Expression: Option<Rc<PipeExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ToScalarExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ToScalarExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_toScalarExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_toScalarExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ToScalarExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_toScalarExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ToScalarExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_toScalarExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_toScalarExpression }
}
antlr_rust::tid!{ToScalarExpressionContextExt<'a>}

impl<'input> ToScalarExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ToScalarExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ToScalarExpressionContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ToScalarExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ToScalarExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TOSCALAR
/// Returns `None` if there is no child corresponding to token TOSCALAR
fn TOSCALAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOSCALAR, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn pipeExpression(&self) -> Option<Rc<PipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn noOptimizationParameter(&self) -> Option<Rc<NoOptimizationParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ToScalarExpressionContextAttrs<'input> for ToScalarExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn toScalarExpression(&mut self,)
	-> Result<Rc<ToScalarExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ToScalarExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 436, RULE_toScalarExpression);
        let mut _localctx: Rc<ToScalarExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2353);
			recog.base.match_token(TOSCALAR,&mut recog.err_handler)?;

			recog.base.set_state(2355);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KIND {
				{
				/*InvokeRule noOptimizationParameter*/
				recog.base.set_state(2354);
				recog.noOptimizationParameter()?;

				}
			}

			recog.base.set_state(2357);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule pipeExpression*/
			recog.base.set_state(2358);
			let tmp = recog.pipeExpression()?;
			 cast_mut::<_,ToScalarExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2359);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- toTableExpression ----------------
pub type ToTableExpressionContextAll<'input> = ToTableExpressionContext<'input>;


pub type ToTableExpressionContext<'input> = BaseParserRuleContext<'input,ToTableExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ToTableExpressionContextExt<'input>{
	pub Expression: Option<Rc<PipeExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ToTableExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ToTableExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_toTableExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_toTableExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ToTableExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_toTableExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ToTableExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_toTableExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_toTableExpression }
}
antlr_rust::tid!{ToTableExpressionContextExt<'a>}

impl<'input> ToTableExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ToTableExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ToTableExpressionContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ToTableExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ToTableExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TOTABLE
/// Returns `None` if there is no child corresponding to token TOTABLE
fn TOTABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOTABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn pipeExpression(&self) -> Option<Rc<PipeExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn noOptimizationParameter(&self) -> Option<Rc<NoOptimizationParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ToTableExpressionContextAttrs<'input> for ToTableExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn toTableExpression(&mut self,)
	-> Result<Rc<ToTableExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ToTableExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 438, RULE_toTableExpression);
        let mut _localctx: Rc<ToTableExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2361);
			recog.base.match_token(TOTABLE,&mut recog.err_handler)?;

			recog.base.set_state(2363);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==KIND {
				{
				/*InvokeRule noOptimizationParameter*/
				recog.base.set_state(2362);
				recog.noOptimizationParameter()?;

				}
			}

			recog.base.set_state(2365);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule pipeExpression*/
			recog.base.set_state(2366);
			let tmp = recog.pipeExpression()?;
			 cast_mut::<_,ToTableExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2367);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- noOptimizationParameter ----------------
pub type NoOptimizationParameterContextAll<'input> = NoOptimizationParameterContext<'input>;


pub type NoOptimizationParameterContext<'input> = BaseParserRuleContext<'input,NoOptimizationParameterContextExt<'input>>;

#[derive(Clone)]
pub struct NoOptimizationParameterContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NoOptimizationParameterContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NoOptimizationParameterContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_noOptimizationParameter(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_noOptimizationParameter(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NoOptimizationParameterContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_noOptimizationParameter(self);
	}
}

impl<'input> CustomRuleContext<'input> for NoOptimizationParameterContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_noOptimizationParameter }
	//fn type_rule_index() -> usize where Self: Sized { RULE_noOptimizationParameter }
}
antlr_rust::tid!{NoOptimizationParameterContextExt<'a>}

impl<'input> NoOptimizationParameterContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NoOptimizationParameterContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NoOptimizationParameterContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait NoOptimizationParameterContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NoOptimizationParameterContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token NOOPTIMIZATION
/// Returns `None` if there is no child corresponding to token NOOPTIMIZATION
fn NOOPTIMIZATION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NOOPTIMIZATION, 0)
}

}

impl<'input> NoOptimizationParameterContextAttrs<'input> for NoOptimizationParameterContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn noOptimizationParameter(&mut self,)
	-> Result<Rc<NoOptimizationParameterContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NoOptimizationParameterContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 440, RULE_noOptimizationParameter);
        let mut _localctx: Rc<NoOptimizationParameterContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2369);
			recog.base.match_token(KIND,&mut recog.err_handler)?;

			recog.base.set_state(2370);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2371);
			recog.base.match_token(NOOPTIMIZATION,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dotCompositeFunctionCallExpression ----------------
pub type DotCompositeFunctionCallExpressionContextAll<'input> = DotCompositeFunctionCallExpressionContext<'input>;


pub type DotCompositeFunctionCallExpressionContext<'input> = BaseParserRuleContext<'input,DotCompositeFunctionCallExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DotCompositeFunctionCallExpressionContextExt<'input>{
	pub Call: Option<Rc<FunctionCallExpressionContextAll<'input>>>,
	pub dotCompositeFunctionCallOperation: Option<Rc<DotCompositeFunctionCallOperationContextAll<'input>>>,
	pub Operations:Vec<Rc<DotCompositeFunctionCallOperationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DotCompositeFunctionCallExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DotCompositeFunctionCallExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dotCompositeFunctionCallExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_dotCompositeFunctionCallExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DotCompositeFunctionCallExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_dotCompositeFunctionCallExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DotCompositeFunctionCallExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dotCompositeFunctionCallExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dotCompositeFunctionCallExpression }
}
antlr_rust::tid!{DotCompositeFunctionCallExpressionContextExt<'a>}

impl<'input> DotCompositeFunctionCallExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DotCompositeFunctionCallExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DotCompositeFunctionCallExpressionContextExt{
				Call: None, dotCompositeFunctionCallOperation: None, 
				Operations: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DotCompositeFunctionCallExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DotCompositeFunctionCallExpressionContextExt<'input>>{

fn functionCallExpression(&self) -> Option<Rc<FunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dotCompositeFunctionCallOperation_all(&self) ->  Vec<Rc<DotCompositeFunctionCallOperationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn dotCompositeFunctionCallOperation(&self, i: usize) -> Option<Rc<DotCompositeFunctionCallOperationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DotCompositeFunctionCallExpressionContextAttrs<'input> for DotCompositeFunctionCallExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dotCompositeFunctionCallExpression(&mut self,)
	-> Result<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DotCompositeFunctionCallExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 442, RULE_dotCompositeFunctionCallExpression);
        let mut _localctx: Rc<DotCompositeFunctionCallExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule functionCallExpression*/
			recog.base.set_state(2373);
			let tmp = recog.functionCallExpression()?;
			 cast_mut::<_,DotCompositeFunctionCallExpressionContext >(&mut _localctx).Call = Some(tmp.clone());
			  

			recog.base.set_state(2377);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(208,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					/*InvokeRule dotCompositeFunctionCallOperation*/
					recog.base.set_state(2374);
					let tmp = recog.dotCompositeFunctionCallOperation()?;
					 cast_mut::<_,DotCompositeFunctionCallExpressionContext >(&mut _localctx).dotCompositeFunctionCallOperation = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,DotCompositeFunctionCallExpressionContext >(&mut _localctx).dotCompositeFunctionCallOperation.clone().unwrap()
					 ;
					 cast_mut::<_,DotCompositeFunctionCallExpressionContext >(&mut _localctx).Operations.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2379);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(208,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dotCompositeFunctionCallOperation ----------------
pub type DotCompositeFunctionCallOperationContextAll<'input> = DotCompositeFunctionCallOperationContext<'input>;


pub type DotCompositeFunctionCallOperationContext<'input> = BaseParserRuleContext<'input,DotCompositeFunctionCallOperationContextExt<'input>>;

#[derive(Clone)]
pub struct DotCompositeFunctionCallOperationContextExt<'input>{
	pub Call: Option<Rc<FunctionCallExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DotCompositeFunctionCallOperationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DotCompositeFunctionCallOperationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dotCompositeFunctionCallOperation(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_dotCompositeFunctionCallOperation(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DotCompositeFunctionCallOperationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_dotCompositeFunctionCallOperation(self);
	}
}

impl<'input> CustomRuleContext<'input> for DotCompositeFunctionCallOperationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dotCompositeFunctionCallOperation }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dotCompositeFunctionCallOperation }
}
antlr_rust::tid!{DotCompositeFunctionCallOperationContextExt<'a>}

impl<'input> DotCompositeFunctionCallOperationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DotCompositeFunctionCallOperationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DotCompositeFunctionCallOperationContextExt{
				Call: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DotCompositeFunctionCallOperationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DotCompositeFunctionCallOperationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn functionCallExpression(&self) -> Option<Rc<FunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DotCompositeFunctionCallOperationContextAttrs<'input> for DotCompositeFunctionCallOperationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dotCompositeFunctionCallOperation(&mut self,)
	-> Result<Rc<DotCompositeFunctionCallOperationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DotCompositeFunctionCallOperationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 444, RULE_dotCompositeFunctionCallOperation);
        let mut _localctx: Rc<DotCompositeFunctionCallOperationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2380);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule functionCallExpression*/
			recog.base.set_state(2381);
			let tmp = recog.functionCallExpression()?;
			 cast_mut::<_,DotCompositeFunctionCallOperationContext >(&mut _localctx).Call = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- functionCallExpression ----------------
pub type FunctionCallExpressionContextAll<'input> = FunctionCallExpressionContext<'input>;


pub type FunctionCallExpressionContext<'input> = BaseParserRuleContext<'input,FunctionCallExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct FunctionCallExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for FunctionCallExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for FunctionCallExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_functionCallExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_functionCallExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for FunctionCallExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_functionCallExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for FunctionCallExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_functionCallExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_functionCallExpression }
}
antlr_rust::tid!{FunctionCallExpressionContextExt<'a>}

impl<'input> FunctionCallExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<FunctionCallExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,FunctionCallExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait FunctionCallExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<FunctionCallExpressionContextExt<'input>>{

fn namedFunctionCallExpression(&self) -> Option<Rc<NamedFunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn countExpression(&self) -> Option<Rc<CountExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> FunctionCallExpressionContextAttrs<'input> for FunctionCallExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn functionCallExpression(&mut self,)
	-> Result<Rc<FunctionCallExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = FunctionCallExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 446, RULE_functionCallExpression);
        let mut _localctx: Rc<FunctionCallExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2385);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 OPENBRACKET | ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN |
			 CLUSTER | DATABASE | DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE |
			 FACET | FORK | FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO |
			 LEGEND | LET | LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL |
			 NULLS | ON | OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN |
			 PLUGIN | QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT |
			 SERIES | STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED |
			 UUID | VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE |
			 YAXIS | YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule namedFunctionCallExpression*/
					recog.base.set_state(2383);
					recog.namedFunctionCallExpression()?;

					}
				}

			 COUNT 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule countExpression*/
					recog.base.set_state(2384);
					recog.countExpression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- namedFunctionCallExpression ----------------
pub type NamedFunctionCallExpressionContextAll<'input> = NamedFunctionCallExpressionContext<'input>;


pub type NamedFunctionCallExpressionContext<'input> = BaseParserRuleContext<'input,NamedFunctionCallExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NamedFunctionCallExpressionContextExt<'input>{
	pub Name: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub argumentExpression: Option<Rc<ArgumentExpressionContextAll<'input>>>,
	pub Arguments:Vec<Rc<ArgumentExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NamedFunctionCallExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NamedFunctionCallExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_namedFunctionCallExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_namedFunctionCallExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NamedFunctionCallExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_namedFunctionCallExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NamedFunctionCallExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_namedFunctionCallExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_namedFunctionCallExpression }
}
antlr_rust::tid!{NamedFunctionCallExpressionContextExt<'a>}

impl<'input> NamedFunctionCallExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NamedFunctionCallExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NamedFunctionCallExpressionContextExt{
				Name: None, argumentExpression: None, 
				Arguments: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait NamedFunctionCallExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NamedFunctionCallExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn argumentExpression_all(&self) ->  Vec<Rc<ArgumentExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn argumentExpression(&self, i: usize) -> Option<Rc<ArgumentExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> NamedFunctionCallExpressionContextAttrs<'input> for NamedFunctionCallExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn namedFunctionCallExpression(&mut self,)
	-> Result<Rc<NamedFunctionCallExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NamedFunctionCallExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 448, RULE_namedFunctionCallExpression);
        let mut _localctx: Rc<NamedFunctionCallExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule simpleNameReference*/
			recog.base.set_state(2387);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2388);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2397);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ASTERISK) | (1usize << DASH) | (1usize << OPENBRACKET) | (1usize << OPENPAREN))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (PLUS - 33)) | (1usize << (ACCESS - 33)) | (1usize << (ACCUMULATE - 33)) | (1usize << (AGGREGATIONS - 33)) | (1usize << (ALIAS - 33)) | (1usize << (ALL - 33)) | (1usize << (AS - 33)) | (1usize << (AXES - 33)) | (1usize << (BASE - 33)) | (1usize << (BIN - 33)) | (1usize << (BY - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (CONSUME - 33)) | (1usize << (CONTAINS - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (CONTEXTUAL_DATATABLE - 65)) | (1usize << (COUNT - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATATABLE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DELTA - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (EDGES - 65)) | (1usize << (EVALUATE - 65)) | (1usize << (EXECUTE - 65)) | (1usize << (EXTEND - 65)) | (1usize << (EXTERNALDATA - 65)) | (1usize << (EXTERNAL_DATA - 65)) | (1usize << (FACET - 65)) | (1usize << (FILTER - 65)) | (1usize << (FIND - 65)) | (1usize << (FORK - 65)) | (1usize << (FROM - 65)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (MATERIALIZED_VIEW_COMBINE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || ((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (DYNAMIC - 279)) | (1usize << (GUID - 279)) | (1usize << (LONGLITERAL - 279)) | (1usize << (INTLITERAL - 279)) | (1usize << (REALLITERAL - 279)) | (1usize << (DECIMALLITERAL - 279)) | (1usize << (STRINGLITERAL - 279)) | (1usize << (BOOLEANLITERAL - 279)))) != 0) || ((((_la - 311)) & !0x3f) == 0 && ((1usize << (_la - 311)) & ((1usize << (DATETIMELITERAL - 311)) | (1usize << (TIMESPANLITERAL - 311)) | (1usize << (TYPELITERAL - 311)) | (1usize << (GUIDLITERAL - 311)) | (1usize << (IDENTIFIER - 311)))) != 0) {
				{
				/*InvokeRule argumentExpression*/
				recog.base.set_state(2389);
				let tmp = recog.argumentExpression()?;
				 cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).argumentExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).argumentExpression.clone().unwrap()
				 ;
				 cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).Arguments.push(temp);
				  
				recog.base.set_state(2394);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(2390);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule argumentExpression*/
					recog.base.set_state(2391);
					let tmp = recog.argumentExpression()?;
					 cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).argumentExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).argumentExpression.clone().unwrap()
					 ;
					 cast_mut::<_,NamedFunctionCallExpressionContext >(&mut _localctx).Arguments.push(temp);
					  
					}
					}
					recog.base.set_state(2396);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(2399);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- argumentExpression ----------------
pub type ArgumentExpressionContextAll<'input> = ArgumentExpressionContext<'input>;


pub type ArgumentExpressionContext<'input> = BaseParserRuleContext<'input,ArgumentExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ArgumentExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ArgumentExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ArgumentExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_argumentExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_argumentExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ArgumentExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_argumentExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ArgumentExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_argumentExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_argumentExpression }
}
antlr_rust::tid!{ArgumentExpressionContextExt<'a>}

impl<'input> ArgumentExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ArgumentExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ArgumentExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ArgumentExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ArgumentExpressionContextExt<'input>>{

fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn starExpression(&self) -> Option<Rc<StarExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ArgumentExpressionContextAttrs<'input> for ArgumentExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn argumentExpression(&mut self,)
	-> Result<Rc<ArgumentExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ArgumentExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 450, RULE_argumentExpression);
        let mut _localctx: Rc<ArgumentExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2403);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(212,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule namedExpression*/
					recog.base.set_state(2401);
					recog.namedExpression()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule starExpression*/
					recog.base.set_state(2402);
					recog.starExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- countExpression ----------------
pub type CountExpressionContextAll<'input> = CountExpressionContext<'input>;


pub type CountExpressionContext<'input> = BaseParserRuleContext<'input,CountExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct CountExpressionContextExt<'input>{
	pub Expression: Option<Rc<NamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for CountExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for CountExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_countExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_countExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for CountExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_countExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for CountExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_countExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_countExpression }
}
antlr_rust::tid!{CountExpressionContextExt<'a>}

impl<'input> CountExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<CountExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,CountExpressionContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait CountExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<CountExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn namedExpression(&self) -> Option<Rc<NamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> CountExpressionContextAttrs<'input> for CountExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn countExpression(&mut self,)
	-> Result<Rc<CountExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = CountExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 452, RULE_countExpression);
        let mut _localctx: Rc<CountExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2405);
			recog.base.match_token(COUNT,&mut recog.err_handler)?;

			recog.base.set_state(2406);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2408);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << ASTERISK) | (1usize << DASH) | (1usize << OPENBRACKET) | (1usize << OPENPAREN))) != 0) || ((((_la - 33)) & !0x3f) == 0 && ((1usize << (_la - 33)) & ((1usize << (PLUS - 33)) | (1usize << (ACCESS - 33)) | (1usize << (ACCUMULATE - 33)) | (1usize << (AGGREGATIONS - 33)) | (1usize << (ALIAS - 33)) | (1usize << (ALL - 33)) | (1usize << (AS - 33)) | (1usize << (AXES - 33)) | (1usize << (BASE - 33)) | (1usize << (BIN - 33)) | (1usize << (BY - 33)) | (1usize << (CLUSTER - 33)) | (1usize << (CONSUME - 33)) | (1usize << (CONTAINS - 33)))) != 0) || ((((_la - 65)) & !0x3f) == 0 && ((1usize << (_la - 65)) & ((1usize << (CONTEXTUAL_DATATABLE - 65)) | (1usize << (COUNT - 65)) | (1usize << (DATABASE - 65)) | (1usize << (DATATABLE - 65)) | (1usize << (DECLARE - 65)) | (1usize << (DEFAULT - 65)) | (1usize << (DELTA - 65)) | (1usize << (DISTINCT - 65)) | (1usize << (EDGES - 65)) | (1usize << (EVALUATE - 65)) | (1usize << (EXECUTE - 65)) | (1usize << (EXTEND - 65)) | (1usize << (EXTERNALDATA - 65)) | (1usize << (EXTERNAL_DATA - 65)) | (1usize << (FACET - 65)) | (1usize << (FILTER - 65)) | (1usize << (FIND - 65)) | (1usize << (FORK - 65)) | (1usize << (FROM - 65)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (MATERIALIZED_VIEW_COMBINE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || ((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (DYNAMIC - 279)) | (1usize << (GUID - 279)) | (1usize << (LONGLITERAL - 279)) | (1usize << (INTLITERAL - 279)) | (1usize << (REALLITERAL - 279)) | (1usize << (DECIMALLITERAL - 279)) | (1usize << (STRINGLITERAL - 279)) | (1usize << (BOOLEANLITERAL - 279)))) != 0) || ((((_la - 311)) & !0x3f) == 0 && ((1usize << (_la - 311)) & ((1usize << (DATETIMELITERAL - 311)) | (1usize << (TIMESPANLITERAL - 311)) | (1usize << (TYPELITERAL - 311)) | (1usize << (GUIDLITERAL - 311)) | (1usize << (IDENTIFIER - 311)))) != 0) {
				{
				/*InvokeRule namedExpression*/
				recog.base.set_state(2407);
				let tmp = recog.namedExpression()?;
				 cast_mut::<_,CountExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2410);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- starExpression ----------------
pub type StarExpressionContextAll<'input> = StarExpressionContext<'input>;


pub type StarExpressionContext<'input> = BaseParserRuleContext<'input,StarExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StarExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StarExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StarExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_starExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_starExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StarExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_starExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StarExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_starExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_starExpression }
}
antlr_rust::tid!{StarExpressionContextExt<'a>}

impl<'input> StarExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StarExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StarExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StarExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StarExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> StarExpressionContextAttrs<'input> for StarExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn starExpression(&mut self,)
	-> Result<Rc<StarExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StarExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 454, RULE_starExpression);
        let mut _localctx: Rc<StarExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2412);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- primaryExpression ----------------
pub type PrimaryExpressionContextAll<'input> = PrimaryExpressionContext<'input>;


pub type PrimaryExpressionContext<'input> = BaseParserRuleContext<'input,PrimaryExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct PrimaryExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for PrimaryExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for PrimaryExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_primaryExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_primaryExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for PrimaryExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_primaryExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for PrimaryExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_primaryExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_primaryExpression }
}
antlr_rust::tid!{PrimaryExpressionContextExt<'a>}

impl<'input> PrimaryExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<PrimaryExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,PrimaryExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait PrimaryExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<PrimaryExpressionContextExt<'input>>{

fn unsignedLiteralExpression(&self) -> Option<Rc<UnsignedLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn nameReferenceWithDataScope(&self) -> Option<Rc<NameReferenceWithDataScopeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dataTableExpression(&self) -> Option<Rc<DataTableExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn externalDataExpression(&self) -> Option<Rc<ExternalDataExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn contextualDataTableExpression(&self) -> Option<Rc<ContextualDataTableExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn materializedViewCombineExpression(&self) -> Option<Rc<MaterializedViewCombineExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn parenthesizedExpression(&self) -> Option<Rc<ParenthesizedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> PrimaryExpressionContextAttrs<'input> for PrimaryExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn primaryExpression(&mut self,)
	-> Result<Rc<PrimaryExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = PrimaryExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 456, RULE_primaryExpression);
        let mut _localctx: Rc<PrimaryExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2421);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DYNAMIC | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL | STRINGLITERAL |
			 BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL | TYPELITERAL | GUIDLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule unsignedLiteralExpression*/
					recog.base.set_state(2414);
					recog.unsignedLiteralExpression()?;

					}
				}

			 OPENBRACKET | ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN |
			 CLUSTER | DATABASE | DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE |
			 FACET | FORK | FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO |
			 LEGEND | LET | LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL |
			 NULLS | ON | OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN |
			 PLUGIN | QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT |
			 SERIES | STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED |
			 UUID | VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE |
			 YAXIS | YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule nameReferenceWithDataScope*/
					recog.base.set_state(2415);
					recog.nameReferenceWithDataScope()?;

					}
				}

			 DATATABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule dataTableExpression*/
					recog.base.set_state(2416);
					recog.dataTableExpression()?;

					}
				}

			 EXTERNALDATA | EXTERNAL_DATA 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule externalDataExpression*/
					recog.base.set_state(2417);
					recog.externalDataExpression()?;

					}
				}

			 CONTEXTUAL_DATATABLE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule contextualDataTableExpression*/
					recog.base.set_state(2418);
					recog.contextualDataTableExpression()?;

					}
				}

			 MATERIALIZED_VIEW_COMBINE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule materializedViewCombineExpression*/
					recog.base.set_state(2419);
					recog.materializedViewCombineExpression()?;

					}
				}

			 OPENPAREN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule parenthesizedExpression*/
					recog.base.set_state(2420);
					recog.parenthesizedExpression()?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- nameReferenceWithDataScope ----------------
pub type NameReferenceWithDataScopeContextAll<'input> = NameReferenceWithDataScopeContext<'input>;


pub type NameReferenceWithDataScopeContext<'input> = BaseParserRuleContext<'input,NameReferenceWithDataScopeContextExt<'input>>;

#[derive(Clone)]
pub struct NameReferenceWithDataScopeContextExt<'input>{
	pub Name: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub Scope: Option<Rc<DataScopeClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NameReferenceWithDataScopeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NameReferenceWithDataScopeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_nameReferenceWithDataScope(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_nameReferenceWithDataScope(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NameReferenceWithDataScopeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_nameReferenceWithDataScope(self);
	}
}

impl<'input> CustomRuleContext<'input> for NameReferenceWithDataScopeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_nameReferenceWithDataScope }
	//fn type_rule_index() -> usize where Self: Sized { RULE_nameReferenceWithDataScope }
}
antlr_rust::tid!{NameReferenceWithDataScopeContextExt<'a>}

impl<'input> NameReferenceWithDataScopeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NameReferenceWithDataScopeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NameReferenceWithDataScopeContextExt{
				Name: None, Scope: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NameReferenceWithDataScopeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NameReferenceWithDataScopeContextExt<'input>>{

fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dataScopeClause(&self) -> Option<Rc<DataScopeClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NameReferenceWithDataScopeContextAttrs<'input> for NameReferenceWithDataScopeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn nameReferenceWithDataScope(&mut self,)
	-> Result<Rc<NameReferenceWithDataScopeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NameReferenceWithDataScopeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 458, RULE_nameReferenceWithDataScope);
        let mut _localctx: Rc<NameReferenceWithDataScopeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule simpleNameReference*/
			recog.base.set_state(2423);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,NameReferenceWithDataScopeContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2425);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DATASCOPE {
				{
				/*InvokeRule dataScopeClause*/
				recog.base.set_state(2424);
				let tmp = recog.dataScopeClause()?;
				 cast_mut::<_,NameReferenceWithDataScopeContext >(&mut _localctx).Scope = Some(tmp.clone());
				  

				}
			}

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dataScopeClause ----------------
pub type DataScopeClauseContextAll<'input> = DataScopeClauseContext<'input>;


pub type DataScopeClauseContext<'input> = BaseParserRuleContext<'input,DataScopeClauseContextExt<'input>>;

#[derive(Clone)]
pub struct DataScopeClauseContextExt<'input>{
	pub KindToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DataScopeClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DataScopeClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dataScopeClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_dataScopeClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DataScopeClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_dataScopeClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for DataScopeClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataScopeClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataScopeClause }
}
antlr_rust::tid!{DataScopeClauseContextExt<'a>}

impl<'input> DataScopeClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DataScopeClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DataScopeClauseContextExt{
				KindToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DataScopeClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DataScopeClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DATASCOPE
/// Returns `None` if there is no child corresponding to token DATASCOPE
fn DATASCOPE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATASCOPE, 0)
}
/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
/// Retrieves first TerminalNode corresponding to token HOTCACHE
/// Returns `None` if there is no child corresponding to token HOTCACHE
fn HOTCACHE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HOTCACHE, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}

}

impl<'input> DataScopeClauseContextAttrs<'input> for DataScopeClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dataScopeClause(&mut self,)
	-> Result<Rc<DataScopeClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DataScopeClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 460, RULE_dataScopeClause);
        let mut _localctx: Rc<DataScopeClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2427);
			recog.base.match_token(DATASCOPE,&mut recog.err_handler)?;

			recog.base.set_state(2428);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2429);
			 cast_mut::<_,DataScopeClauseContext >(&mut _localctx).KindToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==ALL || _la==HOTCACHE) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,DataScopeClauseContext >(&mut _localctx).KindToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parenthesizedExpression ----------------
pub type ParenthesizedExpressionContextAll<'input> = ParenthesizedExpressionContext<'input>;


pub type ParenthesizedExpressionContext<'input> = BaseParserRuleContext<'input,ParenthesizedExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ParenthesizedExpressionContextExt<'input>{
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParenthesizedExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParenthesizedExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parenthesizedExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parenthesizedExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParenthesizedExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parenthesizedExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParenthesizedExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parenthesizedExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parenthesizedExpression }
}
antlr_rust::tid!{ParenthesizedExpressionContextExt<'a>}

impl<'input> ParenthesizedExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParenthesizedExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParenthesizedExpressionContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParenthesizedExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParenthesizedExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParenthesizedExpressionContextAttrs<'input> for ParenthesizedExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parenthesizedExpression(&mut self,)
	-> Result<Rc<ParenthesizedExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParenthesizedExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 462, RULE_parenthesizedExpression);
        let mut _localctx: Rc<ParenthesizedExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2431);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2432);
			let tmp = recog.expression()?;
			 cast_mut::<_,ParenthesizedExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2433);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rangeExpression ----------------
pub type RangeExpressionContextAll<'input> = RangeExpressionContext<'input>;


pub type RangeExpressionContext<'input> = BaseParserRuleContext<'input,RangeExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct RangeExpressionContextExt<'input>{
	pub Expression: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub FromExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub ToExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
	pub StepExpression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RangeExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RangeExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rangeExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_rangeExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RangeExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_rangeExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for RangeExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rangeExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rangeExpression }
}
antlr_rust::tid!{RangeExpressionContextExt<'a>}

impl<'input> RangeExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RangeExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RangeExpressionContextExt{
				Expression: None, FromExpression: None, ToExpression: None, StepExpression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RangeExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RangeExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token STEP
/// Returns `None` if there is no child corresponding to token STEP
fn STEP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STEP, 0)
}
fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unnamedExpression_all(&self) ->  Vec<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn unnamedExpression(&self, i: usize) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RangeExpressionContextAttrs<'input> for RangeExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rangeExpression(&mut self,)
	-> Result<Rc<RangeExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RangeExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 464, RULE_rangeExpression);
        let mut _localctx: Rc<RangeExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2435);
			recog.base.match_token(RANGE,&mut recog.err_handler)?;

			/*InvokeRule simpleNameReference*/
			recog.base.set_state(2436);
			let tmp = recog.simpleNameReference()?;
			 cast_mut::<_,RangeExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2437);
			recog.base.match_token(FROM,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2438);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,RangeExpressionContext >(&mut _localctx).FromExpression = Some(tmp.clone());
			  

			recog.base.set_state(2439);
			recog.base.match_token(TO,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2440);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,RangeExpressionContext >(&mut _localctx).ToExpression = Some(tmp.clone());
			  

			recog.base.set_state(2441);
			recog.base.match_token(STEP,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2442);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,RangeExpressionContext >(&mut _localctx).StepExpression = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityExpression ----------------
pub type EntityExpressionContextAll<'input> = EntityExpressionContext<'input>;


pub type EntityExpressionContext<'input> = BaseParserRuleContext<'input,EntityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct EntityExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityExpression }
}
antlr_rust::tid!{EntityExpressionContextExt<'a>}

impl<'input> EntityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityExpressionContextExt<'input>>{

fn entityNameReference(&self) -> Option<Rc<EntityNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn entityPathOrElementExpression(&self) -> Option<Rc<EntityPathOrElementExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EntityExpressionContextAttrs<'input> for EntityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityExpression(&mut self,)
	-> Result<Rc<EntityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 466, RULE_entityExpression);
        let mut _localctx: Rc<EntityExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2446);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(216,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule entityNameReference*/
					recog.base.set_state(2444);
					recog.entityNameReference()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule entityPathOrElementExpression*/
					recog.base.set_state(2445);
					recog.entityPathOrElementExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityPathOrElementExpression ----------------
pub type EntityPathOrElementExpressionContextAll<'input> = EntityPathOrElementExpressionContext<'input>;


pub type EntityPathOrElementExpressionContext<'input> = BaseParserRuleContext<'input,EntityPathOrElementExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct EntityPathOrElementExpressionContextExt<'input>{
	pub Expression: Option<Rc<EntityNameReferenceContextAll<'input>>>,
	pub entityPathOrElementOperator: Option<Rc<EntityPathOrElementOperatorContextAll<'input>>>,
	pub Operators:Vec<Rc<EntityPathOrElementOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityPathOrElementExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityPathOrElementExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityPathOrElementExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityPathOrElementExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityPathOrElementExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityPathOrElementExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityPathOrElementExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityPathOrElementExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityPathOrElementExpression }
}
antlr_rust::tid!{EntityPathOrElementExpressionContextExt<'a>}

impl<'input> EntityPathOrElementExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityPathOrElementExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityPathOrElementExpressionContextExt{
				Expression: None, entityPathOrElementOperator: None, 
				Operators: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityPathOrElementExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityPathOrElementExpressionContextExt<'input>>{

fn entityNameReference(&self) -> Option<Rc<EntityNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn entityPathOrElementOperator_all(&self) ->  Vec<Rc<EntityPathOrElementOperatorContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn entityPathOrElementOperator(&self, i: usize) -> Option<Rc<EntityPathOrElementOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> EntityPathOrElementExpressionContextAttrs<'input> for EntityPathOrElementExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityPathOrElementExpression(&mut self,)
	-> Result<Rc<EntityPathOrElementExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityPathOrElementExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 468, RULE_entityPathOrElementExpression);
        let mut _localctx: Rc<EntityPathOrElementExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule entityNameReference*/
			recog.base.set_state(2448);
			let tmp = recog.entityNameReference()?;
			 cast_mut::<_,EntityPathOrElementExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2450); 
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			loop {
				{
				{
				/*InvokeRule entityPathOrElementOperator*/
				recog.base.set_state(2449);
				let tmp = recog.entityPathOrElementOperator()?;
				 cast_mut::<_,EntityPathOrElementExpressionContext >(&mut _localctx).entityPathOrElementOperator = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,EntityPathOrElementExpressionContext >(&mut _localctx).entityPathOrElementOperator.clone().unwrap()
				 ;
				 cast_mut::<_,EntityPathOrElementExpressionContext >(&mut _localctx).Operators.push(temp);
				  
				}
				}
				recog.base.set_state(2452); 
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if !(_la==DOT || _la==OPENBRACKET) {break}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityPathOrElementOperator ----------------
pub type EntityPathOrElementOperatorContextAll<'input> = EntityPathOrElementOperatorContext<'input>;


pub type EntityPathOrElementOperatorContext<'input> = BaseParserRuleContext<'input,EntityPathOrElementOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct EntityPathOrElementOperatorContextExt<'input>{
	pub Path: Option<Rc<EntityPathOperatorContextAll<'input>>>,
	pub Element: Option<Rc<EntityElementOperatorContextAll<'input>>>,
	pub PathElement: Option<Rc<LegacyEntityPathElementOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityPathOrElementOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityPathOrElementOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityPathOrElementOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityPathOrElementOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityPathOrElementOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityPathOrElementOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityPathOrElementOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityPathOrElementOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityPathOrElementOperator }
}
antlr_rust::tid!{EntityPathOrElementOperatorContextExt<'a>}

impl<'input> EntityPathOrElementOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityPathOrElementOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityPathOrElementOperatorContextExt{
				Path: None, Element: None, PathElement: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityPathOrElementOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityPathOrElementOperatorContextExt<'input>>{

fn entityPathOperator(&self) -> Option<Rc<EntityPathOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn entityElementOperator(&self) -> Option<Rc<EntityElementOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn legacyEntityPathElementOperator(&self) -> Option<Rc<LegacyEntityPathElementOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EntityPathOrElementOperatorContextAttrs<'input> for EntityPathOrElementOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityPathOrElementOperator(&mut self,)
	-> Result<Rc<EntityPathOrElementOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityPathOrElementOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 470, RULE_entityPathOrElementOperator);
        let mut _localctx: Rc<EntityPathOrElementOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2457);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(218,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule entityPathOperator*/
					recog.base.set_state(2454);
					let tmp = recog.entityPathOperator()?;
					 cast_mut::<_,EntityPathOrElementOperatorContext >(&mut _localctx).Path = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule entityElementOperator*/
					recog.base.set_state(2455);
					let tmp = recog.entityElementOperator()?;
					 cast_mut::<_,EntityPathOrElementOperatorContext >(&mut _localctx).Element = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule legacyEntityPathElementOperator*/
					recog.base.set_state(2456);
					let tmp = recog.legacyEntityPathElementOperator()?;
					 cast_mut::<_,EntityPathOrElementOperatorContext >(&mut _localctx).PathElement = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityPathOperator ----------------
pub type EntityPathOperatorContextAll<'input> = EntityPathOperatorContext<'input>;


pub type EntityPathOperatorContext<'input> = BaseParserRuleContext<'input,EntityPathOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct EntityPathOperatorContextExt<'input>{
	pub Name: Option<Rc<EntityNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityPathOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityPathOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityPathOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityPathOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityPathOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityPathOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityPathOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityPathOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityPathOperator }
}
antlr_rust::tid!{EntityPathOperatorContextExt<'a>}

impl<'input> EntityPathOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityPathOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityPathOperatorContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityPathOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityPathOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn entityName(&self) -> Option<Rc<EntityNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EntityPathOperatorContextAttrs<'input> for EntityPathOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityPathOperator(&mut self,)
	-> Result<Rc<EntityPathOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityPathOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 472, RULE_entityPathOperator);
        let mut _localctx: Rc<EntityPathOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2459);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule entityName*/
			recog.base.set_state(2460);
			let tmp = recog.entityName()?;
			 cast_mut::<_,EntityPathOperatorContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityElementOperator ----------------
pub type EntityElementOperatorContextAll<'input> = EntityElementOperatorContext<'input>;


pub type EntityElementOperatorContext<'input> = BaseParserRuleContext<'input,EntityElementOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct EntityElementOperatorContextExt<'input>{
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityElementOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityElementOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityElementOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityElementOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityElementOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityElementOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityElementOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityElementOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityElementOperator }
}
antlr_rust::tid!{EntityElementOperatorContextExt<'a>}

impl<'input> EntityElementOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityElementOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityElementOperatorContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityElementOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityElementOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EntityElementOperatorContextAttrs<'input> for EntityElementOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityElementOperator(&mut self,)
	-> Result<Rc<EntityElementOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityElementOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 474, RULE_entityElementOperator);
        let mut _localctx: Rc<EntityElementOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2462);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2463);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,EntityElementOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2464);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- legacyEntityPathElementOperator ----------------
pub type LegacyEntityPathElementOperatorContextAll<'input> = LegacyEntityPathElementOperatorContext<'input>;


pub type LegacyEntityPathElementOperatorContext<'input> = BaseParserRuleContext<'input,LegacyEntityPathElementOperatorContextExt<'input>>;

#[derive(Clone)]
pub struct LegacyEntityPathElementOperatorContextExt<'input>{
	pub Expression: Option<Rc<UnnamedExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LegacyEntityPathElementOperatorContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LegacyEntityPathElementOperatorContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_legacyEntityPathElementOperator(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_legacyEntityPathElementOperator(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LegacyEntityPathElementOperatorContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_legacyEntityPathElementOperator(self);
	}
}

impl<'input> CustomRuleContext<'input> for LegacyEntityPathElementOperatorContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_legacyEntityPathElementOperator }
	//fn type_rule_index() -> usize where Self: Sized { RULE_legacyEntityPathElementOperator }
}
antlr_rust::tid!{LegacyEntityPathElementOperatorContextExt<'a>}

impl<'input> LegacyEntityPathElementOperatorContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LegacyEntityPathElementOperatorContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LegacyEntityPathElementOperatorContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LegacyEntityPathElementOperatorContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LegacyEntityPathElementOperatorContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn unnamedExpression(&self) -> Option<Rc<UnnamedExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LegacyEntityPathElementOperatorContextAttrs<'input> for LegacyEntityPathElementOperatorContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn legacyEntityPathElementOperator(&mut self,)
	-> Result<Rc<LegacyEntityPathElementOperatorContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LegacyEntityPathElementOperatorContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 476, RULE_legacyEntityPathElementOperator);
        let mut _localctx: Rc<LegacyEntityPathElementOperatorContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2466);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			recog.base.set_state(2467);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule unnamedExpression*/
			recog.base.set_state(2468);
			let tmp = recog.unnamedExpression()?;
			 cast_mut::<_,LegacyEntityPathElementOperatorContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2469);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityName ----------------
pub type EntityNameContextAll<'input> = EntityNameContext<'input>;


pub type EntityNameContext<'input> = BaseParserRuleContext<'input,EntityNameContextExt<'input>>;

#[derive(Clone)]
pub struct EntityNameContextExt<'input>{
	pub ATSIGN: Option<Rc<AtSignNameContextAll<'input>>>,
	pub Name: Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>>,
	pub ExtendedName: Option<Rc<ExtendedPathNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityName(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityName }
}
antlr_rust::tid!{EntityNameContextExt<'a>}

impl<'input> EntityNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityNameContextExt{
				ATSIGN: None, Name: None, ExtendedName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityNameContextExt<'input>>{

fn atSignName(&self) -> Option<Rc<AtSignNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn identifierOrExtendedKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendedPathName(&self) -> Option<Rc<ExtendedPathNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EntityNameContextAttrs<'input> for EntityNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityName(&mut self,)
	-> Result<Rc<EntityNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 478, RULE_entityName);
        let mut _localctx: Rc<EntityNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2474);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ATSIGN 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule atSignName*/
					recog.base.set_state(2471);
					let tmp = recog.atSignName()?;
					 cast_mut::<_,EntityNameContext >(&mut _localctx).ATSIGN = Some(tmp.clone());
					  

					}
				}

			 OPENBRACKET | ACCESS | ACCUMULATE | AGGREGATIONS | ALIAS | ALL | AS |
			 AXES | BASE | BIN | BY | CLUSTER | CONSUME | CONTAINS | COUNT | DATABASE |
			 DATATABLE | DECLARE | DEFAULT | DELTA | DISTINCT | EDGES | EVALUATE |
			 EXECUTE | EXTEND | EXTERNALDATA | FACET | FILTER | FIND | FORK | FROM |
			 HAS | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | IN | INTO | INVOKE |
			 LEGEND | LET | LIMIT | LINEAR | LIST | LOOKUP | LOG | MAP | MATERIALIZE |
			 NODES | NONE | NULL | NULLS | OF | ON | OPTIONAL | OUTPUT | PACK | PARSE |
			 PARTITION | PARTITIONBY | PATTERN | PLUGIN | PRINT | QUERYPARAMETERS |
			 RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SAMPLE | SAMPLE_DISTINCT |
			 SCAN | SEARCH | SERIALIZE | SERIES | SET | SORT | STACKED | STACKED100 |
			 STEP | SUMMARIZE | TAKE | THRESHOLD | TITLE | TO | TOP | TOP_HITTERS |
			 TOP_NESTED | TOSCALAR | TOTABLE | TYPEOF | UNSTACKED | UUID | VIEW |
			 VISIBLE | WHERE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule identifierOrExtendedKeywordOrEscapedName*/
					recog.base.set_state(2472);
					let tmp = recog.identifierOrExtendedKeywordOrEscapedName()?;
					 cast_mut::<_,EntityNameContext >(&mut _localctx).Name = Some(tmp.clone());
					  

					}
				}

			 KIND | WITHSOURCE | WITH_SOURCE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule extendedPathName*/
					recog.base.set_state(2473);
					let tmp = recog.extendedPathName()?;
					 cast_mut::<_,EntityNameContext >(&mut _localctx).ExtendedName = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- entityNameReference ----------------
pub type EntityNameReferenceContextAll<'input> = EntityNameReferenceContext<'input>;


pub type EntityNameReferenceContext<'input> = BaseParserRuleContext<'input,EntityNameReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct EntityNameReferenceContextExt<'input>{
	pub Name: Option<Rc<EntityNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EntityNameReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EntityNameReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_entityNameReference(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_entityNameReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EntityNameReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_entityNameReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for EntityNameReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_entityNameReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_entityNameReference }
}
antlr_rust::tid!{EntityNameReferenceContextExt<'a>}

impl<'input> EntityNameReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EntityNameReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EntityNameReferenceContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EntityNameReferenceContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EntityNameReferenceContextExt<'input>>{

fn entityName(&self) -> Option<Rc<EntityNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EntityNameReferenceContextAttrs<'input> for EntityNameReferenceContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn entityNameReference(&mut self,)
	-> Result<Rc<EntityNameReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EntityNameReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 480, RULE_entityNameReference);
        let mut _localctx: Rc<EntityNameReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule entityName*/
			recog.base.set_state(2476);
			let tmp = recog.entityName()?;
			 cast_mut::<_,EntityNameReferenceContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- atSignName ----------------
pub type AtSignNameContextAll<'input> = AtSignNameContext<'input>;


pub type AtSignNameContext<'input> = BaseParserRuleContext<'input,AtSignNameContextExt<'input>>;

#[derive(Clone)]
pub struct AtSignNameContextExt<'input>{
	pub NameToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for AtSignNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for AtSignNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_atSignName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_atSignName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for AtSignNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_atSignName(self);
	}
}

impl<'input> CustomRuleContext<'input> for AtSignNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_atSignName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_atSignName }
}
antlr_rust::tid!{AtSignNameContextExt<'a>}

impl<'input> AtSignNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<AtSignNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,AtSignNameContextExt{
				NameToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait AtSignNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<AtSignNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ATSIGN
/// Returns `None` if there is no child corresponding to token ATSIGN
fn ATSIGN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ATSIGN, 0)
}

}

impl<'input> AtSignNameContextAttrs<'input> for AtSignNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn atSignName(&mut self,)
	-> Result<Rc<AtSignNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = AtSignNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 482, RULE_atSignName);
        let mut _localctx: Rc<AtSignNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2478);
			let tmp = recog.base.match_token(ATSIGN,&mut recog.err_handler)?;
			 cast_mut::<_,AtSignNameContext >(&mut _localctx).NameToken = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extendedPathName ----------------
pub type ExtendedPathNameContextAll<'input> = ExtendedPathNameContext<'input>;


pub type ExtendedPathNameContext<'input> = BaseParserRuleContext<'input,ExtendedPathNameContextExt<'input>>;

#[derive(Clone)]
pub struct ExtendedPathNameContextExt<'input>{
	pub NameToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExtendedPathNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExtendedPathNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extendedPathName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_extendedPathName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExtendedPathNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_extendedPathName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtendedPathNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extendedPathName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extendedPathName }
}
antlr_rust::tid!{ExtendedPathNameContextExt<'a>}

impl<'input> ExtendedPathNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtendedPathNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtendedPathNameContextExt{
				NameToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtendedPathNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExtendedPathNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token KIND
/// Returns `None` if there is no child corresponding to token KIND
fn KIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(KIND, 0)
}
/// Retrieves first TerminalNode corresponding to token WITHSOURCE
/// Returns `None` if there is no child corresponding to token WITHSOURCE
fn WITHSOURCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITHSOURCE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH_SOURCE
/// Returns `None` if there is no child corresponding to token WITH_SOURCE
fn WITH_SOURCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH_SOURCE, 0)
}

}

impl<'input> ExtendedPathNameContextAttrs<'input> for ExtendedPathNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extendedPathName(&mut self,)
	-> Result<Rc<ExtendedPathNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtendedPathNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 484, RULE_extendedPathName);
        let mut _localctx: Rc<ExtendedPathNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2480);
			 cast_mut::<_,ExtendedPathNameContext >(&mut _localctx).NameToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==KIND || _la==WITHSOURCE || _la==WITH_SOURCE) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ExtendedPathNameContext >(&mut _localctx).NameToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedEntityExpression ----------------
pub type WildcardedEntityExpressionContextAll<'input> = WildcardedEntityExpressionContext<'input>;


pub type WildcardedEntityExpressionContext<'input> = BaseParserRuleContext<'input,WildcardedEntityExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedEntityExpressionContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedEntityExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedEntityExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedEntityExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedEntityExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedEntityExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedEntityExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedEntityExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedEntityExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedEntityExpression }
}
antlr_rust::tid!{WildcardedEntityExpressionContextExt<'a>}

impl<'input> WildcardedEntityExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedEntityExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedEntityExpressionContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedEntityExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedEntityExpressionContextExt<'input>>{

fn wildcardedNameReference(&self) -> Option<Rc<WildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dotCompositeFunctionCallExpression(&self) -> Option<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn wildcardedPathExpression(&self) -> Option<Rc<WildcardedPathExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WildcardedEntityExpressionContextAttrs<'input> for WildcardedEntityExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedEntityExpression(&mut self,)
	-> Result<Rc<WildcardedEntityExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedEntityExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 486, RULE_wildcardedEntityExpression);
        let mut _localctx: Rc<WildcardedEntityExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2485);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(220,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule wildcardedNameReference*/
					recog.base.set_state(2482);
					recog.wildcardedNameReference()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule dotCompositeFunctionCallExpression*/
					recog.base.set_state(2483);
					recog.dotCompositeFunctionCallExpression()?;

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule wildcardedPathExpression*/
					recog.base.set_state(2484);
					recog.wildcardedPathExpression()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedPathExpression ----------------
pub type WildcardedPathExpressionContextAll<'input> = WildcardedPathExpressionContext<'input>;


pub type WildcardedPathExpressionContext<'input> = BaseParserRuleContext<'input,WildcardedPathExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedPathExpressionContextExt<'input>{
	pub Expression: Option<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>>,
	pub Name: Option<Rc<WildcardedPathNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedPathExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedPathExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedPathExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedPathExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedPathExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedPathExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedPathExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedPathExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedPathExpression }
}
antlr_rust::tid!{WildcardedPathExpressionContextExt<'a>}

impl<'input> WildcardedPathExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedPathExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedPathExpressionContextExt{
				Expression: None, Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedPathExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedPathExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DOT
/// Returns `None` if there is no child corresponding to token DOT
fn DOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOT, 0)
}
fn dotCompositeFunctionCallExpression(&self) -> Option<Rc<DotCompositeFunctionCallExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn wildcardedPathName(&self) -> Option<Rc<WildcardedPathNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WildcardedPathExpressionContextAttrs<'input> for WildcardedPathExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedPathExpression(&mut self,)
	-> Result<Rc<WildcardedPathExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedPathExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 488, RULE_wildcardedPathExpression);
        let mut _localctx: Rc<WildcardedPathExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule dotCompositeFunctionCallExpression*/
			recog.base.set_state(2487);
			let tmp = recog.dotCompositeFunctionCallExpression()?;
			 cast_mut::<_,WildcardedPathExpressionContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2488);
			recog.base.match_token(DOT,&mut recog.err_handler)?;

			/*InvokeRule wildcardedPathName*/
			recog.base.set_state(2489);
			let tmp = recog.wildcardedPathName()?;
			 cast_mut::<_,WildcardedPathExpressionContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedPathName ----------------
pub type WildcardedPathNameContextAll<'input> = WildcardedPathNameContext<'input>;


pub type WildcardedPathNameContext<'input> = BaseParserRuleContext<'input,WildcardedPathNameContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedPathNameContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedPathNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedPathNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedPathName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedPathName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedPathNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedPathName(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedPathNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedPathName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedPathName }
}
antlr_rust::tid!{WildcardedPathNameContextExt<'a>}

impl<'input> WildcardedPathNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedPathNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedPathNameContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedPathNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedPathNameContextExt<'input>>{

fn wildcardedName(&self) -> Option<Rc<WildcardedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn entityName(&self) -> Option<Rc<EntityNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WildcardedPathNameContextAttrs<'input> for WildcardedPathNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedPathName(&mut self,)
	-> Result<Rc<WildcardedPathNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedPathNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 490, RULE_wildcardedPathName);
        let mut _localctx: Rc<WildcardedPathNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2493);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(221,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule wildcardedName*/
					recog.base.set_state(2491);
					recog.wildcardedName()?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule entityName*/
					recog.base.set_state(2492);
					recog.entityName()?;

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- contextualDataTableExpression ----------------
pub type ContextualDataTableExpressionContextAll<'input> = ContextualDataTableExpressionContext<'input>;


pub type ContextualDataTableExpressionContext<'input> = BaseParserRuleContext<'input,ContextualDataTableExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ContextualDataTableExpressionContextExt<'input>{
	pub Id: Option<TokenType<'input>>,
	pub Schema: Option<Rc<RowSchemaContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ContextualDataTableExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ContextualDataTableExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_contextualDataTableExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_contextualDataTableExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ContextualDataTableExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_contextualDataTableExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ContextualDataTableExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_contextualDataTableExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_contextualDataTableExpression }
}
antlr_rust::tid!{ContextualDataTableExpressionContextExt<'a>}

impl<'input> ContextualDataTableExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ContextualDataTableExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ContextualDataTableExpressionContextExt{
				Id: None, 
				Schema: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ContextualDataTableExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ContextualDataTableExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token CONTEXTUAL_DATATABLE
/// Returns `None` if there is no child corresponding to token CONTEXTUAL_DATATABLE
fn CONTEXTUAL_DATATABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONTEXTUAL_DATATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token GUIDLITERAL
/// Returns `None` if there is no child corresponding to token GUIDLITERAL
fn GUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUIDLITERAL, 0)
}
fn rowSchema(&self) -> Option<Rc<RowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ContextualDataTableExpressionContextAttrs<'input> for ContextualDataTableExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn contextualDataTableExpression(&mut self,)
	-> Result<Rc<ContextualDataTableExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ContextualDataTableExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 492, RULE_contextualDataTableExpression);
        let mut _localctx: Rc<ContextualDataTableExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2495);
			recog.base.match_token(CONTEXTUAL_DATATABLE,&mut recog.err_handler)?;

			recog.base.set_state(2496);
			let tmp = recog.base.match_token(GUIDLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,ContextualDataTableExpressionContext >(&mut _localctx).Id = Some(tmp.clone());
			  

			/*InvokeRule rowSchema*/
			recog.base.set_state(2497);
			let tmp = recog.rowSchema()?;
			 cast_mut::<_,ContextualDataTableExpressionContext >(&mut _localctx).Schema = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dataTableExpression ----------------
pub type DataTableExpressionContextAll<'input> = DataTableExpressionContext<'input>;


pub type DataTableExpressionContext<'input> = BaseParserRuleContext<'input,DataTableExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DataTableExpressionContextExt<'input>{
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Schema: Option<Rc<RowSchemaContextAll<'input>>>,
	pub literalExpression: Option<Rc<LiteralExpressionContextAll<'input>>>,
	pub Values:Vec<Rc<LiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DataTableExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DataTableExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dataTableExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_dataTableExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DataTableExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_dataTableExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DataTableExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dataTableExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dataTableExpression }
}
antlr_rust::tid!{DataTableExpressionContextExt<'a>}

impl<'input> DataTableExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DataTableExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DataTableExpressionContextExt{
				relaxedQueryOperatorParameter: None, Schema: None, literalExpression: None, 
				Parameters: Vec::new(), Values: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait DataTableExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DataTableExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DATATABLE
/// Returns `None` if there is no child corresponding to token DATATABLE
fn DATATABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn rowSchema(&self) -> Option<Rc<RowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn literalExpression_all(&self) ->  Vec<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn literalExpression(&self, i: usize) -> Option<Rc<LiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> DataTableExpressionContextAttrs<'input> for DataTableExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dataTableExpression(&mut self,)
	-> Result<Rc<DataTableExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DataTableExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 494, RULE_dataTableExpression);
        let mut _localctx: Rc<DataTableExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2499);
			recog.base.match_token(DATATABLE,&mut recog.err_handler)?;

			recog.base.set_state(2503);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(2500);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DataTableExpressionContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2505);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule rowSchema*/
			recog.base.set_state(2506);
			let tmp = recog.rowSchema()?;
			 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).Schema = Some(tmp.clone());
			  

			recog.base.set_state(2507);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			recog.base.set_state(2509);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DASH || _la==PLUS || ((((_la - 285)) & !0x3f) == 0 && ((1usize << (_la - 285)) & ((1usize << (DYNAMIC - 285)) | (1usize << (LONGLITERAL - 285)) | (1usize << (INTLITERAL - 285)) | (1usize << (REALLITERAL - 285)) | (1usize << (DECIMALLITERAL - 285)) | (1usize << (STRINGLITERAL - 285)) | (1usize << (BOOLEANLITERAL - 285)) | (1usize << (DATETIMELITERAL - 285)) | (1usize << (TIMESPANLITERAL - 285)) | (1usize << (TYPELITERAL - 285)) | (1usize << (GUIDLITERAL - 285)))) != 0) {
				{
				/*InvokeRule literalExpression*/
				recog.base.set_state(2508);
				let tmp = recog.literalExpression()?;
				 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).literalExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,DataTableExpressionContext >(&mut _localctx).literalExpression.clone().unwrap()
				 ;
				 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).Values.push(temp);
				  
				}
			}

			recog.base.set_state(2515);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(224,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2511);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule literalExpression*/
					recog.base.set_state(2512);
					let tmp = recog.literalExpression()?;
					 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).literalExpression = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,DataTableExpressionContext >(&mut _localctx).literalExpression.clone().unwrap()
					 ;
					 cast_mut::<_,DataTableExpressionContext >(&mut _localctx).Values.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2517);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(224,&mut recog.base)?;
			}
			recog.base.set_state(2519);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2518);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2521);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowSchema ----------------
pub type RowSchemaContextAll<'input> = RowSchemaContext<'input>;


pub type RowSchemaContext<'input> = BaseParserRuleContext<'input,RowSchemaContextExt<'input>>;

#[derive(Clone)]
pub struct RowSchemaContextExt<'input>{
	pub rowSchemaColumnDeclaration: Option<Rc<RowSchemaColumnDeclarationContextAll<'input>>>,
	pub Columns:Vec<Rc<RowSchemaColumnDeclarationContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RowSchemaContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RowSchemaContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowSchema(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_rowSchema(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RowSchemaContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_rowSchema(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowSchemaContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowSchema }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowSchema }
}
antlr_rust::tid!{RowSchemaContextExt<'a>}

impl<'input> RowSchemaContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowSchemaContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowSchemaContextExt{
				rowSchemaColumnDeclaration: None, 
				Columns: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait RowSchemaContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RowSchemaContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn rowSchemaColumnDeclaration_all(&self) ->  Vec<Rc<RowSchemaColumnDeclarationContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn rowSchemaColumnDeclaration(&self, i: usize) -> Option<Rc<RowSchemaColumnDeclarationContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> RowSchemaContextAttrs<'input> for RowSchemaContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowSchema(&mut self,)
	-> Result<Rc<RowSchemaContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowSchemaContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 496, RULE_rowSchema);
        let mut _localctx: Rc<RowSchemaContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2523);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2525);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (ACCUMULATE - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AS - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (BY - 30)) | (1usize << (CLUSTER - 30)) | (1usize << (CONSUME - 30)))) != 0) || ((((_la - 62)) & !0x3f) == 0 && ((1usize << (_la - 62)) & ((1usize << (CONTAINS - 62)) | (1usize << (COUNT - 62)) | (1usize << (DATABASE - 62)) | (1usize << (DATATABLE - 62)) | (1usize << (DECLARE - 62)) | (1usize << (DEFAULT - 62)) | (1usize << (DELTA - 62)) | (1usize << (DISTINCT - 62)) | (1usize << (EDGES - 62)) | (1usize << (EVALUATE - 62)) | (1usize << (EXECUTE - 62)) | (1usize << (EXTEND - 62)) | (1usize << (EXTERNALDATA - 62)) | (1usize << (FACET - 62)) | (1usize << (FILTER - 62)) | (1usize << (FIND - 62)))) != 0) || ((((_la - 94)) & !0x3f) == 0 && ((1usize << (_la - 94)) & ((1usize << (FORK - 94)) | (1usize << (FROM - 94)) | (1usize << (HAS - 94)) | (1usize << (HIDDEN_ - 94)) | (1usize << (HOT - 94)))) != 0) || ((((_la - 126)) & !0x3f) == 0 && ((1usize << (_la - 126)) & ((1usize << (HOTDATA - 126)) | (1usize << (HOTINDEX - 126)) | (1usize << (ID - 126)) | (1usize << (IN - 126)) | (1usize << (INTO - 126)) | (1usize << (INVOKE - 126)) | (1usize << (LEGEND - 126)) | (1usize << (LET - 126)) | (1usize << (LIMIT - 126)) | (1usize << (LINEAR - 126)) | (1usize << (LIST - 126)) | (1usize << (LOOKUP - 126)) | (1usize << (LOG - 126)) | (1usize << (MAP - 126)) | (1usize << (MATERIALIZE - 126)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (NODES - 161)) | (1usize << (NONE - 161)) | (1usize << (NULL - 161)) | (1usize << (NULLS - 161)) | (1usize << (OF - 161)) | (1usize << (ON - 161)) | (1usize << (OPTIONAL - 161)) | (1usize << (OUTPUT - 161)) | (1usize << (PACK - 161)))) != 0) || ((((_la - 194)) & !0x3f) == 0 && ((1usize << (_la - 194)) & ((1usize << (PARSE - 194)) | (1usize << (PARTITION - 194)) | (1usize << (PARTITIONBY - 194)) | (1usize << (PATTERN - 194)) | (1usize << (PLUGIN - 194)) | (1usize << (PRINT - 194)) | (1usize << (QUERYPARAMETERS - 194)) | (1usize << (RANGE - 194)) | (1usize << (REDUCE - 194)) | (1usize << (RENDER - 194)) | (1usize << (REPLACE - 194)) | (1usize << (RESTRICT - 194)) | (1usize << (SAMPLE - 194)) | (1usize << (SAMPLE_DISTINCT - 194)) | (1usize << (SCAN - 194)) | (1usize << (SEARCH - 194)))) != 0) || ((((_la - 226)) & !0x3f) == 0 && ((1usize << (_la - 226)) & ((1usize << (SERIALIZE - 226)) | (1usize << (SERIES - 226)) | (1usize << (SET - 226)) | (1usize << (SORT - 226)) | (1usize << (STACKED - 226)) | (1usize << (STACKED100 - 226)) | (1usize << (STEP - 226)) | (1usize << (SUMMARIZE - 226)) | (1usize << (TAKE - 226)) | (1usize << (THRESHOLD - 226)) | (1usize << (TITLE - 226)) | (1usize << (TO - 226)) | (1usize << (TOP - 226)) | (1usize << (TOP_HITTERS - 226)) | (1usize << (TOP_NESTED - 226)) | (1usize << (TOSCALAR - 226)) | (1usize << (TOTABLE - 226)) | (1usize << (TYPEOF - 226)) | (1usize << (UNSTACKED - 226)) | (1usize << (UUID - 226)) | (1usize << (VIEW - 226)))) != 0) || ((((_la - 258)) & !0x3f) == 0 && ((1usize << (_la - 258)) & ((1usize << (VISIBLE - 258)) | (1usize << (WHERE - 258)) | (1usize << (WITH - 258)) | (1usize << (XAXIS - 258)) | (1usize << (XCOLUMN - 258)) | (1usize << (XMAX - 258)) | (1usize << (XMIN - 258)) | (1usize << (XTITLE - 258)) | (1usize << (YAXIS - 258)) | (1usize << (YCOLUMNS - 258)) | (1usize << (YMAX - 258)) | (1usize << (YMIN - 258)) | (1usize << (YSPLIT - 258)) | (1usize << (YTITLE - 258)) | (1usize << (BOOL - 258)) | (1usize << (GUID - 258)))) != 0) || _la==IDENTIFIER {
				{
				/*InvokeRule rowSchemaColumnDeclaration*/
				recog.base.set_state(2524);
				let tmp = recog.rowSchemaColumnDeclaration()?;
				 cast_mut::<_,RowSchemaContext >(&mut _localctx).rowSchemaColumnDeclaration = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,RowSchemaContext >(&mut _localctx).rowSchemaColumnDeclaration.clone().unwrap()
				 ;
				 cast_mut::<_,RowSchemaContext >(&mut _localctx).Columns.push(temp);
				  
				}
			}

			recog.base.set_state(2531);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(227,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2527);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule rowSchemaColumnDeclaration*/
					recog.base.set_state(2528);
					let tmp = recog.rowSchemaColumnDeclaration()?;
					 cast_mut::<_,RowSchemaContext >(&mut _localctx).rowSchemaColumnDeclaration = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,RowSchemaContext >(&mut _localctx).rowSchemaColumnDeclaration.clone().unwrap()
					 ;
					 cast_mut::<_,RowSchemaContext >(&mut _localctx).Columns.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2533);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(227,&mut recog.base)?;
			}
			recog.base.set_state(2535);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==COMMA {
				{
				recog.base.set_state(2534);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				}
			}

			recog.base.set_state(2537);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- rowSchemaColumnDeclaration ----------------
pub type RowSchemaColumnDeclarationContextAll<'input> = RowSchemaColumnDeclarationContext<'input>;


pub type RowSchemaColumnDeclarationContext<'input> = BaseParserRuleContext<'input,RowSchemaColumnDeclarationContextExt<'input>>;

#[derive(Clone)]
pub struct RowSchemaColumnDeclarationContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub Type: Option<Rc<ScalarTypeContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RowSchemaColumnDeclarationContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RowSchemaColumnDeclarationContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_rowSchemaColumnDeclaration(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_rowSchemaColumnDeclaration(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RowSchemaColumnDeclarationContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_rowSchemaColumnDeclaration(self);
	}
}

impl<'input> CustomRuleContext<'input> for RowSchemaColumnDeclarationContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_rowSchemaColumnDeclaration }
	//fn type_rule_index() -> usize where Self: Sized { RULE_rowSchemaColumnDeclaration }
}
antlr_rust::tid!{RowSchemaColumnDeclarationContextExt<'a>}

impl<'input> RowSchemaColumnDeclarationContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RowSchemaColumnDeclarationContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RowSchemaColumnDeclarationContextExt{
				Name: None, Type: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RowSchemaColumnDeclarationContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RowSchemaColumnDeclarationContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
fn parameterName(&self) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn scalarType(&self) -> Option<Rc<ScalarTypeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> RowSchemaColumnDeclarationContextAttrs<'input> for RowSchemaColumnDeclarationContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn rowSchemaColumnDeclaration(&mut self,)
	-> Result<Rc<RowSchemaColumnDeclarationContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RowSchemaColumnDeclarationContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 498, RULE_rowSchemaColumnDeclaration);
        let mut _localctx: Rc<RowSchemaColumnDeclarationContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(2539);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,RowSchemaColumnDeclarationContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2540);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule scalarType*/
			recog.base.set_state(2541);
			let tmp = recog.scalarType()?;
			 cast_mut::<_,RowSchemaColumnDeclarationContext >(&mut _localctx).Type = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- externalDataExpression ----------------
pub type ExternalDataExpressionContextAll<'input> = ExternalDataExpressionContext<'input>;


pub type ExternalDataExpressionContext<'input> = BaseParserRuleContext<'input,ExternalDataExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct ExternalDataExpressionContextExt<'input>{
	pub Keyword: Option<TokenType<'input>>,
	pub relaxedQueryOperatorParameter: Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Parameters:Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>>,
	pub Schema: Option<Rc<RowSchemaContextAll<'input>>>,
	pub stringLiteralExpression: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub ConnectionStrings:Vec<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub WithClause: Option<Rc<ExternalDataWithClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExternalDataExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExternalDataExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_externalDataExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_externalDataExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExternalDataExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_externalDataExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExternalDataExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_externalDataExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_externalDataExpression }
}
antlr_rust::tid!{ExternalDataExpressionContextExt<'a>}

impl<'input> ExternalDataExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExternalDataExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExternalDataExpressionContextExt{
				Keyword: None, 
				relaxedQueryOperatorParameter: None, Schema: None, stringLiteralExpression: None, WithClause: None, 
				Parameters: Vec::new(), ConnectionStrings: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExternalDataExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExternalDataExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn rowSchema(&self) -> Option<Rc<RowSchemaContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLiteralExpression_all(&self) ->  Vec<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn stringLiteralExpression(&self, i: usize) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves first TerminalNode corresponding to token EXTERNALDATA
/// Returns `None` if there is no child corresponding to token EXTERNALDATA
fn EXTERNALDATA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXTERNALDATA, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNAL_DATA
/// Returns `None` if there is no child corresponding to token EXTERNAL_DATA
fn EXTERNAL_DATA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXTERNAL_DATA, 0)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}
fn relaxedQueryOperatorParameter_all(&self) ->  Vec<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn relaxedQueryOperatorParameter(&self, i: usize) -> Option<Rc<RelaxedQueryOperatorParameterContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn externalDataWithClause(&self) -> Option<Rc<ExternalDataWithClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExternalDataExpressionContextAttrs<'input> for ExternalDataExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn externalDataExpression(&mut self,)
	-> Result<Rc<ExternalDataExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExternalDataExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 500, RULE_externalDataExpression);
        let mut _localctx: Rc<ExternalDataExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2543);
			 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).Keyword = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==EXTERNALDATA || _la==EXTERNAL_DATA) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).Keyword = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2547);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while ((((_la - 51)) & !0x3f) == 0 && ((1usize << (_la - 51)) & ((1usize << (BAGEXPANSION - 51)) | (1usize << (BIN_LEGACY - 51)) | (1usize << (CROSSCLUSTER__ - 51)) | (1usize << (CROSSDB__ - 51)) | (1usize << (DECODEBLOCKS - 51)))) != 0) || ((((_la - 85)) & !0x3f) == 0 && ((1usize << (_la - 85)) & ((1usize << (EXPANDOUTPUT - 85)) | (1usize << (HINT_CONCURRENCY - 85)) | (1usize << (HINT_DISTRIBUTION - 85)) | (1usize << (HINT_MATERIALIZED - 85)) | (1usize << (HINT_NUM_PARTITIONS - 85)))) != 0) || ((((_la - 117)) & !0x3f) == 0 && ((1usize << (_la - 117)) & ((1usize << (HINT_PASS_FILTERS - 117)) | (1usize << (HINT_PASS_FILTERS_COLUMN - 117)) | (1usize << (HINT_PROGRESSIVE_TOP - 117)) | (1usize << (HINT_REMOTE - 117)) | (1usize << (HINT_SUFFLEKEY - 117)) | (1usize << (HINT_SPREAD - 117)) | (1usize << (HINT_STRATEGY - 117)) | (1usize << (ID__ - 117)) | (1usize << (ISFUZZY - 117)) | (1usize << (ISFUZZY__ - 117)) | (1usize << (KIND - 117)))) != 0) || _la==PACKEDCOLUMN__ || _la==SOURCECOLUMNINDEX__ || ((((_la - 261)) & !0x3f) == 0 && ((1usize << (_la - 261)) & ((1usize << (WITHNOSOURCE__ - 261)) | (1usize << (WITHSOURCE - 261)) | (1usize << (WITH_ITEM_INDEX - 261)) | (1usize << (WITH_MATCH_ID - 261)) | (1usize << (WITH_SOURCE - 261)) | (1usize << (WITH_STEP_NAME - 261)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule relaxedQueryOperatorParameter*/
				recog.base.set_state(2544);
				let tmp = recog.relaxedQueryOperatorParameter()?;
				 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).relaxedQueryOperatorParameter = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).relaxedQueryOperatorParameter.clone().unwrap()
				 ;
				 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).Parameters.push(temp);
				  
				}
				}
				recog.base.set_state(2549);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			/*InvokeRule rowSchema*/
			recog.base.set_state(2550);
			let tmp = recog.rowSchema()?;
			 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).Schema = Some(tmp.clone());
			  

			recog.base.set_state(2551);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule stringLiteralExpression*/
			recog.base.set_state(2552);
			let tmp = recog.stringLiteralExpression()?;
			 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).stringLiteralExpression = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).stringLiteralExpression.clone().unwrap()
			 ;
			 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).ConnectionStrings.push(temp);
			  
			recog.base.set_state(2557);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==COMMA {
				{
				{
				recog.base.set_state(2553);
				recog.base.match_token(COMMA,&mut recog.err_handler)?;

				/*InvokeRule stringLiteralExpression*/
				recog.base.set_state(2554);
				let tmp = recog.stringLiteralExpression()?;
				 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).stringLiteralExpression = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).stringLiteralExpression.clone().unwrap()
				 ;
				 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).ConnectionStrings.push(temp);
				  
				}
				}
				recog.base.set_state(2559);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			recog.base.set_state(2560);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			recog.base.set_state(2562);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(231,&mut recog.base)? {
				x if x == 1=>{
					{
					/*InvokeRule externalDataWithClause*/
					recog.base.set_state(2561);
					let tmp = recog.externalDataWithClause()?;
					 cast_mut::<_,ExternalDataExpressionContext >(&mut _localctx).WithClause = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- externalDataWithClause ----------------
pub type ExternalDataWithClauseContextAll<'input> = ExternalDataWithClauseContext<'input>;


pub type ExternalDataWithClauseContext<'input> = BaseParserRuleContext<'input,ExternalDataWithClauseContextExt<'input>>;

#[derive(Clone)]
pub struct ExternalDataWithClauseContextExt<'input>{
	pub externalDataWithClauseProperty: Option<Rc<ExternalDataWithClausePropertyContextAll<'input>>>,
	pub Properties:Vec<Rc<ExternalDataWithClausePropertyContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExternalDataWithClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExternalDataWithClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_externalDataWithClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_externalDataWithClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExternalDataWithClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_externalDataWithClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExternalDataWithClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_externalDataWithClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_externalDataWithClause }
}
antlr_rust::tid!{ExternalDataWithClauseContextExt<'a>}

impl<'input> ExternalDataWithClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExternalDataWithClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExternalDataWithClauseContextExt{
				externalDataWithClauseProperty: None, 
				Properties: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExternalDataWithClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExternalDataWithClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn externalDataWithClauseProperty_all(&self) ->  Vec<Rc<ExternalDataWithClausePropertyContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn externalDataWithClauseProperty(&self, i: usize) -> Option<Rc<ExternalDataWithClausePropertyContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> ExternalDataWithClauseContextAttrs<'input> for ExternalDataWithClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn externalDataWithClause(&mut self,)
	-> Result<Rc<ExternalDataWithClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExternalDataWithClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 502, RULE_externalDataWithClause);
        let mut _localctx: Rc<ExternalDataWithClauseContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2564);
			recog.base.match_token(WITH,&mut recog.err_handler)?;

			recog.base.set_state(2565);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			recog.base.set_state(2577);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 30)) & !0x3f) == 0 && ((1usize << (_la - 30)) & ((1usize << (OPENBRACKET - 30)) | (1usize << (ACCESS - 30)) | (1usize << (ACCUMULATE - 30)) | (1usize << (AGGREGATIONS - 30)) | (1usize << (ALIAS - 30)) | (1usize << (ALL - 30)) | (1usize << (AS - 30)) | (1usize << (AXES - 30)) | (1usize << (BASE - 30)) | (1usize << (BIN - 30)) | (1usize << (BY - 30)) | (1usize << (CLUSTER - 30)) | (1usize << (CONSUME - 30)))) != 0) || ((((_la - 62)) & !0x3f) == 0 && ((1usize << (_la - 62)) & ((1usize << (CONTAINS - 62)) | (1usize << (COUNT - 62)) | (1usize << (DATABASE - 62)) | (1usize << (DATATABLE - 62)) | (1usize << (DECLARE - 62)) | (1usize << (DEFAULT - 62)) | (1usize << (DELTA - 62)) | (1usize << (DISTINCT - 62)) | (1usize << (EDGES - 62)) | (1usize << (EVALUATE - 62)) | (1usize << (EXECUTE - 62)) | (1usize << (EXTEND - 62)) | (1usize << (EXTERNALDATA - 62)) | (1usize << (FACET - 62)) | (1usize << (FILTER - 62)) | (1usize << (FIND - 62)))) != 0) || ((((_la - 94)) & !0x3f) == 0 && ((1usize << (_la - 94)) & ((1usize << (FORK - 94)) | (1usize << (FROM - 94)) | (1usize << (HAS - 94)) | (1usize << (HIDDEN_ - 94)) | (1usize << (HOT - 94)))) != 0) || ((((_la - 126)) & !0x3f) == 0 && ((1usize << (_la - 126)) & ((1usize << (HOTDATA - 126)) | (1usize << (HOTINDEX - 126)) | (1usize << (ID - 126)) | (1usize << (IN - 126)) | (1usize << (INTO - 126)) | (1usize << (INVOKE - 126)) | (1usize << (LEGEND - 126)) | (1usize << (LET - 126)) | (1usize << (LIMIT - 126)) | (1usize << (LINEAR - 126)) | (1usize << (LIST - 126)) | (1usize << (LOOKUP - 126)) | (1usize << (LOG - 126)) | (1usize << (MAP - 126)) | (1usize << (MATERIALIZE - 126)))) != 0) || ((((_la - 161)) & !0x3f) == 0 && ((1usize << (_la - 161)) & ((1usize << (NODES - 161)) | (1usize << (NONE - 161)) | (1usize << (NULL - 161)) | (1usize << (NULLS - 161)) | (1usize << (OF - 161)) | (1usize << (ON - 161)) | (1usize << (OPTIONAL - 161)) | (1usize << (OUTPUT - 161)) | (1usize << (PACK - 161)))) != 0) || ((((_la - 194)) & !0x3f) == 0 && ((1usize << (_la - 194)) & ((1usize << (PARSE - 194)) | (1usize << (PARTITION - 194)) | (1usize << (PARTITIONBY - 194)) | (1usize << (PATTERN - 194)) | (1usize << (PLUGIN - 194)) | (1usize << (PRINT - 194)) | (1usize << (QUERYPARAMETERS - 194)) | (1usize << (RANGE - 194)) | (1usize << (REDUCE - 194)) | (1usize << (RENDER - 194)) | (1usize << (REPLACE - 194)) | (1usize << (RESTRICT - 194)) | (1usize << (SAMPLE - 194)) | (1usize << (SAMPLE_DISTINCT - 194)) | (1usize << (SCAN - 194)) | (1usize << (SEARCH - 194)))) != 0) || ((((_la - 226)) & !0x3f) == 0 && ((1usize << (_la - 226)) & ((1usize << (SERIALIZE - 226)) | (1usize << (SERIES - 226)) | (1usize << (SET - 226)) | (1usize << (SORT - 226)) | (1usize << (STACKED - 226)) | (1usize << (STACKED100 - 226)) | (1usize << (STEP - 226)) | (1usize << (SUMMARIZE - 226)) | (1usize << (TAKE - 226)) | (1usize << (THRESHOLD - 226)) | (1usize << (TITLE - 226)) | (1usize << (TO - 226)) | (1usize << (TOP - 226)) | (1usize << (TOP_HITTERS - 226)) | (1usize << (TOP_NESTED - 226)) | (1usize << (TOSCALAR - 226)) | (1usize << (TOTABLE - 226)) | (1usize << (TYPEOF - 226)) | (1usize << (UNSTACKED - 226)) | (1usize << (UUID - 226)) | (1usize << (VIEW - 226)))) != 0) || ((((_la - 258)) & !0x3f) == 0 && ((1usize << (_la - 258)) & ((1usize << (VISIBLE - 258)) | (1usize << (WHERE - 258)) | (1usize << (WITH - 258)) | (1usize << (XAXIS - 258)) | (1usize << (XCOLUMN - 258)) | (1usize << (XMAX - 258)) | (1usize << (XMIN - 258)) | (1usize << (XTITLE - 258)) | (1usize << (YAXIS - 258)) | (1usize << (YCOLUMNS - 258)) | (1usize << (YMAX - 258)) | (1usize << (YMIN - 258)) | (1usize << (YSPLIT - 258)) | (1usize << (YTITLE - 258)) | (1usize << (BOOL - 258)) | (1usize << (GUID - 258)))) != 0) || _la==IDENTIFIER {
				{
				/*InvokeRule externalDataWithClauseProperty*/
				recog.base.set_state(2566);
				let tmp = recog.externalDataWithClauseProperty()?;
				 cast_mut::<_,ExternalDataWithClauseContext >(&mut _localctx).externalDataWithClauseProperty = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,ExternalDataWithClauseContext >(&mut _localctx).externalDataWithClauseProperty.clone().unwrap()
				 ;
				 cast_mut::<_,ExternalDataWithClauseContext >(&mut _localctx).Properties.push(temp);
				  
				recog.base.set_state(2571);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(232,&mut recog.base)?;
				while { _alt!=2 && _alt!=INVALID_ALT } {
					if _alt==1 {
						{
						{
						recog.base.set_state(2567);
						recog.base.match_token(COMMA,&mut recog.err_handler)?;

						/*InvokeRule externalDataWithClauseProperty*/
						recog.base.set_state(2568);
						let tmp = recog.externalDataWithClauseProperty()?;
						 cast_mut::<_,ExternalDataWithClauseContext >(&mut _localctx).externalDataWithClauseProperty = Some(tmp.clone());
						  

						let temp =  cast_mut::<_,ExternalDataWithClauseContext >(&mut _localctx).externalDataWithClauseProperty.clone().unwrap()
						 ;
						 cast_mut::<_,ExternalDataWithClauseContext >(&mut _localctx).Properties.push(temp);
						  
						}
						} 
					}
					recog.base.set_state(2573);
					recog.err_handler.sync(&mut recog.base)?;
					_alt = recog.interpreter.adaptive_predict(232,&mut recog.base)?;
				}
				recog.base.set_state(2575);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				if _la==COMMA {
					{
					recog.base.set_state(2574);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					}
				}

				}
			}

			recog.base.set_state(2579);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- externalDataWithClauseProperty ----------------
pub type ExternalDataWithClausePropertyContextAll<'input> = ExternalDataWithClausePropertyContext<'input>;


pub type ExternalDataWithClausePropertyContext<'input> = BaseParserRuleContext<'input,ExternalDataWithClausePropertyContextExt<'input>>;

#[derive(Clone)]
pub struct ExternalDataWithClausePropertyContextExt<'input>{
	pub Name: Option<Rc<ParameterNameContextAll<'input>>>,
	pub StringValue: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub TokenValue: Option<TokenType<'input>>,
	pub NameValue: Option<Rc<ParameterNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExternalDataWithClausePropertyContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExternalDataWithClausePropertyContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_externalDataWithClauseProperty(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_externalDataWithClauseProperty(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExternalDataWithClausePropertyContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_externalDataWithClauseProperty(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExternalDataWithClausePropertyContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_externalDataWithClauseProperty }
	//fn type_rule_index() -> usize where Self: Sized { RULE_externalDataWithClauseProperty }
}
antlr_rust::tid!{ExternalDataWithClausePropertyContextExt<'a>}

impl<'input> ExternalDataWithClausePropertyContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExternalDataWithClausePropertyContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExternalDataWithClausePropertyContextExt{
				TokenValue: None, 
				Name: None, StringValue: None, NameValue: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExternalDataWithClausePropertyContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExternalDataWithClausePropertyContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token EQUAL
/// Returns `None` if there is no child corresponding to token EQUAL
fn EQUAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EQUAL, 0)
}
fn parameterName_all(&self) ->  Vec<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn parameterName(&self, i: usize) -> Option<Rc<ParameterNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LONGLITERAL
/// Returns `None` if there is no child corresponding to token LONGLITERAL
fn LONGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONGLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token REALLITERAL
/// Returns `None` if there is no child corresponding to token REALLITERAL
fn REALLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REALLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEANLITERAL
/// Returns `None` if there is no child corresponding to token BOOLEANLITERAL
fn BOOLEANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEANLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIMELITERAL
/// Returns `None` if there is no child corresponding to token DATETIMELITERAL
fn DATETIMELITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATETIMELITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPELITERAL
/// Returns `None` if there is no child corresponding to token TYPELITERAL
fn TYPELITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TYPELITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token GUIDLITERAL
/// Returns `None` if there is no child corresponding to token GUIDLITERAL
fn GUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUIDLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token RAWGUIDLITERAL
/// Returns `None` if there is no child corresponding to token RAWGUIDLITERAL
fn RAWGUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RAWGUIDLITERAL, 0)
}

}

impl<'input> ExternalDataWithClausePropertyContextAttrs<'input> for ExternalDataWithClausePropertyContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn externalDataWithClauseProperty(&mut self,)
	-> Result<Rc<ExternalDataWithClausePropertyContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExternalDataWithClausePropertyContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 504, RULE_externalDataWithClauseProperty);
        let mut _localctx: Rc<ExternalDataWithClausePropertyContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule parameterName*/
			recog.base.set_state(2581);
			let tmp = recog.parameterName()?;
			 cast_mut::<_,ExternalDataWithClausePropertyContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2582);
			recog.base.match_token(EQUAL,&mut recog.err_handler)?;

			recog.base.set_state(2586);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 STRINGLITERAL 
				=> {
					{
					/*InvokeRule stringLiteralExpression*/
					recog.base.set_state(2583);
					let tmp = recog.stringLiteralExpression()?;
					 cast_mut::<_,ExternalDataWithClausePropertyContext >(&mut _localctx).StringValue = Some(tmp.clone());
					  

					}
				}

			 LONGLITERAL | REALLITERAL | BOOLEANLITERAL | DATETIMELITERAL | TYPELITERAL |
			 RAWGUIDLITERAL | GUIDLITERAL 
				=> {
					{
					recog.base.set_state(2584);
					 cast_mut::<_,ExternalDataWithClausePropertyContext >(&mut _localctx).TokenValue = recog.base.input.lt(1).cloned();
					 
					_la = recog.base.input.la(1);
					if { !(((((_la - 305)) & !0x3f) == 0 && ((1usize << (_la - 305)) & ((1usize << (LONGLITERAL - 305)) | (1usize << (REALLITERAL - 305)) | (1usize << (BOOLEANLITERAL - 305)) | (1usize << (DATETIMELITERAL - 305)) | (1usize << (TYPELITERAL - 305)) | (1usize << (RAWGUIDLITERAL - 305)) | (1usize << (GUIDLITERAL - 305)))) != 0)) } {
						let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
						 cast_mut::<_,ExternalDataWithClausePropertyContext >(&mut _localctx).TokenValue = Some(tmp.clone());
						  

					}
					else {
						if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
						recog.err_handler.report_match(&mut recog.base);
						recog.base.consume(&mut recog.err_handler);
					}
					}
				}

			 OPENBRACKET | ACCESS | ACCUMULATE | AGGREGATIONS | ALIAS | ALL | AS |
			 AXES | BASE | BIN | BY | CLUSTER | CONSUME | CONTAINS | COUNT | DATABASE |
			 DATATABLE | DECLARE | DEFAULT | DELTA | DISTINCT | EDGES | EVALUATE |
			 EXECUTE | EXTEND | EXTERNALDATA | FACET | FILTER | FIND | FORK | FROM |
			 HAS | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | IN | INTO | INVOKE |
			 LEGEND | LET | LIMIT | LINEAR | LIST | LOOKUP | LOG | MAP | MATERIALIZE |
			 NODES | NONE | NULL | NULLS | OF | ON | OPTIONAL | OUTPUT | PACK | PARSE |
			 PARTITION | PARTITIONBY | PATTERN | PLUGIN | PRINT | QUERYPARAMETERS |
			 RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SAMPLE | SAMPLE_DISTINCT |
			 SCAN | SEARCH | SERIALIZE | SERIES | SET | SORT | STACKED | STACKED100 |
			 STEP | SUMMARIZE | TAKE | THRESHOLD | TITLE | TO | TOP | TOP_HITTERS |
			 TOP_NESTED | TOSCALAR | TOTABLE | TYPEOF | UNSTACKED | UUID | VIEW |
			 VISIBLE | WHERE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID | IDENTIFIER 
				=> {
					{
					/*InvokeRule parameterName*/
					recog.base.set_state(2585);
					let tmp = recog.parameterName()?;
					 cast_mut::<_,ExternalDataWithClausePropertyContext >(&mut _localctx).NameValue = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- materializedViewCombineExpression ----------------
pub type MaterializedViewCombineExpressionContextAll<'input> = MaterializedViewCombineExpressionContext<'input>;


pub type MaterializedViewCombineExpressionContext<'input> = BaseParserRuleContext<'input,MaterializedViewCombineExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct MaterializedViewCombineExpressionContextExt<'input>{
	pub Name: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub BaseClause: Option<Rc<MaterializeViewCombineBaseClauseContextAll<'input>>>,
	pub DeltaClause: Option<Rc<MaterializedViewCombineDeltaClauseContextAll<'input>>>,
	pub AggregationsClause: Option<Rc<MaterializedViewCombineAggregationsClauseContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MaterializedViewCombineExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MaterializedViewCombineExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_materializedViewCombineExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_materializedViewCombineExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MaterializedViewCombineExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_materializedViewCombineExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaterializedViewCombineExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_materializedViewCombineExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_materializedViewCombineExpression }
}
antlr_rust::tid!{MaterializedViewCombineExpressionContextExt<'a>}

impl<'input> MaterializedViewCombineExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaterializedViewCombineExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaterializedViewCombineExpressionContextExt{
				Name: None, BaseClause: None, DeltaClause: None, AggregationsClause: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MaterializedViewCombineExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MaterializedViewCombineExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token MATERIALIZED_VIEW_COMBINE
/// Returns `None` if there is no child corresponding to token MATERIALIZED_VIEW_COMBINE
fn MATERIALIZED_VIEW_COMBINE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZED_VIEW_COMBINE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn materializeViewCombineBaseClause(&self) -> Option<Rc<MaterializeViewCombineBaseClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn materializedViewCombineDeltaClause(&self) -> Option<Rc<MaterializedViewCombineDeltaClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn materializedViewCombineAggregationsClause(&self) -> Option<Rc<MaterializedViewCombineAggregationsClauseContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MaterializedViewCombineExpressionContextAttrs<'input> for MaterializedViewCombineExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn materializedViewCombineExpression(&mut self,)
	-> Result<Rc<MaterializedViewCombineExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaterializedViewCombineExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 506, RULE_materializedViewCombineExpression);
        let mut _localctx: Rc<MaterializedViewCombineExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2588);
			recog.base.match_token(MATERIALIZED_VIEW_COMBINE,&mut recog.err_handler)?;

			recog.base.set_state(2589);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule stringLiteralExpression*/
			recog.base.set_state(2590);
			let tmp = recog.stringLiteralExpression()?;
			 cast_mut::<_,MaterializedViewCombineExpressionContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2591);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			/*InvokeRule materializeViewCombineBaseClause*/
			recog.base.set_state(2592);
			let tmp = recog.materializeViewCombineBaseClause()?;
			 cast_mut::<_,MaterializedViewCombineExpressionContext >(&mut _localctx).BaseClause = Some(tmp.clone());
			  

			/*InvokeRule materializedViewCombineDeltaClause*/
			recog.base.set_state(2593);
			let tmp = recog.materializedViewCombineDeltaClause()?;
			 cast_mut::<_,MaterializedViewCombineExpressionContext >(&mut _localctx).DeltaClause = Some(tmp.clone());
			  

			/*InvokeRule materializedViewCombineAggregationsClause*/
			recog.base.set_state(2594);
			let tmp = recog.materializedViewCombineAggregationsClause()?;
			 cast_mut::<_,MaterializedViewCombineExpressionContext >(&mut _localctx).AggregationsClause = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- materializeViewCombineBaseClause ----------------
pub type MaterializeViewCombineBaseClauseContextAll<'input> = MaterializeViewCombineBaseClauseContext<'input>;


pub type MaterializeViewCombineBaseClauseContext<'input> = BaseParserRuleContext<'input,MaterializeViewCombineBaseClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MaterializeViewCombineBaseClauseContextExt<'input>{
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MaterializeViewCombineBaseClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MaterializeViewCombineBaseClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_materializeViewCombineBaseClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_materializeViewCombineBaseClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MaterializeViewCombineBaseClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_materializeViewCombineBaseClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaterializeViewCombineBaseClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_materializeViewCombineBaseClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_materializeViewCombineBaseClause }
}
antlr_rust::tid!{MaterializeViewCombineBaseClauseContextExt<'a>}

impl<'input> MaterializeViewCombineBaseClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaterializeViewCombineBaseClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaterializeViewCombineBaseClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MaterializeViewCombineBaseClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MaterializeViewCombineBaseClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BASE
/// Returns `None` if there is no child corresponding to token BASE
fn BASE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BASE, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MaterializeViewCombineBaseClauseContextAttrs<'input> for MaterializeViewCombineBaseClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn materializeViewCombineBaseClause(&mut self,)
	-> Result<Rc<MaterializeViewCombineBaseClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaterializeViewCombineBaseClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 508, RULE_materializeViewCombineBaseClause);
        let mut _localctx: Rc<MaterializeViewCombineBaseClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2596);
			recog.base.match_token(BASE,&mut recog.err_handler)?;

			recog.base.set_state(2597);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2598);
			let tmp = recog.expression()?;
			 cast_mut::<_,MaterializeViewCombineBaseClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2599);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- materializedViewCombineDeltaClause ----------------
pub type MaterializedViewCombineDeltaClauseContextAll<'input> = MaterializedViewCombineDeltaClauseContext<'input>;


pub type MaterializedViewCombineDeltaClauseContext<'input> = BaseParserRuleContext<'input,MaterializedViewCombineDeltaClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MaterializedViewCombineDeltaClauseContextExt<'input>{
	pub Expression: Option<Rc<ExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MaterializedViewCombineDeltaClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MaterializedViewCombineDeltaClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_materializedViewCombineDeltaClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_materializedViewCombineDeltaClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MaterializedViewCombineDeltaClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_materializedViewCombineDeltaClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaterializedViewCombineDeltaClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_materializedViewCombineDeltaClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_materializedViewCombineDeltaClause }
}
antlr_rust::tid!{MaterializedViewCombineDeltaClauseContextExt<'a>}

impl<'input> MaterializedViewCombineDeltaClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaterializedViewCombineDeltaClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaterializedViewCombineDeltaClauseContextExt{
				Expression: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MaterializedViewCombineDeltaClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MaterializedViewCombineDeltaClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DELTA
/// Returns `None` if there is no child corresponding to token DELTA
fn DELTA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DELTA, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn expression(&self) -> Option<Rc<ExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MaterializedViewCombineDeltaClauseContextAttrs<'input> for MaterializedViewCombineDeltaClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn materializedViewCombineDeltaClause(&mut self,)
	-> Result<Rc<MaterializedViewCombineDeltaClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaterializedViewCombineDeltaClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 510, RULE_materializedViewCombineDeltaClause);
        let mut _localctx: Rc<MaterializedViewCombineDeltaClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2601);
			recog.base.match_token(DELTA,&mut recog.err_handler)?;

			recog.base.set_state(2602);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule expression*/
			recog.base.set_state(2603);
			let tmp = recog.expression()?;
			 cast_mut::<_,MaterializedViewCombineDeltaClauseContext >(&mut _localctx).Expression = Some(tmp.clone());
			  

			recog.base.set_state(2604);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- materializedViewCombineAggregationsClause ----------------
pub type MaterializedViewCombineAggregationsClauseContextAll<'input> = MaterializedViewCombineAggregationsClauseContext<'input>;


pub type MaterializedViewCombineAggregationsClauseContext<'input> = BaseParserRuleContext<'input,MaterializedViewCombineAggregationsClauseContextExt<'input>>;

#[derive(Clone)]
pub struct MaterializedViewCombineAggregationsClauseContextExt<'input>{
	pub Operator: Option<Rc<SummarizeOperatorContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for MaterializedViewCombineAggregationsClauseContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for MaterializedViewCombineAggregationsClauseContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_materializedViewCombineAggregationsClause(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_materializedViewCombineAggregationsClause(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for MaterializedViewCombineAggregationsClauseContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_materializedViewCombineAggregationsClause(self);
	}
}

impl<'input> CustomRuleContext<'input> for MaterializedViewCombineAggregationsClauseContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_materializedViewCombineAggregationsClause }
	//fn type_rule_index() -> usize where Self: Sized { RULE_materializedViewCombineAggregationsClause }
}
antlr_rust::tid!{MaterializedViewCombineAggregationsClauseContextExt<'a>}

impl<'input> MaterializedViewCombineAggregationsClauseContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<MaterializedViewCombineAggregationsClauseContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,MaterializedViewCombineAggregationsClauseContextExt{
				Operator: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait MaterializedViewCombineAggregationsClauseContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<MaterializedViewCombineAggregationsClauseContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token AGGREGATIONS
/// Returns `None` if there is no child corresponding to token AGGREGATIONS
fn AGGREGATIONS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AGGREGATIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn summarizeOperator(&self) -> Option<Rc<SummarizeOperatorContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> MaterializedViewCombineAggregationsClauseContextAttrs<'input> for MaterializedViewCombineAggregationsClauseContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn materializedViewCombineAggregationsClause(&mut self,)
	-> Result<Rc<MaterializedViewCombineAggregationsClauseContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = MaterializedViewCombineAggregationsClauseContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 512, RULE_materializedViewCombineAggregationsClause);
        let mut _localctx: Rc<MaterializedViewCombineAggregationsClauseContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2606);
			recog.base.match_token(AGGREGATIONS,&mut recog.err_handler)?;

			recog.base.set_state(2607);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule summarizeOperator*/
			recog.base.set_state(2608);
			let tmp = recog.summarizeOperator()?;
			 cast_mut::<_,MaterializedViewCombineAggregationsClauseContext >(&mut _localctx).Operator = Some(tmp.clone());
			  

			recog.base.set_state(2609);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- scalarType ----------------
pub type ScalarTypeContextAll<'input> = ScalarTypeContext<'input>;


pub type ScalarTypeContext<'input> = BaseParserRuleContext<'input,ScalarTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ScalarTypeContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ScalarTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ScalarTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_scalarType(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_scalarType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ScalarTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_scalarType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ScalarTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_scalarType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_scalarType }
}
antlr_rust::tid!{ScalarTypeContextExt<'a>}

impl<'input> ScalarTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ScalarTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ScalarTypeContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ScalarTypeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ScalarTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BOOL
/// Returns `None` if there is no child corresponding to token BOOL
fn BOOL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOL, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIME
/// Returns `None` if there is no child corresponding to token DATETIME
fn DATETIME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATETIME, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DYNAMIC
/// Returns `None` if there is no child corresponding to token DYNAMIC
fn DYNAMIC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DYNAMIC, 0)
}
/// Retrieves first TerminalNode corresponding to token GUID
/// Returns `None` if there is no child corresponding to token GUID
fn GUID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUID, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT64
/// Returns `None` if there is no child corresponding to token INT64
fn INT64(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT64, 0)
}
/// Retrieves first TerminalNode corresponding to token INT8
/// Returns `None` if there is no child corresponding to token INT8
fn INT8(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT8, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING
/// Returns `None` if there is no child corresponding to token STRING
fn STRING(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESPAN
/// Returns `None` if there is no child corresponding to token TIMESPAN
fn TIMESPAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMESPAN, 0)
}
/// Retrieves first TerminalNode corresponding to token UNIQUEID
/// Returns `None` if there is no child corresponding to token UNIQUEID
fn UNIQUEID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UNIQUEID, 0)
}

}

impl<'input> ScalarTypeContextAttrs<'input> for ScalarTypeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn scalarType(&mut self,)
	-> Result<Rc<ScalarTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ScalarTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 514, RULE_scalarType);
        let mut _localctx: Rc<ScalarTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2611);
			 cast_mut::<_,ScalarTypeContext >(&mut _localctx).Token = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (BOOLEAN - 279)) | (1usize << (DATE - 279)) | (1usize << (DATETIME - 279)) | (1usize << (DECIMAL - 279)) | (1usize << (DOUBLE - 279)) | (1usize << (DYNAMIC - 279)) | (1usize << (GUID - 279)) | (1usize << (INT - 279)) | (1usize << (INT8 - 279)) | (1usize << (INT64 - 279)) | (1usize << (LONG - 279)) | (1usize << (STRING - 279)) | (1usize << (REAL - 279)) | (1usize << (TIME - 279)) | (1usize << (TIMESPAN - 279)) | (1usize << (UNIQUEID - 279)))) != 0)) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ScalarTypeContext >(&mut _localctx).Token = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extendedScalarType ----------------
pub type ExtendedScalarTypeContextAll<'input> = ExtendedScalarTypeContext<'input>;


pub type ExtendedScalarTypeContext<'input> = BaseParserRuleContext<'input,ExtendedScalarTypeContextExt<'input>>;

#[derive(Clone)]
pub struct ExtendedScalarTypeContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExtendedScalarTypeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExtendedScalarTypeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extendedScalarType(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_extendedScalarType(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExtendedScalarTypeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_extendedScalarType(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtendedScalarTypeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extendedScalarType }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extendedScalarType }
}
antlr_rust::tid!{ExtendedScalarTypeContextExt<'a>}

impl<'input> ExtendedScalarTypeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtendedScalarTypeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtendedScalarTypeContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtendedScalarTypeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExtendedScalarTypeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BOOL
/// Returns `None` if there is no child corresponding to token BOOL
fn BOOL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOL, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOLEAN
/// Returns `None` if there is no child corresponding to token BOOLEAN
fn BOOLEAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEAN, 0)
}
/// Retrieves first TerminalNode corresponding to token DATE
/// Returns `None` if there is no child corresponding to token DATE
fn DATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATE, 0)
}
/// Retrieves first TerminalNode corresponding to token DATETIME
/// Returns `None` if there is no child corresponding to token DATETIME
fn DATETIME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATETIME, 0)
}
/// Retrieves first TerminalNode corresponding to token DECIMAL
/// Returns `None` if there is no child corresponding to token DECIMAL
fn DECIMAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECIMAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DOUBLE
/// Returns `None` if there is no child corresponding to token DOUBLE
fn DOUBLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DOUBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DYNAMIC
/// Returns `None` if there is no child corresponding to token DYNAMIC
fn DYNAMIC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DYNAMIC, 0)
}
/// Retrieves first TerminalNode corresponding to token FLOAT
/// Returns `None` if there is no child corresponding to token FLOAT
fn FLOAT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FLOAT, 0)
}
/// Retrieves first TerminalNode corresponding to token GUID
/// Returns `None` if there is no child corresponding to token GUID
fn GUID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUID, 0)
}
/// Retrieves first TerminalNode corresponding to token INT
/// Returns `None` if there is no child corresponding to token INT
fn INT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT, 0)
}
/// Retrieves first TerminalNode corresponding to token INT16
/// Returns `None` if there is no child corresponding to token INT16
fn INT16(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT16, 0)
}
/// Retrieves first TerminalNode corresponding to token INT32
/// Returns `None` if there is no child corresponding to token INT32
fn INT32(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT32, 0)
}
/// Retrieves first TerminalNode corresponding to token INT64
/// Returns `None` if there is no child corresponding to token INT64
fn INT64(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT64, 0)
}
/// Retrieves first TerminalNode corresponding to token INT8
/// Returns `None` if there is no child corresponding to token INT8
fn INT8(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INT8, 0)
}
/// Retrieves first TerminalNode corresponding to token LONG
/// Returns `None` if there is no child corresponding to token LONG
fn LONG(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONG, 0)
}
/// Retrieves first TerminalNode corresponding to token REAL
/// Returns `None` if there is no child corresponding to token REAL
fn REAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REAL, 0)
}
/// Retrieves first TerminalNode corresponding to token STRING
/// Returns `None` if there is no child corresponding to token STRING
fn STRING(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STRING, 0)
}
/// Retrieves first TerminalNode corresponding to token TIME
/// Returns `None` if there is no child corresponding to token TIME
fn TIME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIME, 0)
}
/// Retrieves first TerminalNode corresponding to token TIMESPAN
/// Returns `None` if there is no child corresponding to token TIMESPAN
fn TIMESPAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMESPAN, 0)
}
/// Retrieves first TerminalNode corresponding to token UINT
/// Returns `None` if there is no child corresponding to token UINT
fn UINT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UINT, 0)
}
/// Retrieves first TerminalNode corresponding to token UINT16
/// Returns `None` if there is no child corresponding to token UINT16
fn UINT16(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UINT16, 0)
}
/// Retrieves first TerminalNode corresponding to token UINT32
/// Returns `None` if there is no child corresponding to token UINT32
fn UINT32(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UINT32, 0)
}
/// Retrieves first TerminalNode corresponding to token UINT64
/// Returns `None` if there is no child corresponding to token UINT64
fn UINT64(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UINT64, 0)
}
/// Retrieves first TerminalNode corresponding to token UINT8
/// Returns `None` if there is no child corresponding to token UINT8
fn UINT8(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UINT8, 0)
}
/// Retrieves first TerminalNode corresponding to token ULONG
/// Returns `None` if there is no child corresponding to token ULONG
fn ULONG(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ULONG, 0)
}
/// Retrieves first TerminalNode corresponding to token UNIQUEID
/// Returns `None` if there is no child corresponding to token UNIQUEID
fn UNIQUEID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UNIQUEID, 0)
}

}

impl<'input> ExtendedScalarTypeContextAttrs<'input> for ExtendedScalarTypeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extendedScalarType(&mut self,)
	-> Result<Rc<ExtendedScalarTypeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtendedScalarTypeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 516, RULE_extendedScalarType);
        let mut _localctx: Rc<ExtendedScalarTypeContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2613);
			 cast_mut::<_,ExtendedScalarTypeContext >(&mut _localctx).Token = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (BOOLEAN - 279)) | (1usize << (DATE - 279)) | (1usize << (DATETIME - 279)) | (1usize << (DECIMAL - 279)) | (1usize << (DOUBLE - 279)) | (1usize << (DYNAMIC - 279)) | (1usize << (FLOAT - 279)) | (1usize << (GUID - 279)) | (1usize << (INT - 279)) | (1usize << (INT8 - 279)) | (1usize << (INT16 - 279)) | (1usize << (INT32 - 279)) | (1usize << (INT64 - 279)) | (1usize << (LONG - 279)) | (1usize << (STRING - 279)) | (1usize << (REAL - 279)) | (1usize << (TIME - 279)) | (1usize << (TIMESPAN - 279)) | (1usize << (UINT - 279)) | (1usize << (UINT8 - 279)) | (1usize << (UINT16 - 279)) | (1usize << (UINT32 - 279)) | (1usize << (UINT64 - 279)) | (1usize << (ULONG - 279)) | (1usize << (UNIQUEID - 279)))) != 0)) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ExtendedScalarTypeContext >(&mut _localctx).Token = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- parameterName ----------------
pub type ParameterNameContextAll<'input> = ParameterNameContext<'input>;


pub type ParameterNameContext<'input> = BaseParserRuleContext<'input,ParameterNameContextExt<'input>>;

#[derive(Clone)]
pub struct ParameterNameContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ParameterNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ParameterNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_parameterName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_parameterName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ParameterNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_parameterName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ParameterNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_parameterName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_parameterName }
}
antlr_rust::tid!{ParameterNameContextExt<'a>}

impl<'input> ParameterNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ParameterNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ParameterNameContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ParameterNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ParameterNameContextExt<'input>>{

fn identifierOrExtendedKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ParameterNameContextAttrs<'input> for ParameterNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn parameterName(&mut self,)
	-> Result<Rc<ParameterNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ParameterNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 518, RULE_parameterName);
        let mut _localctx: Rc<ParameterNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifierOrExtendedKeywordOrEscapedName*/
			recog.base.set_state(2615);
			let tmp = recog.identifierOrExtendedKeywordOrEscapedName()?;
			 cast_mut::<_,ParameterNameContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- simpleNameReference ----------------
pub type SimpleNameReferenceContextAll<'input> = SimpleNameReferenceContext<'input>;


pub type SimpleNameReferenceContext<'input> = BaseParserRuleContext<'input,SimpleNameReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct SimpleNameReferenceContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SimpleNameReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SimpleNameReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_simpleNameReference(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_simpleNameReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SimpleNameReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_simpleNameReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleNameReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_simpleNameReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_simpleNameReference }
}
antlr_rust::tid!{SimpleNameReferenceContextExt<'a>}

impl<'input> SimpleNameReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SimpleNameReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SimpleNameReferenceContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SimpleNameReferenceContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SimpleNameReferenceContextExt<'input>>{

fn identifierOrKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SimpleNameReferenceContextAttrs<'input> for SimpleNameReferenceContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn simpleNameReference(&mut self,)
	-> Result<Rc<SimpleNameReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SimpleNameReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 520, RULE_simpleNameReference);
        let mut _localctx: Rc<SimpleNameReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifierOrKeywordOrEscapedName*/
			recog.base.set_state(2617);
			let tmp = recog.identifierOrKeywordOrEscapedName()?;
			 cast_mut::<_,SimpleNameReferenceContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extendedNameReference ----------------
pub type ExtendedNameReferenceContextAll<'input> = ExtendedNameReferenceContext<'input>;


pub type ExtendedNameReferenceContext<'input> = BaseParserRuleContext<'input,ExtendedNameReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct ExtendedNameReferenceContextExt<'input>{
	pub Name: Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExtendedNameReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExtendedNameReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extendedNameReference(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_extendedNameReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExtendedNameReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_extendedNameReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtendedNameReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extendedNameReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extendedNameReference }
}
antlr_rust::tid!{ExtendedNameReferenceContextExt<'a>}

impl<'input> ExtendedNameReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtendedNameReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtendedNameReferenceContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtendedNameReferenceContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExtendedNameReferenceContextExt<'input>>{

fn identifierOrExtendedKeywordOrEscapedName(&self) -> Option<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> ExtendedNameReferenceContextAttrs<'input> for ExtendedNameReferenceContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extendedNameReference(&mut self,)
	-> Result<Rc<ExtendedNameReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtendedNameReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 522, RULE_extendedNameReference);
        let mut _localctx: Rc<ExtendedNameReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule identifierOrExtendedKeywordOrEscapedName*/
			recog.base.set_state(2619);
			let tmp = recog.identifierOrExtendedKeywordOrEscapedName()?;
			 cast_mut::<_,ExtendedNameReferenceContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedNameReference ----------------
pub type WildcardedNameReferenceContextAll<'input> = WildcardedNameReferenceContext<'input>;


pub type WildcardedNameReferenceContext<'input> = BaseParserRuleContext<'input,WildcardedNameReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedNameReferenceContextExt<'input>{
	pub Name: Option<Rc<WildcardedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedNameReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedNameReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedNameReference(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedNameReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedNameReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedNameReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedNameReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedNameReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedNameReference }
}
antlr_rust::tid!{WildcardedNameReferenceContextExt<'a>}

impl<'input> WildcardedNameReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedNameReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedNameReferenceContextExt{
				Name: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedNameReferenceContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedNameReferenceContextExt<'input>>{

fn wildcardedName(&self) -> Option<Rc<WildcardedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WildcardedNameReferenceContextAttrs<'input> for WildcardedNameReferenceContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedNameReference(&mut self,)
	-> Result<Rc<WildcardedNameReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedNameReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 524, RULE_wildcardedNameReference);
        let mut _localctx: Rc<WildcardedNameReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			/*InvokeRule wildcardedName*/
			recog.base.set_state(2621);
			let tmp = recog.wildcardedName()?;
			 cast_mut::<_,WildcardedNameReferenceContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- simpleOrWildcardedNameReference ----------------
pub type SimpleOrWildcardedNameReferenceContextAll<'input> = SimpleOrWildcardedNameReferenceContext<'input>;


pub type SimpleOrWildcardedNameReferenceContext<'input> = BaseParserRuleContext<'input,SimpleOrWildcardedNameReferenceContextExt<'input>>;

#[derive(Clone)]
pub struct SimpleOrWildcardedNameReferenceContextExt<'input>{
	pub SimpleName: Option<Rc<SimpleNameReferenceContextAll<'input>>>,
	pub WildcardedName: Option<Rc<WildcardedNameReferenceContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SimpleOrWildcardedNameReferenceContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SimpleOrWildcardedNameReferenceContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_simpleOrWildcardedNameReference(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_simpleOrWildcardedNameReference(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SimpleOrWildcardedNameReferenceContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_simpleOrWildcardedNameReference(self);
	}
}

impl<'input> CustomRuleContext<'input> for SimpleOrWildcardedNameReferenceContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_simpleOrWildcardedNameReference }
	//fn type_rule_index() -> usize where Self: Sized { RULE_simpleOrWildcardedNameReference }
}
antlr_rust::tid!{SimpleOrWildcardedNameReferenceContextExt<'a>}

impl<'input> SimpleOrWildcardedNameReferenceContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SimpleOrWildcardedNameReferenceContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SimpleOrWildcardedNameReferenceContextExt{
				SimpleName: None, WildcardedName: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SimpleOrWildcardedNameReferenceContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SimpleOrWildcardedNameReferenceContextExt<'input>>{

fn simpleNameReference(&self) -> Option<Rc<SimpleNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn wildcardedNameReference(&self) -> Option<Rc<WildcardedNameReferenceContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SimpleOrWildcardedNameReferenceContextAttrs<'input> for SimpleOrWildcardedNameReferenceContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn simpleOrWildcardedNameReference(&mut self,)
	-> Result<Rc<SimpleOrWildcardedNameReferenceContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SimpleOrWildcardedNameReferenceContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 526, RULE_simpleOrWildcardedNameReference);
        let mut _localctx: Rc<SimpleOrWildcardedNameReferenceContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2625);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(236,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule simpleNameReference*/
					recog.base.set_state(2623);
					let tmp = recog.simpleNameReference()?;
					 cast_mut::<_,SimpleOrWildcardedNameReferenceContext >(&mut _localctx).SimpleName = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule wildcardedNameReference*/
					recog.base.set_state(2624);
					let tmp = recog.wildcardedNameReference()?;
					 cast_mut::<_,SimpleOrWildcardedNameReferenceContext >(&mut _localctx).WildcardedName = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierName ----------------
pub type IdentifierNameContextAll<'input> = IdentifierNameContext<'input>;


pub type IdentifierNameContext<'input> = BaseParserRuleContext<'input,IdentifierNameContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierNameContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for IdentifierNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for IdentifierNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_identifierName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for IdentifierNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_identifierName(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierName }
}
antlr_rust::tid!{IdentifierNameContextExt<'a>}

impl<'input> IdentifierNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierNameContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<IdentifierNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}

}

impl<'input> IdentifierNameContextAttrs<'input> for IdentifierNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierName(&mut self,)
	-> Result<Rc<IdentifierNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 528, RULE_identifierName);
        let mut _localctx: Rc<IdentifierNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2627);
			let tmp = recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;
			 cast_mut::<_,IdentifierNameContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- keywordName ----------------
pub type KeywordNameContextAll<'input> = KeywordNameContext<'input>;


pub type KeywordNameContext<'input> = BaseParserRuleContext<'input,KeywordNameContextExt<'input>>;

#[derive(Clone)]
pub struct KeywordNameContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for KeywordNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for KeywordNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_keywordName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_keywordName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for KeywordNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_keywordName(self);
	}
}

impl<'input> CustomRuleContext<'input> for KeywordNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_keywordName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_keywordName }
}
antlr_rust::tid!{KeywordNameContextExt<'a>}

impl<'input> KeywordNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<KeywordNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,KeywordNameContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait KeywordNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<KeywordNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ACCESS
/// Returns `None` if there is no child corresponding to token ACCESS
fn ACCESS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ACCESS, 0)
}
/// Retrieves first TerminalNode corresponding to token AGGREGATIONS
/// Returns `None` if there is no child corresponding to token AGGREGATIONS
fn AGGREGATIONS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AGGREGATIONS, 0)
}
/// Retrieves first TerminalNode corresponding to token ALIAS
/// Returns `None` if there is no child corresponding to token ALIAS
fn ALIAS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ALIAS, 0)
}
/// Retrieves first TerminalNode corresponding to token ALL
/// Returns `None` if there is no child corresponding to token ALL
fn ALL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ALL, 0)
}
/// Retrieves first TerminalNode corresponding to token AXES
/// Returns `None` if there is no child corresponding to token AXES
fn AXES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AXES, 0)
}
/// Retrieves first TerminalNode corresponding to token BASE
/// Returns `None` if there is no child corresponding to token BASE
fn BASE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BASE, 0)
}
/// Retrieves first TerminalNode corresponding to token BIN
/// Returns `None` if there is no child corresponding to token BIN
fn BIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BIN, 0)
}
/// Retrieves first TerminalNode corresponding to token BOOL
/// Returns `None` if there is no child corresponding to token BOOL
fn BOOL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOL, 0)
}
/// Retrieves first TerminalNode corresponding to token CLUSTER
/// Returns `None` if there is no child corresponding to token CLUSTER
fn CLUSTER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLUSTER, 0)
}
/// Retrieves first TerminalNode corresponding to token DATABASE
/// Returns `None` if there is no child corresponding to token DATABASE
fn DATABASE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATABASE, 0)
}
/// Retrieves first TerminalNode corresponding to token DECLARE
/// Returns `None` if there is no child corresponding to token DECLARE
fn DECLARE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECLARE, 0)
}
/// Retrieves first TerminalNode corresponding to token DEFAULT
/// Returns `None` if there is no child corresponding to token DEFAULT
fn DEFAULT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DEFAULT, 0)
}
/// Retrieves first TerminalNode corresponding to token DELTA
/// Returns `None` if there is no child corresponding to token DELTA
fn DELTA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DELTA, 0)
}
/// Retrieves first TerminalNode corresponding to token EDGES
/// Returns `None` if there is no child corresponding to token EDGES
fn EDGES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EDGES, 0)
}
/// Retrieves first TerminalNode corresponding to token EVALUATE
/// Returns `None` if there is no child corresponding to token EVALUATE
fn EVALUATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EVALUATE, 0)
}
/// Retrieves first TerminalNode corresponding to token EXECUTE
/// Returns `None` if there is no child corresponding to token EXECUTE
fn EXECUTE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXECUTE, 0)
}
/// Retrieves first TerminalNode corresponding to token FACET
/// Returns `None` if there is no child corresponding to token FACET
fn FACET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FACET, 0)
}
/// Retrieves first TerminalNode corresponding to token FORK
/// Returns `None` if there is no child corresponding to token FORK
fn FORK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FORK, 0)
}
/// Retrieves first TerminalNode corresponding to token FROM
/// Returns `None` if there is no child corresponding to token FROM
fn FROM(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FROM, 0)
}
/// Retrieves first TerminalNode corresponding to token GUID
/// Returns `None` if there is no child corresponding to token GUID
fn GUID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUID, 0)
}
/// Retrieves first TerminalNode corresponding to token HIDDEN_
/// Returns `None` if there is no child corresponding to token HIDDEN_
fn HIDDEN_(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HIDDEN_, 0)
}
/// Retrieves first TerminalNode corresponding to token HOT
/// Returns `None` if there is no child corresponding to token HOT
fn HOT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HOT, 0)
}
/// Retrieves first TerminalNode corresponding to token HOTDATA
/// Returns `None` if there is no child corresponding to token HOTDATA
fn HOTDATA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HOTDATA, 0)
}
/// Retrieves first TerminalNode corresponding to token HOTINDEX
/// Returns `None` if there is no child corresponding to token HOTINDEX
fn HOTINDEX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HOTINDEX, 0)
}
/// Retrieves first TerminalNode corresponding to token ID
/// Returns `None` if there is no child corresponding to token ID
fn ID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ID, 0)
}
/// Retrieves first TerminalNode corresponding to token INTO
/// Returns `None` if there is no child corresponding to token INTO
fn INTO(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INTO, 0)
}
/// Retrieves first TerminalNode corresponding to token LEGEND
/// Returns `None` if there is no child corresponding to token LEGEND
fn LEGEND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LEGEND, 0)
}
/// Retrieves first TerminalNode corresponding to token LET
/// Returns `None` if there is no child corresponding to token LET
fn LET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LET, 0)
}
/// Retrieves first TerminalNode corresponding to token LINEAR
/// Returns `None` if there is no child corresponding to token LINEAR
fn LINEAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LINEAR, 0)
}
/// Retrieves first TerminalNode corresponding to token LOG
/// Returns `None` if there is no child corresponding to token LOG
fn LOG(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LOG, 0)
}
/// Retrieves first TerminalNode corresponding to token LOOKUP
/// Returns `None` if there is no child corresponding to token LOOKUP
fn LOOKUP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LOOKUP, 0)
}
/// Retrieves first TerminalNode corresponding to token LIST
/// Returns `None` if there is no child corresponding to token LIST
fn LIST(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIST, 0)
}
/// Retrieves first TerminalNode corresponding to token MAP
/// Returns `None` if there is no child corresponding to token MAP
fn MAP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MAP, 0)
}
/// Retrieves first TerminalNode corresponding to token NODES
/// Returns `None` if there is no child corresponding to token NODES
fn NODES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NODES, 0)
}
/// Retrieves first TerminalNode corresponding to token NONE
/// Returns `None` if there is no child corresponding to token NONE
fn NONE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NONE, 0)
}
/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}
/// Retrieves first TerminalNode corresponding to token NULLS
/// Returns `None` if there is no child corresponding to token NULLS
fn NULLS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NULLS, 0)
}
/// Retrieves first TerminalNode corresponding to token ON
/// Returns `None` if there is no child corresponding to token ON
fn ON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ON, 0)
}
/// Retrieves first TerminalNode corresponding to token OPTIONAL
/// Returns `None` if there is no child corresponding to token OPTIONAL
fn OPTIONAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPTIONAL, 0)
}
/// Retrieves first TerminalNode corresponding to token OUTPUT
/// Returns `None` if there is no child corresponding to token OUTPUT
fn OUTPUT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OUTPUT, 0)
}
/// Retrieves first TerminalNode corresponding to token PACK
/// Returns `None` if there is no child corresponding to token PACK
fn PACK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PACK, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITION
/// Returns `None` if there is no child corresponding to token PARTITION
fn PARTITION(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARTITION, 0)
}
/// Retrieves first TerminalNode corresponding to token PARTITIONBY
/// Returns `None` if there is no child corresponding to token PARTITIONBY
fn PARTITIONBY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARTITIONBY, 0)
}
/// Retrieves first TerminalNode corresponding to token PATTERN
/// Returns `None` if there is no child corresponding to token PATTERN
fn PATTERN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PATTERN, 0)
}
/// Retrieves first TerminalNode corresponding to token PLUGIN
/// Returns `None` if there is no child corresponding to token PLUGIN
fn PLUGIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PLUGIN, 0)
}
/// Retrieves first TerminalNode corresponding to token QUERYPARAMETERS
/// Returns `None` if there is no child corresponding to token QUERYPARAMETERS
fn QUERYPARAMETERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(QUERYPARAMETERS, 0)
}
/// Retrieves first TerminalNode corresponding to token RANGE
/// Returns `None` if there is no child corresponding to token RANGE
fn RANGE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RANGE, 0)
}
/// Retrieves first TerminalNode corresponding to token REDUCE
/// Returns `None` if there is no child corresponding to token REDUCE
fn REDUCE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REDUCE, 0)
}
/// Retrieves first TerminalNode corresponding to token REPLACE
/// Returns `None` if there is no child corresponding to token REPLACE
fn REPLACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REPLACE, 0)
}
/// Retrieves first TerminalNode corresponding to token RENDER
/// Returns `None` if there is no child corresponding to token RENDER
fn RENDER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RENDER, 0)
}
/// Retrieves first TerminalNode corresponding to token RESTRICT
/// Returns `None` if there is no child corresponding to token RESTRICT
fn RESTRICT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(RESTRICT, 0)
}
/// Retrieves first TerminalNode corresponding to token SERIES
/// Returns `None` if there is no child corresponding to token SERIES
fn SERIES(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SERIES, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKED
/// Returns `None` if there is no child corresponding to token STACKED
fn STACKED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKED, 0)
}
/// Retrieves first TerminalNode corresponding to token STACKED100
/// Returns `None` if there is no child corresponding to token STACKED100
fn STACKED100(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STACKED100, 0)
}
/// Retrieves first TerminalNode corresponding to token STEP
/// Returns `None` if there is no child corresponding to token STEP
fn STEP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STEP, 0)
}
/// Retrieves first TerminalNode corresponding to token THRESHOLD
/// Returns `None` if there is no child corresponding to token THRESHOLD
fn THRESHOLD(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(THRESHOLD, 0)
}
/// Retrieves first TerminalNode corresponding to token TYPEOF
/// Returns `None` if there is no child corresponding to token TYPEOF
fn TYPEOF(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TYPEOF, 0)
}
/// Retrieves first TerminalNode corresponding to token UNSTACKED
/// Returns `None` if there is no child corresponding to token UNSTACKED
fn UNSTACKED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UNSTACKED, 0)
}
/// Retrieves first TerminalNode corresponding to token UUID
/// Returns `None` if there is no child corresponding to token UUID
fn UUID(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(UUID, 0)
}
/// Retrieves first TerminalNode corresponding to token VIEW
/// Returns `None` if there is no child corresponding to token VIEW
fn VIEW(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(VIEW, 0)
}
/// Retrieves first TerminalNode corresponding to token VISIBLE
/// Returns `None` if there is no child corresponding to token VISIBLE
fn VISIBLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(VISIBLE, 0)
}
/// Retrieves first TerminalNode corresponding to token WITH
/// Returns `None` if there is no child corresponding to token WITH
fn WITH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WITH, 0)
}
/// Retrieves first TerminalNode corresponding to token XAXIS
/// Returns `None` if there is no child corresponding to token XAXIS
fn XAXIS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XAXIS, 0)
}
/// Retrieves first TerminalNode corresponding to token XCOLUMN
/// Returns `None` if there is no child corresponding to token XCOLUMN
fn XCOLUMN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XCOLUMN, 0)
}
/// Retrieves first TerminalNode corresponding to token XMAX
/// Returns `None` if there is no child corresponding to token XMAX
fn XMAX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XMAX, 0)
}
/// Retrieves first TerminalNode corresponding to token XMIN
/// Returns `None` if there is no child corresponding to token XMIN
fn XMIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token XTITLE
/// Returns `None` if there is no child corresponding to token XTITLE
fn XTITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(XTITLE, 0)
}
/// Retrieves first TerminalNode corresponding to token YAXIS
/// Returns `None` if there is no child corresponding to token YAXIS
fn YAXIS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YAXIS, 0)
}
/// Retrieves first TerminalNode corresponding to token YCOLUMNS
/// Returns `None` if there is no child corresponding to token YCOLUMNS
fn YCOLUMNS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YCOLUMNS, 0)
}
/// Retrieves first TerminalNode corresponding to token YMAX
/// Returns `None` if there is no child corresponding to token YMAX
fn YMAX(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YMAX, 0)
}
/// Retrieves first TerminalNode corresponding to token YMIN
/// Returns `None` if there is no child corresponding to token YMIN
fn YMIN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YMIN, 0)
}
/// Retrieves first TerminalNode corresponding to token YTITLE
/// Returns `None` if there is no child corresponding to token YTITLE
fn YTITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YTITLE, 0)
}
/// Retrieves first TerminalNode corresponding to token YSPLIT
/// Returns `None` if there is no child corresponding to token YSPLIT
fn YSPLIT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(YSPLIT, 0)
}

}

impl<'input> KeywordNameContextAttrs<'input> for KeywordNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn keywordName(&mut self,)
	-> Result<Rc<KeywordNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = KeywordNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 530, RULE_keywordName);
        let mut _localctx: Rc<KeywordNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2629);
			 cast_mut::<_,KeywordNameContext >(&mut _localctx).Token = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 38)) & !0x3f) == 0 && ((1usize << (_la - 38)) & ((1usize << (ACCESS - 38)) | (1usize << (AGGREGATIONS - 38)) | (1usize << (ALIAS - 38)) | (1usize << (ALL - 38)) | (1usize << (AXES - 38)) | (1usize << (BASE - 38)) | (1usize << (BIN - 38)) | (1usize << (CLUSTER - 38)) | (1usize << (DATABASE - 38)))) != 0) || ((((_la - 72)) & !0x3f) == 0 && ((1usize << (_la - 72)) & ((1usize << (DECLARE - 72)) | (1usize << (DEFAULT - 72)) | (1usize << (DELTA - 72)) | (1usize << (EDGES - 72)) | (1usize << (EVALUATE - 72)) | (1usize << (EXECUTE - 72)) | (1usize << (FACET - 72)) | (1usize << (FORK - 72)) | (1usize << (FROM - 72)))) != 0) || ((((_la - 112)) & !0x3f) == 0 && ((1usize << (_la - 112)) & ((1usize << (HIDDEN_ - 112)) | (1usize << (HOT - 112)) | (1usize << (HOTDATA - 112)) | (1usize << (HOTINDEX - 112)) | (1usize << (ID - 112)) | (1usize << (INTO - 112)) | (1usize << (LEGEND - 112)) | (1usize << (LET - 112)))) != 0) || ((((_la - 145)) & !0x3f) == 0 && ((1usize << (_la - 145)) & ((1usize << (LINEAR - 145)) | (1usize << (LIST - 145)) | (1usize << (LOOKUP - 145)) | (1usize << (LOG - 145)) | (1usize << (MAP - 145)) | (1usize << (NODES - 145)) | (1usize << (NONE - 145)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SERIES - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (THRESHOLD - 215)))) != 0) || ((((_la - 253)) & !0x3f) == 0 && ((1usize << (_la - 253)) & ((1usize << (TYPEOF - 253)) | (1usize << (UNSTACKED - 253)) | (1usize << (UUID - 253)) | (1usize << (VIEW - 253)) | (1usize << (VISIBLE - 253)) | (1usize << (WITH - 253)) | (1usize << (XAXIS - 253)) | (1usize << (XCOLUMN - 253)) | (1usize << (XMAX - 253)) | (1usize << (XMIN - 253)) | (1usize << (XTITLE - 253)) | (1usize << (YAXIS - 253)) | (1usize << (YCOLUMNS - 253)) | (1usize << (YMAX - 253)) | (1usize << (YMIN - 253)) | (1usize << (YSPLIT - 253)) | (1usize << (YTITLE - 253)) | (1usize << (BOOL - 253)))) != 0) || _la==GUID) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,KeywordNameContext >(&mut _localctx).Token = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- extendedKeywordName ----------------
pub type ExtendedKeywordNameContextAll<'input> = ExtendedKeywordNameContext<'input>;


pub type ExtendedKeywordNameContext<'input> = BaseParserRuleContext<'input,ExtendedKeywordNameContextExt<'input>>;

#[derive(Clone)]
pub struct ExtendedKeywordNameContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for ExtendedKeywordNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for ExtendedKeywordNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_extendedKeywordName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_extendedKeywordName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for ExtendedKeywordNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_extendedKeywordName(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExtendedKeywordNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_extendedKeywordName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_extendedKeywordName }
}
antlr_rust::tid!{ExtendedKeywordNameContextExt<'a>}

impl<'input> ExtendedKeywordNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExtendedKeywordNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExtendedKeywordNameContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait ExtendedKeywordNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<ExtendedKeywordNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ACCUMULATE
/// Returns `None` if there is no child corresponding to token ACCUMULATE
fn ACCUMULATE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ACCUMULATE, 0)
}
/// Retrieves first TerminalNode corresponding to token AS
/// Returns `None` if there is no child corresponding to token AS
fn AS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(AS, 0)
}
/// Retrieves first TerminalNode corresponding to token BY
/// Returns `None` if there is no child corresponding to token BY
fn BY(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BY, 0)
}
/// Retrieves first TerminalNode corresponding to token CONTAINS
/// Returns `None` if there is no child corresponding to token CONTAINS
fn CONTAINS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONTAINS, 0)
}
/// Retrieves first TerminalNode corresponding to token CONSUME
/// Returns `None` if there is no child corresponding to token CONSUME
fn CONSUME(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CONSUME, 0)
}
/// Retrieves first TerminalNode corresponding to token COUNT
/// Returns `None` if there is no child corresponding to token COUNT
fn COUNT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COUNT, 0)
}
/// Retrieves first TerminalNode corresponding to token DATATABLE
/// Returns `None` if there is no child corresponding to token DATATABLE
fn DATATABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATATABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token DISTINCT
/// Returns `None` if there is no child corresponding to token DISTINCT
fn DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTEND
/// Returns `None` if there is no child corresponding to token EXTEND
fn EXTEND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXTEND, 0)
}
/// Retrieves first TerminalNode corresponding to token EXTERNALDATA
/// Returns `None` if there is no child corresponding to token EXTERNALDATA
fn EXTERNALDATA(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(EXTERNALDATA, 0)
}
/// Retrieves first TerminalNode corresponding to token FIND
/// Returns `None` if there is no child corresponding to token FIND
fn FIND(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FIND, 0)
}
/// Retrieves first TerminalNode corresponding to token FILTER
/// Returns `None` if there is no child corresponding to token FILTER
fn FILTER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(FILTER, 0)
}
/// Retrieves first TerminalNode corresponding to token HAS
/// Returns `None` if there is no child corresponding to token HAS
fn HAS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(HAS, 0)
}
/// Retrieves first TerminalNode corresponding to token IN
/// Returns `None` if there is no child corresponding to token IN
fn IN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IN, 0)
}
/// Retrieves first TerminalNode corresponding to token INVOKE
/// Returns `None` if there is no child corresponding to token INVOKE
fn INVOKE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INVOKE, 0)
}
/// Retrieves first TerminalNode corresponding to token LIMIT
/// Returns `None` if there is no child corresponding to token LIMIT
fn LIMIT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LIMIT, 0)
}
/// Retrieves first TerminalNode corresponding to token MATERIALIZE
/// Returns `None` if there is no child corresponding to token MATERIALIZE
fn MATERIALIZE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(MATERIALIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token OF
/// Returns `None` if there is no child corresponding to token OF
fn OF(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OF, 0)
}
/// Retrieves first TerminalNode corresponding to token PARSE
/// Returns `None` if there is no child corresponding to token PARSE
fn PARSE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PARSE, 0)
}
/// Retrieves first TerminalNode corresponding to token PRINT
/// Returns `None` if there is no child corresponding to token PRINT
fn PRINT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PRINT, 0)
}
/// Retrieves first TerminalNode corresponding to token SAMPLE
/// Returns `None` if there is no child corresponding to token SAMPLE
fn SAMPLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SAMPLE, 0)
}
/// Retrieves first TerminalNode corresponding to token SAMPLE_DISTINCT
/// Returns `None` if there is no child corresponding to token SAMPLE_DISTINCT
fn SAMPLE_DISTINCT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SAMPLE_DISTINCT, 0)
}
/// Retrieves first TerminalNode corresponding to token SCAN
/// Returns `None` if there is no child corresponding to token SCAN
fn SCAN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SCAN, 0)
}
/// Retrieves first TerminalNode corresponding to token SEARCH
/// Returns `None` if there is no child corresponding to token SEARCH
fn SEARCH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SEARCH, 0)
}
/// Retrieves first TerminalNode corresponding to token SERIALIZE
/// Returns `None` if there is no child corresponding to token SERIALIZE
fn SERIALIZE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SERIALIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token SET
/// Returns `None` if there is no child corresponding to token SET
fn SET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SET, 0)
}
/// Retrieves first TerminalNode corresponding to token SORT
/// Returns `None` if there is no child corresponding to token SORT
fn SORT(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SORT, 0)
}
/// Retrieves first TerminalNode corresponding to token SUMMARIZE
/// Returns `None` if there is no child corresponding to token SUMMARIZE
fn SUMMARIZE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(SUMMARIZE, 0)
}
/// Retrieves first TerminalNode corresponding to token TAKE
/// Returns `None` if there is no child corresponding to token TAKE
fn TAKE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TAKE, 0)
}
/// Retrieves first TerminalNode corresponding to token TITLE
/// Returns `None` if there is no child corresponding to token TITLE
fn TITLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TITLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TO
/// Returns `None` if there is no child corresponding to token TO
fn TO(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TO, 0)
}
/// Retrieves first TerminalNode corresponding to token TOP
/// Returns `None` if there is no child corresponding to token TOP
fn TOP(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOP, 0)
}
/// Retrieves first TerminalNode corresponding to token TOSCALAR
/// Returns `None` if there is no child corresponding to token TOSCALAR
fn TOSCALAR(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOSCALAR, 0)
}
/// Retrieves first TerminalNode corresponding to token TOTABLE
/// Returns `None` if there is no child corresponding to token TOTABLE
fn TOTABLE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOTABLE, 0)
}
/// Retrieves first TerminalNode corresponding to token TOP_NESTED
/// Returns `None` if there is no child corresponding to token TOP_NESTED
fn TOP_NESTED(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOP_NESTED, 0)
}
/// Retrieves first TerminalNode corresponding to token TOP_HITTERS
/// Returns `None` if there is no child corresponding to token TOP_HITTERS
fn TOP_HITTERS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TOP_HITTERS, 0)
}
/// Retrieves first TerminalNode corresponding to token WHERE
/// Returns `None` if there is no child corresponding to token WHERE
fn WHERE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(WHERE, 0)
}

}

impl<'input> ExtendedKeywordNameContextAttrs<'input> for ExtendedKeywordNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn extendedKeywordName(&mut self,)
	-> Result<Rc<ExtendedKeywordNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = ExtendedKeywordNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 532, RULE_extendedKeywordName);
        let mut _localctx: Rc<ExtendedKeywordNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2631);
			 cast_mut::<_,ExtendedKeywordNameContext >(&mut _localctx).Token = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(((((_la - 39)) & !0x3f) == 0 && ((1usize << (_la - 39)) & ((1usize << (ACCUMULATE - 39)) | (1usize << (AS - 39)) | (1usize << (BY - 39)) | (1usize << (CONSUME - 39)) | (1usize << (CONTAINS - 39)) | (1usize << (COUNT - 39)))) != 0) || ((((_la - 71)) & !0x3f) == 0 && ((1usize << (_la - 71)) & ((1usize << (DATATABLE - 71)) | (1usize << (DISTINCT - 71)) | (1usize << (EXTEND - 71)) | (1usize << (EXTERNALDATA - 71)) | (1usize << (FILTER - 71)) | (1usize << (FIND - 71)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (IN - 104)) | (1usize << (INVOKE - 104)))) != 0) || _la==LIMIT || _la==MATERIALIZE || ((((_la - 185)) & !0x3f) == 0 && ((1usize << (_la - 185)) & ((1usize << (OF - 185)) | (1usize << (PARSE - 185)) | (1usize << (PRINT - 185)))) != 0) || ((((_la - 221)) & !0x3f) == 0 && ((1usize << (_la - 221)) & ((1usize << (SAMPLE - 221)) | (1usize << (SAMPLE_DISTINCT - 221)) | (1usize << (SCAN - 221)) | (1usize << (SEARCH - 221)) | (1usize << (SERIALIZE - 221)) | (1usize << (SET - 221)) | (1usize << (SORT - 221)) | (1usize << (SUMMARIZE - 221)) | (1usize << (TAKE - 221)) | (1usize << (TITLE - 221)) | (1usize << (TO - 221)) | (1usize << (TOP - 221)) | (1usize << (TOP_HITTERS - 221)) | (1usize << (TOP_NESTED - 221)) | (1usize << (TOSCALAR - 221)) | (1usize << (TOTABLE - 221)))) != 0) || _la==WHERE) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,ExtendedKeywordNameContext >(&mut _localctx).Token = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- escapedName ----------------
pub type EscapedNameContextAll<'input> = EscapedNameContext<'input>;


pub type EscapedNameContext<'input> = BaseParserRuleContext<'input,EscapedNameContextExt<'input>>;

#[derive(Clone)]
pub struct EscapedNameContextExt<'input>{
	pub StringLiteral: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for EscapedNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for EscapedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_escapedName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_escapedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for EscapedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_escapedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for EscapedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_escapedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_escapedName }
}
antlr_rust::tid!{EscapedNameContextExt<'a>}

impl<'input> EscapedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<EscapedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,EscapedNameContextExt{
				StringLiteral: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait EscapedNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<EscapedNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> EscapedNameContextAttrs<'input> for EscapedNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn escapedName(&mut self,)
	-> Result<Rc<EscapedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = EscapedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 534, RULE_escapedName);
        let mut _localctx: Rc<EscapedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2633);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			/*InvokeRule stringLiteralExpression*/
			recog.base.set_state(2634);
			let tmp = recog.stringLiteralExpression()?;
			 cast_mut::<_,EscapedNameContext >(&mut _localctx).StringLiteral = Some(tmp.clone());
			  

			recog.base.set_state(2635);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierOrKeywordName ----------------
pub type IdentifierOrKeywordNameContextAll<'input> = IdentifierOrKeywordNameContext<'input>;


pub type IdentifierOrKeywordNameContext<'input> = BaseParserRuleContext<'input,IdentifierOrKeywordNameContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierOrKeywordNameContextExt<'input>{
	pub Identifier: Option<Rc<IdentifierNameContextAll<'input>>>,
	pub Keyword: Option<Rc<KeywordNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for IdentifierOrKeywordNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for IdentifierOrKeywordNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierOrKeywordName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_identifierOrKeywordName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for IdentifierOrKeywordNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_identifierOrKeywordName(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierOrKeywordNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierOrKeywordName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierOrKeywordName }
}
antlr_rust::tid!{IdentifierOrKeywordNameContextExt<'a>}

impl<'input> IdentifierOrKeywordNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierOrKeywordNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierOrKeywordNameContextExt{
				Identifier: None, Keyword: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierOrKeywordNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<IdentifierOrKeywordNameContextExt<'input>>{

fn identifierName(&self) -> Option<Rc<IdentifierNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn keywordName(&self) -> Option<Rc<KeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierOrKeywordNameContextAttrs<'input> for IdentifierOrKeywordNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierOrKeywordName(&mut self,)
	-> Result<Rc<IdentifierOrKeywordNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierOrKeywordNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 536, RULE_identifierOrKeywordName);
        let mut _localctx: Rc<IdentifierOrKeywordNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2639);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifierName*/
					recog.base.set_state(2637);
					let tmp = recog.identifierName()?;
					 cast_mut::<_,IdentifierOrKeywordNameContext >(&mut _localctx).Identifier = Some(tmp.clone());
					  

					}
				}

			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keywordName*/
					recog.base.set_state(2638);
					let tmp = recog.keywordName()?;
					 cast_mut::<_,IdentifierOrKeywordNameContext >(&mut _localctx).Keyword = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierOrKeywordOrEscapedName ----------------
pub type IdentifierOrKeywordOrEscapedNameContextAll<'input> = IdentifierOrKeywordOrEscapedNameContext<'input>;


pub type IdentifierOrKeywordOrEscapedNameContext<'input> = BaseParserRuleContext<'input,IdentifierOrKeywordOrEscapedNameContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierOrKeywordOrEscapedNameContextExt<'input>{
	pub Identifier: Option<Rc<IdentifierNameContextAll<'input>>>,
	pub Keyword: Option<Rc<KeywordNameContextAll<'input>>>,
	pub Escaped: Option<Rc<EscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for IdentifierOrKeywordOrEscapedNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for IdentifierOrKeywordOrEscapedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierOrKeywordOrEscapedName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_identifierOrKeywordOrEscapedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for IdentifierOrKeywordOrEscapedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_identifierOrKeywordOrEscapedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierOrKeywordOrEscapedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierOrKeywordOrEscapedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierOrKeywordOrEscapedName }
}
antlr_rust::tid!{IdentifierOrKeywordOrEscapedNameContextExt<'a>}

impl<'input> IdentifierOrKeywordOrEscapedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierOrKeywordOrEscapedNameContextExt{
				Identifier: None, Keyword: None, Escaped: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierOrKeywordOrEscapedNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<IdentifierOrKeywordOrEscapedNameContextExt<'input>>{

fn identifierName(&self) -> Option<Rc<IdentifierNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn keywordName(&self) -> Option<Rc<KeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn escapedName(&self) -> Option<Rc<EscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierOrKeywordOrEscapedNameContextAttrs<'input> for IdentifierOrKeywordOrEscapedNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierOrKeywordOrEscapedName(&mut self,)
	-> Result<Rc<IdentifierOrKeywordOrEscapedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierOrKeywordOrEscapedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 538, RULE_identifierOrKeywordOrEscapedName);
        let mut _localctx: Rc<IdentifierOrKeywordOrEscapedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2644);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifierName*/
					recog.base.set_state(2641);
					let tmp = recog.identifierName()?;
					 cast_mut::<_,IdentifierOrKeywordOrEscapedNameContext >(&mut _localctx).Identifier = Some(tmp.clone());
					  

					}
				}

			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keywordName*/
					recog.base.set_state(2642);
					let tmp = recog.keywordName()?;
					 cast_mut::<_,IdentifierOrKeywordOrEscapedNameContext >(&mut _localctx).Keyword = Some(tmp.clone());
					  

					}
				}

			 OPENBRACKET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule escapedName*/
					recog.base.set_state(2643);
					let tmp = recog.escapedName()?;
					 cast_mut::<_,IdentifierOrKeywordOrEscapedNameContext >(&mut _localctx).Escaped = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierOrExtendedKeywordOrEscapedName ----------------
pub type IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input> = IdentifierOrExtendedKeywordOrEscapedNameContext<'input>;


pub type IdentifierOrExtendedKeywordOrEscapedNameContext<'input> = BaseParserRuleContext<'input,IdentifierOrExtendedKeywordOrEscapedNameContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierOrExtendedKeywordOrEscapedNameContextExt<'input>{
	pub Identifier: Option<Rc<IdentifierNameContextAll<'input>>>,
	pub Keyword: Option<Rc<KeywordNameContextAll<'input>>>,
	pub ExtendedKeyword: Option<Rc<ExtendedKeywordNameContextAll<'input>>>,
	pub Escaped: Option<Rc<EscapedNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for IdentifierOrExtendedKeywordOrEscapedNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for IdentifierOrExtendedKeywordOrEscapedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierOrExtendedKeywordOrEscapedName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_identifierOrExtendedKeywordOrEscapedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for IdentifierOrExtendedKeywordOrEscapedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_identifierOrExtendedKeywordOrEscapedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierOrExtendedKeywordOrEscapedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierOrExtendedKeywordOrEscapedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierOrExtendedKeywordOrEscapedName }
}
antlr_rust::tid!{IdentifierOrExtendedKeywordOrEscapedNameContextExt<'a>}

impl<'input> IdentifierOrExtendedKeywordOrEscapedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierOrExtendedKeywordOrEscapedNameContextExt{
				Identifier: None, Keyword: None, ExtendedKeyword: None, Escaped: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierOrExtendedKeywordOrEscapedNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<IdentifierOrExtendedKeywordOrEscapedNameContextExt<'input>>{

fn identifierName(&self) -> Option<Rc<IdentifierNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn keywordName(&self) -> Option<Rc<KeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendedKeywordName(&self) -> Option<Rc<ExtendedKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn escapedName(&self) -> Option<Rc<EscapedNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierOrExtendedKeywordOrEscapedNameContextAttrs<'input> for IdentifierOrExtendedKeywordOrEscapedNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierOrExtendedKeywordOrEscapedName(&mut self,)
	-> Result<Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierOrExtendedKeywordOrEscapedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 540, RULE_identifierOrExtendedKeywordOrEscapedName);
        let mut _localctx: Rc<IdentifierOrExtendedKeywordOrEscapedNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2650);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifierName*/
					recog.base.set_state(2646);
					let tmp = recog.identifierName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordOrEscapedNameContext >(&mut _localctx).Identifier = Some(tmp.clone());
					  

					}
				}

			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keywordName*/
					recog.base.set_state(2647);
					let tmp = recog.keywordName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordOrEscapedNameContext >(&mut _localctx).Keyword = Some(tmp.clone());
					  

					}
				}

			 ACCUMULATE | AS | BY | CONSUME | CONTAINS | COUNT | DATATABLE | DISTINCT |
			 EXTEND | EXTERNALDATA | FILTER | FIND | HAS | IN | INVOKE | LIMIT | MATERIALIZE |
			 OF | PARSE | PRINT | SAMPLE | SAMPLE_DISTINCT | SCAN | SEARCH | SERIALIZE |
			 SET | SORT | SUMMARIZE | TAKE | TITLE | TO | TOP | TOP_HITTERS | TOP_NESTED |
			 TOSCALAR | TOTABLE | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule extendedKeywordName*/
					recog.base.set_state(2648);
					let tmp = recog.extendedKeywordName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordOrEscapedNameContext >(&mut _localctx).ExtendedKeyword = Some(tmp.clone());
					  

					}
				}

			 OPENBRACKET 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule escapedName*/
					recog.base.set_state(2649);
					let tmp = recog.escapedName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordOrEscapedNameContext >(&mut _localctx).Escaped = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- identifierOrExtendedKeywordName ----------------
pub type IdentifierOrExtendedKeywordNameContextAll<'input> = IdentifierOrExtendedKeywordNameContext<'input>;


pub type IdentifierOrExtendedKeywordNameContext<'input> = BaseParserRuleContext<'input,IdentifierOrExtendedKeywordNameContextExt<'input>>;

#[derive(Clone)]
pub struct IdentifierOrExtendedKeywordNameContextExt<'input>{
	pub Identifier: Option<Rc<IdentifierNameContextAll<'input>>>,
	pub Keyword: Option<Rc<KeywordNameContextAll<'input>>>,
	pub ExtendedKeyword: Option<Rc<ExtendedKeywordNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for IdentifierOrExtendedKeywordNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for IdentifierOrExtendedKeywordNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_identifierOrExtendedKeywordName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_identifierOrExtendedKeywordName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for IdentifierOrExtendedKeywordNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_identifierOrExtendedKeywordName(self);
	}
}

impl<'input> CustomRuleContext<'input> for IdentifierOrExtendedKeywordNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_identifierOrExtendedKeywordName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_identifierOrExtendedKeywordName }
}
antlr_rust::tid!{IdentifierOrExtendedKeywordNameContextExt<'a>}

impl<'input> IdentifierOrExtendedKeywordNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IdentifierOrExtendedKeywordNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IdentifierOrExtendedKeywordNameContextExt{
				Identifier: None, Keyword: None, ExtendedKeyword: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IdentifierOrExtendedKeywordNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<IdentifierOrExtendedKeywordNameContextExt<'input>>{

fn identifierName(&self) -> Option<Rc<IdentifierNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn keywordName(&self) -> Option<Rc<KeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendedKeywordName(&self) -> Option<Rc<ExtendedKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> IdentifierOrExtendedKeywordNameContextAttrs<'input> for IdentifierOrExtendedKeywordNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn identifierOrExtendedKeywordName(&mut self,)
	-> Result<Rc<IdentifierOrExtendedKeywordNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IdentifierOrExtendedKeywordNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 542, RULE_identifierOrExtendedKeywordName);
        let mut _localctx: Rc<IdentifierOrExtendedKeywordNameContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2655);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule identifierName*/
					recog.base.set_state(2652);
					let tmp = recog.identifierName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordNameContext >(&mut _localctx).Identifier = Some(tmp.clone());
					  

					}
				}

			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keywordName*/
					recog.base.set_state(2653);
					let tmp = recog.keywordName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordNameContext >(&mut _localctx).Keyword = Some(tmp.clone());
					  

					}
				}

			 ACCUMULATE | AS | BY | CONSUME | CONTAINS | COUNT | DATATABLE | DISTINCT |
			 EXTEND | EXTERNALDATA | FILTER | FIND | HAS | IN | INVOKE | LIMIT | MATERIALIZE |
			 OF | PARSE | PRINT | SAMPLE | SAMPLE_DISTINCT | SCAN | SEARCH | SERIALIZE |
			 SET | SORT | SUMMARIZE | TAKE | TITLE | TO | TOP | TOP_HITTERS | TOP_NESTED |
			 TOSCALAR | TOTABLE | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule extendedKeywordName*/
					recog.base.set_state(2654);
					let tmp = recog.extendedKeywordName()?;
					 cast_mut::<_,IdentifierOrExtendedKeywordNameContext >(&mut _localctx).ExtendedKeyword = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedName ----------------
pub type WildcardedNameContextAll<'input> = WildcardedNameContext<'input>;


pub type WildcardedNameContext<'input> = BaseParserRuleContext<'input,WildcardedNameContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedNameContextExt<'input>{
	pub Prefix: Option<Rc<WildcardedNamePrefixContextAll<'input>>>,
	pub wildcardedNameSegment: Option<Rc<WildcardedNameSegmentContextAll<'input>>>,
	pub Segments:Vec<Rc<WildcardedNameSegmentContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedNameContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedNameContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedName(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedName(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedNameContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedName(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedNameContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedName }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedName }
}
antlr_rust::tid!{WildcardedNameContextExt<'a>}

impl<'input> WildcardedNameContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedNameContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedNameContextExt{
				Prefix: None, wildcardedNameSegment: None, 
				Segments: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedNameContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedNameContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}
fn wildcardedNamePrefix(&self) -> Option<Rc<WildcardedNamePrefixContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn wildcardedNameSegment_all(&self) ->  Vec<Rc<WildcardedNameSegmentContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn wildcardedNameSegment(&self, i: usize) -> Option<Rc<WildcardedNameSegmentContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> WildcardedNameContextAttrs<'input> for WildcardedNameContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedName(&mut self,)
	-> Result<Rc<WildcardedNameContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedNameContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 544, RULE_wildcardedName);
        let mut _localctx: Rc<WildcardedNameContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2658);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if ((((_la - 38)) & !0x3f) == 0 && ((1usize << (_la - 38)) & ((1usize << (ACCESS - 38)) | (1usize << (ACCUMULATE - 38)) | (1usize << (AGGREGATIONS - 38)) | (1usize << (ALIAS - 38)) | (1usize << (ALL - 38)) | (1usize << (AS - 38)) | (1usize << (AXES - 38)) | (1usize << (BASE - 38)) | (1usize << (BIN - 38)) | (1usize << (BY - 38)) | (1usize << (CLUSTER - 38)) | (1usize << (CONSUME - 38)) | (1usize << (CONTAINS - 38)) | (1usize << (COUNT - 38)) | (1usize << (DATABASE - 38)))) != 0) || ((((_la - 71)) & !0x3f) == 0 && ((1usize << (_la - 71)) & ((1usize << (DATATABLE - 71)) | (1usize << (DECLARE - 71)) | (1usize << (DEFAULT - 71)) | (1usize << (DELTA - 71)) | (1usize << (DISTINCT - 71)) | (1usize << (EDGES - 71)) | (1usize << (EVALUATE - 71)) | (1usize << (EXECUTE - 71)) | (1usize << (EXTEND - 71)) | (1usize << (EXTERNALDATA - 71)) | (1usize << (FACET - 71)) | (1usize << (FILTER - 71)) | (1usize << (FIND - 71)) | (1usize << (FORK - 71)) | (1usize << (FROM - 71)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || _la==BOOL || _la==GUID || _la==IDENTIFIER {
				{
				/*InvokeRule wildcardedNamePrefix*/
				recog.base.set_state(2657);
				let tmp = recog.wildcardedNamePrefix()?;
				 cast_mut::<_,WildcardedNameContext >(&mut _localctx).Prefix = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2660);
			recog.base.match_token(ASTERISK,&mut recog.err_handler)?;

			recog.base.set_state(2664);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==ASTERISK || ((((_la - 38)) & !0x3f) == 0 && ((1usize << (_la - 38)) & ((1usize << (ACCESS - 38)) | (1usize << (ACCUMULATE - 38)) | (1usize << (AGGREGATIONS - 38)) | (1usize << (ALIAS - 38)) | (1usize << (ALL - 38)) | (1usize << (AS - 38)) | (1usize << (AXES - 38)) | (1usize << (BASE - 38)) | (1usize << (BIN - 38)) | (1usize << (BY - 38)) | (1usize << (CLUSTER - 38)) | (1usize << (CONSUME - 38)) | (1usize << (CONTAINS - 38)) | (1usize << (COUNT - 38)) | (1usize << (DATABASE - 38)))) != 0) || ((((_la - 71)) & !0x3f) == 0 && ((1usize << (_la - 71)) & ((1usize << (DATATABLE - 71)) | (1usize << (DECLARE - 71)) | (1usize << (DEFAULT - 71)) | (1usize << (DELTA - 71)) | (1usize << (DISTINCT - 71)) | (1usize << (EDGES - 71)) | (1usize << (EVALUATE - 71)) | (1usize << (EXECUTE - 71)) | (1usize << (EXTEND - 71)) | (1usize << (EXTERNALDATA - 71)) | (1usize << (FACET - 71)) | (1usize << (FILTER - 71)) | (1usize << (FIND - 71)) | (1usize << (FORK - 71)) | (1usize << (FROM - 71)))) != 0) || ((((_la - 104)) & !0x3f) == 0 && ((1usize << (_la - 104)) & ((1usize << (HAS - 104)) | (1usize << (HIDDEN_ - 104)) | (1usize << (HOT - 104)) | (1usize << (HOTDATA - 104)) | (1usize << (HOTINDEX - 104)) | (1usize << (ID - 104)) | (1usize << (IN - 104)) | (1usize << (INTO - 104)) | (1usize << (INVOKE - 104)))) != 0) || ((((_la - 140)) & !0x3f) == 0 && ((1usize << (_la - 140)) & ((1usize << (LEGEND - 140)) | (1usize << (LET - 140)) | (1usize << (LIMIT - 140)) | (1usize << (LINEAR - 140)) | (1usize << (LIST - 140)) | (1usize << (LOOKUP - 140)) | (1usize << (LOG - 140)) | (1usize << (MAP - 140)) | (1usize << (MATERIALIZE - 140)) | (1usize << (NODES - 140)) | (1usize << (NONE - 140)))) != 0) || ((((_la - 183)) & !0x3f) == 0 && ((1usize << (_la - 183)) & ((1usize << (NULL - 183)) | (1usize << (NULLS - 183)) | (1usize << (OF - 183)) | (1usize << (ON - 183)) | (1usize << (OPTIONAL - 183)) | (1usize << (OUTPUT - 183)) | (1usize << (PACK - 183)) | (1usize << (PARSE - 183)) | (1usize << (PARTITION - 183)) | (1usize << (PARTITIONBY - 183)) | (1usize << (PATTERN - 183)) | (1usize << (PLUGIN - 183)) | (1usize << (PRINT - 183)) | (1usize << (QUERYPARAMETERS - 183)) | (1usize << (RANGE - 183)))) != 0) || ((((_la - 215)) & !0x3f) == 0 && ((1usize << (_la - 215)) & ((1usize << (REDUCE - 215)) | (1usize << (RENDER - 215)) | (1usize << (REPLACE - 215)) | (1usize << (RESTRICT - 215)) | (1usize << (SAMPLE - 215)) | (1usize << (SAMPLE_DISTINCT - 215)) | (1usize << (SCAN - 215)) | (1usize << (SEARCH - 215)) | (1usize << (SERIALIZE - 215)) | (1usize << (SERIES - 215)) | (1usize << (SET - 215)) | (1usize << (SORT - 215)) | (1usize << (STACKED - 215)) | (1usize << (STACKED100 - 215)) | (1usize << (STEP - 215)) | (1usize << (SUMMARIZE - 215)) | (1usize << (TAKE - 215)) | (1usize << (THRESHOLD - 215)) | (1usize << (TITLE - 215)) | (1usize << (TO - 215)))) != 0) || ((((_la - 247)) & !0x3f) == 0 && ((1usize << (_la - 247)) & ((1usize << (TOP - 247)) | (1usize << (TOP_HITTERS - 247)) | (1usize << (TOP_NESTED - 247)) | (1usize << (TOSCALAR - 247)) | (1usize << (TOTABLE - 247)) | (1usize << (TYPEOF - 247)) | (1usize << (UNSTACKED - 247)) | (1usize << (UUID - 247)) | (1usize << (VIEW - 247)) | (1usize << (VISIBLE - 247)) | (1usize << (WHERE - 247)) | (1usize << (WITH - 247)) | (1usize << (XAXIS - 247)) | (1usize << (XCOLUMN - 247)) | (1usize << (XMAX - 247)) | (1usize << (XMIN - 247)) | (1usize << (XTITLE - 247)) | (1usize << (YAXIS - 247)) | (1usize << (YCOLUMNS - 247)) | (1usize << (YMAX - 247)) | (1usize << (YMIN - 247)) | (1usize << (YSPLIT - 247)) | (1usize << (YTITLE - 247)))) != 0) || ((((_la - 279)) & !0x3f) == 0 && ((1usize << (_la - 279)) & ((1usize << (BOOL - 279)) | (1usize << (GUID - 279)) | (1usize << (LONGLITERAL - 279)))) != 0) || _la==IDENTIFIER {
				{
				{
				/*InvokeRule wildcardedNameSegment*/
				recog.base.set_state(2661);
				let tmp = recog.wildcardedNameSegment()?;
				 cast_mut::<_,WildcardedNameContext >(&mut _localctx).wildcardedNameSegment = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,WildcardedNameContext >(&mut _localctx).wildcardedNameSegment.clone().unwrap()
				 ;
				 cast_mut::<_,WildcardedNameContext >(&mut _localctx).Segments.push(temp);
				  
				}
				}
				recog.base.set_state(2666);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedNamePrefix ----------------
pub type WildcardedNamePrefixContextAll<'input> = WildcardedNamePrefixContext<'input>;


pub type WildcardedNamePrefixContext<'input> = BaseParserRuleContext<'input,WildcardedNamePrefixContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedNamePrefixContextExt<'input>{
	pub Identifier: Option<TokenType<'input>>,
	pub Keyword: Option<Rc<KeywordNameContextAll<'input>>>,
	pub ExtendedKeyword: Option<Rc<ExtendedKeywordNameContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedNamePrefixContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedNamePrefixContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedNamePrefix(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedNamePrefix(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedNamePrefixContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedNamePrefix(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedNamePrefixContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedNamePrefix }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedNamePrefix }
}
antlr_rust::tid!{WildcardedNamePrefixContextExt<'a>}

impl<'input> WildcardedNamePrefixContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedNamePrefixContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedNamePrefixContextExt{
				Identifier: None, 
				Keyword: None, ExtendedKeyword: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedNamePrefixContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedNamePrefixContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}
fn keywordName(&self) -> Option<Rc<KeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendedKeywordName(&self) -> Option<Rc<ExtendedKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> WildcardedNamePrefixContextAttrs<'input> for WildcardedNamePrefixContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedNamePrefix(&mut self,)
	-> Result<Rc<WildcardedNamePrefixContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedNamePrefixContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 546, RULE_wildcardedNamePrefix);
        let mut _localctx: Rc<WildcardedNamePrefixContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2670);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2667);
					let tmp = recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;
					 cast_mut::<_,WildcardedNamePrefixContext >(&mut _localctx).Identifier = Some(tmp.clone());
					  

					}
				}

			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keywordName*/
					recog.base.set_state(2668);
					let tmp = recog.keywordName()?;
					 cast_mut::<_,WildcardedNamePrefixContext >(&mut _localctx).Keyword = Some(tmp.clone());
					  

					}
				}

			 ACCUMULATE | AS | BY | CONSUME | CONTAINS | COUNT | DATATABLE | DISTINCT |
			 EXTEND | EXTERNALDATA | FILTER | FIND | HAS | IN | INVOKE | LIMIT | MATERIALIZE |
			 OF | PARSE | PRINT | SAMPLE | SAMPLE_DISTINCT | SCAN | SEARCH | SERIALIZE |
			 SET | SORT | SUMMARIZE | TAKE | TITLE | TO | TOP | TOP_HITTERS | TOP_NESTED |
			 TOSCALAR | TOTABLE | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule extendedKeywordName*/
					recog.base.set_state(2669);
					let tmp = recog.extendedKeywordName()?;
					 cast_mut::<_,WildcardedNamePrefixContext >(&mut _localctx).ExtendedKeyword = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- wildcardedNameSegment ----------------
pub type WildcardedNameSegmentContextAll<'input> = WildcardedNameSegmentContext<'input>;


pub type WildcardedNameSegmentContext<'input> = BaseParserRuleContext<'input,WildcardedNameSegmentContextExt<'input>>;

#[derive(Clone)]
pub struct WildcardedNameSegmentContextExt<'input>{
	pub Identifier: Option<TokenType<'input>>,
	pub Keyword: Option<Rc<KeywordNameContextAll<'input>>>,
	pub ExtendedKeyword: Option<Rc<ExtendedKeywordNameContextAll<'input>>>,
	pub Number: Option<TokenType<'input>>,
	pub Star: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for WildcardedNameSegmentContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for WildcardedNameSegmentContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_wildcardedNameSegment(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_wildcardedNameSegment(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for WildcardedNameSegmentContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_wildcardedNameSegment(self);
	}
}

impl<'input> CustomRuleContext<'input> for WildcardedNameSegmentContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_wildcardedNameSegment }
	//fn type_rule_index() -> usize where Self: Sized { RULE_wildcardedNameSegment }
}
antlr_rust::tid!{WildcardedNameSegmentContextExt<'a>}

impl<'input> WildcardedNameSegmentContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<WildcardedNameSegmentContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,WildcardedNameSegmentContextExt{
				Identifier: None, Number: None, Star: None, 
				Keyword: None, ExtendedKeyword: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait WildcardedNameSegmentContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<WildcardedNameSegmentContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token IDENTIFIER
/// Returns `None` if there is no child corresponding to token IDENTIFIER
fn IDENTIFIER(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(IDENTIFIER, 0)
}
fn keywordName(&self) -> Option<Rc<KeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn extendedKeywordName(&self) -> Option<Rc<ExtendedKeywordNameContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
/// Retrieves first TerminalNode corresponding to token LONGLITERAL
/// Returns `None` if there is no child corresponding to token LONGLITERAL
fn LONGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONGLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token ASTERISK
/// Returns `None` if there is no child corresponding to token ASTERISK
fn ASTERISK(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(ASTERISK, 0)
}

}

impl<'input> WildcardedNameSegmentContextAttrs<'input> for WildcardedNameSegmentContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn wildcardedNameSegment(&mut self,)
	-> Result<Rc<WildcardedNameSegmentContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = WildcardedNameSegmentContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 548, RULE_wildcardedNameSegment);
        let mut _localctx: Rc<WildcardedNameSegmentContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2677);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 IDENTIFIER 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					recog.base.set_state(2672);
					let tmp = recog.base.match_token(IDENTIFIER,&mut recog.err_handler)?;
					 cast_mut::<_,WildcardedNameSegmentContext >(&mut _localctx).Identifier = Some(tmp.clone());
					  

					}
				}

			 ACCESS | AGGREGATIONS | ALIAS | ALL | AXES | BASE | BIN | CLUSTER | DATABASE |
			 DECLARE | DEFAULT | DELTA | EDGES | EVALUATE | EXECUTE | FACET | FORK |
			 FROM | HIDDEN_ | HOT | HOTDATA | HOTINDEX | ID | INTO | LEGEND | LET |
			 LINEAR | LIST | LOOKUP | LOG | MAP | NODES | NONE | NULL | NULLS | ON |
			 OPTIONAL | OUTPUT | PACK | PARTITION | PARTITIONBY | PATTERN | PLUGIN |
			 QUERYPARAMETERS | RANGE | REDUCE | RENDER | REPLACE | RESTRICT | SERIES |
			 STACKED | STACKED100 | STEP | THRESHOLD | TYPEOF | UNSTACKED | UUID |
			 VIEW | VISIBLE | WITH | XAXIS | XCOLUMN | XMAX | XMIN | XTITLE | YAXIS |
			 YCOLUMNS | YMAX | YMIN | YSPLIT | YTITLE | BOOL | GUID 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule keywordName*/
					recog.base.set_state(2673);
					let tmp = recog.keywordName()?;
					 cast_mut::<_,WildcardedNameSegmentContext >(&mut _localctx).Keyword = Some(tmp.clone());
					  

					}
				}

			 ACCUMULATE | AS | BY | CONSUME | CONTAINS | COUNT | DATATABLE | DISTINCT |
			 EXTEND | EXTERNALDATA | FILTER | FIND | HAS | IN | INVOKE | LIMIT | MATERIALIZE |
			 OF | PARSE | PRINT | SAMPLE | SAMPLE_DISTINCT | SCAN | SEARCH | SERIALIZE |
			 SET | SORT | SUMMARIZE | TAKE | TITLE | TO | TOP | TOP_HITTERS | TOP_NESTED |
			 TOSCALAR | TOTABLE | WHERE 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule extendedKeywordName*/
					recog.base.set_state(2674);
					let tmp = recog.extendedKeywordName()?;
					 cast_mut::<_,WildcardedNameSegmentContext >(&mut _localctx).ExtendedKeyword = Some(tmp.clone());
					  

					}
				}

			 LONGLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					recog.base.set_state(2675);
					let tmp = recog.base.match_token(LONGLITERAL,&mut recog.err_handler)?;
					 cast_mut::<_,WildcardedNameSegmentContext >(&mut _localctx).Number = Some(tmp.clone());
					  

					}
				}

			 ASTERISK 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					recog.base.set_state(2676);
					let tmp = recog.base.match_token(ASTERISK,&mut recog.err_handler)?;
					 cast_mut::<_,WildcardedNameSegmentContext >(&mut _localctx).Star = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- literalExpression ----------------
pub type LiteralExpressionContextAll<'input> = LiteralExpressionContext<'input>;


pub type LiteralExpressionContext<'input> = BaseParserRuleContext<'input,LiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct LiteralExpressionContextExt<'input>{
	pub Signed: Option<Rc<SignedLiteralExpressionContextAll<'input>>>,
	pub Unsigned: Option<Rc<UnsignedLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_literalExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_literalExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_literalExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for LiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_literalExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_literalExpression }
}
antlr_rust::tid!{LiteralExpressionContextExt<'a>}

impl<'input> LiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LiteralExpressionContextExt{
				Signed: None, Unsigned: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LiteralExpressionContextExt<'input>>{

fn signedLiteralExpression(&self) -> Option<Rc<SignedLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn unsignedLiteralExpression(&self) -> Option<Rc<UnsignedLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> LiteralExpressionContextAttrs<'input> for LiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn literalExpression(&mut self,)
	-> Result<Rc<LiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 550, RULE_literalExpression);
        let mut _localctx: Rc<LiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2681);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 DASH | PLUS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule signedLiteralExpression*/
					recog.base.set_state(2679);
					let tmp = recog.signedLiteralExpression()?;
					 cast_mut::<_,LiteralExpressionContext >(&mut _localctx).Signed = Some(tmp.clone());
					  

					}
				}

			 DYNAMIC | LONGLITERAL | INTLITERAL | REALLITERAL | DECIMALLITERAL | STRINGLITERAL |
			 BOOLEANLITERAL | DATETIMELITERAL | TIMESPANLITERAL | TYPELITERAL | GUIDLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule unsignedLiteralExpression*/
					recog.base.set_state(2680);
					let tmp = recog.unsignedLiteralExpression()?;
					 cast_mut::<_,LiteralExpressionContext >(&mut _localctx).Unsigned = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- unsignedLiteralExpression ----------------
pub type UnsignedLiteralExpressionContextAll<'input> = UnsignedLiteralExpressionContext<'input>;


pub type UnsignedLiteralExpressionContext<'input> = BaseParserRuleContext<'input,UnsignedLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct UnsignedLiteralExpressionContextExt<'input>{
	pub Long: Option<Rc<LongLiteralExpressionContextAll<'input>>>,
	pub Int: Option<Rc<IntLiteralExpressionContextAll<'input>>>,
	pub Real: Option<Rc<RealLiteralExpressionContextAll<'input>>>,
	pub Decimal: Option<Rc<DecimalLiteralExpressionContextAll<'input>>>,
	pub DateTime: Option<Rc<DateTimeLiteralExpressionContextAll<'input>>>,
	pub TimeSpan: Option<Rc<TimeSpanLiteralExpressionContextAll<'input>>>,
	pub Boolean: Option<Rc<BooleanLiteralExpressionContextAll<'input>>>,
	pub Guid: Option<Rc<GuidLiteralExpressionContextAll<'input>>>,
	pub Type: Option<Rc<TypeLiteralExpressionContextAll<'input>>>,
	pub String: Option<Rc<StringLiteralExpressionContextAll<'input>>>,
	pub Dynamic: Option<Rc<DynamicLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for UnsignedLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for UnsignedLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_unsignedLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_unsignedLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for UnsignedLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_unsignedLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for UnsignedLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_unsignedLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_unsignedLiteralExpression }
}
antlr_rust::tid!{UnsignedLiteralExpressionContextExt<'a>}

impl<'input> UnsignedLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<UnsignedLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,UnsignedLiteralExpressionContextExt{
				Long: None, Int: None, Real: None, Decimal: None, DateTime: None, TimeSpan: None, Boolean: None, Guid: None, Type: None, String: None, Dynamic: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait UnsignedLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<UnsignedLiteralExpressionContextExt<'input>>{

fn longLiteralExpression(&self) -> Option<Rc<LongLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intLiteralExpression(&self) -> Option<Rc<IntLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn realLiteralExpression(&self) -> Option<Rc<RealLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn decimalLiteralExpression(&self) -> Option<Rc<DecimalLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dateTimeLiteralExpression(&self) -> Option<Rc<DateTimeLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn timeSpanLiteralExpression(&self) -> Option<Rc<TimeSpanLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn booleanLiteralExpression(&self) -> Option<Rc<BooleanLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn guidLiteralExpression(&self) -> Option<Rc<GuidLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn typeLiteralExpression(&self) -> Option<Rc<TypeLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn stringLiteralExpression(&self) -> Option<Rc<StringLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dynamicLiteralExpression(&self) -> Option<Rc<DynamicLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> UnsignedLiteralExpressionContextAttrs<'input> for UnsignedLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn unsignedLiteralExpression(&mut self,)
	-> Result<Rc<UnsignedLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = UnsignedLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 552, RULE_unsignedLiteralExpression);
        let mut _localctx: Rc<UnsignedLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2694);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LONGLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule longLiteralExpression*/
					recog.base.set_state(2683);
					let tmp = recog.longLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Long = Some(tmp.clone());
					  

					}
				}

			 INTLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule intLiteralExpression*/
					recog.base.set_state(2684);
					let tmp = recog.intLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Int = Some(tmp.clone());
					  

					}
				}

			 REALLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule realLiteralExpression*/
					recog.base.set_state(2685);
					let tmp = recog.realLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Real = Some(tmp.clone());
					  

					}
				}

			 DECIMALLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule decimalLiteralExpression*/
					recog.base.set_state(2686);
					let tmp = recog.decimalLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Decimal = Some(tmp.clone());
					  

					}
				}

			 DATETIMELITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule dateTimeLiteralExpression*/
					recog.base.set_state(2687);
					let tmp = recog.dateTimeLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).DateTime = Some(tmp.clone());
					  

					}
				}

			 TIMESPANLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule timeSpanLiteralExpression*/
					recog.base.set_state(2688);
					let tmp = recog.timeSpanLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).TimeSpan = Some(tmp.clone());
					  

					}
				}

			 BOOLEANLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule booleanLiteralExpression*/
					recog.base.set_state(2689);
					let tmp = recog.booleanLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Boolean = Some(tmp.clone());
					  

					}
				}

			 GUIDLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule guidLiteralExpression*/
					recog.base.set_state(2690);
					let tmp = recog.guidLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Guid = Some(tmp.clone());
					  

					}
				}

			 TYPELITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule typeLiteralExpression*/
					recog.base.set_state(2691);
					let tmp = recog.typeLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Type = Some(tmp.clone());
					  

					}
				}

			 STRINGLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule stringLiteralExpression*/
					recog.base.set_state(2692);
					let tmp = recog.stringLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).String = Some(tmp.clone());
					  

					}
				}

			 DYNAMIC 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule dynamicLiteralExpression*/
					recog.base.set_state(2693);
					let tmp = recog.dynamicLiteralExpression()?;
					 cast_mut::<_,UnsignedLiteralExpressionContext >(&mut _localctx).Dynamic = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- numberLikeLiteralExpression ----------------
pub type NumberLikeLiteralExpressionContextAll<'input> = NumberLikeLiteralExpressionContext<'input>;


pub type NumberLikeLiteralExpressionContext<'input> = BaseParserRuleContext<'input,NumberLikeLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NumberLikeLiteralExpressionContextExt<'input>{
	pub Long: Option<Rc<LongLiteralExpressionContextAll<'input>>>,
	pub Int: Option<Rc<IntLiteralExpressionContextAll<'input>>>,
	pub Real: Option<Rc<RealLiteralExpressionContextAll<'input>>>,
	pub Decimal: Option<Rc<DecimalLiteralExpressionContextAll<'input>>>,
	pub Signed: Option<Rc<SignedLiteralExpressionContextAll<'input>>>,
	pub DateTime: Option<Rc<DateTimeLiteralExpressionContextAll<'input>>>,
	pub TimeSpan: Option<Rc<TimeSpanLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NumberLikeLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NumberLikeLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_numberLikeLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_numberLikeLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NumberLikeLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_numberLikeLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NumberLikeLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_numberLikeLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_numberLikeLiteralExpression }
}
antlr_rust::tid!{NumberLikeLiteralExpressionContextExt<'a>}

impl<'input> NumberLikeLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NumberLikeLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NumberLikeLiteralExpressionContextExt{
				Long: None, Int: None, Real: None, Decimal: None, Signed: None, DateTime: None, TimeSpan: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NumberLikeLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NumberLikeLiteralExpressionContextExt<'input>>{

fn longLiteralExpression(&self) -> Option<Rc<LongLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intLiteralExpression(&self) -> Option<Rc<IntLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn realLiteralExpression(&self) -> Option<Rc<RealLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn decimalLiteralExpression(&self) -> Option<Rc<DecimalLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn signedLiteralExpression(&self) -> Option<Rc<SignedLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dateTimeLiteralExpression(&self) -> Option<Rc<DateTimeLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn timeSpanLiteralExpression(&self) -> Option<Rc<TimeSpanLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NumberLikeLiteralExpressionContextAttrs<'input> for NumberLikeLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn numberLikeLiteralExpression(&mut self,)
	-> Result<Rc<NumberLikeLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NumberLikeLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 554, RULE_numberLikeLiteralExpression);
        let mut _localctx: Rc<NumberLikeLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2703);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LONGLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule longLiteralExpression*/
					recog.base.set_state(2696);
					let tmp = recog.longLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).Long = Some(tmp.clone());
					  

					}
				}

			 INTLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule intLiteralExpression*/
					recog.base.set_state(2697);
					let tmp = recog.intLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).Int = Some(tmp.clone());
					  

					}
				}

			 REALLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule realLiteralExpression*/
					recog.base.set_state(2698);
					let tmp = recog.realLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).Real = Some(tmp.clone());
					  

					}
				}

			 DECIMALLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule decimalLiteralExpression*/
					recog.base.set_state(2699);
					let tmp = recog.decimalLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).Decimal = Some(tmp.clone());
					  

					}
				}

			 DASH | PLUS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule signedLiteralExpression*/
					recog.base.set_state(2700);
					let tmp = recog.signedLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).Signed = Some(tmp.clone());
					  

					}
				}

			 DATETIMELITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule dateTimeLiteralExpression*/
					recog.base.set_state(2701);
					let tmp = recog.dateTimeLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).DateTime = Some(tmp.clone());
					  

					}
				}

			 TIMESPANLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule timeSpanLiteralExpression*/
					recog.base.set_state(2702);
					let tmp = recog.timeSpanLiteralExpression()?;
					 cast_mut::<_,NumberLikeLiteralExpressionContext >(&mut _localctx).TimeSpan = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- numericLiteralExpression ----------------
pub type NumericLiteralExpressionContextAll<'input> = NumericLiteralExpressionContext<'input>;


pub type NumericLiteralExpressionContext<'input> = BaseParserRuleContext<'input,NumericLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct NumericLiteralExpressionContextExt<'input>{
	pub Long: Option<Rc<LongLiteralExpressionContextAll<'input>>>,
	pub Int: Option<Rc<IntLiteralExpressionContextAll<'input>>>,
	pub Real: Option<Rc<RealLiteralExpressionContextAll<'input>>>,
	pub Decimal: Option<Rc<DecimalLiteralExpressionContextAll<'input>>>,
	pub Signed: Option<Rc<SignedLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for NumericLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for NumericLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_numericLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_numericLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for NumericLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_numericLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for NumericLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_numericLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_numericLiteralExpression }
}
antlr_rust::tid!{NumericLiteralExpressionContextExt<'a>}

impl<'input> NumericLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<NumericLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,NumericLiteralExpressionContextExt{
				Long: None, Int: None, Real: None, Decimal: None, Signed: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait NumericLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<NumericLiteralExpressionContextExt<'input>>{

fn longLiteralExpression(&self) -> Option<Rc<LongLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn intLiteralExpression(&self) -> Option<Rc<IntLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn realLiteralExpression(&self) -> Option<Rc<RealLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn decimalLiteralExpression(&self) -> Option<Rc<DecimalLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn signedLiteralExpression(&self) -> Option<Rc<SignedLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> NumericLiteralExpressionContextAttrs<'input> for NumericLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn numericLiteralExpression(&mut self,)
	-> Result<Rc<NumericLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = NumericLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 556, RULE_numericLiteralExpression);
        let mut _localctx: Rc<NumericLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2710);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 LONGLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule longLiteralExpression*/
					recog.base.set_state(2705);
					let tmp = recog.longLiteralExpression()?;
					 cast_mut::<_,NumericLiteralExpressionContext >(&mut _localctx).Long = Some(tmp.clone());
					  

					}
				}

			 INTLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule intLiteralExpression*/
					recog.base.set_state(2706);
					let tmp = recog.intLiteralExpression()?;
					 cast_mut::<_,NumericLiteralExpressionContext >(&mut _localctx).Int = Some(tmp.clone());
					  

					}
				}

			 REALLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule realLiteralExpression*/
					recog.base.set_state(2707);
					let tmp = recog.realLiteralExpression()?;
					 cast_mut::<_,NumericLiteralExpressionContext >(&mut _localctx).Real = Some(tmp.clone());
					  

					}
				}

			 DECIMALLITERAL 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule decimalLiteralExpression*/
					recog.base.set_state(2708);
					let tmp = recog.decimalLiteralExpression()?;
					 cast_mut::<_,NumericLiteralExpressionContext >(&mut _localctx).Decimal = Some(tmp.clone());
					  

					}
				}

			 DASH | PLUS 
				=> {
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule signedLiteralExpression*/
					recog.base.set_state(2709);
					let tmp = recog.signedLiteralExpression()?;
					 cast_mut::<_,NumericLiteralExpressionContext >(&mut _localctx).Signed = Some(tmp.clone());
					  

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- signedLiteralExpression ----------------
pub type SignedLiteralExpressionContextAll<'input> = SignedLiteralExpressionContext<'input>;


pub type SignedLiteralExpressionContext<'input> = BaseParserRuleContext<'input,SignedLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SignedLiteralExpressionContextExt<'input>{
	pub Long: Option<Rc<SignedLongLiteralExpressionContextAll<'input>>>,
	pub Real: Option<Rc<SignedRealLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SignedLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SignedLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_signedLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_signedLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SignedLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_signedLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SignedLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_signedLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_signedLiteralExpression }
}
antlr_rust::tid!{SignedLiteralExpressionContextExt<'a>}

impl<'input> SignedLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SignedLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SignedLiteralExpressionContextExt{
				Long: None, Real: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SignedLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SignedLiteralExpressionContextExt<'input>>{

fn signedLongLiteralExpression(&self) -> Option<Rc<SignedLongLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn signedRealLiteralExpression(&self) -> Option<Rc<SignedRealLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> SignedLiteralExpressionContextAttrs<'input> for SignedLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn signedLiteralExpression(&mut self,)
	-> Result<Rc<SignedLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SignedLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 558, RULE_signedLiteralExpression);
        let mut _localctx: Rc<SignedLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2714);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(249,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule signedLongLiteralExpression*/
					recog.base.set_state(2712);
					let tmp = recog.signedLongLiteralExpression()?;
					 cast_mut::<_,SignedLiteralExpressionContext >(&mut _localctx).Long = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule signedRealLiteralExpression*/
					recog.base.set_state(2713);
					let tmp = recog.signedRealLiteralExpression()?;
					 cast_mut::<_,SignedLiteralExpressionContext >(&mut _localctx).Real = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- longLiteralExpression ----------------
pub type LongLiteralExpressionContextAll<'input> = LongLiteralExpressionContext<'input>;


pub type LongLiteralExpressionContext<'input> = BaseParserRuleContext<'input,LongLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct LongLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for LongLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for LongLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_longLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_longLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for LongLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_longLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for LongLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_longLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_longLiteralExpression }
}
antlr_rust::tid!{LongLiteralExpressionContextExt<'a>}

impl<'input> LongLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<LongLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,LongLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait LongLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<LongLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LONGLITERAL
/// Returns `None` if there is no child corresponding to token LONGLITERAL
fn LONGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONGLITERAL, 0)
}

}

impl<'input> LongLiteralExpressionContextAttrs<'input> for LongLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn longLiteralExpression(&mut self,)
	-> Result<Rc<LongLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = LongLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 560, RULE_longLiteralExpression);
        let mut _localctx: Rc<LongLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2716);
			let tmp = recog.base.match_token(LONGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,LongLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- intLiteralExpression ----------------
pub type IntLiteralExpressionContextAll<'input> = IntLiteralExpressionContext<'input>;


pub type IntLiteralExpressionContext<'input> = BaseParserRuleContext<'input,IntLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct IntLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for IntLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for IntLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_intLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_intLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for IntLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_intLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for IntLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_intLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_intLiteralExpression }
}
antlr_rust::tid!{IntLiteralExpressionContextExt<'a>}

impl<'input> IntLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<IntLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,IntLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait IntLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<IntLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token INTLITERAL
/// Returns `None` if there is no child corresponding to token INTLITERAL
fn INTLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(INTLITERAL, 0)
}

}

impl<'input> IntLiteralExpressionContextAttrs<'input> for IntLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn intLiteralExpression(&mut self,)
	-> Result<Rc<IntLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = IntLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 562, RULE_intLiteralExpression);
        let mut _localctx: Rc<IntLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2718);
			let tmp = recog.base.match_token(INTLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,IntLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- realLiteralExpression ----------------
pub type RealLiteralExpressionContextAll<'input> = RealLiteralExpressionContext<'input>;


pub type RealLiteralExpressionContext<'input> = BaseParserRuleContext<'input,RealLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct RealLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for RealLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for RealLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_realLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_realLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for RealLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_realLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for RealLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_realLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_realLiteralExpression }
}
antlr_rust::tid!{RealLiteralExpressionContextExt<'a>}

impl<'input> RealLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<RealLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,RealLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait RealLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<RealLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token REALLITERAL
/// Returns `None` if there is no child corresponding to token REALLITERAL
fn REALLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REALLITERAL, 0)
}

}

impl<'input> RealLiteralExpressionContextAttrs<'input> for RealLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn realLiteralExpression(&mut self,)
	-> Result<Rc<RealLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = RealLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 564, RULE_realLiteralExpression);
        let mut _localctx: Rc<RealLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2720);
			let tmp = recog.base.match_token(REALLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,RealLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- decimalLiteralExpression ----------------
pub type DecimalLiteralExpressionContextAll<'input> = DecimalLiteralExpressionContext<'input>;


pub type DecimalLiteralExpressionContext<'input> = BaseParserRuleContext<'input,DecimalLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DecimalLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DecimalLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DecimalLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_decimalLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_decimalLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DecimalLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_decimalLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DecimalLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_decimalLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_decimalLiteralExpression }
}
antlr_rust::tid!{DecimalLiteralExpressionContextExt<'a>}

impl<'input> DecimalLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DecimalLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DecimalLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DecimalLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DecimalLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DECIMALLITERAL
/// Returns `None` if there is no child corresponding to token DECIMALLITERAL
fn DECIMALLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DECIMALLITERAL, 0)
}

}

impl<'input> DecimalLiteralExpressionContextAttrs<'input> for DecimalLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn decimalLiteralExpression(&mut self,)
	-> Result<Rc<DecimalLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DecimalLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 566, RULE_decimalLiteralExpression);
        let mut _localctx: Rc<DecimalLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2722);
			let tmp = recog.base.match_token(DECIMALLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,DecimalLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dateTimeLiteralExpression ----------------
pub type DateTimeLiteralExpressionContextAll<'input> = DateTimeLiteralExpressionContext<'input>;


pub type DateTimeLiteralExpressionContext<'input> = BaseParserRuleContext<'input,DateTimeLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DateTimeLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DateTimeLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DateTimeLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dateTimeLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_dateTimeLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DateTimeLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_dateTimeLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DateTimeLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dateTimeLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dateTimeLiteralExpression }
}
antlr_rust::tid!{DateTimeLiteralExpressionContextExt<'a>}

impl<'input> DateTimeLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DateTimeLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DateTimeLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DateTimeLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DateTimeLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DATETIMELITERAL
/// Returns `None` if there is no child corresponding to token DATETIMELITERAL
fn DATETIMELITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATETIMELITERAL, 0)
}

}

impl<'input> DateTimeLiteralExpressionContextAttrs<'input> for DateTimeLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dateTimeLiteralExpression(&mut self,)
	-> Result<Rc<DateTimeLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DateTimeLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 568, RULE_dateTimeLiteralExpression);
        let mut _localctx: Rc<DateTimeLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2724);
			let tmp = recog.base.match_token(DATETIMELITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,DateTimeLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- timeSpanLiteralExpression ----------------
pub type TimeSpanLiteralExpressionContextAll<'input> = TimeSpanLiteralExpressionContext<'input>;


pub type TimeSpanLiteralExpressionContext<'input> = BaseParserRuleContext<'input,TimeSpanLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TimeSpanLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TimeSpanLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TimeSpanLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_timeSpanLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_timeSpanLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TimeSpanLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_timeSpanLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for TimeSpanLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_timeSpanLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_timeSpanLiteralExpression }
}
antlr_rust::tid!{TimeSpanLiteralExpressionContextExt<'a>}

impl<'input> TimeSpanLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TimeSpanLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TimeSpanLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TimeSpanLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TimeSpanLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIMESPANLITERAL
/// Returns `None` if there is no child corresponding to token TIMESPANLITERAL
fn TIMESPANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMESPANLITERAL, 0)
}

}

impl<'input> TimeSpanLiteralExpressionContextAttrs<'input> for TimeSpanLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn timeSpanLiteralExpression(&mut self,)
	-> Result<Rc<TimeSpanLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TimeSpanLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 570, RULE_timeSpanLiteralExpression);
        let mut _localctx: Rc<TimeSpanLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2726);
			let tmp = recog.base.match_token(TIMESPANLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,TimeSpanLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- booleanLiteralExpression ----------------
pub type BooleanLiteralExpressionContextAll<'input> = BooleanLiteralExpressionContext<'input>;


pub type BooleanLiteralExpressionContext<'input> = BaseParserRuleContext<'input,BooleanLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct BooleanLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for BooleanLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for BooleanLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_booleanLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_booleanLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for BooleanLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_booleanLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for BooleanLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_booleanLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_booleanLiteralExpression }
}
antlr_rust::tid!{BooleanLiteralExpressionContextExt<'a>}

impl<'input> BooleanLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<BooleanLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,BooleanLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait BooleanLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<BooleanLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BOOLEANLITERAL
/// Returns `None` if there is no child corresponding to token BOOLEANLITERAL
fn BOOLEANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEANLITERAL, 0)
}

}

impl<'input> BooleanLiteralExpressionContextAttrs<'input> for BooleanLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn booleanLiteralExpression(&mut self,)
	-> Result<Rc<BooleanLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = BooleanLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 572, RULE_booleanLiteralExpression);
        let mut _localctx: Rc<BooleanLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2728);
			let tmp = recog.base.match_token(BOOLEANLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,BooleanLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- guidLiteralExpression ----------------
pub type GuidLiteralExpressionContextAll<'input> = GuidLiteralExpressionContext<'input>;


pub type GuidLiteralExpressionContext<'input> = BaseParserRuleContext<'input,GuidLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct GuidLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for GuidLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for GuidLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_guidLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_guidLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for GuidLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_guidLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for GuidLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_guidLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_guidLiteralExpression }
}
antlr_rust::tid!{GuidLiteralExpressionContextExt<'a>}

impl<'input> GuidLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<GuidLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,GuidLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait GuidLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<GuidLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GUIDLITERAL
/// Returns `None` if there is no child corresponding to token GUIDLITERAL
fn GUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUIDLITERAL, 0)
}

}

impl<'input> GuidLiteralExpressionContextAttrs<'input> for GuidLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn guidLiteralExpression(&mut self,)
	-> Result<Rc<GuidLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = GuidLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 574, RULE_guidLiteralExpression);
        let mut _localctx: Rc<GuidLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2730);
			let tmp = recog.base.match_token(GUIDLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,GuidLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- typeLiteralExpression ----------------
pub type TypeLiteralExpressionContextAll<'input> = TypeLiteralExpressionContext<'input>;


pub type TypeLiteralExpressionContext<'input> = BaseParserRuleContext<'input,TypeLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct TypeLiteralExpressionContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for TypeLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for TypeLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_typeLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_typeLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for TypeLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_typeLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for TypeLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_typeLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_typeLiteralExpression }
}
antlr_rust::tid!{TypeLiteralExpressionContextExt<'a>}

impl<'input> TypeLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<TypeLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,TypeLiteralExpressionContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait TypeLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<TypeLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TYPELITERAL
/// Returns `None` if there is no child corresponding to token TYPELITERAL
fn TYPELITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TYPELITERAL, 0)
}

}

impl<'input> TypeLiteralExpressionContextAttrs<'input> for TypeLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn typeLiteralExpression(&mut self,)
	-> Result<Rc<TypeLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = TypeLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 576, RULE_typeLiteralExpression);
        let mut _localctx: Rc<TypeLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2732);
			let tmp = recog.base.match_token(TYPELITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,TypeLiteralExpressionContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- signedLongLiteralExpression ----------------
pub type SignedLongLiteralExpressionContextAll<'input> = SignedLongLiteralExpressionContext<'input>;


pub type SignedLongLiteralExpressionContext<'input> = BaseParserRuleContext<'input,SignedLongLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SignedLongLiteralExpressionContextExt<'input>{
	pub SignToken: Option<TokenType<'input>>,
	pub LiteralToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SignedLongLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SignedLongLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_signedLongLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_signedLongLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SignedLongLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_signedLongLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SignedLongLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_signedLongLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_signedLongLiteralExpression }
}
antlr_rust::tid!{SignedLongLiteralExpressionContextExt<'a>}

impl<'input> SignedLongLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SignedLongLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SignedLongLiteralExpressionContextExt{
				SignToken: None, LiteralToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SignedLongLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SignedLongLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LONGLITERAL
/// Returns `None` if there is no child corresponding to token LONGLITERAL
fn LONGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONGLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token DASH
/// Returns `None` if there is no child corresponding to token DASH
fn DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH, 0)
}

}

impl<'input> SignedLongLiteralExpressionContextAttrs<'input> for SignedLongLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn signedLongLiteralExpression(&mut self,)
	-> Result<Rc<SignedLongLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SignedLongLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 578, RULE_signedLongLiteralExpression);
        let mut _localctx: Rc<SignedLongLiteralExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2734);
			 cast_mut::<_,SignedLongLiteralExpressionContext >(&mut _localctx).SignToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==DASH || _la==PLUS) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,SignedLongLiteralExpressionContext >(&mut _localctx).SignToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2735);
			let tmp = recog.base.match_token(LONGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,SignedLongLiteralExpressionContext >(&mut _localctx).LiteralToken = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- signedRealLiteralExpression ----------------
pub type SignedRealLiteralExpressionContextAll<'input> = SignedRealLiteralExpressionContext<'input>;


pub type SignedRealLiteralExpressionContext<'input> = BaseParserRuleContext<'input,SignedRealLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct SignedRealLiteralExpressionContextExt<'input>{
	pub SignToken: Option<TokenType<'input>>,
	pub LiteralToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for SignedRealLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for SignedRealLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_signedRealLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_signedRealLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for SignedRealLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_signedRealLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for SignedRealLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_signedRealLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_signedRealLiteralExpression }
}
antlr_rust::tid!{SignedRealLiteralExpressionContextExt<'a>}

impl<'input> SignedRealLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<SignedRealLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,SignedRealLiteralExpressionContextExt{
				SignToken: None, LiteralToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait SignedRealLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<SignedRealLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token REALLITERAL
/// Returns `None` if there is no child corresponding to token REALLITERAL
fn REALLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REALLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token PLUS
/// Returns `None` if there is no child corresponding to token PLUS
fn PLUS(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(PLUS, 0)
}
/// Retrieves first TerminalNode corresponding to token DASH
/// Returns `None` if there is no child corresponding to token DASH
fn DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH, 0)
}

}

impl<'input> SignedRealLiteralExpressionContextAttrs<'input> for SignedRealLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn signedRealLiteralExpression(&mut self,)
	-> Result<Rc<SignedRealLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = SignedRealLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 580, RULE_signedRealLiteralExpression);
        let mut _localctx: Rc<SignedRealLiteralExpressionContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2737);
			 cast_mut::<_,SignedRealLiteralExpressionContext >(&mut _localctx).SignToken = recog.base.input.lt(1).cloned();
			 
			_la = recog.base.input.la(1);
			if { !(_la==DASH || _la==PLUS) } {
				let tmp = recog.err_handler.recover_inline(&mut recog.base)?;
				 cast_mut::<_,SignedRealLiteralExpressionContext >(&mut _localctx).SignToken = Some(tmp.clone());
				  

			}
			else {
				if  recog.base.input.la(1)==TOKEN_EOF { recog.base.matched_eof = true };
				recog.err_handler.report_match(&mut recog.base);
				recog.base.consume(&mut recog.err_handler);
			}
			recog.base.set_state(2738);
			let tmp = recog.base.match_token(REALLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,SignedRealLiteralExpressionContext >(&mut _localctx).LiteralToken = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- stringLiteralExpression ----------------
pub type StringLiteralExpressionContextAll<'input> = StringLiteralExpressionContext<'input>;


pub type StringLiteralExpressionContext<'input> = BaseParserRuleContext<'input,StringLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct StringLiteralExpressionContextExt<'input>{
	pub STRINGLITERAL: Option<TokenType<'input>>,
	pub Tokens:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for StringLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for StringLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_stringLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_stringLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for StringLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_stringLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for StringLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stringLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stringLiteralExpression }
}
antlr_rust::tid!{StringLiteralExpressionContextExt<'a>}

impl<'input> StringLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StringLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StringLiteralExpressionContextExt{
				STRINGLITERAL: None, 
				Tokens: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait StringLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<StringLiteralExpressionContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token STRINGLITERAL in current rule
fn STRINGLITERAL_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token STRINGLITERAL, starting from 0.
/// Returns `None` if number of children corresponding to token STRINGLITERAL is less or equal than `i`.
fn STRINGLITERAL(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STRINGLITERAL, i)
}

}

impl<'input> StringLiteralExpressionContextAttrs<'input> for StringLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn stringLiteralExpression(&mut self,)
	-> Result<Rc<StringLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StringLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 582, RULE_stringLiteralExpression);
        let mut _localctx: Rc<StringLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2740);
			let tmp = recog.base.match_token(STRINGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,StringLiteralExpressionContext >(&mut _localctx).STRINGLITERAL = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,StringLiteralExpressionContext >(&mut _localctx).STRINGLITERAL.clone().unwrap()
			 ;
			 cast_mut::<_,StringLiteralExpressionContext >(&mut _localctx).Tokens.push(temp);
			  
			recog.base.set_state(2744);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(250,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					{
					{
					recog.base.set_state(2741);
					let tmp = recog.base.match_token(STRINGLITERAL,&mut recog.err_handler)?;
					 cast_mut::<_,StringLiteralExpressionContext >(&mut _localctx).STRINGLITERAL = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,StringLiteralExpressionContext >(&mut _localctx).STRINGLITERAL.clone().unwrap()
					 ;
					 cast_mut::<_,StringLiteralExpressionContext >(&mut _localctx).Tokens.push(temp);
					  
					}
					} 
				}
				recog.base.set_state(2746);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(250,&mut recog.base)?;
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- dynamicLiteralExpression ----------------
pub type DynamicLiteralExpressionContextAll<'input> = DynamicLiteralExpressionContext<'input>;


pub type DynamicLiteralExpressionContext<'input> = BaseParserRuleContext<'input,DynamicLiteralExpressionContextExt<'input>>;

#[derive(Clone)]
pub struct DynamicLiteralExpressionContextExt<'input>{
	pub Value: Option<Rc<JsonValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for DynamicLiteralExpressionContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for DynamicLiteralExpressionContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_dynamicLiteralExpression(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_dynamicLiteralExpression(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for DynamicLiteralExpressionContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_dynamicLiteralExpression(self);
	}
}

impl<'input> CustomRuleContext<'input> for DynamicLiteralExpressionContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_dynamicLiteralExpression }
	//fn type_rule_index() -> usize where Self: Sized { RULE_dynamicLiteralExpression }
}
antlr_rust::tid!{DynamicLiteralExpressionContextExt<'a>}

impl<'input> DynamicLiteralExpressionContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<DynamicLiteralExpressionContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,DynamicLiteralExpressionContextExt{
				Value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait DynamicLiteralExpressionContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<DynamicLiteralExpressionContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DYNAMIC
/// Returns `None` if there is no child corresponding to token DYNAMIC
fn DYNAMIC(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DYNAMIC, 0)
}
/// Retrieves first TerminalNode corresponding to token OPENPAREN
/// Returns `None` if there is no child corresponding to token OPENPAREN
fn OPENPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENPAREN, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEPAREN
/// Returns `None` if there is no child corresponding to token CLOSEPAREN
fn CLOSEPAREN(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEPAREN, 0)
}
fn jsonValue(&self) -> Option<Rc<JsonValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> DynamicLiteralExpressionContextAttrs<'input> for DynamicLiteralExpressionContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn dynamicLiteralExpression(&mut self,)
	-> Result<Rc<DynamicLiteralExpressionContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = DynamicLiteralExpressionContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 584, RULE_dynamicLiteralExpression);
        let mut _localctx: Rc<DynamicLiteralExpressionContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2747);
			recog.base.match_token(DYNAMIC,&mut recog.err_handler)?;

			recog.base.set_state(2748);
			recog.base.match_token(OPENPAREN,&mut recog.err_handler)?;

			/*InvokeRule jsonValue*/
			recog.base.set_state(2749);
			let tmp = recog.jsonValue()?;
			 cast_mut::<_,DynamicLiteralExpressionContext >(&mut _localctx).Value = Some(tmp.clone());
			  

			recog.base.set_state(2750);
			recog.base.match_token(CLOSEPAREN,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonValue ----------------
pub type JsonValueContextAll<'input> = JsonValueContext<'input>;


pub type JsonValueContext<'input> = BaseParserRuleContext<'input,JsonValueContextExt<'input>>;

#[derive(Clone)]
pub struct JsonValueContextExt<'input>{
	pub Array: Option<Rc<JsonArrayContextAll<'input>>>,
	pub Boolean: Option<Rc<JsonBooleanContextAll<'input>>>,
	pub DateTime: Option<Rc<JsonDateTimeContextAll<'input>>>,
	pub Guid: Option<Rc<JsonGuidContextAll<'input>>>,
	pub Long: Option<Rc<JsonLongContextAll<'input>>>,
	pub Null: Option<Rc<JsonNullContextAll<'input>>>,
	pub Object: Option<Rc<JsonObjectContextAll<'input>>>,
	pub Real: Option<Rc<JsonRealContextAll<'input>>>,
	pub String: Option<Rc<JsonStringContextAll<'input>>>,
	pub Timespan: Option<Rc<JsonTimeSpanContextAll<'input>>>,
	pub Dynamic: Option<Rc<DynamicLiteralExpressionContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonValueContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonValueContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonValue(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonValue(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonValueContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonValue(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonValueContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonValue }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonValue }
}
antlr_rust::tid!{JsonValueContextExt<'a>}

impl<'input> JsonValueContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonValueContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonValueContextExt{
				Array: None, Boolean: None, DateTime: None, Guid: None, Long: None, Null: None, Object: None, Real: None, String: None, Timespan: None, Dynamic: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonValueContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonValueContextExt<'input>>{

fn jsonArray(&self) -> Option<Rc<JsonArrayContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonBoolean(&self) -> Option<Rc<JsonBooleanContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonDateTime(&self) -> Option<Rc<JsonDateTimeContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonGuid(&self) -> Option<Rc<JsonGuidContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonLong(&self) -> Option<Rc<JsonLongContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonNull(&self) -> Option<Rc<JsonNullContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonObject(&self) -> Option<Rc<JsonObjectContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonReal(&self) -> Option<Rc<JsonRealContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonString(&self) -> Option<Rc<JsonStringContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn jsonTimeSpan(&self) -> Option<Rc<JsonTimeSpanContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}
fn dynamicLiteralExpression(&self) -> Option<Rc<DynamicLiteralExpressionContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JsonValueContextAttrs<'input> for JsonValueContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonValue(&mut self,)
	-> Result<Rc<JsonValueContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonValueContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 586, RULE_jsonValue);
        let mut _localctx: Rc<JsonValueContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			recog.base.set_state(2763);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(251,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule jsonArray*/
					recog.base.set_state(2752);
					let tmp = recog.jsonArray()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Array = Some(tmp.clone());
					  

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule jsonBoolean*/
					recog.base.set_state(2753);
					let tmp = recog.jsonBoolean()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Boolean = Some(tmp.clone());
					  

					}
				}
			,
				3 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 3);
					recog.base.enter_outer_alt(None, 3);
					{
					/*InvokeRule jsonDateTime*/
					recog.base.set_state(2754);
					let tmp = recog.jsonDateTime()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).DateTime = Some(tmp.clone());
					  

					}
				}
			,
				4 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 4);
					recog.base.enter_outer_alt(None, 4);
					{
					/*InvokeRule jsonGuid*/
					recog.base.set_state(2755);
					let tmp = recog.jsonGuid()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Guid = Some(tmp.clone());
					  

					}
				}
			,
				5 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 5);
					recog.base.enter_outer_alt(None, 5);
					{
					/*InvokeRule jsonLong*/
					recog.base.set_state(2756);
					let tmp = recog.jsonLong()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Long = Some(tmp.clone());
					  

					}
				}
			,
				6 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 6);
					recog.base.enter_outer_alt(None, 6);
					{
					/*InvokeRule jsonNull*/
					recog.base.set_state(2757);
					let tmp = recog.jsonNull()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Null = Some(tmp.clone());
					  

					}
				}
			,
				7 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 7);
					recog.base.enter_outer_alt(None, 7);
					{
					/*InvokeRule jsonObject*/
					recog.base.set_state(2758);
					let tmp = recog.jsonObject()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Object = Some(tmp.clone());
					  

					}
				}
			,
				8 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 8);
					recog.base.enter_outer_alt(None, 8);
					{
					/*InvokeRule jsonReal*/
					recog.base.set_state(2759);
					let tmp = recog.jsonReal()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Real = Some(tmp.clone());
					  

					}
				}
			,
				9 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 9);
					recog.base.enter_outer_alt(None, 9);
					{
					/*InvokeRule jsonString*/
					recog.base.set_state(2760);
					let tmp = recog.jsonString()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).String = Some(tmp.clone());
					  

					}
				}
			,
				10 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 10);
					recog.base.enter_outer_alt(None, 10);
					{
					/*InvokeRule jsonTimeSpan*/
					recog.base.set_state(2761);
					let tmp = recog.jsonTimeSpan()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Timespan = Some(tmp.clone());
					  

					}
				}
			,
				11 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 11);
					recog.base.enter_outer_alt(None, 11);
					{
					/*InvokeRule dynamicLiteralExpression*/
					recog.base.set_state(2762);
					let tmp = recog.dynamicLiteralExpression()?;
					 cast_mut::<_,JsonValueContext >(&mut _localctx).Dynamic = Some(tmp.clone());
					  

					}
				}

				_ => {}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonObject ----------------
pub type JsonObjectContextAll<'input> = JsonObjectContext<'input>;


pub type JsonObjectContext<'input> = BaseParserRuleContext<'input,JsonObjectContextExt<'input>>;

#[derive(Clone)]
pub struct JsonObjectContextExt<'input>{
	pub jsonPair: Option<Rc<JsonPairContextAll<'input>>>,
	pub Pairs:Vec<Rc<JsonPairContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonObjectContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonObjectContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonObject(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonObject(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonObjectContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonObject(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonObjectContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonObject }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonObject }
}
antlr_rust::tid!{JsonObjectContextExt<'a>}

impl<'input> JsonObjectContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonObjectContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonObjectContextExt{
				jsonPair: None, 
				Pairs: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonObjectContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonObjectContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACE
/// Returns `None` if there is no child corresponding to token OPENBRACE
fn OPENBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACE, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACE
/// Returns `None` if there is no child corresponding to token CLOSEBRACE
fn CLOSEBRACE(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACE, 0)
}
fn jsonPair_all(&self) ->  Vec<Rc<JsonPairContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn jsonPair(&self, i: usize) -> Option<Rc<JsonPairContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> JsonObjectContextAttrs<'input> for JsonObjectContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonObject(&mut self,)
	-> Result<Rc<JsonObjectContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonObjectContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 588, RULE_jsonObject);
        let mut _localctx: Rc<JsonObjectContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2765);
			recog.base.match_token(OPENBRACE,&mut recog.err_handler)?;

			recog.base.set_state(2774);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==STRINGLITERAL {
				{
				/*InvokeRule jsonPair*/
				recog.base.set_state(2766);
				let tmp = recog.jsonPair()?;
				 cast_mut::<_,JsonObjectContext >(&mut _localctx).jsonPair = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,JsonObjectContext >(&mut _localctx).jsonPair.clone().unwrap()
				 ;
				 cast_mut::<_,JsonObjectContext >(&mut _localctx).Pairs.push(temp);
				  
				recog.base.set_state(2771);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(2767);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule jsonPair*/
					recog.base.set_state(2768);
					let tmp = recog.jsonPair()?;
					 cast_mut::<_,JsonObjectContext >(&mut _localctx).jsonPair = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,JsonObjectContext >(&mut _localctx).jsonPair.clone().unwrap()
					 ;
					 cast_mut::<_,JsonObjectContext >(&mut _localctx).Pairs.push(temp);
					  
					}
					}
					recog.base.set_state(2773);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(2776);
			recog.base.match_token(CLOSEBRACE,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonPair ----------------
pub type JsonPairContextAll<'input> = JsonPairContext<'input>;


pub type JsonPairContext<'input> = BaseParserRuleContext<'input,JsonPairContextExt<'input>>;

#[derive(Clone)]
pub struct JsonPairContextExt<'input>{
	pub Name: Option<TokenType<'input>>,
	pub Value: Option<Rc<JsonValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonPairContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonPairContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonPair(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonPair(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonPairContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonPair(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonPairContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonPair }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonPair }
}
antlr_rust::tid!{JsonPairContextExt<'a>}

impl<'input> JsonPairContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonPairContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonPairContextExt{
				Name: None, 
				Value: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonPairContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonPairContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token COLON
/// Returns `None` if there is no child corresponding to token COLON
fn COLON(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COLON, 0)
}
/// Retrieves first TerminalNode corresponding to token STRINGLITERAL
/// Returns `None` if there is no child corresponding to token STRINGLITERAL
fn STRINGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STRINGLITERAL, 0)
}
fn jsonValue(&self) -> Option<Rc<JsonValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> JsonPairContextAttrs<'input> for JsonPairContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonPair(&mut self,)
	-> Result<Rc<JsonPairContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonPairContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 590, RULE_jsonPair);
        let mut _localctx: Rc<JsonPairContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2778);
			let tmp = recog.base.match_token(STRINGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonPairContext >(&mut _localctx).Name = Some(tmp.clone());
			  

			recog.base.set_state(2779);
			recog.base.match_token(COLON,&mut recog.err_handler)?;

			/*InvokeRule jsonValue*/
			recog.base.set_state(2780);
			let tmp = recog.jsonValue()?;
			 cast_mut::<_,JsonPairContext >(&mut _localctx).Value = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonArray ----------------
pub type JsonArrayContextAll<'input> = JsonArrayContext<'input>;


pub type JsonArrayContext<'input> = BaseParserRuleContext<'input,JsonArrayContextExt<'input>>;

#[derive(Clone)]
pub struct JsonArrayContextExt<'input>{
	pub jsonValue: Option<Rc<JsonValueContextAll<'input>>>,
	pub Values:Vec<Rc<JsonValueContextAll<'input>>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonArrayContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonArrayContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonArray(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonArray(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonArrayContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonArray(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonArrayContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonArray }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonArray }
}
antlr_rust::tid!{JsonArrayContextExt<'a>}

impl<'input> JsonArrayContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonArrayContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonArrayContextExt{
				jsonValue: None, 
				Values: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonArrayContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonArrayContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token OPENBRACKET
/// Returns `None` if there is no child corresponding to token OPENBRACKET
fn OPENBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(OPENBRACKET, 0)
}
/// Retrieves first TerminalNode corresponding to token CLOSEBRACKET
/// Returns `None` if there is no child corresponding to token CLOSEBRACKET
fn CLOSEBRACKET(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(CLOSEBRACKET, 0)
}
fn jsonValue_all(&self) ->  Vec<Rc<JsonValueContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn jsonValue(&self, i: usize) -> Option<Rc<JsonValueContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}
/// Retrieves all `TerminalNode`s corresponding to token COMMA in current rule
fn COMMA_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token COMMA, starting from 0.
/// Returns `None` if number of children corresponding to token COMMA is less or equal than `i`.
fn COMMA(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(COMMA, i)
}

}

impl<'input> JsonArrayContextAttrs<'input> for JsonArrayContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonArray(&mut self,)
	-> Result<Rc<JsonArrayContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonArrayContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 592, RULE_jsonArray);
        let mut _localctx: Rc<JsonArrayContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2782);
			recog.base.match_token(OPENBRACKET,&mut recog.err_handler)?;

			recog.base.set_state(2791);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if (((_la) & !0x3f) == 0 && ((1usize << _la) & ((1usize << DASH) | (1usize << OPENBRACE) | (1usize << OPENBRACKET))) != 0) || _la==NULL || ((((_la - 285)) & !0x3f) == 0 && ((1usize << (_la - 285)) & ((1usize << (DYNAMIC - 285)) | (1usize << (LONGLITERAL - 285)) | (1usize << (REALLITERAL - 285)) | (1usize << (STRINGLITERAL - 285)) | (1usize << (BOOLEANLITERAL - 285)) | (1usize << (DATETIMELITERAL - 285)) | (1usize << (TIMESPANLITERAL - 285)) | (1usize << (GUIDLITERAL - 285)))) != 0) {
				{
				/*InvokeRule jsonValue*/
				recog.base.set_state(2783);
				let tmp = recog.jsonValue()?;
				 cast_mut::<_,JsonArrayContext >(&mut _localctx).jsonValue = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,JsonArrayContext >(&mut _localctx).jsonValue.clone().unwrap()
				 ;
				 cast_mut::<_,JsonArrayContext >(&mut _localctx).Values.push(temp);
				  
				recog.base.set_state(2788);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
				while _la==COMMA {
					{
					{
					recog.base.set_state(2784);
					recog.base.match_token(COMMA,&mut recog.err_handler)?;

					/*InvokeRule jsonValue*/
					recog.base.set_state(2785);
					let tmp = recog.jsonValue()?;
					 cast_mut::<_,JsonArrayContext >(&mut _localctx).jsonValue = Some(tmp.clone());
					  

					let temp =  cast_mut::<_,JsonArrayContext >(&mut _localctx).jsonValue.clone().unwrap()
					 ;
					 cast_mut::<_,JsonArrayContext >(&mut _localctx).Values.push(temp);
					  
					}
					}
					recog.base.set_state(2790);
					recog.err_handler.sync(&mut recog.base)?;
					_la = recog.base.input.la(1);
				}
				}
			}

			recog.base.set_state(2793);
			recog.base.match_token(CLOSEBRACKET,&mut recog.err_handler)?;

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonBoolean ----------------
pub type JsonBooleanContextAll<'input> = JsonBooleanContext<'input>;


pub type JsonBooleanContext<'input> = BaseParserRuleContext<'input,JsonBooleanContextExt<'input>>;

#[derive(Clone)]
pub struct JsonBooleanContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonBooleanContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonBooleanContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonBoolean(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonBoolean(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonBooleanContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonBoolean(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonBooleanContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonBoolean }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonBoolean }
}
antlr_rust::tid!{JsonBooleanContextExt<'a>}

impl<'input> JsonBooleanContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonBooleanContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonBooleanContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonBooleanContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonBooleanContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token BOOLEANLITERAL
/// Returns `None` if there is no child corresponding to token BOOLEANLITERAL
fn BOOLEANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(BOOLEANLITERAL, 0)
}

}

impl<'input> JsonBooleanContextAttrs<'input> for JsonBooleanContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonBoolean(&mut self,)
	-> Result<Rc<JsonBooleanContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonBooleanContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 594, RULE_jsonBoolean);
        let mut _localctx: Rc<JsonBooleanContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2795);
			let tmp = recog.base.match_token(BOOLEANLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonBooleanContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonDateTime ----------------
pub type JsonDateTimeContextAll<'input> = JsonDateTimeContext<'input>;


pub type JsonDateTimeContext<'input> = BaseParserRuleContext<'input,JsonDateTimeContextExt<'input>>;

#[derive(Clone)]
pub struct JsonDateTimeContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonDateTimeContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonDateTimeContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonDateTime(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonDateTime(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonDateTimeContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonDateTime(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonDateTimeContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonDateTime }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonDateTime }
}
antlr_rust::tid!{JsonDateTimeContextExt<'a>}

impl<'input> JsonDateTimeContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonDateTimeContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonDateTimeContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonDateTimeContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonDateTimeContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token DATETIMELITERAL
/// Returns `None` if there is no child corresponding to token DATETIMELITERAL
fn DATETIMELITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DATETIMELITERAL, 0)
}

}

impl<'input> JsonDateTimeContextAttrs<'input> for JsonDateTimeContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonDateTime(&mut self,)
	-> Result<Rc<JsonDateTimeContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonDateTimeContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 596, RULE_jsonDateTime);
        let mut _localctx: Rc<JsonDateTimeContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2797);
			let tmp = recog.base.match_token(DATETIMELITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonDateTimeContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonGuid ----------------
pub type JsonGuidContextAll<'input> = JsonGuidContext<'input>;


pub type JsonGuidContext<'input> = BaseParserRuleContext<'input,JsonGuidContextExt<'input>>;

#[derive(Clone)]
pub struct JsonGuidContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonGuidContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonGuidContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonGuid(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonGuid(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonGuidContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonGuid(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonGuidContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonGuid }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonGuid }
}
antlr_rust::tid!{JsonGuidContextExt<'a>}

impl<'input> JsonGuidContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonGuidContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonGuidContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonGuidContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonGuidContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token GUIDLITERAL
/// Returns `None` if there is no child corresponding to token GUIDLITERAL
fn GUIDLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(GUIDLITERAL, 0)
}

}

impl<'input> JsonGuidContextAttrs<'input> for JsonGuidContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonGuid(&mut self,)
	-> Result<Rc<JsonGuidContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonGuidContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 598, RULE_jsonGuid);
        let mut _localctx: Rc<JsonGuidContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2799);
			let tmp = recog.base.match_token(GUIDLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonGuidContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonNull ----------------
pub type JsonNullContextAll<'input> = JsonNullContext<'input>;


pub type JsonNullContext<'input> = BaseParserRuleContext<'input,JsonNullContextExt<'input>>;

#[derive(Clone)]
pub struct JsonNullContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonNullContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonNullContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonNull(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonNull(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonNullContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonNull(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonNullContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonNull }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonNull }
}
antlr_rust::tid!{JsonNullContextExt<'a>}

impl<'input> JsonNullContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonNullContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonNullContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonNullContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonNullContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token NULL
/// Returns `None` if there is no child corresponding to token NULL
fn NULL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(NULL, 0)
}

}

impl<'input> JsonNullContextAttrs<'input> for JsonNullContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonNull(&mut self,)
	-> Result<Rc<JsonNullContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonNullContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 600, RULE_jsonNull);
        let mut _localctx: Rc<JsonNullContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2801);
			let tmp = recog.base.match_token(NULL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonNullContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonString ----------------
pub type JsonStringContextAll<'input> = JsonStringContext<'input>;


pub type JsonStringContext<'input> = BaseParserRuleContext<'input,JsonStringContextExt<'input>>;

#[derive(Clone)]
pub struct JsonStringContextExt<'input>{
	pub STRINGLITERAL: Option<TokenType<'input>>,
	pub Tokens:Vec<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonStringContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonStringContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonString(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonString(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonStringContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonString(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonStringContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonString }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonString }
}
antlr_rust::tid!{JsonStringContextExt<'a>}

impl<'input> JsonStringContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonStringContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonStringContextExt{
				STRINGLITERAL: None, 
				Tokens: Vec::new(), 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonStringContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonStringContextExt<'input>>{

/// Retrieves all `TerminalNode`s corresponding to token STRINGLITERAL in current rule
fn STRINGLITERAL_all(&self) -> Vec<Rc<TerminalNode<'input,HqlParserContextType>>>  where Self:Sized{
	self.children_of_type()
}
/// Retrieves 'i's TerminalNode corresponding to token STRINGLITERAL, starting from 0.
/// Returns `None` if number of children corresponding to token STRINGLITERAL is less or equal than `i`.
fn STRINGLITERAL(&self, i: usize) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(STRINGLITERAL, i)
}

}

impl<'input> JsonStringContextAttrs<'input> for JsonStringContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonString(&mut self,)
	-> Result<Rc<JsonStringContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonStringContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 602, RULE_jsonString);
        let mut _localctx: Rc<JsonStringContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2803);
			let tmp = recog.base.match_token(STRINGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonStringContext >(&mut _localctx).STRINGLITERAL = Some(tmp.clone());
			  

			let temp =  cast_mut::<_,JsonStringContext >(&mut _localctx).STRINGLITERAL.clone().unwrap()
			 ;
			 cast_mut::<_,JsonStringContext >(&mut _localctx).Tokens.push(temp);
			  
			recog.base.set_state(2807);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			while _la==STRINGLITERAL {
				{
				{
				recog.base.set_state(2804);
				let tmp = recog.base.match_token(STRINGLITERAL,&mut recog.err_handler)?;
				 cast_mut::<_,JsonStringContext >(&mut _localctx).STRINGLITERAL = Some(tmp.clone());
				  

				let temp =  cast_mut::<_,JsonStringContext >(&mut _localctx).STRINGLITERAL.clone().unwrap()
				 ;
				 cast_mut::<_,JsonStringContext >(&mut _localctx).Tokens.push(temp);
				  
				}
				}
				recog.base.set_state(2809);
				recog.err_handler.sync(&mut recog.base)?;
				_la = recog.base.input.la(1);
			}
			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonTimeSpan ----------------
pub type JsonTimeSpanContextAll<'input> = JsonTimeSpanContext<'input>;


pub type JsonTimeSpanContext<'input> = BaseParserRuleContext<'input,JsonTimeSpanContextExt<'input>>;

#[derive(Clone)]
pub struct JsonTimeSpanContextExt<'input>{
	pub Token: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonTimeSpanContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonTimeSpanContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonTimeSpan(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonTimeSpan(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonTimeSpanContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonTimeSpan(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonTimeSpanContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonTimeSpan }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonTimeSpan }
}
antlr_rust::tid!{JsonTimeSpanContextExt<'a>}

impl<'input> JsonTimeSpanContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonTimeSpanContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonTimeSpanContextExt{
				Token: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonTimeSpanContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonTimeSpanContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token TIMESPANLITERAL
/// Returns `None` if there is no child corresponding to token TIMESPANLITERAL
fn TIMESPANLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(TIMESPANLITERAL, 0)
}

}

impl<'input> JsonTimeSpanContextAttrs<'input> for JsonTimeSpanContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonTimeSpan(&mut self,)
	-> Result<Rc<JsonTimeSpanContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonTimeSpanContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 604, RULE_jsonTimeSpan);
        let mut _localctx: Rc<JsonTimeSpanContextAll> = _localctx;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2810);
			let tmp = recog.base.match_token(TIMESPANLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonTimeSpanContext >(&mut _localctx).Token = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonLong ----------------
pub type JsonLongContextAll<'input> = JsonLongContext<'input>;


pub type JsonLongContext<'input> = BaseParserRuleContext<'input,JsonLongContextExt<'input>>;

#[derive(Clone)]
pub struct JsonLongContextExt<'input>{
	pub SignToken: Option<TokenType<'input>>,
	pub LiteralToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonLongContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonLongContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonLong(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonLong(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonLongContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonLong(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonLongContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonLong }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonLong }
}
antlr_rust::tid!{JsonLongContextExt<'a>}

impl<'input> JsonLongContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonLongContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonLongContextExt{
				SignToken: None, LiteralToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonLongContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonLongContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token LONGLITERAL
/// Returns `None` if there is no child corresponding to token LONGLITERAL
fn LONGLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(LONGLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DASH
/// Returns `None` if there is no child corresponding to token DASH
fn DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH, 0)
}

}

impl<'input> JsonLongContextAttrs<'input> for JsonLongContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonLong(&mut self,)
	-> Result<Rc<JsonLongContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonLongContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 606, RULE_jsonLong);
        let mut _localctx: Rc<JsonLongContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2813);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DASH {
				{
				recog.base.set_state(2812);
				let tmp = recog.base.match_token(DASH,&mut recog.err_handler)?;
				 cast_mut::<_,JsonLongContext >(&mut _localctx).SignToken = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2815);
			let tmp = recog.base.match_token(LONGLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonLongContext >(&mut _localctx).LiteralToken = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- jsonReal ----------------
pub type JsonRealContextAll<'input> = JsonRealContext<'input>;


pub type JsonRealContext<'input> = BaseParserRuleContext<'input,JsonRealContextExt<'input>>;

#[derive(Clone)]
pub struct JsonRealContextExt<'input>{
	pub SignToken: Option<TokenType<'input>>,
	pub LiteralToken: Option<TokenType<'input>>,
ph:PhantomData<&'input str>
}

impl<'input> HqlParserContext<'input> for JsonRealContext<'input>{}

impl<'input,'a> Listenable<dyn HqlListener<'input> + 'a> for JsonRealContext<'input>{
		fn enter(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.enter_every_rule(self);
			listener.enter_jsonReal(self);
		}
		fn exit(&self,listener: &mut (dyn HqlListener<'input> + 'a)) {
			listener.exit_jsonReal(self);
			listener.exit_every_rule(self);
		}
}

impl<'input,'a> Visitable<dyn HqlVisitor<'input> + 'a> for JsonRealContext<'input>{
	fn accept(&self,visitor: &mut (dyn HqlVisitor<'input> + 'a)) {
		visitor.visit_jsonReal(self);
	}
}

impl<'input> CustomRuleContext<'input> for JsonRealContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = HqlParserContextType;
	fn get_rule_index(&self) -> usize { RULE_jsonReal }
	//fn type_rule_index() -> usize where Self: Sized { RULE_jsonReal }
}
antlr_rust::tid!{JsonRealContextExt<'a>}

impl<'input> JsonRealContextExt<'input>{
	fn new(parent: Option<Rc<dyn HqlParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<JsonRealContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,JsonRealContextExt{
				SignToken: None, LiteralToken: None, 
				ph:PhantomData
			}),
		)
	}
}

pub trait JsonRealContextAttrs<'input>: HqlParserContext<'input> + BorrowMut<JsonRealContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token REALLITERAL
/// Returns `None` if there is no child corresponding to token REALLITERAL
fn REALLITERAL(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(REALLITERAL, 0)
}
/// Retrieves first TerminalNode corresponding to token DASH
/// Returns `None` if there is no child corresponding to token DASH
fn DASH(&self) -> Option<Rc<TerminalNode<'input,HqlParserContextType>>> where Self:Sized{
	self.get_token(DASH, 0)
}

}

impl<'input> JsonRealContextAttrs<'input> for JsonRealContext<'input>{}

impl<'input, I, H> HqlParser<'input, I, H>
where
    I: TokenStream<'input, TF = LocalTokenFactory<'input> > + TidAble<'input>,
    H: ErrorStrategy<'input,BaseParserType<'input,I>>
{
	pub fn jsonReal(&mut self,)
	-> Result<Rc<JsonRealContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = JsonRealContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 608, RULE_jsonReal);
        let mut _localctx: Rc<JsonRealContextAll> = _localctx;
		let mut _la: isize = -1;
		let result: Result<(), ANTLRError> = (|| {

			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(2818);
			recog.err_handler.sync(&mut recog.base)?;
			_la = recog.base.input.la(1);
			if _la==DASH {
				{
				recog.base.set_state(2817);
				let tmp = recog.base.match_token(DASH,&mut recog.err_handler)?;
				 cast_mut::<_,JsonRealContext >(&mut _localctx).SignToken = Some(tmp.clone());
				  

				}
			}

			recog.base.set_state(2820);
			let tmp = recog.base.match_token(REALLITERAL,&mut recog.err_handler)?;
			 cast_mut::<_,JsonRealContext >(&mut _localctx).LiteralToken = Some(tmp.clone());
			  

			}
			Ok(())
		})();
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}

lazy_static! {
    static ref _ATN: Arc<ATN> =
        Arc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static ref _decision_to_DFA: Arc<Vec<antlr_rust::RwLock<DFA>>> = {
        let mut dfa = Vec::new();
        let size = _ATN.decision_to_state.len();
        for i in 0..size {
            dfa.push(DFA::new(
                _ATN.clone(),
                _ATN.get_decision_state(i),
                i as isize,
            ).into())
        }
        Arc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\u{140}\u{b09}\x04\x02\x09\x02\x04\x03\x09\x03\x04\x04\x09\x04\x04\x05\x09\
	\x05\x04\x06\x09\x06\x04\x07\x09\x07\x04\x08\x09\x08\x04\x09\x09\x09\x04\
	\x0a\x09\x0a\x04\x0b\x09\x0b\x04\x0c\x09\x0c\x04\x0d\x09\x0d\x04\x0e\x09\
	\x0e\x04\x0f\x09\x0f\x04\x10\x09\x10\x04\x11\x09\x11\x04\x12\x09\x12\x04\
	\x13\x09\x13\x04\x14\x09\x14\x04\x15\x09\x15\x04\x16\x09\x16\x04\x17\x09\
	\x17\x04\x18\x09\x18\x04\x19\x09\x19\x04\x1a\x09\x1a\x04\x1b\x09\x1b\x04\
	\x1c\x09\x1c\x04\x1d\x09\x1d\x04\x1e\x09\x1e\x04\x1f\x09\x1f\x04\x20\x09\
	\x20\x04\x21\x09\x21\x04\x22\x09\x22\x04\x23\x09\x23\x04\x24\x09\x24\x04\
	\x25\x09\x25\x04\x26\x09\x26\x04\x27\x09\x27\x04\x28\x09\x28\x04\x29\x09\
	\x29\x04\x2a\x09\x2a\x04\x2b\x09\x2b\x04\x2c\x09\x2c\x04\x2d\x09\x2d\x04\
	\x2e\x09\x2e\x04\x2f\x09\x2f\x04\x30\x09\x30\x04\x31\x09\x31\x04\x32\x09\
	\x32\x04\x33\x09\x33\x04\x34\x09\x34\x04\x35\x09\x35\x04\x36\x09\x36\x04\
	\x37\x09\x37\x04\x38\x09\x38\x04\x39\x09\x39\x04\x3a\x09\x3a\x04\x3b\x09\
	\x3b\x04\x3c\x09\x3c\x04\x3d\x09\x3d\x04\x3e\x09\x3e\x04\x3f\x09\x3f\x04\
	\x40\x09\x40\x04\x41\x09\x41\x04\x42\x09\x42\x04\x43\x09\x43\x04\x44\x09\
	\x44\x04\x45\x09\x45\x04\x46\x09\x46\x04\x47\x09\x47\x04\x48\x09\x48\x04\
	\x49\x09\x49\x04\x4a\x09\x4a\x04\x4b\x09\x4b\x04\x4c\x09\x4c\x04\x4d\x09\
	\x4d\x04\x4e\x09\x4e\x04\x4f\x09\x4f\x04\x50\x09\x50\x04\x51\x09\x51\x04\
	\x52\x09\x52\x04\x53\x09\x53\x04\x54\x09\x54\x04\x55\x09\x55\x04\x56\x09\
	\x56\x04\x57\x09\x57\x04\x58\x09\x58\x04\x59\x09\x59\x04\x5a\x09\x5a\x04\
	\x5b\x09\x5b\x04\x5c\x09\x5c\x04\x5d\x09\x5d\x04\x5e\x09\x5e\x04\x5f\x09\
	\x5f\x04\x60\x09\x60\x04\x61\x09\x61\x04\x62\x09\x62\x04\x63\x09\x63\x04\
	\x64\x09\x64\x04\x65\x09\x65\x04\x66\x09\x66\x04\x67\x09\x67\x04\x68\x09\
	\x68\x04\x69\x09\x69\x04\x6a\x09\x6a\x04\x6b\x09\x6b\x04\x6c\x09\x6c\x04\
	\x6d\x09\x6d\x04\x6e\x09\x6e\x04\x6f\x09\x6f\x04\x70\x09\x70\x04\x71\x09\
	\x71\x04\x72\x09\x72\x04\x73\x09\x73\x04\x74\x09\x74\x04\x75\x09\x75\x04\
	\x76\x09\x76\x04\x77\x09\x77\x04\x78\x09\x78\x04\x79\x09\x79\x04\x7a\x09\
	\x7a\x04\x7b\x09\x7b\x04\x7c\x09\x7c\x04\x7d\x09\x7d\x04\x7e\x09\x7e\x04\
	\x7f\x09\x7f\x04\u{80}\x09\u{80}\x04\u{81}\x09\u{81}\x04\u{82}\x09\u{82}\
	\x04\u{83}\x09\u{83}\x04\u{84}\x09\u{84}\x04\u{85}\x09\u{85}\x04\u{86}\x09\
	\u{86}\x04\u{87}\x09\u{87}\x04\u{88}\x09\u{88}\x04\u{89}\x09\u{89}\x04\u{8a}\
	\x09\u{8a}\x04\u{8b}\x09\u{8b}\x04\u{8c}\x09\u{8c}\x04\u{8d}\x09\u{8d}\x04\
	\u{8e}\x09\u{8e}\x04\u{8f}\x09\u{8f}\x04\u{90}\x09\u{90}\x04\u{91}\x09\u{91}\
	\x04\u{92}\x09\u{92}\x04\u{93}\x09\u{93}\x04\u{94}\x09\u{94}\x04\u{95}\x09\
	\u{95}\x04\u{96}\x09\u{96}\x04\u{97}\x09\u{97}\x04\u{98}\x09\u{98}\x04\u{99}\
	\x09\u{99}\x04\u{9a}\x09\u{9a}\x04\u{9b}\x09\u{9b}\x04\u{9c}\x09\u{9c}\x04\
	\u{9d}\x09\u{9d}\x04\u{9e}\x09\u{9e}\x04\u{9f}\x09\u{9f}\x04\u{a0}\x09\u{a0}\
	\x04\u{a1}\x09\u{a1}\x04\u{a2}\x09\u{a2}\x04\u{a3}\x09\u{a3}\x04\u{a4}\x09\
	\u{a4}\x04\u{a5}\x09\u{a5}\x04\u{a6}\x09\u{a6}\x04\u{a7}\x09\u{a7}\x04\u{a8}\
	\x09\u{a8}\x04\u{a9}\x09\u{a9}\x04\u{aa}\x09\u{aa}\x04\u{ab}\x09\u{ab}\x04\
	\u{ac}\x09\u{ac}\x04\u{ad}\x09\u{ad}\x04\u{ae}\x09\u{ae}\x04\u{af}\x09\u{af}\
	\x04\u{b0}\x09\u{b0}\x04\u{b1}\x09\u{b1}\x04\u{b2}\x09\u{b2}\x04\u{b3}\x09\
	\u{b3}\x04\u{b4}\x09\u{b4}\x04\u{b5}\x09\u{b5}\x04\u{b6}\x09\u{b6}\x04\u{b7}\
	\x09\u{b7}\x04\u{b8}\x09\u{b8}\x04\u{b9}\x09\u{b9}\x04\u{ba}\x09\u{ba}\x04\
	\u{bb}\x09\u{bb}\x04\u{bc}\x09\u{bc}\x04\u{bd}\x09\u{bd}\x04\u{be}\x09\u{be}\
	\x04\u{bf}\x09\u{bf}\x04\u{c0}\x09\u{c0}\x04\u{c1}\x09\u{c1}\x04\u{c2}\x09\
	\u{c2}\x04\u{c3}\x09\u{c3}\x04\u{c4}\x09\u{c4}\x04\u{c5}\x09\u{c5}\x04\u{c6}\
	\x09\u{c6}\x04\u{c7}\x09\u{c7}\x04\u{c8}\x09\u{c8}\x04\u{c9}\x09\u{c9}\x04\
	\u{ca}\x09\u{ca}\x04\u{cb}\x09\u{cb}\x04\u{cc}\x09\u{cc}\x04\u{cd}\x09\u{cd}\
	\x04\u{ce}\x09\u{ce}\x04\u{cf}\x09\u{cf}\x04\u{d0}\x09\u{d0}\x04\u{d1}\x09\
	\u{d1}\x04\u{d2}\x09\u{d2}\x04\u{d3}\x09\u{d3}\x04\u{d4}\x09\u{d4}\x04\u{d5}\
	\x09\u{d5}\x04\u{d6}\x09\u{d6}\x04\u{d7}\x09\u{d7}\x04\u{d8}\x09\u{d8}\x04\
	\u{d9}\x09\u{d9}\x04\u{da}\x09\u{da}\x04\u{db}\x09\u{db}\x04\u{dc}\x09\u{dc}\
	\x04\u{dd}\x09\u{dd}\x04\u{de}\x09\u{de}\x04\u{df}\x09\u{df}\x04\u{e0}\x09\
	\u{e0}\x04\u{e1}\x09\u{e1}\x04\u{e2}\x09\u{e2}\x04\u{e3}\x09\u{e3}\x04\u{e4}\
	\x09\u{e4}\x04\u{e5}\x09\u{e5}\x04\u{e6}\x09\u{e6}\x04\u{e7}\x09\u{e7}\x04\
	\u{e8}\x09\u{e8}\x04\u{e9}\x09\u{e9}\x04\u{ea}\x09\u{ea}\x04\u{eb}\x09\u{eb}\
	\x04\u{ec}\x09\u{ec}\x04\u{ed}\x09\u{ed}\x04\u{ee}\x09\u{ee}\x04\u{ef}\x09\
	\u{ef}\x04\u{f0}\x09\u{f0}\x04\u{f1}\x09\u{f1}\x04\u{f2}\x09\u{f2}\x04\u{f3}\
	\x09\u{f3}\x04\u{f4}\x09\u{f4}\x04\u{f5}\x09\u{f5}\x04\u{f6}\x09\u{f6}\x04\
	\u{f7}\x09\u{f7}\x04\u{f8}\x09\u{f8}\x04\u{f9}\x09\u{f9}\x04\u{fa}\x09\u{fa}\
	\x04\u{fb}\x09\u{fb}\x04\u{fc}\x09\u{fc}\x04\u{fd}\x09\u{fd}\x04\u{fe}\x09\
	\u{fe}\x04\u{ff}\x09\u{ff}\x04\u{100}\x09\u{100}\x04\u{101}\x09\u{101}\x04\
	\u{102}\x09\u{102}\x04\u{103}\x09\u{103}\x04\u{104}\x09\u{104}\x04\u{105}\
	\x09\u{105}\x04\u{106}\x09\u{106}\x04\u{107}\x09\u{107}\x04\u{108}\x09\u{108}\
	\x04\u{109}\x09\u{109}\x04\u{10a}\x09\u{10a}\x04\u{10b}\x09\u{10b}\x04\u{10c}\
	\x09\u{10c}\x04\u{10d}\x09\u{10d}\x04\u{10e}\x09\u{10e}\x04\u{10f}\x09\u{10f}\
	\x04\u{110}\x09\u{110}\x04\u{111}\x09\u{111}\x04\u{112}\x09\u{112}\x04\u{113}\
	\x09\u{113}\x04\u{114}\x09\u{114}\x04\u{115}\x09\u{115}\x04\u{116}\x09\u{116}\
	\x04\u{117}\x09\u{117}\x04\u{118}\x09\u{118}\x04\u{119}\x09\u{119}\x04\u{11a}\
	\x09\u{11a}\x04\u{11b}\x09\u{11b}\x04\u{11c}\x09\u{11c}\x04\u{11d}\x09\u{11d}\
	\x04\u{11e}\x09\u{11e}\x04\u{11f}\x09\u{11f}\x04\u{120}\x09\u{120}\x04\u{121}\
	\x09\u{121}\x04\u{122}\x09\u{122}\x04\u{123}\x09\u{123}\x04\u{124}\x09\u{124}\
	\x04\u{125}\x09\u{125}\x04\u{126}\x09\u{126}\x04\u{127}\x09\u{127}\x04\u{128}\
	\x09\u{128}\x04\u{129}\x09\u{129}\x04\u{12a}\x09\u{12a}\x04\u{12b}\x09\u{12b}\
	\x04\u{12c}\x09\u{12c}\x04\u{12d}\x09\u{12d}\x04\u{12e}\x09\u{12e}\x04\u{12f}\
	\x09\u{12f}\x04\u{130}\x09\u{130}\x04\u{131}\x09\u{131}\x04\u{132}\x09\u{132}\
	\x03\x02\x03\x02\x03\x03\x03\x03\x03\x03\x07\x03\u{26a}\x0a\x03\x0c\x03\
	\x0e\x03\u{26d}\x0b\x03\x03\x03\x05\x03\u{270}\x0a\x03\x03\x03\x03\x03\x03\
	\x04\x03\x04\x03\x04\x03\x04\x03\x04\x03\x04\x03\x04\x05\x04\u{27b}\x0a\
	\x04\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\x03\x05\x03\x06\x03\x06\x03\
	\x06\x03\x06\x03\x06\x05\x06\u{288}\x0a\x06\x03\x07\x03\x07\x03\x07\x03\
	\x07\x03\x07\x03\x08\x03\x08\x03\x08\x03\x08\x03\x08\x05\x08\u{294}\x0a\
	\x08\x03\x08\x03\x08\x03\x08\x03\x09\x03\x09\x03\x09\x03\x09\x03\x09\x03\
	\x09\x05\x09\u{29f}\x0a\x09\x03\x09\x03\x09\x03\x09\x03\x0a\x03\x0a\x03\
	\x0a\x07\x0a\u{2a7}\x0a\x0a\x0c\x0a\x0e\x0a\u{2aa}\x0b\x0a\x03\x0b\x03\x0b\
	\x03\x0b\x03\x0b\x03\x0b\x03\x0b\x03\x0b\x03\x0b\x03\x0c\x03\x0c\x03\x0c\
	\x03\x0c\x03\x0c\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x03\x0d\
	\x03\x0d\x03\x0d\x03\x0d\x03\x0d\x05\x0d\u{2c4}\x0a\x0d\x03\x0e\x03\x0e\
	\x03\x0e\x03\x0e\x05\x0e\u{2ca}\x0a\x0e\x03\x0f\x03\x0f\x03\x0f\x03\x10\
	\x03\x10\x03\x10\x03\x10\x05\x10\u{2d3}\x0a\x10\x03\x11\x03\x11\x03\x11\
	\x03\x11\x03\x12\x03\x12\x03\x12\x03\x12\x07\x12\u{2dd}\x0a\x12\x0c\x12\
	\x0e\x12\u{2e0}\x0b\x12\x03\x12\x03\x12\x03\x13\x03\x13\x03\x13\x03\x13\
	\x03\x14\x03\x14\x03\x14\x03\x14\x07\x14\u{2ec}\x0a\x14\x0c\x14\x0e\x14\
	\u{2ef}\x0b\x14\x03\x14\x05\x14\u{2f2}\x0a\x14\x03\x14\x05\x14\u{2f5}\x0a\
	\x14\x03\x14\x03\x14\x03\x15\x03\x15\x05\x15\u{2fb}\x0a\x15\x03\x16\x03\
	\x16\x03\x16\x03\x16\x05\x16\u{301}\x0a\x16\x03\x17\x03\x17\x03\x17\x05\
	\x17\u{306}\x0a\x17\x03\x17\x03\x17\x06\x17\u{30a}\x0a\x17\x0d\x17\x0e\x17\
	\u{30b}\x03\x17\x03\x17\x03\x18\x03\x18\x03\x18\x03\x18\x07\x18\u{314}\x0a\
	\x18\x0c\x18\x0e\x18\u{317}\x0b\x18\x03\x18\x03\x18\x03\x19\x03\x19\x03\
	\x19\x03\x19\x03\x1a\x03\x1a\x03\x1a\x03\x1a\x03\x1b\x03\x1b\x05\x1b\u{325}\
	\x0a\x1b\x03\x1b\x03\x1b\x03\x1b\x05\x1b\u{32a}\x0a\x1b\x03\x1c\x03\x1c\
	\x03\x1c\x03\x1c\x07\x1c\u{330}\x0a\x1c\x0c\x1c\x0e\x1c\u{333}\x0b\x1c\x03\
	\x1c\x03\x1c\x03\x1d\x03\x1d\x03\x1d\x03\x1d\x03\x1d\x03\x1e\x03\x1e\x03\
	\x1f\x03\x1f\x03\x1f\x03\x1f\x07\x1f\u{342}\x0a\x1f\x0c\x1f\x0e\x1f\u{345}\
	\x0b\x1f\x03\x1f\x03\x1f\x03\x1f\x03\x20\x03\x20\x03\x20\x03\x20\x03\x20\
	\x03\x20\x03\x20\x07\x20\u{351}\x0a\x20\x0c\x20\x0e\x20\u{354}\x0b\x20\x03\
	\x20\x03\x20\x03\x21\x03\x21\x05\x21\u{35a}\x0a\x21\x03\x22\x03\x22\x03\
	\x22\x03\x22\x05\x22\u{360}\x0a\x22\x03\x23\x03\x23\x05\x23\u{364}\x0a\x23\
	\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x03\x24\x07\x24\u{36c}\x0a\x24\
	\x0c\x24\x0e\x24\u{36f}\x0b\x24\x03\x24\x03\x24\x03\x25\x03\x25\x03\x25\
	\x03\x25\x05\x25\u{377}\x0a\x25\x03\x26\x03\x26\x03\x27\x03\x27\x03\x28\
	\x03\x28\x07\x28\u{37f}\x0a\x28\x0c\x28\x0e\x28\u{382}\x0b\x28\x03\x29\x03\
	\x29\x03\x29\x03\x2a\x03\x2a\x07\x2a\u{389}\x0a\x2a\x0c\x2a\x0e\x2a\u{38c}\
	\x0b\x2a\x03\x2b\x03\x2b\x03\x2b\x03\x2b\x03\x2b\x03\x2b\x05\x2b\u{394}\
	\x0a\x2b\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\
	\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\
	\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\
	\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\
	\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\
	\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x03\x2c\x05\x2c\u{3c7}\x0a\x2c\x03\x2d\
	\x03\x2d\x03\x2d\x03\x2d\x05\x2d\u{3cd}\x0a\x2d\x03\x2e\x03\x2e\x03\x2e\
	\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\
	\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x03\x2e\
	\x03\x2e\x03\x2e\x03\x2e\x03\x2e\x05\x2e\u{3e8}\x0a\x2e\x03\x2f\x03\x2f\
	\x07\x2f\u{3ec}\x0a\x2f\x0c\x2f\x0e\x2f\u{3ef}\x0b\x2f\x03\x2f\x03\x2f\x03\
	\x30\x03\x30\x03\x30\x03\x31\x03\x31\x07\x31\u{3f8}\x0a\x31\x0c\x31\x0e\
	\x31\u{3fb}\x0b\x31\x03\x32\x03\x32\x07\x32\u{3ff}\x0a\x32\x0c\x32\x0e\x32\
	\u{402}\x0b\x32\x03\x33\x03\x33\x03\x33\x03\x34\x03\x34\x07\x34\u{409}\x0a\
	\x34\x0c\x34\x0e\x34\u{40c}\x0b\x34\x03\x34\x03\x34\x05\x34\u{410}\x0a\x34\
	\x03\x35\x03\x35\x03\x36\x03\x36\x03\x36\x07\x36\u{417}\x0a\x36\x0c\x36\
	\x0e\x36\u{41a}\x0b\x36\x03\x37\x03\x37\x07\x37\u{41e}\x0a\x37\x0c\x37\x0e\
	\x37\u{421}\x0b\x37\x03\x37\x03\x37\x05\x37\u{425}\x0a\x37\x03\x38\x03\x38\
	\x03\x38\x03\x39\x03\x39\x03\x39\x03\x39\x07\x39\u{42e}\x0a\x39\x0c\x39\
	\x0e\x39\u{431}\x0b\x39\x03\x3a\x03\x3a\x03\x3b\x03\x3b\x03\x3b\x03\x3b\
	\x03\x3b\x07\x3b\u{43a}\x0a\x3b\x0c\x3b\x0e\x3b\u{43d}\x0b\x3b\x03\x3b\x03\
	\x3b\x05\x3b\u{441}\x0a\x3b\x03\x3c\x03\x3c\x03\x3c\x03\x3d\x03\x3d\x03\
	\x3d\x03\x3d\x03\x3d\x03\x3e\x03\x3e\x05\x3e\u{44d}\x0a\x3e\x03\x3e\x05\
	\x3e\u{450}\x0a\x3e\x03\x3e\x03\x3e\x03\x3e\x05\x3e\u{455}\x0a\x3e\x03\x3e\
	\x05\x3e\u{458}\x0a\x3e\x03\x3f\x07\x3f\u{45b}\x0a\x3f\x0c\x3f\x0e\x3f\u{45e}\
	\x0b\x3f\x03\x3f\x05\x3f\u{461}\x0a\x3f\x03\x3f\x03\x3f\x03\x40\x03\x40\
	\x03\x40\x03\x40\x03\x40\x07\x40\u{46a}\x0a\x40\x0c\x40\x0e\x40\u{46d}\x0b\
	\x40\x03\x40\x03\x40\x03\x41\x03\x41\x03\x41\x03\x41\x07\x41\u{475}\x0a\
	\x41\x0c\x41\x0e\x41\u{478}\x0b\x41\x03\x42\x03\x42\x05\x42\u{47c}\x0a\x42\
	\x03\x43\x03\x43\x05\x43\u{480}\x0a\x43\x03\x44\x03\x44\x03\x44\x03\x45\
	\x03\x45\x03\x45\x03\x45\x03\x45\x03\x46\x03\x46\x03\x47\x03\x47\x03\x47\
	\x05\x47\u{48f}\x0a\x47\x03\x48\x03\x48\x03\x49\x03\x49\x03\x49\x07\x49\
	\u{496}\x0a\x49\x0c\x49\x0e\x49\u{499}\x0b\x49\x03\x4a\x03\x4a\x05\x4a\u{49d}\
	\x0a\x4a\x03\x4b\x03\x4b\x03\x4b\x07\x4b\u{4a2}\x0a\x4b\x0c\x4b\x0e\x4b\
	\u{4a5}\x0b\x4b\x03\x4c\x03\x4c\x06\x4c\u{4a9}\x0a\x4c\x0d\x4c\x0e\x4c\u{4aa}\
	\x03\x4d\x05\x4d\u{4ae}\x0a\x4d\x03\x4d\x03\x4d\x03\x4d\x03\x4d\x03\x4e\
	\x03\x4e\x03\x4e\x03\x4f\x03\x4f\x07\x4f\u{4b9}\x0a\x4f\x0c\x4f\x0e\x4f\
	\u{4bc}\x0b\x4f\x03\x50\x03\x50\x03\x50\x03\x51\x03\x51\x03\x52\x03\x52\
	\x07\x52\u{4c5}\x0a\x52\x0c\x52\x0e\x52\u{4c8}\x0b\x52\x03\x53\x03\x53\x07\
	\x53\u{4cc}\x0a\x53\x0c\x53\x0e\x53\u{4cf}\x0b\x53\x03\x53\x03\x53\x03\x53\
	\x03\x53\x03\x53\x05\x53\u{4d6}\x0a\x53\x03\x53\x05\x53\u{4d9}\x0a\x53\x03\
	\x54\x03\x54\x03\x54\x05\x54\u{4de}\x0a\x54\x03\x55\x03\x55\x03\x55\x03\
	\x55\x03\x56\x03\x56\x03\x57\x03\x57\x03\x57\x05\x57\u{4e9}\x0a\x57\x03\
	\x57\x03\x57\x03\x58\x03\x58\x03\x58\x03\x58\x03\x58\x03\x59\x03\x59\x03\
	\x59\x03\x5a\x03\x5a\x03\x5a\x03\x5a\x07\x5a\u{4f9}\x0a\x5a\x0c\x5a\x0e\
	\x5a\u{4fc}\x0b\x5a\x03\x5b\x03\x5b\x03\x5b\x05\x5b\u{501}\x0a\x5b\x03\x5c\
	\x03\x5c\x03\x5c\x03\x5c\x03\x5c\x03\x5d\x03\x5d\x05\x5d\u{50a}\x0a\x5d\
	\x03\x5d\x07\x5d\u{50d}\x0a\x5d\x0c\x5d\x0e\x5d\u{510}\x0b\x5d\x03\x5e\x03\
	\x5e\x03\x5e\x03\x5f\x03\x5f\x07\x5f\u{517}\x0a\x5f\x0c\x5f\x0e\x5f\u{51a}\
	\x0b\x5f\x03\x5f\x03\x5f\x03\x5f\x03\x5f\x03\x5f\x05\x5f\u{521}\x0a\x5f\
	\x03\x5f\x05\x5f\u{524}\x0a\x5f\x03\x60\x03\x60\x03\x60\x03\x61\x03\x61\
	\x07\x61\u{52b}\x0a\x61\x0c\x61\x0e\x61\u{52e}\x0b\x61\x03\x61\x03\x61\x03\
	\x61\x05\x61\u{533}\x0a\x61\x03\x62\x03\x62\x03\x62\x03\x62\x07\x62\u{539}\
	\x0a\x62\x0c\x62\x0e\x62\u{53c}\x0b\x62\x05\x62\u{53e}\x0a\x62\x03\x63\x03\
	\x63\x03\x63\x03\x64\x03\x64\x07\x64\u{545}\x0a\x64\x0c\x64\x0e\x64\u{548}\
	\x0b\x64\x03\x64\x03\x64\x03\x64\x03\x65\x03\x65\x07\x65\u{54f}\x0a\x65\
	\x0c\x65\x0e\x65\u{552}\x0b\x65\x03\x65\x03\x65\x03\x65\x03\x65\x03\x65\
	\x03\x65\x03\x65\x07\x65\u{55b}\x0a\x65\x0c\x65\x0e\x65\u{55e}\x0b\x65\x03\
	\x65\x05\x65\u{561}\x0a\x65\x03\x65\x03\x65\x03\x66\x03\x66\x03\x66\x05\
	\x66\u{568}\x0a\x66\x03\x67\x03\x67\x03\x67\x03\x67\x03\x67\x07\x67\u{56f}\
	\x0a\x67\x0c\x67\x0e\x67\u{572}\x0b\x67\x03\x67\x03\x67\x03\x68\x03\x68\
	\x07\x68\u{578}\x0a\x68\x0c\x68\x0e\x68\u{57b}\x0b\x68\x03\x68\x03\x68\x03\
	\x68\x03\x68\x03\x68\x05\x68\u{582}\x0a\x68\x03\x68\x05\x68\u{585}\x0a\x68\
	\x03\x69\x03\x69\x03\x69\x03\x69\x03\x6a\x03\x6a\x03\x6a\x03\x6a\x03\x6a\
	\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6b\x03\x6c\x03\x6c\x07\x6c\
	\u{598}\x0a\x6c\x0c\x6c\x0e\x6c\u{59b}\x0b\x6c\x03\x6c\x03\x6c\x03\x6c\x07\
	\x6c\u{5a0}\x0a\x6c\x0c\x6c\x0e\x6c\u{5a3}\x0b\x6c\x03\x6c\x03\x6c\x03\x6c\
	\x05\x6c\u{5a8}\x0a\x6c\x03\x6c\x05\x6c\u{5ab}\x0a\x6c\x03\x6d\x03\x6d\x03\
	\x6d\x03\x6e\x03\x6e\x05\x6e\u{5b2}\x0a\x6e\x03\x6f\x03\x6f\x03\x6f\x03\
	\x6f\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\x70\x03\
	\x70\x03\x70\x03\x71\x03\x71\x05\x71\u{5c4}\x0a\x71\x03\x71\x03\x71\x05\
	\x71\u{5c8}\x0a\x71\x03\x71\x03\x71\x03\x71\x03\x72\x03\x72\x03\x72\x03\
	\x72\x07\x72\u{5d1}\x0a\x72\x0c\x72\x0e\x72\u{5d4}\x0b\x72\x03\x73\x03\x73\
	\x07\x73\u{5d8}\x0a\x73\x0c\x73\x0e\x73\u{5db}\x0b\x73\x03\x73\x03\x73\x03\
	\x73\x07\x73\u{5e0}\x0a\x73\x0c\x73\x0e\x73\u{5e3}\x0b\x73\x03\x73\x05\x73\
	\u{5e6}\x0a\x73\x03\x73\x05\x73\u{5e9}\x0a\x73\x03\x73\x03\x73\x03\x73\x03\
	\x73\x03\x73\x03\x74\x03\x74\x03\x74\x03\x75\x03\x75\x03\x75\x03\x76\x03\
	\x76\x05\x76\u{5f8}\x0a\x76\x03\x77\x03\x77\x03\x77\x03\x78\x03\x78\x07\
	\x78\u{5ff}\x0a\x78\x0c\x78\x0e\x78\u{602}\x0b\x78\x03\x78\x03\x78\x03\x78\
	\x07\x78\u{607}\x0a\x78\x0c\x78\x0e\x78\u{60a}\x0b\x78\x03\x78\x05\x78\u{60d}\
	\x0a\x78\x03\x79\x03\x79\x05\x79\u{611}\x0a\x79\x03\x7a\x03\x7a\x05\x7a\
	\u{615}\x0a\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7a\x03\x7b\x03\x7b\x03\x7b\
	\x03\x7b\x05\x7b\u{61f}\x0a\x7b\x03\x7c\x03\x7c\x03\x7c\x03\x7c\x03\x7d\
	\x03\x7d\x03\x7d\x05\x7d\u{628}\x0a\x7d\x03\x7e\x05\x7e\u{62b}\x0a\x7e\x03\
	\x7e\x07\x7e\u{62e}\x0a\x7e\x0c\x7e\x0e\x7e\u{631}\x0b\x7e\x03\x7e\x05\x7e\
	\u{634}\x0a\x7e\x03\x7f\x05\x7f\u{637}\x0a\x7f\x03\x7f\x03\x7f\x05\x7f\u{63b}\
	\x0a\x7f\x03\u{80}\x03\u{80}\x05\u{80}\u{63f}\x0a\u{80}\x03\u{80}\x03\u{80}\
	\x03\u{80}\x03\u{80}\x03\u{81}\x03\u{81}\x03\u{81}\x03\u{81}\x05\u{81}\u{649}\
	\x0a\u{81}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x03\u{82}\x07\u{82}\u{650}\
	\x0a\u{82}\x0c\u{82}\x0e\u{82}\u{653}\x0b\u{82}\x03\u{82}\x03\u{82}\x03\
	\u{83}\x03\u{83}\x07\u{83}\u{659}\x0a\u{83}\x0c\u{83}\x0e\u{83}\u{65c}\x0b\
	\u{83}\x03\u{83}\x03\u{83}\x03\u{83}\x05\u{83}\u{661}\x0a\u{83}\x03\u{83}\
	\x03\u{83}\x05\u{83}\u{665}\x0a\u{83}\x03\u{84}\x03\u{84}\x03\u{84}\x05\
	\u{84}\u{66a}\x0a\u{84}\x03\u{85}\x03\u{85}\x03\u{85}\x03\u{85}\x03\u{86}\
	\x03\u{86}\x03\u{86}\x03\u{86}\x03\u{87}\x03\u{87}\x07\u{87}\u{676}\x0a\
	\u{87}\x0c\u{87}\x0e\u{87}\u{679}\x0b\u{87}\x03\u{87}\x03\u{87}\x05\u{87}\
	\u{67d}\x0a\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{87}\x03\u{88}\x03\
	\u{88}\x03\u{88}\x03\u{89}\x03\u{89}\x03\u{89}\x03\u{89}\x07\u{89}\u{68a}\
	\x0a\u{89}\x0c\u{89}\x0e\u{89}\u{68d}\x0b\u{89}\x03\u{8a}\x03\u{8a}\x03\
	\u{8a}\x03\u{8a}\x07\u{8a}\u{693}\x0a\u{8a}\x0c\u{8a}\x0e\u{8a}\u{696}\x0b\
	\u{8a}\x05\u{8a}\u{698}\x0a\u{8a}\x03\u{8b}\x03\u{8b}\x03\u{8b}\x03\u{8b}\
	\x07\u{8b}\u{69e}\x0a\u{8b}\x0c\u{8b}\x0e\u{8b}\u{6a1}\x0b\u{8b}\x03\u{8c}\
	\x03\u{8c}\x03\u{8c}\x03\u{8c}\x07\u{8c}\u{6a7}\x0a\u{8c}\x0c\u{8c}\x0e\
	\u{8c}\u{6aa}\x0b\u{8c}\x05\u{8c}\u{6ac}\x0a\u{8c}\x03\u{8d}\x03\u{8d}\x03\
	\u{8d}\x03\u{8d}\x07\u{8d}\u{6b2}\x0a\u{8d}\x0c\u{8d}\x0e\u{8d}\u{6b5}\x0b\
	\u{8d}\x05\u{8d}\u{6b7}\x0a\u{8d}\x03\u{8e}\x03\u{8e}\x03\u{8e}\x03\u{8e}\
	\x07\u{8e}\u{6bd}\x0a\u{8e}\x0c\u{8e}\x0e\u{8e}\u{6c0}\x0b\u{8e}\x05\u{8e}\
	\u{6c2}\x0a\u{8e}\x03\u{8f}\x03\u{8f}\x05\u{8f}\u{6c6}\x0a\u{8f}\x03\u{90}\
	\x03\u{90}\x07\u{90}\u{6ca}\x0a\u{90}\x0c\u{90}\x0e\u{90}\u{6cd}\x0b\u{90}\
	\x03\u{90}\x03\u{90}\x03\u{90}\x05\u{90}\u{6d2}\x0a\u{90}\x03\u{91}\x03\
	\u{91}\x03\u{91}\x03\u{91}\x07\u{91}\u{6d8}\x0a\u{91}\x0c\u{91}\x0e\u{91}\
	\u{6db}\x0b\u{91}\x03\u{92}\x03\u{92}\x03\u{92}\x03\u{92}\x05\u{92}\u{6e1}\
	\x0a\u{92}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x03\u{93}\x07\u{93}\u{6e8}\
	\x0a\u{93}\x0c\u{93}\x0e\u{93}\u{6eb}\x0b\u{93}\x05\u{93}\u{6ed}\x0a\u{93}\
	\x03\u{93}\x03\u{93}\x03\u{94}\x06\u{94}\u{6f2}\x0a\u{94}\x0d\u{94}\x0e\
	\u{94}\u{6f3}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\
	\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\x03\u{95}\
	\x05\u{95}\u{729}\x0a\u{95}\x03\u{96}\x03\u{96}\x03\u{96}\x07\u{96}\u{72e}\
	\x0a\u{96}\x0c\u{96}\x0e\u{96}\u{731}\x0b\u{96}\x03\u{97}\x03\u{97}\x03\
	\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\x03\u{97}\
	\x03\u{97}\x03\u{97}\x03\u{97}\x05\u{97}\u{740}\x0a\u{97}\x03\u{98}\x03\
	\u{98}\x07\u{98}\u{744}\x0a\u{98}\x0c\u{98}\x0e\u{98}\u{747}\x0b\u{98}\x03\
	\u{98}\x03\u{98}\x03\u{98}\x03\u{98}\x03\u{99}\x03\u{99}\x07\u{99}\u{74f}\
	\x0a\u{99}\x0c\u{99}\x0e\u{99}\u{752}\x0b\u{99}\x03\u{99}\x03\u{99}\x03\
	\u{9a}\x03\u{9a}\x07\u{9a}\u{758}\x0a\u{9a}\x0c\u{9a}\x0e\u{9a}\u{75b}\x0b\
	\u{9a}\x03\u{9a}\x05\u{9a}\u{75e}\x0a\u{9a}\x03\u{9a}\x05\u{9a}\u{761}\x0a\
	\u{9a}\x03\u{9a}\x05\u{9a}\u{764}\x0a\u{9a}\x03\u{9a}\x03\u{9a}\x03\u{9a}\
	\x06\u{9a}\u{769}\x0a\u{9a}\x0d\u{9a}\x0e\u{9a}\u{76a}\x03\u{9a}\x03\u{9a}\
	\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9b}\x03\u{9c}\x03\
	\u{9c}\x03\u{9c}\x03\u{9c}\x03\u{9c}\x07\u{9c}\u{77a}\x0a\u{9c}\x0c\u{9c}\
	\x0e\u{9c}\u{77d}\x0b\u{9c}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\u{9d}\x03\
	\u{9d}\x07\u{9d}\u{784}\x0a\u{9d}\x0c\u{9d}\x0e\u{9d}\u{787}\x0b\u{9d}\x03\
	\u{9d}\x03\u{9d}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x05\u{9e}\u{78e}\x0a\u{9e}\
	\x03\u{9e}\x05\u{9e}\u{791}\x0a\u{9e}\x03\u{9e}\x03\u{9e}\x03\u{9e}\x05\
	\u{9e}\u{796}\x0a\u{9e}\x03\u{9e}\x03\u{9e}\x03\u{9f}\x03\u{9f}\x03\u{9f}\
	\x03\u{9f}\x03\u{a0}\x03\u{a0}\x03\u{a0}\x03\u{a0}\x07\u{a0}\u{7a2}\x0a\
	\u{a0}\x0c\u{a0}\x0e\u{a0}\u{7a5}\x0b\u{a0}\x03\u{a1}\x03\u{a1}\x03\u{a1}\
	\x03\u{a1}\x03\u{a2}\x03\u{a2}\x07\u{a2}\u{7ad}\x0a\u{a2}\x0c\u{a2}\x0e\
	\u{a2}\u{7b0}\x0b\u{a2}\x03\u{a2}\x05\u{a2}\u{7b3}\x0a\u{a2}\x03\u{a2}\x05\
	\u{a2}\u{7b6}\x0a\u{a2}\x03\u{a2}\x03\u{a2}\x03\u{a2}\x05\u{a2}\u{7bb}\x0a\
	\u{a2}\x03\u{a3}\x03\u{a3}\x03\u{a3}\x03\u{a3}\x03\u{a4}\x03\u{a4}\x03\u{a4}\
	\x03\u{a4}\x03\u{a4}\x07\u{a4}\u{7c6}\x0a\u{a4}\x0c\u{a4}\x0e\u{a4}\u{7c9}\
	\x0b\u{a4}\x03\u{a4}\x03\u{a4}\x03\u{a5}\x03\u{a5}\x07\u{a5}\u{7cf}\x0a\
	\u{a5}\x0c\u{a5}\x0e\u{a5}\u{7d2}\x0b\u{a5}\x03\u{a5}\x03\u{a5}\x03\u{a5}\
	\x07\u{a5}\u{7d7}\x0a\u{a5}\x0c\u{a5}\x0e\u{a5}\u{7da}\x0b\u{a5}\x03\u{a6}\
	\x03\u{a6}\x07\u{a6}\u{7de}\x0a\u{a6}\x0c\u{a6}\x0e\u{a6}\u{7e1}\x0b\u{a6}\
	\x03\u{a6}\x03\u{a6}\x03\u{a6}\x03\u{a6}\x07\u{a6}\u{7e7}\x0a\u{a6}\x0c\
	\u{a6}\x0e\u{a6}\u{7ea}\x0b\u{a6}\x03\u{a7}\x03\u{a7}\x03\u{a7}\x03\u{a8}\
	\x05\u{a8}\u{7f0}\x0a\u{a8}\x03\u{a8}\x03\u{a8}\x05\u{a8}\u{7f4}\x0a\u{a8}\
	\x03\u{a9}\x03\u{a9}\x07\u{a9}\u{7f8}\x0a\u{a9}\x0c\u{a9}\x0e\u{a9}\u{7fb}\
	\x0b\u{a9}\x03\u{a9}\x03\u{a9}\x03\u{a9}\x07\u{a9}\u{800}\x0a\u{a9}\x0c\
	\u{a9}\x0e\u{a9}\u{803}\x0b\u{a9}\x05\u{a9}\u{805}\x0a\u{a9}\x03\u{a9}\x05\
	\u{a9}\u{808}\x0a\u{a9}\x03\u{aa}\x03\u{aa}\x03\u{aa}\x03\u{aa}\x03\u{aa}\
	\x03\u{aa}\x05\u{aa}\u{810}\x0a\u{aa}\x03\u{ab}\x03\u{ab}\x03\u{ab}\x03\
	\u{ab}\x03\u{ac}\x03\u{ac}\x07\u{ac}\u{818}\x0a\u{ac}\x0c\u{ac}\x0e\u{ac}\
	\u{81b}\x0b\u{ac}\x03\u{ac}\x03\u{ac}\x03\u{ad}\x03\u{ad}\x07\u{ad}\u{821}\
	\x0a\u{ad}\x0c\u{ad}\x0e\u{ad}\u{824}\x0b\u{ad}\x03\u{ad}\x03\u{ad}\x03\
	\u{ad}\x03\u{ad}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x03\u{ae}\x05\u{ae}\
	\u{82f}\x0a\u{ae}\x03\u{af}\x03\u{af}\x03\u{af}\x03\u{b0}\x03\u{b0}\x03\
	\u{b0}\x07\u{b0}\u{837}\x0a\u{b0}\x0c\u{b0}\x0e\u{b0}\u{83a}\x0b\u{b0}\x03\
	\u{b1}\x03\u{b1}\x05\u{b1}\u{83e}\x0a\u{b1}\x03\u{b1}\x03\u{b1}\x03\u{b1}\
	\x05\u{b1}\u{843}\x0a\u{b1}\x03\u{b1}\x03\u{b1}\x03\u{b1}\x03\u{b2}\x03\
	\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b2}\x03\u{b3}\x03\u{b3}\x07\u{b3}\u{84f}\
	\x0a\u{b3}\x0c\u{b3}\x0e\u{b3}\u{852}\x0b\u{b3}\x03\u{b3}\x03\u{b3}\x03\
	\u{b3}\x07\u{b3}\u{857}\x0a\u{b3}\x0c\u{b3}\x0e\u{b3}\u{85a}\x0b\u{b3}\x03\
	\u{b4}\x03\u{b4}\x03\u{b4}\x05\u{b4}\u{85f}\x0a\u{b4}\x03\u{b5}\x03\u{b5}\
	\x07\u{b5}\u{863}\x0a\u{b5}\x0c\u{b5}\x0e\u{b5}\u{866}\x0b\u{b5}\x03\u{b5}\
	\x03\u{b5}\x03\u{b6}\x03\u{b6}\x05\u{b6}\u{86c}\x0a\u{b6}\x03\u{b7}\x03\
	\u{b7}\x07\u{b7}\u{870}\x0a\u{b7}\x0c\u{b7}\x0e\u{b7}\u{873}\x0b\u{b7}\x03\
	\u{b8}\x03\u{b8}\x03\u{b8}\x03\u{b9}\x03\u{b9}\x03\u{b9}\x03\u{b9}\x05\u{b9}\
	\u{87c}\x0a\u{b9}\x03\u{ba}\x03\u{ba}\x03\u{ba}\x03\u{ba}\x05\u{ba}\u{882}\
	\x0a\u{ba}\x03\u{bb}\x03\u{bb}\x03\u{bb}\x03\u{bb}\x05\u{bb}\u{888}\x0a\
	\u{bb}\x03\u{bc}\x05\u{bc}\u{88b}\x0a\u{bc}\x03\u{bc}\x03\u{bc}\x03\u{bd}\
	\x03\u{bd}\x05\u{bd}\u{891}\x0a\u{bd}\x03\u{bd}\x03\u{bd}\x03\u{be}\x03\
	\u{be}\x03\u{be}\x03\u{be}\x07\u{be}\u{899}\x0a\u{be}\x0c\u{be}\x0e\u{be}\
	\u{89c}\x0b\u{be}\x03\u{be}\x03\u{be}\x03\u{bf}\x03\u{bf}\x03\u{bf}\x03\
	\u{bf}\x03\u{c0}\x03\u{c0}\x03\u{c1}\x03\u{c1}\x07\u{c1}\u{8a8}\x0a\u{c1}\
	\x0c\u{c1}\x0e\u{c1}\u{8ab}\x0b\u{c1}\x03\u{c2}\x03\u{c2}\x03\u{c2}\x03\
	\u{c3}\x03\u{c3}\x07\u{c3}\u{8b2}\x0a\u{c3}\x0c\u{c3}\x0e\u{c3}\u{8b5}\x0b\
	\u{c3}\x03\u{c4}\x03\u{c4}\x03\u{c4}\x03\u{c5}\x03\u{c5}\x03\u{c5}\x03\u{c5}\
	\x03\u{c5}\x05\u{c5}\u{8bf}\x0a\u{c5}\x03\u{c6}\x03\u{c6}\x03\u{c6}\x03\
	\u{c6}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x03\u{c7}\x07\u{c7}\
	\u{8cb}\x0a\u{c7}\x0c\u{c7}\x0e\u{c7}\u{8ce}\x0b\u{c7}\x03\u{c7}\x03\u{c7}\
	\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\u{c8}\x03\
	\u{c8}\x03\u{c9}\x03\u{c9}\x03\u{c9}\x03\u{c9}\x03\u{ca}\x03\u{ca}\x03\u{ca}\
	\x05\u{ca}\u{8e1}\x0a\u{ca}\x03\u{cb}\x03\u{cb}\x07\u{cb}\u{8e5}\x0a\u{cb}\
	\x0c\u{cb}\x0e\u{cb}\u{8e8}\x0b\u{cb}\x03\u{cc}\x03\u{cc}\x03\u{cc}\x03\
	\u{cd}\x03\u{cd}\x07\u{cd}\u{8ef}\x0a\u{cd}\x0c\u{cd}\x0e\u{cd}\u{8f2}\x0b\
	\u{cd}\x03\u{ce}\x03\u{ce}\x03\u{ce}\x03\u{cf}\x03\u{cf}\x05\u{cf}\u{8f9}\
	\x0a\u{cf}\x03\u{d0}\x03\u{d0}\x07\u{d0}\u{8fd}\x0a\u{d0}\x0c\u{d0}\x0e\
	\u{d0}\u{900}\x0b\u{d0}\x03\u{d1}\x03\u{d1}\x05\u{d1}\u{904}\x0a\u{d1}\x03\
	\u{d1}\x03\u{d1}\x03\u{d2}\x03\u{d2}\x03\u{d3}\x03\u{d3}\x03\u{d3}\x03\u{d3}\
	\x03\u{d4}\x05\u{d4}\u{90f}\x0a\u{d4}\x03\u{d4}\x03\u{d4}\x03\u{d5}\x03\
	\u{d5}\x03\u{d5}\x05\u{d5}\u{916}\x0a\u{d5}\x03\u{d6}\x03\u{d6}\x03\u{d6}\
	\x05\u{d6}\u{91b}\x0a\u{d6}\x03\u{d7}\x03\u{d7}\x06\u{d7}\u{91f}\x0a\u{d7}\
	\x0d\u{d7}\x0e\u{d7}\u{920}\x03\u{d8}\x03\u{d8}\x03\u{d8}\x05\u{d8}\u{926}\
	\x0a\u{d8}\x03\u{d9}\x03\u{d9}\x03\u{d9}\x03\u{da}\x03\u{da}\x03\u{da}\x03\
	\u{da}\x03\u{db}\x03\u{db}\x03\u{db}\x03\u{db}\x03\u{db}\x03\u{dc}\x03\u{dc}\
	\x05\u{dc}\u{936}\x0a\u{dc}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\u{dc}\x03\
	\u{dd}\x03\u{dd}\x05\u{dd}\u{93e}\x0a\u{dd}\x03\u{dd}\x03\u{dd}\x03\u{dd}\
	\x03\u{dd}\x03\u{de}\x03\u{de}\x03\u{de}\x03\u{de}\x03\u{df}\x03\u{df}\x07\
	\u{df}\u{94a}\x0a\u{df}\x0c\u{df}\x0e\u{df}\u{94d}\x0b\u{df}\x03\u{e0}\x03\
	\u{e0}\x03\u{e0}\x03\u{e1}\x03\u{e1}\x05\u{e1}\u{954}\x0a\u{e1}\x03\u{e2}\
	\x03\u{e2}\x03\u{e2}\x03\u{e2}\x03\u{e2}\x07\u{e2}\u{95b}\x0a\u{e2}\x0c\
	\u{e2}\x0e\u{e2}\u{95e}\x0b\u{e2}\x05\u{e2}\u{960}\x0a\u{e2}\x03\u{e2}\x03\
	\u{e2}\x03\u{e3}\x03\u{e3}\x05\u{e3}\u{966}\x0a\u{e3}\x03\u{e4}\x03\u{e4}\
	\x03\u{e4}\x05\u{e4}\u{96b}\x0a\u{e4}\x03\u{e4}\x03\u{e4}\x03\u{e5}\x03\
	\u{e5}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\x03\u{e6}\
	\x05\u{e6}\u{978}\x0a\u{e6}\x03\u{e7}\x03\u{e7}\x05\u{e7}\u{97c}\x0a\u{e7}\
	\x03\u{e8}\x03\u{e8}\x03\u{e8}\x03\u{e8}\x03\u{e9}\x03\u{e9}\x03\u{e9}\x03\
	\u{e9}\x03\u{ea}\x03\u{ea}\x03\u{ea}\x03\u{ea}\x03\u{ea}\x03\u{ea}\x03\u{ea}\
	\x03\u{ea}\x03\u{ea}\x03\u{eb}\x03\u{eb}\x05\u{eb}\u{991}\x0a\u{eb}\x03\
	\u{ec}\x03\u{ec}\x06\u{ec}\u{995}\x0a\u{ec}\x0d\u{ec}\x0e\u{ec}\u{996}\x03\
	\u{ed}\x03\u{ed}\x03\u{ed}\x05\u{ed}\u{99c}\x0a\u{ed}\x03\u{ee}\x03\u{ee}\
	\x03\u{ee}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{ef}\x03\u{f0}\x03\u{f0}\x03\
	\u{f0}\x03\u{f0}\x03\u{f0}\x03\u{f1}\x03\u{f1}\x03\u{f1}\x05\u{f1}\u{9ad}\
	\x0a\u{f1}\x03\u{f2}\x03\u{f2}\x03\u{f3}\x03\u{f3}\x03\u{f4}\x03\u{f4}\x03\
	\u{f5}\x03\u{f5}\x03\u{f5}\x05\u{f5}\u{9b8}\x0a\u{f5}\x03\u{f6}\x03\u{f6}\
	\x03\u{f6}\x03\u{f6}\x03\u{f7}\x03\u{f7}\x05\u{f7}\u{9c0}\x0a\u{f7}\x03\
	\u{f8}\x03\u{f8}\x03\u{f8}\x03\u{f8}\x03\u{f9}\x03\u{f9}\x07\u{f9}\u{9c8}\
	\x0a\u{f9}\x0c\u{f9}\x0e\u{f9}\u{9cb}\x0b\u{f9}\x03\u{f9}\x03\u{f9}\x03\
	\u{f9}\x05\u{f9}\u{9d0}\x0a\u{f9}\x03\u{f9}\x03\u{f9}\x07\u{f9}\u{9d4}\x0a\
	\u{f9}\x0c\u{f9}\x0e\u{f9}\u{9d7}\x0b\u{f9}\x03\u{f9}\x05\u{f9}\u{9da}\x0a\
	\u{f9}\x03\u{f9}\x03\u{f9}\x03\u{fa}\x03\u{fa}\x05\u{fa}\u{9e0}\x0a\u{fa}\
	\x03\u{fa}\x03\u{fa}\x07\u{fa}\u{9e4}\x0a\u{fa}\x0c\u{fa}\x0e\u{fa}\u{9e7}\
	\x0b\u{fa}\x03\u{fa}\x05\u{fa}\u{9ea}\x0a\u{fa}\x03\u{fa}\x03\u{fa}\x03\
	\u{fb}\x03\u{fb}\x03\u{fb}\x03\u{fb}\x03\u{fc}\x03\u{fc}\x07\u{fc}\u{9f4}\
	\x0a\u{fc}\x0c\u{fc}\x0e\u{fc}\u{9f7}\x0b\u{fc}\x03\u{fc}\x03\u{fc}\x03\
	\u{fc}\x03\u{fc}\x03\u{fc}\x07\u{fc}\u{9fe}\x0a\u{fc}\x0c\u{fc}\x0e\u{fc}\
	\u{a01}\x0b\u{fc}\x03\u{fc}\x03\u{fc}\x05\u{fc}\u{a05}\x0a\u{fc}\x03\u{fd}\
	\x03\u{fd}\x03\u{fd}\x03\u{fd}\x03\u{fd}\x07\u{fd}\u{a0c}\x0a\u{fd}\x0c\
	\u{fd}\x0e\u{fd}\u{a0f}\x0b\u{fd}\x03\u{fd}\x05\u{fd}\u{a12}\x0a\u{fd}\x05\
	\u{fd}\u{a14}\x0a\u{fd}\x03\u{fd}\x03\u{fd}\x03\u{fe}\x03\u{fe}\x03\u{fe}\
	\x03\u{fe}\x03\u{fe}\x05\u{fe}\u{a1d}\x0a\u{fe}\x03\u{ff}\x03\u{ff}\x03\
	\u{ff}\x03\u{ff}\x03\u{ff}\x03\u{ff}\x03\u{ff}\x03\u{ff}\x03\u{100}\x03\
	\u{100}\x03\u{100}\x03\u{100}\x03\u{100}\x03\u{101}\x03\u{101}\x03\u{101}\
	\x03\u{101}\x03\u{101}\x03\u{102}\x03\u{102}\x03\u{102}\x03\u{102}\x03\u{102}\
	\x03\u{103}\x03\u{103}\x03\u{104}\x03\u{104}\x03\u{105}\x03\u{105}\x03\u{106}\
	\x03\u{106}\x03\u{107}\x03\u{107}\x03\u{108}\x03\u{108}\x03\u{109}\x03\u{109}\
	\x05\u{109}\u{a44}\x0a\u{109}\x03\u{10a}\x03\u{10a}\x03\u{10b}\x03\u{10b}\
	\x03\u{10c}\x03\u{10c}\x03\u{10d}\x03\u{10d}\x03\u{10d}\x03\u{10d}\x03\u{10e}\
	\x03\u{10e}\x05\u{10e}\u{a52}\x0a\u{10e}\x03\u{10f}\x03\u{10f}\x03\u{10f}\
	\x05\u{10f}\u{a57}\x0a\u{10f}\x03\u{110}\x03\u{110}\x03\u{110}\x03\u{110}\
	\x05\u{110}\u{a5d}\x0a\u{110}\x03\u{111}\x03\u{111}\x03\u{111}\x05\u{111}\
	\u{a62}\x0a\u{111}\x03\u{112}\x05\u{112}\u{a65}\x0a\u{112}\x03\u{112}\x03\
	\u{112}\x07\u{112}\u{a69}\x0a\u{112}\x0c\u{112}\x0e\u{112}\u{a6c}\x0b\u{112}\
	\x03\u{113}\x03\u{113}\x03\u{113}\x05\u{113}\u{a71}\x0a\u{113}\x03\u{114}\
	\x03\u{114}\x03\u{114}\x03\u{114}\x03\u{114}\x05\u{114}\u{a78}\x0a\u{114}\
	\x03\u{115}\x03\u{115}\x05\u{115}\u{a7c}\x0a\u{115}\x03\u{116}\x03\u{116}\
	\x03\u{116}\x03\u{116}\x03\u{116}\x03\u{116}\x03\u{116}\x03\u{116}\x03\u{116}\
	\x03\u{116}\x03\u{116}\x05\u{116}\u{a89}\x0a\u{116}\x03\u{117}\x03\u{117}\
	\x03\u{117}\x03\u{117}\x03\u{117}\x03\u{117}\x03\u{117}\x05\u{117}\u{a92}\
	\x0a\u{117}\x03\u{118}\x03\u{118}\x03\u{118}\x03\u{118}\x03\u{118}\x05\u{118}\
	\u{a99}\x0a\u{118}\x03\u{119}\x03\u{119}\x05\u{119}\u{a9d}\x0a\u{119}\x03\
	\u{11a}\x03\u{11a}\x03\u{11b}\x03\u{11b}\x03\u{11c}\x03\u{11c}\x03\u{11d}\
	\x03\u{11d}\x03\u{11e}\x03\u{11e}\x03\u{11f}\x03\u{11f}\x03\u{120}\x03\u{120}\
	\x03\u{121}\x03\u{121}\x03\u{122}\x03\u{122}\x03\u{123}\x03\u{123}\x03\u{123}\
	\x03\u{124}\x03\u{124}\x03\u{124}\x03\u{125}\x03\u{125}\x07\u{125}\u{ab9}\
	\x0a\u{125}\x0c\u{125}\x0e\u{125}\u{abc}\x0b\u{125}\x03\u{126}\x03\u{126}\
	\x03\u{126}\x03\u{126}\x03\u{126}\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\
	\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\x03\u{127}\
	\x05\u{127}\u{ace}\x0a\u{127}\x03\u{128}\x03\u{128}\x03\u{128}\x03\u{128}\
	\x07\u{128}\u{ad4}\x0a\u{128}\x0c\u{128}\x0e\u{128}\u{ad7}\x0b\u{128}\x05\
	\u{128}\u{ad9}\x0a\u{128}\x03\u{128}\x03\u{128}\x03\u{129}\x03\u{129}\x03\
	\u{129}\x03\u{129}\x03\u{12a}\x03\u{12a}\x03\u{12a}\x03\u{12a}\x07\u{12a}\
	\u{ae5}\x0a\u{12a}\x0c\u{12a}\x0e\u{12a}\u{ae8}\x0b\u{12a}\x05\u{12a}\u{aea}\
	\x0a\u{12a}\x03\u{12a}\x03\u{12a}\x03\u{12b}\x03\u{12b}\x03\u{12c}\x03\u{12c}\
	\x03\u{12d}\x03\u{12d}\x03\u{12e}\x03\u{12e}\x03\u{12f}\x03\u{12f}\x07\u{12f}\
	\u{af8}\x0a\u{12f}\x0c\u{12f}\x0e\u{12f}\u{afb}\x0b\u{12f}\x03\u{130}\x03\
	\u{130}\x03\u{131}\x05\u{131}\u{b00}\x0a\u{131}\x03\u{131}\x03\u{131}\x03\
	\u{132}\x05\u{132}\u{b05}\x0a\u{132}\x03\u{132}\x03\u{132}\x03\u{132}\x02\
	\x02\u{133}\x02\x04\x06\x08\x0a\x0c\x0e\x10\x12\x14\x16\x18\x1a\x1c\x1e\
	\x20\x22\x24\x26\x28\x2a\x2c\x2e\x30\x32\x34\x36\x38\x3a\x3c\x3e\x40\x42\
	\x44\x46\x48\x4a\x4c\x4e\x50\x52\x54\x56\x58\x5a\x5c\x5e\x60\x62\x64\x66\
	\x68\x6a\x6c\x6e\x70\x72\x74\x76\x78\x7a\x7c\x7e\u{80}\u{82}\u{84}\u{86}\
	\u{88}\u{8a}\u{8c}\u{8e}\u{90}\u{92}\u{94}\u{96}\u{98}\u{9a}\u{9c}\u{9e}\
	\u{a0}\u{a2}\u{a4}\u{a6}\u{a8}\u{aa}\u{ac}\u{ae}\u{b0}\u{b2}\u{b4}\u{b6}\
	\u{b8}\u{ba}\u{bc}\u{be}\u{c0}\u{c2}\u{c4}\u{c6}\u{c8}\u{ca}\u{cc}\u{ce}\
	\u{d0}\u{d2}\u{d4}\u{d6}\u{d8}\u{da}\u{dc}\u{de}\u{e0}\u{e2}\u{e4}\u{e6}\
	\u{e8}\u{ea}\u{ec}\u{ee}\u{f0}\u{f2}\u{f4}\u{f6}\u{f8}\u{fa}\u{fc}\u{fe}\
	\u{100}\u{102}\u{104}\u{106}\u{108}\u{10a}\u{10c}\u{10e}\u{110}\u{112}\u{114}\
	\u{116}\u{118}\u{11a}\u{11c}\u{11e}\u{120}\u{122}\u{124}\u{126}\u{128}\u{12a}\
	\u{12c}\u{12e}\u{130}\u{132}\u{134}\u{136}\u{138}\u{13a}\u{13c}\u{13e}\u{140}\
	\u{142}\u{144}\u{146}\u{148}\u{14a}\u{14c}\u{14e}\u{150}\u{152}\u{154}\u{156}\
	\u{158}\u{15a}\u{15c}\u{15e}\u{160}\u{162}\u{164}\u{166}\u{168}\u{16a}\u{16c}\
	\u{16e}\u{170}\u{172}\u{174}\u{176}\u{178}\u{17a}\u{17c}\u{17e}\u{180}\u{182}\
	\u{184}\u{186}\u{188}\u{18a}\u{18c}\u{18e}\u{190}\u{192}\u{194}\u{196}\u{198}\
	\u{19a}\u{19c}\u{19e}\u{1a0}\u{1a2}\u{1a4}\u{1a6}\u{1a8}\u{1aa}\u{1ac}\u{1ae}\
	\u{1b0}\u{1b2}\u{1b4}\u{1b6}\u{1b8}\u{1ba}\u{1bc}\u{1be}\u{1c0}\u{1c2}\u{1c4}\
	\u{1c6}\u{1c8}\u{1ca}\u{1cc}\u{1ce}\u{1d0}\u{1d2}\u{1d4}\u{1d6}\u{1d8}\u{1da}\
	\u{1dc}\u{1de}\u{1e0}\u{1e2}\u{1e4}\u{1e6}\u{1e8}\u{1ea}\u{1ec}\u{1ee}\u{1f0}\
	\u{1f2}\u{1f4}\u{1f6}\u{1f8}\u{1fa}\u{1fc}\u{1fe}\u{200}\u{202}\u{204}\u{206}\
	\u{208}\u{20a}\u{20c}\u{20e}\u{210}\u{212}\u{214}\u{216}\u{218}\u{21a}\u{21c}\
	\u{21e}\u{220}\u{222}\u{224}\u{226}\u{228}\u{22a}\u{22c}\u{22e}\u{230}\u{232}\
	\u{234}\u{236}\u{238}\u{23a}\u{23c}\u{23e}\u{240}\u{242}\u{244}\u{246}\u{248}\
	\u{24a}\u{24c}\u{24e}\u{250}\u{252}\u{254}\u{256}\u{258}\u{25a}\u{25c}\u{25e}\
	\u{260}\u{262}\x02\x27\x04\x02\x0e\x0f\x1b\x1b\x04\x02\x10\x10\x1c\x1c\x03\
	\x02\x08\x09\x04\x02\x50\x50\u{a3}\u{a3}\x03\x02\x0e\x0f\x04\x02\u{9f}\u{9f}\
	\u{a1}\u{a1}\x04\x02\u{a0}\u{a0}\u{a2}\u{a2}\x04\x02\u{da}\u{db}\u{e7}\u{e7}\
	\x05\x02\x32\x32\x4e\x4e\x63\x64\x11\x02\x27\x27\x2e\x2e\x30\x30\x36\x36\
	\x3c\x3c\x3e\x3e\u{8c}\u{8c}\u{94}\u{95}\u{cc}\u{cd}\u{e2}\u{e2}\u{ec}\u{ec}\
	\u{f1}\u{f1}\u{f4}\u{f6}\u{fe}\u{fe}\u{13e}\u{13e}\x06\x02\x4c\x4c\u{9b}\
	\u{9b}\u{ea}\u{eb}\u{101}\u{101}\x04\x02\u{93}\u{93}\u{97}\u{97}\x04\x02\
	\x72\x72\u{104}\u{104}\x05\x02\x34\x34\u{a4}\u{a4}\u{c3}\u{c3}\x05\x02\x2c\
	\x2c\u{8d}\u{8d}\u{a4}\u{a4}\x04\x02\u{bf}\u{bf}\u{e8}\u{e8}\x04\x02\x32\
	\x32\x4e\x4e\x04\x02\x5e\x5e\u{8d}\u{8d}\x04\x02\u{92}\u{92}\u{f2}\u{f2}\
	\x04\x02\x5c\x5c\u{105}\u{105}\x0f\x02\x35\x35\x3a\x3a\x45\x46\x4b\x4b\x57\
	\x57\x73\x7d\u{83}\u{83}\u{88}\u{89}\u{8b}\u{8b}\u{cb}\u{cb}\u{e9}\u{e9}\
	\u{107}\u{10a}\u{10c}\u{10d}\x10\x02\x35\x35\x3a\x3a\x45\x46\x4b\x4b\x57\
	\x57\x73\x7d\u{83}\u{83}\u{88}\u{89}\u{8b}\u{8b}\u{cb}\u{cb}\u{e9}\u{e9}\
	\u{107}\u{10a}\u{10c}\u{10d}\u{13e}\u{13e}\x05\x02\x14\x14\x16\x16\x1e\x1e\
	\x05\x02\x6b\x6c\u{84}\u{85}\u{b1}\u{b2}\x04\x02\x38\x38\u{a6}\u{a6}\x04\
	\x02\x18\x1a\x1d\x1d\x04\x02\x0d\x0d\x23\x23\x05\x02\x03\x03\x22\x22\x25\
	\x25\x0d\x02\x15\x15\x17\x17\x40\x42\x51\x52\x6a\x6a\x6d\x71\u{90}\u{91}\
	\u{9c}\u{9c}\u{a7}\u{b0}\u{b3}\u{b8}\u{ed}\u{ee}\x04\x02\x2c\x2c\x7f\x7f\
	\x05\x02\u{8b}\u{8b}\u{108}\u{108}\u{10c}\u{10c}\x03\x02\x59\x5a\x06\x02\
	\u{133}\u{133}\u{135}\u{135}\u{138}\u{139}\u{13b}\u{13d}\x06\x02\u{119}\
	\u{11f}\u{121}\u{123}\u{126}\u{12b}\u{132}\u{132}\x03\x02\u{119}\u{132}\
	\x29\x02\x28\x28\x2a\x2c\x34\x34\x37\x37\x39\x39\x3d\x3d\x47\x47\x4a\x4a\
	\x4c\x4d\x50\x50\x54\x55\x5b\x5b\x60\x61\x72\x72\x7e\x7e\u{80}\u{82}\u{86}\
	\u{86}\u{8e}\u{8f}\u{93}\u{93}\u{95}\u{97}\u{9b}\u{9b}\u{a3}\u{a4}\u{b9}\
	\u{ba}\u{bc}\u{bd}\u{c1}\u{c2}\u{c7}\u{c8}\u{ca}\u{ca}\u{ce}\u{ce}\u{d7}\
	\u{d9}\u{dc}\u{de}\u{e5}\u{e5}\u{ea}\u{eb}\u{ef}\u{ef}\u{f3}\u{f3}\u{ff}\
	\u{ff}\u{101}\u{104}\u{106}\u{106}\u{10e}\u{119}\u{121}\u{121}\x1b\x02\x29\
	\x29\x31\x31\x3b\x3b\x3f\x40\x44\x44\x49\x49\x4f\x4f\x58\x59\x5c\x5d\x6a\
	\x6a\u{84}\u{84}\u{87}\u{87}\u{92}\u{92}\u{9d}\u{9d}\u{bb}\u{bb}\u{c4}\u{c4}\
	\u{cf}\u{cf}\u{df}\u{e1}\u{e3}\u{e4}\u{e6}\u{e6}\u{e8}\u{e8}\u{f0}\u{f0}\
	\u{f2}\u{f2}\u{f7}\u{fd}\u{105}\u{105}\x02\u{b7a}\x02\u{264}\x03\x02\x02\
	\x02\x04\u{266}\x03\x02\x02\x02\x06\u{27a}\x03\x02\x02\x02\x08\u{27c}\x03\
	\x02\x02\x02\x0a\u{287}\x03\x02\x02\x02\x0c\u{289}\x03\x02\x02\x02\x0e\u{28e}\
	\x03\x02\x02\x02\x10\u{298}\x03\x02\x02\x02\x12\u{2a3}\x03\x02\x02\x02\x14\
	\u{2ab}\x03\x02\x02\x02\x16\u{2b3}\x03\x02\x02\x02\x18\u{2c3}\x03\x02\x02\
	\x02\x1a\u{2c5}\x03\x02\x02\x02\x1c\u{2cb}\x03\x02\x02\x02\x1e\u{2ce}\x03\
	\x02\x02\x02\x20\u{2d4}\x03\x02\x02\x02\x22\u{2d8}\x03\x02\x02\x02\x24\u{2e3}\
	\x03\x02\x02\x02\x26\u{2e7}\x03\x02\x02\x02\x28\u{2fa}\x03\x02\x02\x02\x2a\
	\u{2fc}\x03\x02\x02\x02\x2c\u{302}\x03\x02\x02\x02\x2e\u{30f}\x03\x02\x02\
	\x02\x30\u{31a}\x03\x02\x02\x02\x32\u{31e}\x03\x02\x02\x02\x34\u{322}\x03\
	\x02\x02\x02\x36\u{32b}\x03\x02\x02\x02\x38\u{336}\x03\x02\x02\x02\x3a\u{33b}\
	\x03\x02\x02\x02\x3c\u{33d}\x03\x02\x02\x02\x3e\u{349}\x03\x02\x02\x02\x40\
	\u{359}\x03\x02\x02\x02\x42\u{35b}\x03\x02\x02\x02\x44\u{363}\x03\x02\x02\
	\x02\x46\u{365}\x03\x02\x02\x02\x48\u{372}\x03\x02\x02\x02\x4a\u{378}\x03\
	\x02\x02\x02\x4c\u{37a}\x03\x02\x02\x02\x4e\u{37c}\x03\x02\x02\x02\x50\u{383}\
	\x03\x02\x02\x02\x52\u{386}\x03\x02\x02\x02\x54\u{393}\x03\x02\x02\x02\x56\
	\u{3c6}\x03\x02\x02\x02\x58\u{3cc}\x03\x02\x02\x02\x5a\u{3e7}\x03\x02\x02\
	\x02\x5c\u{3e9}\x03\x02\x02\x02\x5e\u{3f2}\x03\x02\x02\x02\x60\u{3f5}\x03\
	\x02\x02\x02\x62\u{3fc}\x03\x02\x02\x02\x64\u{403}\x03\x02\x02\x02\x66\u{406}\
	\x03\x02\x02\x02\x68\u{411}\x03\x02\x02\x02\x6a\u{413}\x03\x02\x02\x02\x6c\
	\u{41b}\x03\x02\x02\x02\x6e\u{426}\x03\x02\x02\x02\x70\u{429}\x03\x02\x02\
	\x02\x72\u{432}\x03\x02\x02\x02\x74\u{434}\x03\x02\x02\x02\x76\u{442}\x03\
	\x02\x02\x02\x78\u{445}\x03\x02\x02\x02\x7a\u{44a}\x03\x02\x02\x02\x7c\u{45c}\
	\x03\x02\x02\x02\x7e\u{464}\x03\x02\x02\x02\u{80}\u{470}\x03\x02\x02\x02\
	\u{82}\u{47b}\x03\x02\x02\x02\u{84}\u{47d}\x03\x02\x02\x02\u{86}\u{481}\
	\x03\x02\x02\x02\u{88}\u{484}\x03\x02\x02\x02\u{8a}\u{489}\x03\x02\x02\x02\
	\u{8c}\u{48b}\x03\x02\x02\x02\u{8e}\u{490}\x03\x02\x02\x02\u{90}\u{492}\
	\x03\x02\x02\x02\u{92}\u{49c}\x03\x02\x02\x02\u{94}\u{49e}\x03\x02\x02\x02\
	\u{96}\u{4a6}\x03\x02\x02\x02\u{98}\u{4ad}\x03\x02\x02\x02\u{9a}\u{4b3}\
	\x03\x02\x02\x02\u{9c}\u{4b6}\x03\x02\x02\x02\u{9e}\u{4bd}\x03\x02\x02\x02\
	\u{a0}\u{4c0}\x03\x02\x02\x02\u{a2}\u{4c2}\x03\x02\x02\x02\u{a4}\u{4c9}\
	\x03\x02\x02\x02\u{a6}\u{4dd}\x03\x02\x02\x02\u{a8}\u{4df}\x03\x02\x02\x02\
	\u{aa}\u{4e3}\x03\x02\x02\x02\u{ac}\u{4e5}\x03\x02\x02\x02\u{ae}\u{4ec}\
	\x03\x02\x02\x02\u{b0}\u{4f1}\x03\x02\x02\x02\u{b2}\u{4f4}\x03\x02\x02\x02\
	\u{b4}\u{4fd}\x03\x02\x02\x02\u{b6}\u{502}\x03\x02\x02\x02\u{b8}\u{507}\
	\x03\x02\x02\x02\u{ba}\u{511}\x03\x02\x02\x02\u{bc}\u{514}\x03\x02\x02\x02\
	\u{be}\u{525}\x03\x02\x02\x02\u{c0}\u{528}\x03\x02\x02\x02\u{c2}\u{534}\
	\x03\x02\x02\x02\u{c4}\u{53f}\x03\x02\x02\x02\u{c6}\u{542}\x03\x02\x02\x02\
	\u{c8}\u{54c}\x03\x02\x02\x02\u{ca}\u{567}\x03\x02\x02\x02\u{cc}\u{569}\
	\x03\x02\x02\x02\u{ce}\u{575}\x03\x02\x02\x02\u{d0}\u{586}\x03\x02\x02\x02\
	\u{d2}\u{58a}\x03\x02\x02\x02\u{d4}\u{58f}\x03\x02\x02\x02\u{d6}\u{595}\
	\x03\x02\x02\x02\u{d8}\u{5ac}\x03\x02\x02\x02\u{da}\u{5af}\x03\x02\x02\x02\
	\u{dc}\u{5b3}\x03\x02\x02\x02\u{de}\u{5b7}\x03\x02\x02\x02\u{e0}\u{5c3}\
	\x03\x02\x02\x02\u{e2}\u{5cc}\x03\x02\x02\x02\u{e4}\u{5d5}\x03\x02\x02\x02\
	\u{e6}\u{5ef}\x03\x02\x02\x02\u{e8}\u{5f2}\x03\x02\x02\x02\u{ea}\u{5f5}\
	\x03\x02\x02\x02\u{ec}\u{5f9}\x03\x02\x02\x02\u{ee}\u{5fc}\x03\x02\x02\x02\
	\u{f0}\u{60e}\x03\x02\x02\x02\u{f2}\u{612}\x03\x02\x02\x02\u{f4}\u{61a}\
	\x03\x02\x02\x02\u{f6}\u{620}\x03\x02\x02\x02\u{f8}\u{624}\x03\x02\x02\x02\
	\u{fa}\u{62a}\x03\x02\x02\x02\u{fc}\u{636}\x03\x02\x02\x02\u{fe}\u{63c}\
	\x03\x02\x02\x02\u{100}\u{644}\x03\x02\x02\x02\u{102}\u{64a}\x03\x02\x02\
	\x02\u{104}\u{656}\x03\x02\x02\x02\u{106}\u{666}\x03\x02\x02\x02\u{108}\
	\u{66b}\x03\x02\x02\x02\u{10a}\u{66f}\x03\x02\x02\x02\u{10c}\u{673}\x03\
	\x02\x02\x02\u{10e}\u{682}\x03\x02\x02\x02\u{110}\u{685}\x03\x02\x02\x02\
	\u{112}\u{68e}\x03\x02\x02\x02\u{114}\u{699}\x03\x02\x02\x02\u{116}\u{6a2}\
	\x03\x02\x02\x02\u{118}\u{6ad}\x03\x02\x02\x02\u{11a}\u{6b8}\x03\x02\x02\
	\x02\u{11c}\u{6c3}\x03\x02\x02\x02\u{11e}\u{6c7}\x03\x02\x02\x02\u{120}\
	\u{6d3}\x03\x02\x02\x02\u{122}\u{6dc}\x03\x02\x02\x02\u{124}\u{6e2}\x03\
	\x02\x02\x02\u{126}\u{6f1}\x03\x02\x02\x02\u{128}\u{728}\x03\x02\x02\x02\
	\u{12a}\u{72a}\x03\x02\x02\x02\u{12c}\u{73f}\x03\x02\x02\x02\u{12e}\u{741}\
	\x03\x02\x02\x02\u{130}\u{74c}\x03\x02\x02\x02\u{132}\u{755}\x03\x02\x02\
	\x02\u{134}\u{76e}\x03\x02\x02\x02\u{136}\u{774}\x03\x02\x02\x02\u{138}\
	\u{77e}\x03\x02\x02\x02\u{13a}\u{78a}\x03\x02\x02\x02\u{13c}\u{799}\x03\
	\x02\x02\x02\u{13e}\u{79d}\x03\x02\x02\x02\u{140}\u{7a6}\x03\x02\x02\x02\
	\u{142}\u{7aa}\x03\x02\x02\x02\u{144}\u{7bc}\x03\x02\x02\x02\u{146}\u{7c0}\
	\x03\x02\x02\x02\u{148}\u{7cc}\x03\x02\x02\x02\u{14a}\u{7db}\x03\x02\x02\
	\x02\u{14c}\u{7eb}\x03\x02\x02\x02\u{14e}\u{7ef}\x03\x02\x02\x02\u{150}\
	\u{7f5}\x03\x02\x02\x02\u{152}\u{809}\x03\x02\x02\x02\u{154}\u{811}\x03\
	\x02\x02\x02\u{156}\u{815}\x03\x02\x02\x02\u{158}\u{81e}\x03\x02\x02\x02\
	\u{15a}\u{829}\x03\x02\x02\x02\u{15c}\u{830}\x03\x02\x02\x02\u{15e}\u{833}\
	\x03\x02\x02\x02\u{160}\u{83b}\x03\x02\x02\x02\u{162}\u{847}\x03\x02\x02\
	\x02\u{164}\u{84c}\x03\x02\x02\x02\u{166}\u{85e}\x03\x02\x02\x02\u{168}\
	\u{860}\x03\x02\x02\x02\u{16a}\u{86b}\x03\x02\x02\x02\u{16c}\u{86d}\x03\
	\x02\x02\x02\u{16e}\u{874}\x03\x02\x02\x02\u{170}\u{877}\x03\x02\x02\x02\
	\u{172}\u{87d}\x03\x02\x02\x02\u{174}\u{883}\x03\x02\x02\x02\u{176}\u{88a}\
	\x03\x02\x02\x02\u{178}\u{890}\x03\x02\x02\x02\u{17a}\u{894}\x03\x02\x02\
	\x02\u{17c}\u{89f}\x03\x02\x02\x02\u{17e}\u{8a3}\x03\x02\x02\x02\u{180}\
	\u{8a5}\x03\x02\x02\x02\u{182}\u{8ac}\x03\x02\x02\x02\u{184}\u{8af}\x03\
	\x02\x02\x02\u{186}\u{8b6}\x03\x02\x02\x02\u{188}\u{8be}\x03\x02\x02\x02\
	\u{18a}\u{8c0}\x03\x02\x02\x02\u{18c}\u{8c4}\x03\x02\x02\x02\u{18e}\u{8d1}\
	\x03\x02\x02\x02\u{190}\u{8d9}\x03\x02\x02\x02\u{192}\u{8dd}\x03\x02\x02\
	\x02\u{194}\u{8e2}\x03\x02\x02\x02\u{196}\u{8e9}\x03\x02\x02\x02\u{198}\
	\u{8ec}\x03\x02\x02\x02\u{19a}\u{8f3}\x03\x02\x02\x02\u{19c}\u{8f8}\x03\
	\x02\x02\x02\u{19e}\u{8fa}\x03\x02\x02\x02\u{1a0}\u{903}\x03\x02\x02\x02\
	\u{1a2}\u{907}\x03\x02\x02\x02\u{1a4}\u{909}\x03\x02\x02\x02\u{1a6}\u{90e}\
	\x03\x02\x02\x02\u{1a8}\u{915}\x03\x02\x02\x02\u{1aa}\u{91a}\x03\x02\x02\
	\x02\u{1ac}\u{91c}\x03\x02\x02\x02\u{1ae}\u{925}\x03\x02\x02\x02\u{1b0}\
	\u{927}\x03\x02\x02\x02\u{1b2}\u{92a}\x03\x02\x02\x02\u{1b4}\u{92e}\x03\
	\x02\x02\x02\u{1b6}\u{933}\x03\x02\x02\x02\u{1b8}\u{93b}\x03\x02\x02\x02\
	\u{1ba}\u{943}\x03\x02\x02\x02\u{1bc}\u{947}\x03\x02\x02\x02\u{1be}\u{94e}\
	\x03\x02\x02\x02\u{1c0}\u{953}\x03\x02\x02\x02\u{1c2}\u{955}\x03\x02\x02\
	\x02\u{1c4}\u{965}\x03\x02\x02\x02\u{1c6}\u{967}\x03\x02\x02\x02\u{1c8}\
	\u{96e}\x03\x02\x02\x02\u{1ca}\u{977}\x03\x02\x02\x02\u{1cc}\u{979}\x03\
	\x02\x02\x02\u{1ce}\u{97d}\x03\x02\x02\x02\u{1d0}\u{981}\x03\x02\x02\x02\
	\u{1d2}\u{985}\x03\x02\x02\x02\u{1d4}\u{990}\x03\x02\x02\x02\u{1d6}\u{992}\
	\x03\x02\x02\x02\u{1d8}\u{99b}\x03\x02\x02\x02\u{1da}\u{99d}\x03\x02\x02\
	\x02\u{1dc}\u{9a0}\x03\x02\x02\x02\u{1de}\u{9a4}\x03\x02\x02\x02\u{1e0}\
	\u{9ac}\x03\x02\x02\x02\u{1e2}\u{9ae}\x03\x02\x02\x02\u{1e4}\u{9b0}\x03\
	\x02\x02\x02\u{1e6}\u{9b2}\x03\x02\x02\x02\u{1e8}\u{9b7}\x03\x02\x02\x02\
	\u{1ea}\u{9b9}\x03\x02\x02\x02\u{1ec}\u{9bf}\x03\x02\x02\x02\u{1ee}\u{9c1}\
	\x03\x02\x02\x02\u{1f0}\u{9c5}\x03\x02\x02\x02\u{1f2}\u{9dd}\x03\x02\x02\
	\x02\u{1f4}\u{9ed}\x03\x02\x02\x02\u{1f6}\u{9f1}\x03\x02\x02\x02\u{1f8}\
	\u{a06}\x03\x02\x02\x02\u{1fa}\u{a17}\x03\x02\x02\x02\u{1fc}\u{a1e}\x03\
	\x02\x02\x02\u{1fe}\u{a26}\x03\x02\x02\x02\u{200}\u{a2b}\x03\x02\x02\x02\
	\u{202}\u{a30}\x03\x02\x02\x02\u{204}\u{a35}\x03\x02\x02\x02\u{206}\u{a37}\
	\x03\x02\x02\x02\u{208}\u{a39}\x03\x02\x02\x02\u{20a}\u{a3b}\x03\x02\x02\
	\x02\u{20c}\u{a3d}\x03\x02\x02\x02\u{20e}\u{a3f}\x03\x02\x02\x02\u{210}\
	\u{a43}\x03\x02\x02\x02\u{212}\u{a45}\x03\x02\x02\x02\u{214}\u{a47}\x03\
	\x02\x02\x02\u{216}\u{a49}\x03\x02\x02\x02\u{218}\u{a4b}\x03\x02\x02\x02\
	\u{21a}\u{a51}\x03\x02\x02\x02\u{21c}\u{a56}\x03\x02\x02\x02\u{21e}\u{a5c}\
	\x03\x02\x02\x02\u{220}\u{a61}\x03\x02\x02\x02\u{222}\u{a64}\x03\x02\x02\
	\x02\u{224}\u{a70}\x03\x02\x02\x02\u{226}\u{a77}\x03\x02\x02\x02\u{228}\
	\u{a7b}\x03\x02\x02\x02\u{22a}\u{a88}\x03\x02\x02\x02\u{22c}\u{a91}\x03\
	\x02\x02\x02\u{22e}\u{a98}\x03\x02\x02\x02\u{230}\u{a9c}\x03\x02\x02\x02\
	\u{232}\u{a9e}\x03\x02\x02\x02\u{234}\u{aa0}\x03\x02\x02\x02\u{236}\u{aa2}\
	\x03\x02\x02\x02\u{238}\u{aa4}\x03\x02\x02\x02\u{23a}\u{aa6}\x03\x02\x02\
	\x02\u{23c}\u{aa8}\x03\x02\x02\x02\u{23e}\u{aaa}\x03\x02\x02\x02\u{240}\
	\u{aac}\x03\x02\x02\x02\u{242}\u{aae}\x03\x02\x02\x02\u{244}\u{ab0}\x03\
	\x02\x02\x02\u{246}\u{ab3}\x03\x02\x02\x02\u{248}\u{ab6}\x03\x02\x02\x02\
	\u{24a}\u{abd}\x03\x02\x02\x02\u{24c}\u{acd}\x03\x02\x02\x02\u{24e}\u{acf}\
	\x03\x02\x02\x02\u{250}\u{adc}\x03\x02\x02\x02\u{252}\u{ae0}\x03\x02\x02\
	\x02\u{254}\u{aed}\x03\x02\x02\x02\u{256}\u{aef}\x03\x02\x02\x02\u{258}\
	\u{af1}\x03\x02\x02\x02\u{25a}\u{af3}\x03\x02\x02\x02\u{25c}\u{af5}\x03\
	\x02\x02\x02\u{25e}\u{afc}\x03\x02\x02\x02\u{260}\u{aff}\x03\x02\x02\x02\
	\u{262}\u{b04}\x03\x02\x02\x02\u{264}\u{265}\x05\x04\x03\x02\u{265}\x03\
	\x03\x02\x02\x02\u{266}\u{26b}\x05\x06\x04\x02\u{267}\u{268}\x07\x24\x02\
	\x02\u{268}\u{26a}\x05\x06\x04\x02\u{269}\u{267}\x03\x02\x02\x02\u{26a}\
	\u{26d}\x03\x02\x02\x02\u{26b}\u{269}\x03\x02\x02\x02\u{26b}\u{26c}\x03\
	\x02\x02\x02\u{26c}\u{26f}\x03\x02\x02\x02\u{26d}\u{26b}\x03\x02\x02\x02\
	\u{26e}\u{270}\x07\x24\x02\x02\u{26f}\u{26e}\x03\x02\x02\x02\u{26f}\u{270}\
	\x03\x02\x02\x02\u{270}\u{271}\x03\x02\x02\x02\u{271}\u{272}\x07\x02\x02\
	\x03\u{272}\x05\x03\x02\x02\x02\u{273}\u{27b}\x05\x08\x05\x02\u{274}\u{27b}\
	\x05\x2a\x16\x02\u{275}\u{27b}\x05\x46\x24\x02\u{276}\u{27b}\x05\x0a\x06\
	\x02\u{277}\u{27b}\x05\x4a\x26\x02\u{278}\u{27b}\x05\x3e\x20\x02\u{279}\
	\u{27b}\x05\x42\x22\x02\u{27a}\u{273}\x03\x02\x02\x02\u{27a}\u{274}\x03\
	\x02\x02\x02\u{27a}\u{275}\x03\x02\x02\x02\u{27a}\u{276}\x03\x02\x02\x02\
	\u{27a}\u{277}\x03\x02\x02\x02\u{27a}\u{278}\x03\x02\x02\x02\u{27a}\u{279}\
	\x03\x02\x02\x02\u{27b}\x07\x03\x02\x02\x02\u{27c}\u{27d}\x07\x2b\x02\x02\
	\u{27d}\u{27e}\x07\x47\x02\x02\u{27e}\u{27f}\x05\u{21c}\u{10f}\x02\u{27f}\
	\u{280}\x07\x13\x02\x02\u{280}\u{281}\x05\u{17e}\u{c0}\x02\u{281}\x09\x03\
	\x02\x02\x02\u{282}\u{288}\x05\x0e\x08\x02\u{283}\u{288}\x05\x10\x09\x02\
	\u{284}\u{288}\x05\x0c\x07\x02\u{285}\u{288}\x05\x14\x0b\x02\u{286}\u{288}\
	\x05\x16\x0c\x02\u{287}\u{282}\x03\x02\x02\x02\u{287}\u{283}\x03\x02\x02\
	\x02\u{287}\u{284}\x03\x02\x02\x02\u{287}\u{285}\x03\x02\x02\x02\u{287}\
	\u{286}\x03\x02\x02\x02\u{288}\x0b\x03\x02\x02\x02\u{289}\u{28a}\x07\u{8f}\
	\x02\x02\u{28a}\u{28b}\x05\u{21c}\u{10f}\x02\u{28b}\u{28c}\x07\x13\x02\x02\
	\u{28c}\u{28d}\x05\x4c\x27\x02\u{28d}\x0d\x03\x02\x02\x02\u{28e}\u{28f}\
	\x07\u{8f}\x02\x02\u{28f}\u{290}\x05\u{21c}\u{10f}\x02\u{290}\u{291}\x07\
	\x13\x02\x02\u{291}\u{293}\x07\x21\x02\x02\u{292}\u{294}\x05\x18\x0d\x02\
	\u{293}\u{292}\x03\x02\x02\x02\u{293}\u{294}\x03\x02\x02\x02\u{294}\u{295}\
	\x03\x02\x02\x02\u{295}\u{296}\x07\x0a\x02\x02\u{296}\u{297}\x05\x26\x14\
	\x02\u{297}\x0f\x03\x02\x02\x02\u{298}\u{299}\x07\u{8f}\x02\x02\u{299}\u{29a}\
	\x05\u{21c}\u{10f}\x02\u{29a}\u{29b}\x07\x13\x02\x02\u{29b}\u{29c}\x07\u{103}\
	\x02\x02\u{29c}\u{29e}\x07\x21\x02\x02\u{29d}\u{29f}\x05\x12\x0a\x02\u{29e}\
	\u{29d}\x03\x02\x02\x02\u{29e}\u{29f}\x03\x02\x02\x02\u{29f}\u{2a0}\x03\
	\x02\x02\x02\u{2a0}\u{2a1}\x07\x0a\x02\x02\u{2a1}\u{2a2}\x05\x26\x14\x02\
	\u{2a2}\x11\x03\x02\x02\x02\u{2a3}\u{2a8}\x05\x1a\x0e\x02\u{2a4}\u{2a5}\
	\x07\x0b\x02\x02\u{2a5}\u{2a7}\x05\x1a\x0e\x02\u{2a6}\u{2a4}\x03\x02\x02\
	\x02\u{2a7}\u{2aa}\x03\x02\x02\x02\u{2a8}\u{2a6}\x03\x02\x02\x02\u{2a8}\
	\u{2a9}\x03\x02\x02\x02\u{2a9}\x13\x03\x02\x02\x02\u{2aa}\u{2a8}\x03\x02\
	\x02\x02\u{2ab}\u{2ac}\x07\u{8f}\x02\x02\u{2ac}\u{2ad}\x05\u{21c}\u{10f}\
	\x02\u{2ad}\u{2ae}\x07\x13\x02\x02\u{2ae}\u{2af}\x07\u{9d}\x02\x02\u{2af}\
	\u{2b0}\x07\x21\x02\x02\u{2b0}\u{2b1}\x05\x4e\x28\x02\u{2b1}\u{2b2}\x07\
	\x0a\x02\x02\u{2b2}\x15\x03\x02\x02\x02\u{2b3}\u{2b4}\x07\u{8f}\x02\x02\
	\u{2b4}\u{2b5}\x05\u{21c}\u{10f}\x02\u{2b5}\u{2b6}\x07\x13\x02\x02\u{2b6}\
	\u{2b7}\x05\u{cc}\x67\x02\u{2b7}\x17\x03\x02\x02\x02\u{2b8}\u{2b9}\x05\x1e\
	\x10\x02\u{2b9}\u{2ba}\x07\x0b\x02\x02\u{2ba}\u{2bb}\x05\x1e\x10\x02\u{2bb}\
	\u{2bc}\x03\x02\x02\x02\u{2bc}\u{2bd}\x07\x0b\x02\x02\u{2bd}\u{2be}\x05\
	\x1a\x0e\x02\u{2be}\u{2c4}\x03\x02\x02\x02\u{2bf}\u{2c0}\x05\x1a\x0e\x02\
	\u{2c0}\u{2c1}\x07\x0b\x02\x02\u{2c1}\u{2c2}\x05\x1a\x0e\x02\u{2c2}\u{2c4}\
	\x03\x02\x02\x02\u{2c3}\u{2b8}\x03\x02\x02\x02\u{2c3}\u{2bf}\x03\x02\x02\
	\x02\u{2c4}\x19\x03\x02\x02\x02\u{2c5}\u{2c6}\x05\u{208}\u{105}\x02\u{2c6}\
	\u{2c7}\x07\x0c\x02\x02\u{2c7}\u{2c9}\x05\u{204}\u{103}\x02\u{2c8}\u{2ca}\
	\x05\x1c\x0f\x02\u{2c9}\u{2c8}\x03\x02\x02\x02\u{2c9}\u{2ca}\x03\x02\x02\
	\x02\u{2ca}\x1b\x03\x02\x02\x02\u{2cb}\u{2cc}\x07\x13\x02\x02\u{2cc}\u{2cd}\
	\x05\u{228}\u{115}\x02\u{2cd}\x1d\x03\x02\x02\x02\u{2ce}\u{2cf}\x05\u{208}\
	\u{105}\x02\u{2cf}\u{2d2}\x07\x0c\x02\x02\u{2d0}\u{2d3}\x05\x20\x11\x02\
	\u{2d1}\u{2d3}\x05\x22\x12\x02\u{2d2}\u{2d0}\x03\x02\x02\x02\u{2d2}\u{2d1}\
	\x03\x02\x02\x02\u{2d3}\x1f\x03\x02\x02\x02\u{2d4}\u{2d5}\x07\x21\x02\x02\
	\u{2d5}\u{2d6}\x07\x03\x02\x02\u{2d6}\u{2d7}\x07\x0a\x02\x02\u{2d7}\x21\
	\x03\x02\x02\x02\u{2d8}\u{2d9}\x07\x21\x02\x02\u{2d9}\u{2de}\x05\x24\x13\
	\x02\u{2da}\u{2db}\x07\x0b\x02\x02\u{2db}\u{2dd}\x05\x24\x13\x02\u{2dc}\
	\u{2da}\x03\x02\x02\x02\u{2dd}\u{2e0}\x03\x02\x02\x02\u{2de}\u{2dc}\x03\
	\x02\x02\x02\u{2de}\u{2df}\x03\x02\x02\x02\u{2df}\u{2e1}\x03\x02\x02\x02\
	\u{2e0}\u{2de}\x03\x02\x02\x02\u{2e1}\u{2e2}\x07\x0a\x02\x02\u{2e2}\x23\
	\x03\x02\x02\x02\u{2e3}\u{2e4}\x05\u{208}\u{105}\x02\u{2e4}\u{2e5}\x07\x0c\
	\x02\x02\u{2e5}\u{2e6}\x05\u{204}\u{103}\x02\u{2e6}\x25\x03\x02\x02\x02\
	\u{2e7}\u{2ed}\x07\x1f\x02\x02\u{2e8}\u{2e9}\x05\x28\x15\x02\u{2e9}\u{2ea}\
	\x07\x24\x02\x02\u{2ea}\u{2ec}\x03\x02\x02\x02\u{2eb}\u{2e8}\x03\x02\x02\
	\x02\u{2ec}\u{2ef}\x03\x02\x02\x02\u{2ed}\u{2eb}\x03\x02\x02\x02\u{2ed}\
	\u{2ee}\x03\x02\x02\x02\u{2ee}\u{2f1}\x03\x02\x02\x02\u{2ef}\u{2ed}\x03\
	\x02\x02\x02\u{2f0}\u{2f2}\x05\x4c\x27\x02\u{2f1}\u{2f0}\x03\x02\x02\x02\
	\u{2f1}\u{2f2}\x03\x02\x02\x02\u{2f2}\u{2f4}\x03\x02\x02\x02\u{2f3}\u{2f5}\
	\x07\x24\x02\x02\u{2f4}\u{2f3}\x03\x02\x02\x02\u{2f4}\u{2f5}\x03\x02\x02\
	\x02\u{2f5}\u{2f6}\x03\x02\x02\x02\u{2f6}\u{2f7}\x07\x06\x02\x02\u{2f7}\
	\x27\x03\x02\x02\x02\u{2f8}\u{2fb}\x05\x0a\x06\x02\u{2f9}\u{2fb}\x05\x46\
	\x24\x02\u{2fa}\u{2f8}\x03\x02\x02\x02\u{2fa}\u{2f9}\x03\x02\x02\x02\u{2fb}\
	\x29\x03\x02\x02\x02\u{2fc}\u{2fd}\x07\x4a\x02\x02\u{2fd}\u{2fe}\x07\u{ca}\
	\x02\x02\u{2fe}\u{300}\x05\u{20a}\u{106}\x02\u{2ff}\u{301}\x05\x2c\x17\x02\
	\u{300}\u{2ff}\x03\x02\x02\x02\u{300}\u{301}\x03\x02\x02\x02\u{301}\x2b\
	\x03\x02\x02\x02\u{302}\u{303}\x07\x13\x02\x02\u{303}\u{305}\x05\x2e\x18\
	\x02\u{304}\u{306}\x05\x32\x1a\x02\u{305}\u{304}\x03\x02\x02\x02\u{305}\
	\u{306}\x03\x02\x02\x02\u{306}\u{307}\x03\x02\x02\x02\u{307}\u{309}\x07\
	\x1f\x02\x02\u{308}\u{30a}\x05\x34\x1b\x02\u{309}\u{308}\x03\x02\x02\x02\
	\u{30a}\u{30b}\x03\x02\x02\x02\u{30b}\u{309}\x03\x02\x02\x02\u{30b}\u{30c}\
	\x03\x02\x02\x02\u{30c}\u{30d}\x03\x02\x02\x02\u{30d}\u{30e}\x07\x06\x02\
	\x02\u{30e}\x2d\x03\x02\x02\x02\u{30f}\u{310}\x07\x21\x02\x02\u{310}\u{315}\
	\x05\x30\x19\x02\u{311}\u{312}\x07\x0b\x02\x02\u{312}\u{314}\x05\x30\x19\
	\x02\u{313}\u{311}\x03\x02\x02\x02\u{314}\u{317}\x03\x02\x02\x02\u{315}\
	\u{313}\x03\x02\x02\x02\u{315}\u{316}\x03\x02\x02\x02\u{316}\u{318}\x03\
	\x02\x02\x02\u{317}\u{315}\x03\x02\x02\x02\u{318}\u{319}\x07\x0a\x02\x02\
	\u{319}\x2f\x03\x02\x02\x02\u{31a}\u{31b}\x05\u{208}\u{105}\x02\u{31b}\u{31c}\
	\x07\x0c\x02\x02\u{31c}\u{31d}\x05\u{204}\u{103}\x02\u{31d}\x31\x03\x02\
	\x02\x02\u{31e}\u{31f}\x07\x20\x02\x02\u{31f}\u{320}\x05\x30\x19\x02\u{320}\
	\u{321}\x07\x07\x02\x02\u{321}\x33\x03\x02\x02\x02\u{322}\u{324}\x05\x36\
	\x1c\x02\u{323}\u{325}\x05\x38\x1d\x02\u{324}\u{323}\x03\x02\x02\x02\u{324}\
	\u{325}\x03\x02\x02\x02\u{325}\u{326}\x03\x02\x02\x02\u{326}\u{327}\x07\
	\x13\x02\x02\u{327}\u{329}\x05\x3c\x1f\x02\u{328}\u{32a}\x07\x24\x02\x02\
	\u{329}\u{328}\x03\x02\x02\x02\u{329}\u{32a}\x03\x02\x02\x02\u{32a}\x35\
	\x03\x02\x02\x02\u{32b}\u{32c}\x07\x21\x02\x02\u{32c}\u{331}\x05\x3a\x1e\
	\x02\u{32d}\u{32e}\x07\x0b\x02\x02\u{32e}\u{330}\x05\x3a\x1e\x02\u{32f}\
	\u{32d}\x03\x02\x02\x02\u{330}\u{333}\x03\x02\x02\x02\u{331}\u{32f}\x03\
	\x02\x02\x02\u{331}\u{332}\x03\x02\x02\x02\u{332}\u{334}\x03\x02\x02\x02\
	\u{333}\u{331}\x03\x02\x02\x02\u{334}\u{335}\x07\x0a\x02\x02\u{335}\x37\
	\x03\x02\x02\x02\u{336}\u{337}\x07\x11\x02\x02\u{337}\u{338}\x07\x20\x02\
	\x02\u{338}\u{339}\x05\x3a\x1e\x02\u{339}\u{33a}\x07\x07\x02\x02\u{33a}\
	\x39\x03\x02\x02\x02\u{33b}\u{33c}\x05\u{248}\u{125}\x02\u{33c}\x3b\x03\
	\x02\x02\x02\u{33d}\u{343}\x07\x1f\x02\x02\u{33e}\u{33f}\x05\x28\x15\x02\
	\u{33f}\u{340}\x07\x24\x02\x02\u{340}\u{342}\x03\x02\x02\x02\u{341}\u{33e}\
	\x03\x02\x02\x02\u{342}\u{345}\x03\x02\x02\x02\u{343}\u{341}\x03\x02\x02\
	\x02\u{343}\u{344}\x03\x02\x02\x02\u{344}\u{346}\x03\x02\x02\x02\u{345}\
	\u{343}\x03\x02\x02\x02\u{346}\u{347}\x05\x4c\x27\x02\u{347}\u{348}\x07\
	\x06\x02\x02\u{348}\x3d\x03\x02\x02\x02\u{349}\u{34a}\x07\u{de}\x02\x02\
	\u{34a}\u{34b}\x07\x28\x02\x02\u{34b}\u{34c}\x07\u{f8}\x02\x02\u{34c}\u{34d}\
	\x07\x21\x02\x02\u{34d}\u{352}\x05\x40\x21\x02\u{34e}\u{34f}\x07\x0b\x02\
	\x02\u{34f}\u{351}\x05\x40\x21\x02\u{350}\u{34e}\x03\x02\x02\x02\u{351}\
	\u{354}\x03\x02\x02\x02\u{352}\u{350}\x03\x02\x02\x02\u{352}\u{353}\x03\
	\x02\x02\x02\u{353}\u{355}\x03\x02\x02\x02\u{354}\u{352}\x03\x02\x02\x02\
	\u{355}\u{356}\x07\x0a\x02\x02\u{356}\x3f\x03\x02\x02\x02\u{357}\u{35a}\
	\x05\u{20a}\u{106}\x02\u{358}\u{35a}\x05\u{1e8}\u{f5}\x02\u{359}\u{357}\
	\x03\x02\x02\x02\u{359}\u{358}\x03\x02\x02\x02\u{35a}\x41\x03\x02\x02\x02\
	\u{35b}\u{35c}\x07\u{e6}\x02\x02\u{35c}\u{35f}\x05\u{21a}\u{10e}\x02\u{35d}\
	\u{35e}\x07\x13\x02\x02\u{35e}\u{360}\x05\x44\x23\x02\u{35f}\u{35d}\x03\
	\x02\x02\x02\u{35f}\u{360}\x03\x02\x02\x02\u{360}\x43\x03\x02\x02\x02\u{361}\
	\u{364}\x05\u{21a}\u{10e}\x02\u{362}\u{364}\x05\u{228}\u{115}\x02\u{363}\
	\u{361}\x03\x02\x02\x02\u{363}\u{362}\x03\x02\x02\x02\u{364}\x45\x03\x02\
	\x02\x02\u{365}\u{366}\x07\x4a\x02\x02\u{366}\u{367}\x07\u{d7}\x02\x02\u{367}\
	\u{368}\x07\x21\x02\x02\u{368}\u{36d}\x05\x48\x25\x02\u{369}\u{36a}\x07\
	\x0b\x02\x02\u{36a}\u{36c}\x05\x48\x25\x02\u{36b}\u{369}\x03\x02\x02\x02\
	\u{36c}\u{36f}\x03\x02\x02\x02\u{36d}\u{36b}\x03\x02\x02\x02\u{36d}\u{36e}\
	\x03\x02\x02\x02\u{36e}\u{370}\x03\x02\x02\x02\u{36f}\u{36d}\x03\x02\x02\
	\x02\u{370}\u{371}\x07\x0a\x02\x02\u{371}\x47\x03\x02\x02\x02\u{372}\u{373}\
	\x05\u{208}\u{105}\x02\u{373}\u{374}\x07\x0c\x02\x02\u{374}\u{376}\x05\u{204}\
	\u{103}\x02\u{375}\u{377}\x05\x1c\x0f\x02\u{376}\u{375}\x03\x02\x02\x02\
	\u{376}\u{377}\x03\x02\x02\x02\u{377}\x49\x03\x02\x02\x02\u{378}\u{379}\
	\x05\x4c\x27\x02\u{379}\x4b\x03\x02\x02\x02\u{37a}\u{37b}\x05\x4e\x28\x02\
	\u{37b}\x4d\x03\x02\x02\x02\u{37c}\u{380}\x05\x54\x2b\x02\u{37d}\u{37f}\
	\x05\x50\x29\x02\u{37e}\u{37d}\x03\x02\x02\x02\u{37f}\u{382}\x03\x02\x02\
	\x02\u{380}\u{37e}\x03\x02\x02\x02\u{380}\u{381}\x03\x02\x02\x02\u{381}\
	\x4f\x03\x02\x02\x02\u{382}\u{380}\x03\x02\x02\x02\u{383}\u{384}\x07\x05\
	\x02\x02\u{384}\u{385}\x05\x56\x2c\x02\u{385}\x51\x03\x02\x02\x02\u{386}\
	\u{38a}\x05\x56\x2c\x02\u{387}\u{389}\x05\x50\x29\x02\u{388}\u{387}\x03\
	\x02\x02\x02\u{389}\u{38c}\x03\x02\x02\x02\u{38a}\u{388}\x03\x02\x02\x02\
	\u{38a}\u{38b}\x03\x02\x02\x02\u{38b}\x53\x03\x02\x02\x02\u{38c}\u{38a}\
	\x03\x02\x02\x02\u{38d}\u{394}\x05\x58\x2d\x02\u{38e}\u{394}\x05\u{110}\
	\u{89}\x02\u{38f}\u{394}\x05\u{c8}\x65\x02\u{390}\u{394}\x05\u{1d2}\u{ea}\
	\x02\u{391}\u{394}\x05\u{17c}\u{bf}\x02\u{392}\u{394}\x05\u{17e}\u{c0}\x02\
	\u{393}\u{38d}\x03\x02\x02\x02\u{393}\u{38e}\x03\x02\x02\x02\u{393}\u{38f}\
	\x03\x02\x02\x02\u{393}\u{390}\x03\x02\x02\x02\u{393}\u{391}\x03\x02\x02\
	\x02\u{393}\u{392}\x03\x02\x02\x02\u{394}\x55\x03\x02\x02\x02\u{395}\u{3c7}\
	\x05\x5c\x2f\x02\u{396}\u{3c7}\x05\x5e\x30\x02\u{397}\u{3c7}\x05\x60\x31\
	\x02\u{398}\u{3c7}\x05\x62\x32\x02\u{399}\u{3c7}\x05\x66\x34\x02\u{39a}\
	\u{3c7}\x05\x72\x3a\x02\u{39b}\u{3c7}\x05\x70\x39\x02\u{39c}\u{3c7}\x05\
	\x74\x3b\x02\u{39d}\u{3c7}\x05\x7a\x3e\x02\u{39e}\u{3c7}\x05\u{96}\x4c\x02\
	\u{39f}\u{3c7}\x05\u{a0}\x51\x02\u{3a0}\u{3c7}\x05\u{a2}\x52\x02\u{3a1}\
	\u{3c7}\x05\u{a4}\x53\x02\u{3a2}\u{3c7}\x05\u{b4}\x5b\x02\u{3a3}\u{3c7}\
	\x05\u{bc}\x5f\x02\u{3a4}\u{3c7}\x05\u{b6}\x5c\x02\u{3a5}\u{3c7}\x05\u{be}\
	\x60\x02\u{3a6}\u{3c7}\x05\u{c0}\x61\x02\u{3a7}\u{3c7}\x05\u{c6}\x64\x02\
	\u{3a8}\u{3c7}\x05\u{ce}\x68\x02\u{3a9}\u{3c7}\x05\u{d6}\x6c\x02\u{3aa}\
	\u{3c7}\x05\u{ee}\x78\x02\u{3ab}\u{3c7}\x05\u{e4}\x73\x02\u{3ac}\u{3c7}\
	\x05\x6c\x37\x02\u{3ad}\u{3c7}\x05\u{f2}\x7a\x02\u{3ae}\u{3c7}\x05\u{100}\
	\u{81}\x02\u{3af}\u{3c7}\x05\u{fe}\u{80}\x02\u{3b0}\u{3c7}\x05\u{104}\u{83}\
	\x02\u{3b1}\u{3c7}\x05\u{10c}\u{87}\x02\u{3b2}\u{3c7}\x05\u{116}\u{8c}\x02\
	\u{3b3}\u{3c7}\x05\u{112}\u{8a}\x02\u{3b4}\u{3c7}\x05\u{118}\u{8d}\x02\u{3b5}\
	\u{3c7}\x05\u{11a}\u{8e}\x02\u{3b6}\u{3c7}\x05\u{114}\u{8b}\x02\u{3b7}\u{3c7}\
	\x05\u{11e}\u{90}\x02\u{3b8}\u{3c7}\x05\u{122}\u{92}\x02\u{3b9}\u{3c7}\x05\
	\u{130}\u{99}\x02\u{3ba}\u{3c7}\x05\u{12e}\u{98}\x02\u{3bb}\u{3c7}\x05\u{132}\
	\u{9a}\x02\u{3bc}\u{3c7}\x05\u{142}\u{a2}\x02\u{3bd}\u{3c7}\x05\u{148}\u{a5}\
	\x02\u{3be}\u{3c7}\x05\u{14a}\u{a6}\x02\u{3bf}\u{3c7}\x05\u{150}\u{a9}\x02\
	\u{3c0}\u{3c7}\x05\u{156}\u{ac}\x02\u{3c1}\u{3c7}\x05\u{15a}\u{ae}\x02\u{3c2}\
	\u{3c7}\x05\u{158}\u{ad}\x02\u{3c3}\u{3c7}\x05\u{15e}\u{b0}\x02\u{3c4}\u{3c7}\
	\x05\u{164}\u{b3}\x02\u{3c5}\u{3c7}\x05\u{168}\u{b5}\x02\u{3c6}\u{395}\x03\
	\x02\x02\x02\u{3c6}\u{396}\x03\x02\x02\x02\u{3c6}\u{397}\x03\x02\x02\x02\
	\u{3c6}\u{398}\x03\x02\x02\x02\u{3c6}\u{399}\x03\x02\x02\x02\u{3c6}\u{39a}\
	\x03\x02\x02\x02\u{3c6}\u{39b}\x03\x02\x02\x02\u{3c6}\u{39c}\x03\x02\x02\
	\x02\u{3c6}\u{39d}\x03\x02\x02\x02\u{3c6}\u{39e}\x03\x02\x02\x02\u{3c6}\
	\u{39f}\x03\x02\x02\x02\u{3c6}\u{3a0}\x03\x02\x02\x02\u{3c6}\u{3a1}\x03\
	\x02\x02\x02\u{3c6}\u{3a2}\x03\x02\x02\x02\u{3c6}\u{3a3}\x03\x02\x02\x02\
	\u{3c6}\u{3a4}\x03\x02\x02\x02\u{3c6}\u{3a5}\x03\x02\x02\x02\u{3c6}\u{3a6}\
	\x03\x02\x02\x02\u{3c6}\u{3a7}\x03\x02\x02\x02\u{3c6}\u{3a8}\x03\x02\x02\
	\x02\u{3c6}\u{3a9}\x03\x02\x02\x02\u{3c6}\u{3aa}\x03\x02\x02\x02\u{3c6}\
	\u{3ab}\x03\x02\x02\x02\u{3c6}\u{3ac}\x03\x02\x02\x02\u{3c6}\u{3ad}\x03\
	\x02\x02\x02\u{3c6}\u{3ae}\x03\x02\x02\x02\u{3c6}\u{3af}\x03\x02\x02\x02\
	\u{3c6}\u{3b0}\x03\x02\x02\x02\u{3c6}\u{3b1}\x03\x02\x02\x02\u{3c6}\u{3b2}\
	\x03\x02\x02\x02\u{3c6}\u{3b3}\x03\x02\x02\x02\u{3c6}\u{3b4}\x03\x02\x02\
	\x02\u{3c6}\u{3b5}\x03\x02\x02\x02\u{3c6}\u{3b6}\x03\x02\x02\x02\u{3c6}\
	\u{3b7}\x03\x02\x02\x02\u{3c6}\u{3b8}\x03\x02\x02\x02\u{3c6}\u{3b9}\x03\
	\x02\x02\x02\u{3c6}\u{3ba}\x03\x02\x02\x02\u{3c6}\u{3bb}\x03\x02\x02\x02\
	\u{3c6}\u{3bc}\x03\x02\x02\x02\u{3c6}\u{3bd}\x03\x02\x02\x02\u{3c6}\u{3be}\
	\x03\x02\x02\x02\u{3c6}\u{3bf}\x03\x02\x02\x02\u{3c6}\u{3c0}\x03\x02\x02\
	\x02\u{3c6}\u{3c1}\x03\x02\x02\x02\u{3c6}\u{3c2}\x03\x02\x02\x02\u{3c6}\
	\u{3c3}\x03\x02\x02\x02\u{3c6}\u{3c4}\x03\x02\x02\x02\u{3c6}\u{3c5}\x03\
	\x02\x02\x02\u{3c7}\x57\x03\x02\x02\x02\u{3c8}\u{3cd}\x05\x7a\x3e\x02\u{3c9}\
	\u{3cd}\x05\u{142}\u{a2}\x02\u{3ca}\u{3cd}\x05\u{164}\u{b3}\x02\u{3cb}\u{3cd}\
	\x05\x6c\x37\x02\u{3cc}\u{3c8}\x03\x02\x02\x02\u{3cc}\u{3c9}\x03\x02\x02\
	\x02\u{3cc}\u{3ca}\x03\x02\x02\x02\u{3cc}\u{3cb}\x03\x02\x02\x02\u{3cd}\
	\x59\x03\x02\x02\x02\u{3ce}\u{3e8}\x05\x62\x32\x02\u{3cf}\u{3e8}\x05\x70\
	\x39\x02\u{3d0}\u{3e8}\x05\u{168}\u{b5}\x02\u{3d1}\u{3e8}\x05\u{f2}\x7a\
	\x02\u{3d2}\u{3e8}\x05\u{fe}\u{80}\x02\u{3d3}\u{3e8}\x05\u{156}\u{ac}\x02\
	\u{3d4}\u{3e8}\x05\u{15e}\u{b0}\x02\u{3d5}\u{3e8}\x05\u{116}\u{8c}\x02\u{3d6}\
	\u{3e8}\x05\u{112}\u{8a}\x02\u{3d7}\u{3e8}\x05\u{118}\u{8d}\x02\u{3d8}\u{3e8}\
	\x05\u{11a}\u{8e}\x02\u{3d9}\u{3e8}\x05\u{114}\u{8b}\x02\u{3da}\u{3e8}\x05\
	\u{150}\u{a9}\x02\u{3db}\u{3e8}\x05\x66\x34\x02\u{3dc}\u{3e8}\x05\u{15a}\
	\u{ae}\x02\u{3dd}\u{3e8}\x05\u{158}\u{ad}\x02\u{3de}\u{3e8}\x05\u{14a}\u{a6}\
	\x02\u{3df}\u{3e8}\x05\u{ee}\x78\x02\u{3e0}\u{3e8}\x05\u{11e}\u{90}\x02\
	\u{3e1}\u{3e8}\x05\u{130}\u{99}\x02\u{3e2}\u{3e8}\x05\u{12e}\u{98}\x02\u{3e3}\
	\u{3e8}\x05\x5c\x2f\x02\u{3e4}\u{3e8}\x05\u{be}\x60\x02\u{3e5}\u{3e8}\x05\
	\x72\x3a\x02\u{3e6}\u{3e8}\x05\u{132}\u{9a}\x02\u{3e7}\u{3ce}\x03\x02\x02\
	\x02\u{3e7}\u{3cf}\x03\x02\x02\x02\u{3e7}\u{3d0}\x03\x02\x02\x02\u{3e7}\
	\u{3d1}\x03\x02\x02\x02\u{3e7}\u{3d2}\x03\x02\x02\x02\u{3e7}\u{3d3}\x03\
	\x02\x02\x02\u{3e7}\u{3d4}\x03\x02\x02\x02\u{3e7}\u{3d5}\x03\x02\x02\x02\
	\u{3e7}\u{3d6}\x03\x02\x02\x02\u{3e7}\u{3d7}\x03\x02\x02\x02\u{3e7}\u{3d8}\
	\x03\x02\x02\x02\u{3e7}\u{3d9}\x03\x02\x02\x02\u{3e7}\u{3da}\x03\x02\x02\
	\x02\u{3e7}\u{3db}\x03\x02\x02\x02\u{3e7}\u{3dc}\x03\x02\x02\x02\u{3e7}\
	\u{3dd}\x03\x02\x02\x02\u{3e7}\u{3de}\x03\x02\x02\x02\u{3e7}\u{3df}\x03\
	\x02\x02\x02\u{3e7}\u{3e0}\x03\x02\x02\x02\u{3e7}\u{3e1}\x03\x02\x02\x02\
	\u{3e7}\u{3e2}\x03\x02\x02\x02\u{3e7}\u{3e3}\x03\x02\x02\x02\u{3e7}\u{3e4}\
	\x03\x02\x02\x02\u{3e7}\u{3e5}\x03\x02\x02\x02\u{3e7}\u{3e6}\x03\x02\x02\
	\x02\u{3e8}\x5b\x03\x02\x02\x02\u{3e9}\u{3ed}\x07\x31\x02\x02\u{3ea}\u{3ec}\
	\x05\u{172}\u{ba}\x02\u{3eb}\u{3ea}\x03\x02\x02\x02\u{3ec}\u{3ef}\x03\x02\
	\x02\x02\u{3ed}\u{3eb}\x03\x02\x02\x02\u{3ed}\u{3ee}\x03\x02\x02\x02\u{3ee}\
	\u{3f0}\x03\x02\x02\x02\u{3ef}\u{3ed}\x03\x02\x02\x02\u{3f0}\u{3f1}\x05\
	\u{21c}\u{10f}\x02\u{3f1}\x5d\x03\x02\x02\x02\u{3f2}\u{3f3}\x07\x33\x02\
	\x02\u{3f3}\u{3f4}\x05\u{1f2}\u{fa}\x02\u{3f4}\x5f\x03\x02\x02\x02\u{3f5}\
	\u{3f9}\x07\x3f\x02\x02\u{3f6}\u{3f8}\x05\u{172}\u{ba}\x02\u{3f7}\u{3f6}\
	\x03\x02\x02\x02\u{3f8}\u{3fb}\x03\x02\x02\x02\u{3f9}\u{3f7}\x03\x02\x02\
	\x02\u{3f9}\u{3fa}\x03\x02\x02\x02\u{3fa}\x61\x03\x02\x02\x02\u{3fb}\u{3f9}\
	\x03\x02\x02\x02\u{3fc}\u{400}\x07\x44\x02\x02\u{3fd}\u{3ff}\x05\u{172}\
	\u{ba}\x02\u{3fe}\u{3fd}\x03\x02\x02\x02\u{3ff}\u{402}\x03\x02\x02\x02\u{400}\
	\u{3fe}\x03\x02\x02\x02\u{400}\u{401}\x03\x02\x02\x02\u{401}\x63\x03\x02\
	\x02\x02\u{402}\u{400}\x03\x02\x02\x02\u{403}\u{404}\x07\x31\x02\x02\u{404}\
	\u{405}\x05\u{212}\u{10a}\x02\u{405}\x65\x03\x02\x02\x02\u{406}\u{40a}\x07\
	\x4f\x02\x02\u{407}\u{409}\x05\u{172}\u{ba}\x02\u{408}\u{407}\x03\x02\x02\
	\x02\u{409}\u{40c}\x03\x02\x02\x02\u{40a}\u{408}\x03\x02\x02\x02\u{40a}\
	\u{40b}\x03\x02\x02\x02\u{40b}\u{40f}\x03\x02\x02\x02\u{40c}\u{40a}\x03\
	\x02\x02\x02\u{40d}\u{410}\x05\x68\x35\x02\u{40e}\u{410}\x05\x6a\x36\x02\
	\u{40f}\u{40d}\x03\x02\x02\x02\u{40f}\u{40e}\x03\x02\x02\x02\u{410}\x67\
	\x03\x02\x02\x02\u{411}\u{412}\x07\x03\x02\x02\u{412}\x69\x03\x02\x02\x02\
	\u{413}\u{418}\x05\u{17e}\u{c0}\x02\u{414}\u{415}\x07\x0b\x02\x02\u{415}\
	\u{417}\x05\u{17e}\u{c0}\x02\u{416}\u{414}\x03\x02\x02\x02\u{417}\u{41a}\
	\x03\x02\x02\x02\u{418}\u{416}\x03\x02\x02\x02\u{418}\u{419}\x03\x02\x02\
	\x02\u{419}\x6b\x03\x02\x02\x02\u{41a}\u{418}\x03\x02\x02\x02\u{41b}\u{41f}\
	\x07\x54\x02\x02\u{41c}\u{41e}\x05\u{172}\u{ba}\x02\u{41d}\u{41c}\x03\x02\
	\x02\x02\u{41e}\u{421}\x03\x02\x02\x02\u{41f}\u{41d}\x03\x02\x02\x02\u{41f}\
	\u{420}\x03\x02\x02\x02\u{420}\u{422}\x03\x02\x02\x02\u{421}\u{41f}\x03\
	\x02\x02\x02\u{422}\u{424}\x05\u{1c0}\u{e1}\x02\u{423}\u{425}\x05\x6e\x38\
	\x02\u{424}\u{423}\x03\x02\x02\x02\u{424}\u{425}\x03\x02\x02\x02\u{425}\
	\x6d\x03\x02\x02\x02\u{426}\u{427}\x07\x0c\x02\x02\u{427}\u{428}\x05\u{1f2}\
	\u{fa}\x02\u{428}\x6f\x03\x02\x02\x02\u{429}\u{42a}\x07\x58\x02\x02\u{42a}\
	\u{42f}\x05\u{176}\u{bc}\x02\u{42b}\u{42c}\x07\x0b\x02\x02\u{42c}\u{42e}\
	\x05\u{176}\u{bc}\x02\u{42d}\u{42b}\x03\x02\x02\x02\u{42e}\u{431}\x03\x02\
	\x02\x02\u{42f}\u{42d}\x03\x02\x02\x02\u{42f}\u{430}\x03\x02\x02\x02\u{430}\
	\x71\x03\x02\x02\x02\u{431}\u{42f}\x03\x02\x02\x02\u{432}\u{433}\x07\x56\
	\x02\x02\u{433}\x73\x03\x02\x02\x02\u{434}\u{435}\x07\x5b\x02\x02\u{435}\
	\u{436}\x07\x3b\x02\x02\u{436}\u{43b}\x05\u{1d4}\u{eb}\x02\u{437}\u{438}\
	\x07\x0b\x02\x02\u{438}\u{43a}\x05\u{1d4}\u{eb}\x02\u{439}\u{437}\x03\x02\
	\x02\x02\u{43a}\u{43d}\x03\x02\x02\x02\u{43b}\u{439}\x03\x02\x02\x02\u{43b}\
	\u{43c}\x03\x02\x02\x02\u{43c}\u{440}\x03\x02\x02\x02\u{43d}\u{43b}\x03\
	\x02\x02\x02\u{43e}\u{441}\x05\x76\x3c\x02\u{43f}\u{441}\x05\x78\x3d\x02\
	\u{440}\u{43e}\x03\x02\x02\x02\u{440}\u{43f}\x03\x02\x02\x02\u{440}\u{441}\
	\x03\x02\x02\x02\u{441}\x75\x03\x02\x02\x02\u{442}\u{443}\x07\u{106}\x02\
	\x02\u{443}\u{444}\x05\x5a\x2e\x02\u{444}\x77\x03\x02\x02\x02\u{445}\u{446}\
	\x07\u{106}\x02\x02\u{446}\u{447}\x07\x21\x02\x02\u{447}\u{448}\x05\u{9c}\
	\x4f\x02\u{448}\u{449}\x07\x0a\x02\x02\u{449}\x79\x03\x02\x02\x02\u{44a}\
	\u{44c}\x07\x5d\x02\x02\u{44b}\u{44d}\x05\u{1ce}\u{e8}\x02\u{44c}\u{44b}\
	\x03\x02\x02\x02\u{44c}\u{44d}\x03\x02\x02\x02\u{44d}\u{44f}\x03\x02\x02\
	\x02\u{44e}\u{450}\x05\x7c\x3f\x02\u{44f}\u{44e}\x03\x02\x02\x02\u{44f}\
	\u{450}\x03\x02\x02\x02\u{450}\u{451}\x03\x02\x02\x02\u{451}\u{454}\x05\
	\u{17e}\u{c0}\x02\u{452}\u{455}\x05\u{80}\x41\x02\u{453}\u{455}\x05\u{8a}\
	\x46\x02\u{454}\u{452}\x03\x02\x02\x02\u{454}\u{453}\x03\x02\x02\x02\u{454}\
	\u{455}\x03\x02\x02\x02\u{455}\u{457}\x03\x02\x02\x02\u{456}\u{458}\x05\
	\u{8c}\x47\x02\u{457}\u{456}\x03\x02\x02\x02\u{457}\u{458}\x03\x02\x02\x02\
	\u{458}\x7b\x03\x02\x02\x02\u{459}\u{45b}\x05\u{172}\u{ba}\x02\u{45a}\u{459}\
	\x03\x02\x02\x02\u{45b}\u{45e}\x03\x02\x02\x02\u{45c}\u{45a}\x03\x02\x02\
	\x02\u{45c}\u{45d}\x03\x02\x02\x02\u{45d}\u{460}\x03\x02\x02\x02\u{45e}\
	\u{45c}\x03\x02\x02\x02\u{45f}\u{461}\x05\x7e\x40\x02\u{460}\u{45f}\x03\
	\x02\x02\x02\u{460}\u{461}\x03\x02\x02\x02\u{461}\u{462}\x03\x02\x02\x02\
	\u{462}\u{463}\x07\u{105}\x02\x02\u{463}\x7d\x03\x02\x02\x02\u{464}\u{465}\
	\x07\u{84}\x02\x02\u{465}\u{466}\x07\x21\x02\x02\u{466}\u{46b}\x05\u{92}\
	\x4a\x02\u{467}\u{468}\x07\x0b\x02\x02\u{468}\u{46a}\x05\u{92}\x4a\x02\u{469}\
	\u{467}\x03\x02\x02\x02\u{46a}\u{46d}\x03\x02\x02\x02\u{46b}\u{469}\x03\
	\x02\x02\x02\u{46b}\u{46c}\x03\x02\x02\x02\u{46c}\u{46e}\x03\x02\x02\x02\
	\u{46d}\u{46b}\x03\x02\x02\x02\u{46e}\u{46f}\x07\x0a\x02\x02\u{46f}\x7f\
	\x03\x02\x02\x02\u{470}\u{471}\x07\u{d0}\x02\x02\u{471}\u{476}\x05\u{82}\
	\x42\x02\u{472}\u{473}\x07\x0b\x02\x02\u{473}\u{475}\x05\u{82}\x42\x02\u{474}\
	\u{472}\x03\x02\x02\x02\u{475}\u{478}\x03\x02\x02\x02\u{476}\u{474}\x03\
	\x02\x02\x02\u{476}\u{477}\x03\x02\x02\x02\u{477}\u{81}\x03\x02\x02\x02\
	\u{478}\u{476}\x03\x02\x02\x02\u{479}\u{47c}\x05\u{84}\x43\x02\u{47a}\u{47c}\
	\x05\u{88}\x45\x02\u{47b}\u{479}\x03\x02\x02\x02\u{47b}\u{47a}\x03\x02\x02\
	\x02\u{47c}\u{83}\x03\x02\x02\x02\u{47d}\u{47f}\x05\u{208}\u{105}\x02\u{47e}\
	\u{480}\x05\u{86}\x44\x02\u{47f}\u{47e}\x03\x02\x02\x02\u{47f}\u{480}\x03\
	\x02\x02\x02\u{480}\u{85}\x03\x02\x02\x02\u{481}\u{482}\x07\x0c\x02\x02\
	\u{482}\u{483}\x05\u{206}\u{104}\x02\u{483}\u{87}\x03\x02\x02\x02\u{484}\
	\u{485}\x07\u{c2}\x02\x02\u{485}\u{486}\x07\x21\x02\x02\u{486}\u{487}\x07\
	\x03\x02\x02\u{487}\u{488}\x07\x0a\x02\x02\u{488}\u{89}\x03\x02\x02\x02\
	\u{489}\u{48a}\x07\u{d6}\x02\x02\u{48a}\u{8b}\x03\x02\x02\x02\u{48b}\u{48e}\
	\x07\u{d2}\x02\x02\u{48c}\u{48f}\x05\u{8e}\x48\x02\u{48d}\u{48f}\x05\u{90}\
	\x49\x02\u{48e}\u{48c}\x03\x02\x02\x02\u{48e}\u{48d}\x03\x02\x02\x02\u{48f}\
	\u{8d}\x03\x02\x02\x02\u{490}\u{491}\x07\x03\x02\x02\u{491}\u{8f}\x03\x02\
	\x02\x02\u{492}\u{497}\x05\u{84}\x43\x02\u{493}\u{494}\x07\x0b\x02\x02\u{494}\
	\u{496}\x05\u{84}\x43\x02\u{495}\u{493}\x03\x02\x02\x02\u{496}\u{499}\x03\
	\x02\x02\x02\u{497}\u{495}\x03\x02\x02\x02\u{497}\u{498}\x03\x02\x02\x02\
	\u{498}\u{91}\x03\x02\x02\x02\u{499}\u{497}\x03\x02\x02\x02\u{49a}\u{49d}\
	\x05\u{94}\x4b\x02\u{49b}\u{49d}\x05\u{1e8}\u{f5}\x02\u{49c}\u{49a}\x03\
	\x02\x02\x02\u{49c}\u{49b}\x03\x02\x02\x02\u{49d}\u{93}\x03\x02\x02\x02\
	\u{49e}\u{4a3}\x05\u{1e2}\u{f2}\x02\u{49f}\u{4a0}\x07\x05\x02\x02\u{4a0}\
	\u{4a2}\x05\x5c\x2f\x02\u{4a1}\u{49f}\x03\x02\x02\x02\u{4a2}\u{4a5}\x03\
	\x02\x02\x02\u{4a3}\u{4a1}\x03\x02\x02\x02\u{4a3}\u{4a4}\x03\x02\x02\x02\
	\u{4a4}\u{95}\x03\x02\x02\x02\u{4a5}\u{4a3}\x03\x02\x02\x02\u{4a6}\u{4a8}\
	\x07\x60\x02\x02\u{4a7}\u{4a9}\x05\u{98}\x4d\x02\u{4a8}\u{4a7}\x03\x02\x02\
	\x02\u{4a9}\u{4aa}\x03\x02\x02\x02\u{4aa}\u{4a8}\x03\x02\x02\x02\u{4aa}\
	\u{4ab}\x03\x02\x02\x02\u{4ab}\u{97}\x03\x02\x02\x02\u{4ac}\u{4ae}\x05\u{9a}\
	\x4e\x02\u{4ad}\u{4ac}\x03\x02\x02\x02\u{4ad}\u{4ae}\x03\x02\x02\x02\u{4ae}\
	\u{4af}\x03\x02\x02\x02\u{4af}\u{4b0}\x07\x21\x02\x02\u{4b0}\u{4b1}\x05\
	\u{9c}\x4f\x02\u{4b1}\u{4b2}\x07\x0a\x02\x02\u{4b2}\u{99}\x03\x02\x02\x02\
	\u{4b3}\u{4b4}\x05\u{21c}\u{10f}\x02\u{4b4}\u{4b5}\x07\x13\x02\x02\u{4b5}\
	\u{9b}\x03\x02\x02\x02\u{4b6}\u{4ba}\x05\x5a\x2e\x02\u{4b7}\u{4b9}\x05\u{9e}\
	\x50\x02\u{4b8}\u{4b7}\x03\x02\x02\x02\u{4b9}\u{4bc}\x03\x02\x02\x02\u{4ba}\
	\u{4b8}\x03\x02\x02\x02\u{4ba}\u{4bb}\x03\x02\x02\x02\u{4bb}\u{9d}\x03\x02\
	\x02\x02\u{4bc}\u{4ba}\x03\x02\x02\x02\u{4bd}\u{4be}\x07\x05\x02\x02\u{4be}\
	\u{4bf}\x05\x5a\x2e\x02\u{4bf}\u{9f}\x03\x02\x02\x02\u{4c0}\u{4c1}\x07\x62\
	\x02\x02\u{4c1}\u{a1}\x03\x02\x02\x02\u{4c2}\u{4c6}\x07\x65\x02\x02\u{4c3}\
	\u{4c5}\x05\u{172}\u{ba}\x02\u{4c4}\u{4c3}\x03\x02\x02\x02\u{4c5}\u{4c8}\
	\x03\x02\x02\x02\u{4c6}\u{4c4}\x03\x02\x02\x02\u{4c6}\u{4c7}\x03\x02\x02\
	\x02\u{4c7}\u{a3}\x03\x02\x02\x02\u{4c8}\u{4c6}\x03\x02\x02\x02\u{4c9}\u{4cd}\
	\x07\x66\x02\x02\u{4ca}\u{4cc}\x05\u{172}\u{ba}\x02\u{4cb}\u{4ca}\x03\x02\
	\x02\x02\u{4cc}\u{4cf}\x03\x02\x02\x02\u{4cd}\u{4cb}\x03\x02\x02\x02\u{4cd}\
	\u{4ce}\x03\x02\x02\x02\u{4ce}\u{4d0}\x03\x02\x02\x02\u{4cf}\u{4cd}\x03\
	\x02\x02\x02\u{4d0}\u{4d1}\x05\u{a6}\x54\x02\u{4d1}\u{4d2}\x07\x0b\x02\x02\
	\u{4d2}\u{4d3}\x05\u{a6}\x54\x02\u{4d3}\u{4d5}\x03\x02\x02\x02\u{4d4}\u{4d6}\
	\x05\u{b0}\x59\x02\u{4d5}\u{4d4}\x03\x02\x02\x02\u{4d5}\u{4d6}\x03\x02\x02\
	\x02\u{4d6}\u{4d8}\x03\x02\x02\x02\u{4d7}\u{4d9}\x05\u{b2}\x5a\x02\u{4d8}\
	\u{4d7}\x03\x02\x02\x02\u{4d8}\u{4d9}\x03\x02\x02\x02\u{4d9}\u{a5}\x03\x02\
	\x02\x02\u{4da}\u{4de}\x05\u{a8}\x55\x02\u{4db}\u{4de}\x05\u{aa}\x56\x02\
	\u{4dc}\u{4de}\x05\u{ac}\x57\x02\u{4dd}\u{4da}\x03\x02\x02\x02\u{4dd}\u{4db}\
	\x03\x02\x02\x02\u{4dd}\u{4dc}\x03\x02\x02\x02\u{4de}\u{a7}\x03\x02\x02\
	\x02\u{4df}\u{4e0}\x07\x21\x02\x02\u{4e0}\u{4e1}\x05\u{21c}\u{10f}\x02\u{4e1}\
	\u{4e2}\x07\x0a\x02\x02\u{4e2}\u{a9}\x03\x02\x02\x02\u{4e3}\u{4e4}\x09\x02\
	\x02\x02\u{4e4}\u{ab}\x03\x02\x02\x02\u{4e5}\u{4e6}\x09\x03\x02\x02\u{4e6}\
	\u{4e8}\x05\u{21c}\u{10f}\x02\u{4e7}\u{4e9}\x05\u{ae}\x58\x02\u{4e8}\u{4e7}\
	\x03\x02\x02\x02\u{4e8}\u{4e9}\x03\x02\x02\x02\u{4e9}\u{4ea}\x03\x02\x02\
	\x02\u{4ea}\u{4eb}\x09\x04\x02\x02\u{4eb}\u{ad}\x03\x02\x02\x02\u{4ec}\u{4ed}\
	\x07\x03\x02\x02\u{4ed}\u{4ee}\x05\u{1a6}\u{d4}\x02\u{4ee}\u{4ef}\x07\x12\
	\x02\x02\u{4ef}\u{4f0}\x05\u{1a6}\u{d4}\x02\u{4f0}\u{af}\x03\x02\x02\x02\
	\u{4f1}\u{4f2}\x07\u{105}\x02\x02\u{4f2}\u{4f3}\x05\x4c\x27\x02\u{4f3}\u{b1}\
	\x03\x02\x02\x02\u{4f4}\u{4f5}\x07\u{d0}\x02\x02\u{4f5}\u{4fa}\x05\u{176}\
	\u{bc}\x02\u{4f6}\u{4f7}\x07\x0b\x02\x02\u{4f7}\u{4f9}\x05\u{176}\u{bc}\
	\x02\u{4f8}\u{4f6}\x03\x02\x02\x02\u{4f9}\u{4fc}\x03\x02\x02\x02\u{4fa}\
	\u{4f8}\x03\x02\x02\x02\u{4fa}\u{4fb}\x03\x02\x02\x02\u{4fb}\u{b3}\x03\x02\
	\x02\x02\u{4fc}\u{4fa}\x03\x02\x02\x02\u{4fd}\u{4fe}\x07\x67\x02\x02\u{4fe}\
	\u{500}\x05\u{1a6}\u{d4}\x02\u{4ff}\u{501}\x05\u{c2}\x62\x02\u{500}\u{4ff}\
	\x03\x02\x02\x02\u{500}\u{501}\x03\x02\x02\x02\u{501}\u{b5}\x03\x02\x02\
	\x02\u{502}\u{503}\x07\x69\x02\x02\u{503}\u{504}\x05\u{b8}\x5d\x02\u{504}\
	\u{505}\x07\x0b\x02\x02\u{505}\u{506}\x05\u{b8}\x5d\x02\u{506}\u{b7}\x03\
	\x02\x02\x02\u{507}\u{509}\x09\x05\x02\x02\u{508}\u{50a}\x05\u{ba}\x5e\x02\
	\u{509}\u{508}\x03\x02\x02\x02\u{509}\u{50a}\x03\x02\x02\x02\u{50a}\u{50e}\
	\x03\x02\x02\x02\u{50b}\u{50d}\x05\u{172}\u{ba}\x02\u{50c}\u{50b}\x03\x02\
	\x02\x02\u{50d}\u{510}\x03\x02\x02\x02\u{50e}\u{50c}\x03\x02\x02\x02\u{50e}\
	\u{50f}\x03\x02\x02\x02\u{50f}\u{b9}\x03\x02\x02\x02\u{510}\u{50e}\x03\x02\
	\x02\x02\u{511}\u{512}\x07\x31\x02\x02\u{512}\u{513}\x05\u{21c}\u{10f}\x02\
	\u{513}\u{bb}\x03\x02\x02\x02\u{514}\u{518}\x07\x68\x02\x02\u{515}\u{517}\
	\x05\u{172}\u{ba}\x02\u{516}\u{515}\x03\x02\x02\x02\u{517}\u{51a}\x03\x02\
	\x02\x02\u{518}\u{516}\x03\x02\x02\x02\u{518}\u{519}\x03\x02\x02\x02\u{519}\
	\u{51b}\x03\x02\x02\x02\u{51a}\u{518}\x03\x02\x02\x02\u{51b}\u{51c}\x05\
	\u{a6}\x54\x02\u{51c}\u{51d}\x07\x0b\x02\x02\u{51d}\u{51e}\x05\u{a6}\x54\
	\x02\u{51e}\u{520}\x03\x02\x02\x02\u{51f}\u{521}\x05\u{b0}\x59\x02\u{520}\
	\u{51f}\x03\x02\x02\x02\u{520}\u{521}\x03\x02\x02\x02\u{521}\u{523}\x03\
	\x02\x02\x02\u{522}\u{524}\x05\u{b2}\x5a\x02\u{523}\u{522}\x03\x02\x02\x02\
	\u{523}\u{524}\x03\x02\x02\x02\u{524}\u{bd}\x03\x02\x02\x02\u{525}\u{526}\
	\x07\u{87}\x02\x02\u{526}\u{527}\x05\u{1bc}\u{df}\x02\u{527}\u{bf}\x03\x02\
	\x02\x02\u{528}\u{52c}\x07\u{8a}\x02\x02\u{529}\u{52b}\x05\u{172}\u{ba}\
	\x02\u{52a}\u{529}\x03\x02\x02\x02\u{52b}\u{52e}\x03\x02\x02\x02\u{52c}\
	\u{52a}\x03\x02\x02\x02\u{52c}\u{52d}\x03\x02\x02\x02\u{52d}\u{52f}\x03\
	\x02\x02\x02\u{52e}\u{52c}\x03\x02\x02\x02\u{52f}\u{532}\x05\u{17e}\u{c0}\
	\x02\u{530}\u{533}\x05\u{c2}\x62\x02\u{531}\u{533}\x05\u{c4}\x63\x02\u{532}\
	\u{530}\x03\x02\x02\x02\u{532}\u{531}\x03\x02\x02\x02\u{532}\u{533}\x03\
	\x02\x02\x02\u{533}\u{c1}\x03\x02\x02\x02\u{534}\u{53d}\x07\u{bc}\x02\x02\
	\u{535}\u{53a}\x05\u{17e}\u{c0}\x02\u{536}\u{537}\x07\x0b\x02\x02\u{537}\
	\u{539}\x05\u{17e}\u{c0}\x02\u{538}\u{536}\x03\x02\x02\x02\u{539}\u{53c}\
	\x03\x02\x02\x02\u{53a}\u{538}\x03\x02\x02\x02\u{53a}\u{53b}\x03\x02\x02\
	\x02\u{53b}\u{53e}\x03\x02\x02\x02\u{53c}\u{53a}\x03\x02\x02\x02\u{53d}\
	\u{535}\x03\x02\x02\x02\u{53d}\u{53e}\x03\x02\x02\x02\u{53e}\u{c3}\x03\x02\
	\x02\x02\u{53f}\u{540}\x07\u{105}\x02\x02\u{540}\u{541}\x05\u{17e}\u{c0}\
	\x02\u{541}\u{c5}\x03\x02\x02\x02\u{542}\u{546}\x07\u{96}\x02\x02\u{543}\
	\u{545}\x05\u{172}\u{ba}\x02\u{544}\u{543}\x03\x02\x02\x02\u{545}\u{548}\
	\x03\x02\x02\x02\u{546}\u{544}\x03\x02\x02\x02\u{546}\u{547}\x03\x02\x02\
	\x02\u{547}\u{549}\x03\x02\x02\x02\u{548}\u{546}\x03\x02\x02\x02\u{549}\
	\u{54a}\x05\u{17e}\u{c0}\x02\u{54a}\u{54b}\x05\u{c2}\x62\x02\u{54b}\u{c7}\
	\x03\x02\x02\x02\u{54c}\u{550}\x07\u{98}\x02\x02\u{54d}\u{54f}\x05\u{172}\
	\u{ba}\x02\u{54e}\u{54d}\x03\x02\x02\x02\u{54f}\u{552}\x03\x02\x02\x02\u{550}\
	\u{54e}\x03\x02\x02\x02\u{550}\u{551}\x03\x02\x02\x02\u{551}\u{553}\x03\
	\x02\x02\x02\u{552}\u{550}\x03\x02\x02\x02\u{553}\u{554}\x05\u{ca}\x66\x02\
	\u{554}\u{555}\x07\x31\x02\x02\u{555}\u{556}\x05\u{21c}\u{10f}\x02\u{556}\
	\u{557}\x07\x21\x02\x02\u{557}\u{55c}\x05\x06\x04\x02\u{558}\u{559}\x07\
	\x24\x02\x02\u{559}\u{55b}\x05\x06\x04\x02\u{55a}\u{558}\x03\x02\x02\x02\
	\u{55b}\u{55e}\x03\x02\x02\x02\u{55c}\u{55a}\x03\x02\x02\x02\u{55c}\u{55d}\
	\x03\x02\x02\x02\u{55d}\u{560}\x03\x02\x02\x02\u{55e}\u{55c}\x03\x02\x02\
	\x02\u{55f}\u{561}\x07\x24\x02\x02\u{560}\u{55f}\x03\x02\x02\x02\u{560}\
	\u{561}\x03\x02\x02\x02\u{561}\u{562}\x03\x02\x02\x02\u{562}\u{563}\x07\
	\x0a\x02\x02\u{563}\u{c9}\x03\x02\x02\x02\u{564}\u{568}\x05\u{cc}\x67\x02\
	\u{565}\u{568}\x05\u{20a}\u{106}\x02\u{566}\u{568}\x05\u{1d4}\u{eb}\x02\
	\u{567}\u{564}\x03\x02\x02\x02\u{567}\u{565}\x03\x02\x02\x02\u{567}\u{566}\
	\x03\x02\x02\x02\u{568}\u{cb}\x03\x02\x02\x02\u{569}\u{56a}\x07\x53\x02\
	\x02\u{56a}\u{56b}\x07\x20\x02\x02\u{56b}\u{570}\x05\u{17e}\u{c0}\x02\u{56c}\
	\u{56d}\x07\x0b\x02\x02\u{56d}\u{56f}\x05\u{17e}\u{c0}\x02\u{56e}\u{56c}\
	\x03\x02\x02\x02\u{56f}\u{572}\x03\x02\x02\x02\u{570}\u{56e}\x03\x02\x02\
	\x02\u{570}\u{571}\x03\x02\x02\x02\u{571}\u{573}\x03\x02\x02\x02\u{572}\
	\u{570}\x03\x02\x02\x02\u{573}\u{574}\x07\x07\x02\x02\u{574}\u{cd}\x03\x02\
	\x02\x02\u{575}\u{579}\x07\u{99}\x02\x02\u{576}\u{578}\x05\u{172}\u{ba}\
	\x02\u{577}\u{576}\x03\x02\x02\x02\u{578}\u{57b}\x03\x02\x02\x02\u{579}\
	\u{577}\x03\x02\x02\x02\u{579}\u{57a}\x03\x02\x02\x02\u{57a}\u{57c}\x03\
	\x02\x02\x02\u{57b}\u{579}\x03\x02\x02\x02\u{57c}\u{57d}\x05\u{20a}\u{106}\
	\x02\u{57d}\u{57e}\x09\x06\x02\x02\u{57e}\u{581}\x05\u{20a}\u{106}\x02\u{57f}\
	\u{582}\x05\u{d0}\x69\x02\u{580}\u{582}\x05\u{d2}\x6a\x02\u{581}\u{57f}\
	\x03\x02\x02\x02\u{581}\u{580}\x03\x02\x02\x02\u{581}\u{582}\x03\x02\x02\
	\x02\u{582}\u{584}\x03\x02\x02\x02\u{583}\u{585}\x05\u{d4}\x6b\x02\u{584}\
	\u{583}\x03\x02\x02\x02\u{584}\u{585}\x03\x02\x02\x02\u{585}\u{cf}\x03\x02\
	\x02\x02\u{586}\u{587}\x07\u{10b}\x02\x02\u{587}\u{588}\x07\x13\x02\x02\
	\u{588}\u{589}\x05\u{21c}\u{10f}\x02\u{589}\u{d1}\x03\x02\x02\x02\u{58a}\
	\u{58b}\x07\u{106}\x02\x02\u{58b}\u{58c}\x05\u{1a6}\u{d4}\x02\u{58c}\u{58d}\
	\x07\u{bc}\x02\x02\u{58d}\u{58e}\x05\u{20a}\u{106}\x02\u{58e}\u{d3}\x03\
	\x02\x02\x02\u{58f}\u{590}\x07\u{c9}\x02\x02\u{590}\u{591}\x05\u{1d6}\u{ec}\
	\x02\u{591}\u{592}\x07\x21\x02\x02\u{592}\u{593}\x05\u{16a}\u{b6}\x02\u{593}\
	\u{594}\x07\x0a\x02\x02\u{594}\u{d5}\x03\x02\x02\x02\u{595}\u{599}\x07\u{9a}\
	\x02\x02\u{596}\u{598}\x05\u{172}\u{ba}\x02\u{597}\u{596}\x03\x02\x02\x02\
	\u{598}\u{59b}\x03\x02\x02\x02\u{599}\u{597}\x03\x02\x02\x02\u{599}\u{59a}\
	\x03\x02\x02\x02\u{59a}\u{59c}\x03\x02\x02\x02\u{59b}\u{599}\x03\x02\x02\
	\x02\u{59c}\u{5a1}\x05\u{da}\x6e\x02\u{59d}\u{59e}\x07\x0b\x02\x02\u{59e}\
	\u{5a0}\x05\u{da}\x6e\x02\u{59f}\u{59d}\x03\x02\x02\x02\u{5a0}\u{5a3}\x03\
	\x02\x02\x02\u{5a1}\u{59f}\x03\x02\x02\x02\u{5a1}\u{5a2}\x03\x02\x02\x02\
	\u{5a2}\u{5a4}\x03\x02\x02\x02\u{5a3}\u{5a1}\x03\x02\x02\x02\u{5a4}\u{5a7}\
	\x05\u{d8}\x6d\x02\u{5a5}\u{5a8}\x05\u{de}\x70\x02\u{5a6}\u{5a8}\x05\u{e0}\
	\x71\x02\u{5a7}\u{5a5}\x03\x02\x02\x02\u{5a7}\u{5a6}\x03\x02\x02\x02\u{5a8}\
	\u{5aa}\x03\x02\x02\x02\u{5a9}\u{5ab}\x05\u{e2}\x72\x02\u{5aa}\u{5a9}\x03\
	\x02\x02\x02\u{5aa}\u{5ab}\x03\x02\x02\x02\u{5ab}\u{d7}\x03\x02\x02\x02\
	\u{5ac}\u{5ad}\x07\u{bc}\x02\x02\u{5ad}\u{5ae}\x05\u{176}\u{bc}\x02\u{5ae}\
	\u{d9}\x03\x02\x02\x02\u{5af}\u{5b1}\x05\u{176}\u{bc}\x02\u{5b0}\u{5b2}\
	\x05\u{dc}\x6f\x02\u{5b1}\u{5b0}\x03\x02\x02\x02\u{5b1}\u{5b2}\x03\x02\x02\
	\x02\u{5b2}\u{db}\x03\x02\x02\x02\u{5b3}\u{5b4}\x07\x4c\x02\x02\u{5b4}\u{5b5}\
	\x07\x13\x02\x02\u{5b5}\u{5b6}\x05\u{176}\u{bc}\x02\u{5b6}\u{dd}\x03\x02\
	\x02\x02\u{5b7}\u{5b8}\x07\u{84}\x02\x02\u{5b8}\u{5b9}\x07\u{d8}\x02\x02\
	\u{5b9}\u{5ba}\x07\x21\x02\x02\u{5ba}\u{5bb}\x05\u{176}\u{bc}\x02\u{5bb}\
	\u{5bc}\x07\x0b\x02\x02\u{5bc}\u{5bd}\x05\u{176}\u{bc}\x02\u{5bd}\u{5be}\
	\x07\x0b\x02\x02\u{5be}\u{5bf}\x05\u{176}\u{bc}\x02\u{5bf}\u{5c0}\x07\x0a\
	\x02\x02\u{5c0}\u{df}\x03\x02\x02\x02\u{5c1}\u{5c2}\x07\x61\x02\x02\u{5c2}\
	\u{5c4}\x05\u{176}\u{bc}\x02\u{5c3}\u{5c1}\x03\x02\x02\x02\u{5c3}\u{5c4}\
	\x03\x02\x02\x02\u{5c4}\u{5c7}\x03\x02\x02\x02\u{5c5}\u{5c6}\x07\u{f8}\x02\
	\x02\u{5c6}\u{5c8}\x05\u{176}\u{bc}\x02\u{5c7}\u{5c5}\x03\x02\x02\x02\u{5c7}\
	\u{5c8}\x03\x02\x02\x02\u{5c8}\u{5c9}\x03\x02\x02\x02\u{5c9}\u{5ca}\x07\
	\u{ef}\x02\x02\u{5ca}\u{5cb}\x05\u{176}\u{bc}\x02\u{5cb}\u{e1}\x03\x02\x02\
	\x02\u{5cc}\u{5cd}\x07\x3b\x02\x02\u{5cd}\u{5d2}\x05\u{176}\u{bc}\x02\u{5ce}\
	\u{5cf}\x07\x0b\x02\x02\u{5cf}\u{5d1}\x05\u{176}\u{bc}\x02\u{5d0}\u{5ce}\
	\x03\x02\x02\x02\u{5d1}\u{5d4}\x03\x02\x02\x02\u{5d2}\u{5d0}\x03\x02\x02\
	\x02\u{5d2}\u{5d3}\x03\x02\x02\x02\u{5d3}\u{e3}\x03\x02\x02\x02\u{5d4}\u{5d2}\
	\x03\x02\x02\x02\u{5d5}\u{5d9}\x09\x07\x02\x02\u{5d6}\u{5d8}\x05\u{170}\
	\u{b9}\x02\u{5d7}\u{5d6}\x03\x02\x02\x02\u{5d8}\u{5db}\x03\x02\x02\x02\u{5d9}\
	\u{5d7}\x03\x02\x02\x02\u{5d9}\u{5da}\x03\x02\x02\x02\u{5da}\u{5dc}\x03\
	\x02\x02\x02\u{5db}\u{5d9}\x03\x02\x02\x02\u{5dc}\u{5e1}\x05\u{ea}\x76\x02\
	\u{5dd}\u{5de}\x07\x0b\x02\x02\u{5de}\u{5e0}\x05\u{ea}\x76\x02\u{5df}\u{5dd}\
	\x03\x02\x02\x02\u{5e0}\u{5e3}\x03\x02\x02\x02\u{5e1}\u{5df}\x03\x02\x02\
	\x02\u{5e1}\u{5e2}\x03\x02\x02\x02\u{5e2}\u{5e5}\x03\x02\x02\x02\u{5e3}\
	\u{5e1}\x03\x02\x02\x02\u{5e4}\u{5e6}\x05\u{e6}\x74\x02\u{5e5}\u{5e4}\x03\
	\x02\x02\x02\u{5e5}\u{5e6}\x03\x02\x02\x02\u{5e6}\u{5e8}\x03\x02\x02\x02\
	\u{5e7}\u{5e9}\x05\u{e8}\x75\x02\u{5e8}\u{5e7}\x03\x02\x02\x02\u{5e8}\u{5e9}\
	\x03\x02\x02\x02\u{5e9}\u{5ea}\x03\x02\x02\x02\u{5ea}\u{5eb}\x07\u{bc}\x02\
	\x02\u{5eb}\u{5ec}\x07\x21\x02\x02\u{5ec}\u{5ed}\x05\u{16a}\u{b6}\x02\u{5ed}\
	\u{5ee}\x07\x0a\x02\x02\u{5ee}\u{e5}\x03\x02\x02\x02\u{5ef}\u{5f0}\x07\u{92}\
	\x02\x02\u{5f0}\u{5f1}\x07\u{133}\x02\x02\u{5f1}\u{e7}\x03\x02\x02\x02\u{5f2}\
	\u{5f3}\x07\u{82}\x02\x02\u{5f3}\u{5f4}\x07\u{13d}\x02\x02\u{5f4}\u{e9}\
	\x03\x02\x02\x02\u{5f5}\u{5f7}\x05\u{176}\u{bc}\x02\u{5f6}\u{5f8}\x05\u{ec}\
	\x77\x02\u{5f7}\u{5f6}\x03\x02\x02\x02\u{5f7}\u{5f8}\x03\x02\x02\x02\u{5f8}\
	\u{eb}\x03\x02\x02\x02\u{5f9}\u{5fa}\x07\u{f8}\x02\x02\u{5fa}\u{5fb}\x07\
	\u{13b}\x02\x02\u{5fb}\u{ed}\x03\x02\x02\x02\u{5fc}\u{600}\x09\x08\x02\x02\
	\u{5fd}\u{5ff}\x05\u{170}\u{b9}\x02\u{5fe}\u{5fd}\x03\x02\x02\x02\u{5ff}\
	\u{602}\x03\x02\x02\x02\u{600}\u{5fe}\x03\x02\x02\x02\u{600}\u{601}\x03\
	\x02\x02\x02\u{601}\u{603}\x03\x02\x02\x02\u{602}\u{600}\x03\x02\x02\x02\
	\u{603}\u{608}\x05\u{f0}\x79\x02\u{604}\u{605}\x07\x0b\x02\x02\u{605}\u{607}\
	\x05\u{f0}\x79\x02\u{606}\u{604}\x03\x02\x02\x02\u{607}\u{60a}\x03\x02\x02\
	\x02\u{608}\u{606}\x03\x02\x02\x02\u{608}\u{609}\x03\x02\x02\x02\u{609}\
	\u{60c}\x03\x02\x02\x02\u{60a}\u{608}\x03\x02\x02\x02\u{60b}\u{60d}\x05\
	\u{e6}\x74\x02\u{60c}\u{60b}\x03\x02\x02\x02\u{60c}\u{60d}\x03\x02\x02\x02\
	\u{60d}\u{ef}\x03\x02\x02\x02\u{60e}\u{610}\x05\u{176}\u{bc}\x02\u{60f}\
	\u{611}\x05\u{ec}\x77\x02\u{610}\u{60f}\x03\x02\x02\x02\u{610}\u{611}\x03\
	\x02\x02\x02\u{611}\u{f1}\x03\x02\x02\x02\u{612}\u{614}\x07\u{c4}\x02\x02\
	\u{613}\u{615}\x05\u{f4}\x7b\x02\u{614}\u{613}\x03\x02\x02\x02\u{614}\u{615}\
	\x03\x02\x02\x02\u{615}\u{616}\x03\x02\x02\x02\u{616}\u{617}\x05\u{17e}\
	\u{c0}\x02\u{617}\u{618}\x07\u{106}\x02\x02\u{618}\u{619}\x05\u{fa}\x7e\
	\x02\u{619}\u{f3}\x03\x02\x02\x02\u{61a}\u{61b}\x07\u{8b}\x02\x02\u{61b}\
	\u{61c}\x07\x13\x02\x02\u{61c}\u{61e}\x09\x09\x02\x02\u{61d}\u{61f}\x05\
	\u{f6}\x7c\x02\u{61e}\u{61d}\x03\x02\x02\x02\u{61e}\u{61f}\x03\x02\x02\x02\
	\u{61f}\u{f5}\x03\x02\x02\x02\u{620}\u{621}\x07\x5f\x02\x02\u{621}\u{622}\
	\x07\x13\x02\x02\u{622}\u{623}\x07\u{13e}\x02\x02\u{623}\u{f7}\x03\x02\x02\
	\x02\u{624}\u{627}\x05\u{20a}\u{106}\x02\u{625}\u{626}\x07\x0c\x02\x02\u{626}\
	\u{628}\x05\u{204}\u{103}\x02\u{627}\u{625}\x03\x02\x02\x02\u{627}\u{628}\
	\x03\x02\x02\x02\u{628}\u{f9}\x03\x02\x02\x02\u{629}\u{62b}\x05\u{f8}\x7d\
	\x02\u{62a}\u{629}\x03\x02\x02\x02\u{62a}\u{62b}\x03\x02\x02\x02\u{62b}\
	\u{62f}\x03\x02\x02\x02\u{62c}\u{62e}\x05\u{fc}\x7f\x02\u{62d}\u{62c}\x03\
	\x02\x02\x02\u{62e}\u{631}\x03\x02\x02\x02\u{62f}\u{62d}\x03\x02\x02\x02\
	\u{62f}\u{630}\x03\x02\x02\x02\u{630}\u{633}\x03\x02\x02\x02\u{631}\u{62f}\
	\x03\x02\x02\x02\u{632}\u{634}\x07\x03\x02\x02\u{633}\u{632}\x03\x02\x02\
	\x02\u{633}\u{634}\x03\x02\x02\x02\u{634}\u{fb}\x03\x02\x02\x02\u{635}\u{637}\
	\x07\x03\x02\x02\u{636}\u{635}\x03\x02\x02\x02\u{636}\u{637}\x03\x02\x02\
	\x02\u{637}\u{638}\x03\x02\x02\x02\u{638}\u{63a}\x05\u{248}\u{125}\x02\u{639}\
	\u{63b}\x05\u{f8}\x7d\x02\u{63a}\u{639}\x03\x02\x02\x02\u{63a}\u{63b}\x03\
	\x02\x02\x02\u{63b}\u{fd}\x03\x02\x02\x02\u{63c}\u{63e}\x07\u{c6}\x02\x02\
	\u{63d}\u{63f}\x05\u{f4}\x7b\x02\u{63e}\u{63d}\x03\x02\x02\x02\u{63e}\u{63f}\
	\x03\x02\x02\x02\u{63f}\u{640}\x03\x02\x02\x02\u{640}\u{641}\x05\u{17e}\
	\u{c0}\x02\u{641}\u{642}\x07\u{106}\x02\x02\u{642}\u{643}\x05\u{fa}\x7e\
	\x02\u{643}\u{ff}\x03\x02\x02\x02\u{644}\u{645}\x07\u{c5}\x02\x02\u{645}\
	\u{646}\x05\u{17e}\u{c0}\x02\u{646}\u{648}\x05\u{1f2}\u{fa}\x02\u{647}\u{649}\
	\x05\u{102}\u{82}\x02\u{648}\u{647}\x03\x02\x02\x02\u{648}\u{649}\x03\x02\
	\x02\x02\u{649}\u{101}\x03\x02\x02\x02\u{64a}\u{64b}\x07\u{106}\x02\x02\
	\u{64b}\u{64c}\x07\x21\x02\x02\u{64c}\u{651}\x05\u{174}\u{bb}\x02\u{64d}\
	\u{64e}\x07\x0b\x02\x02\u{64e}\u{650}\x05\u{174}\u{bb}\x02\u{64f}\u{64d}\
	\x03\x02\x02\x02\u{650}\u{653}\x03\x02\x02\x02\u{651}\u{64f}\x03\x02\x02\
	\x02\u{651}\u{652}\x03\x02\x02\x02\u{652}\u{654}\x03\x02\x02\x02\u{653}\
	\u{651}\x03\x02\x02\x02\u{654}\u{655}\x07\x0a\x02\x02\u{655}\u{103}\x03\
	\x02\x02\x02\u{656}\u{65a}\x07\u{c7}\x02\x02\u{657}\u{659}\x05\u{172}\u{ba}\
	\x02\u{658}\u{657}\x03\x02\x02\x02\u{659}\u{65c}\x03\x02\x02\x02\u{65a}\
	\u{658}\x03\x02\x02\x02\u{65a}\u{65b}\x03\x02\x02\x02\u{65b}\u{65d}\x03\
	\x02\x02\x02\u{65c}\u{65a}\x03\x02\x02\x02\u{65d}\u{65e}\x07\x3b\x02\x02\
	\u{65e}\u{660}\x05\u{1d4}\u{eb}\x02\u{65f}\u{661}\x05\u{106}\u{84}\x02\u{660}\
	\u{65f}\x03\x02\x02\x02\u{660}\u{661}\x03\x02\x02\x02\u{661}\u{664}\x03\
	\x02\x02\x02\u{662}\u{665}\x05\u{108}\u{85}\x02\u{663}\u{665}\x05\u{10a}\
	\u{86}\x02\u{664}\u{662}\x03\x02\x02\x02\u{664}\u{663}\x03\x02\x02\x02\u{665}\
	\u{105}\x03\x02\x02\x02\u{666}\u{669}\x07\u{84}\x02\x02\u{667}\u{66a}\x05\
	\u{1c0}\u{e1}\x02\u{668}\u{66a}\x05\u{24a}\u{126}\x02\u{669}\u{667}\x03\
	\x02\x02\x02\u{669}\u{668}\x03\x02\x02\x02\u{66a}\u{107}\x03\x02\x02\x02\
	\u{66b}\u{66c}\x07\x21\x02\x02\u{66c}\u{66d}\x05\x52\x2a\x02\u{66d}\u{66e}\
	\x07\x0a\x02\x02\u{66e}\u{109}\x03\x02\x02\x02\u{66f}\u{670}\x07\x1f\x02\
	\x02\u{670}\u{671}\x05\x4e\x28\x02\u{671}\u{672}\x07\x06\x02\x02\u{672}\
	\u{10b}\x03\x02\x02\x02\u{673}\u{677}\x07\u{c8}\x02\x02\u{674}\u{676}\x05\
	\u{172}\u{ba}\x02\u{675}\u{674}\x03\x02\x02\x02\u{676}\u{679}\x03\x02\x02\
	\x02\u{677}\u{675}\x03\x02\x02\x02\u{677}\u{678}\x03\x02\x02\x02\u{678}\
	\u{67a}\x03\x02\x02\x02\u{679}\u{677}\x03\x02\x02\x02\u{67a}\u{67c}\x05\
	\u{1d4}\u{eb}\x02\u{67b}\u{67d}\x05\u{10e}\u{88}\x02\u{67c}\u{67b}\x03\x02\
	\x02\x02\u{67c}\u{67d}\x03\x02\x02\x02\u{67d}\u{67e}\x03\x02\x02\x02\u{67e}\
	\u{67f}\x07\x21\x02\x02\u{67f}\u{680}\x05\u{16a}\u{b6}\x02\u{680}\u{681}\
	\x07\x0a\x02\x02\u{681}\u{10d}\x03\x02\x02\x02\u{682}\u{683}\x07\u{82}\x02\
	\x02\u{683}\u{684}\x07\u{13d}\x02\x02\u{684}\u{10f}\x03\x02\x02\x02\u{685}\
	\u{686}\x07\u{cf}\x02\x02\u{686}\u{68b}\x05\u{176}\u{bc}\x02\u{687}\u{688}\
	\x07\x0b\x02\x02\u{688}\u{68a}\x05\u{176}\u{bc}\x02\u{689}\u{687}\x03\x02\
	\x02\x02\u{68a}\u{68d}\x03\x02\x02\x02\u{68b}\u{689}\x03\x02\x02\x02\u{68b}\
	\u{68c}\x03\x02\x02\x02\u{68c}\u{111}\x03\x02\x02\x02\u{68d}\u{68b}\x03\
	\x02\x02\x02\u{68e}\u{697}\x07\u{d1}\x02\x02\u{68f}\u{694}\x05\u{210}\u{109}\
	\x02\u{690}\u{691}\x07\x0b\x02\x02\u{691}\u{693}\x05\u{210}\u{109}\x02\u{692}\
	\u{690}\x03\x02\x02\x02\u{693}\u{696}\x03\x02\x02\x02\u{694}\u{692}\x03\
	\x02\x02\x02\u{694}\u{695}\x03\x02\x02\x02\u{695}\u{698}\x03\x02\x02\x02\
	\u{696}\u{694}\x03\x02\x02\x02\u{697}\u{68f}\x03\x02\x02\x02\u{697}\u{698}\
	\x03\x02\x02\x02\u{698}\u{113}\x03\x02\x02\x02\u{699}\u{69a}\x07\u{d3}\x02\
	\x02\u{69a}\u{69f}\x05\u{210}\u{109}\x02\u{69b}\u{69c}\x07\x0b\x02\x02\u{69c}\
	\u{69e}\x05\u{210}\u{109}\x02\u{69d}\u{69b}\x03\x02\x02\x02\u{69e}\u{6a1}\
	\x03\x02\x02\x02\u{69f}\u{69d}\x03\x02\x02\x02\u{69f}\u{6a0}\x03\x02\x02\
	\x02\u{6a0}\u{115}\x03\x02\x02\x02\u{6a1}\u{69f}\x03\x02\x02\x02\u{6a2}\
	\u{6ab}\x07\u{d0}\x02\x02\u{6a3}\u{6a8}\x05\u{176}\u{bc}\x02\u{6a4}\u{6a5}\
	\x07\x0b\x02\x02\u{6a5}\u{6a7}\x05\u{176}\u{bc}\x02\u{6a6}\u{6a4}\x03\x02\
	\x02\x02\u{6a7}\u{6aa}\x03\x02\x02\x02\u{6a8}\u{6a6}\x03\x02\x02\x02\u{6a8}\
	\u{6a9}\x03\x02\x02\x02\u{6a9}\u{6ac}\x03\x02\x02\x02\u{6aa}\u{6a8}\x03\
	\x02\x02\x02\u{6ab}\u{6a3}\x03\x02\x02\x02\u{6ab}\u{6ac}\x03\x02\x02\x02\
	\u{6ac}\u{117}\x03\x02\x02\x02\u{6ad}\u{6b6}\x07\u{d4}\x02\x02\u{6ae}\u{6b3}\
	\x05\u{176}\u{bc}\x02\u{6af}\u{6b0}\x07\x0b\x02\x02\u{6b0}\u{6b2}\x05\u{176}\
	\u{bc}\x02\u{6b1}\u{6af}\x03\x02\x02\x02\u{6b2}\u{6b5}\x03\x02\x02\x02\u{6b3}\
	\u{6b1}\x03\x02\x02\x02\u{6b3}\u{6b4}\x03\x02\x02\x02\u{6b4}\u{6b7}\x03\
	\x02\x02\x02\u{6b5}\u{6b3}\x03\x02\x02\x02\u{6b6}\u{6ae}\x03\x02\x02\x02\
	\u{6b6}\u{6b7}\x03\x02\x02\x02\u{6b7}\u{119}\x03\x02\x02\x02\u{6b8}\u{6c1}\
	\x07\u{d5}\x02\x02\u{6b9}\u{6be}\x05\u{11c}\u{8f}\x02\u{6ba}\u{6bb}\x07\
	\x0b\x02\x02\u{6bb}\u{6bd}\x05\u{11c}\u{8f}\x02\u{6bc}\u{6ba}\x03\x02\x02\
	\x02\u{6bd}\u{6c0}\x03\x02\x02\x02\u{6be}\u{6bc}\x03\x02\x02\x02\u{6be}\
	\u{6bf}\x03\x02\x02\x02\u{6bf}\u{6c2}\x03\x02\x02\x02\u{6c0}\u{6be}\x03\
	\x02\x02\x02\u{6c1}\u{6b9}\x03\x02\x02\x02\u{6c1}\u{6c2}\x03\x02\x02\x02\
	\u{6c2}\u{11b}\x03\x02\x02\x02\u{6c3}\u{6c5}\x05\u{210}\u{109}\x02\u{6c4}\
	\u{6c6}\x09\x0a\x02\x02\u{6c5}\u{6c4}\x03\x02\x02\x02\u{6c5}\u{6c6}\x03\
	\x02\x02\x02\u{6c6}\u{11d}\x03\x02\x02\x02\u{6c7}\u{6cb}\x07\u{d9}\x02\x02\
	\u{6c8}\u{6ca}\x05\u{170}\u{b9}\x02\u{6c9}\u{6c8}\x03\x02\x02\x02\u{6ca}\
	\u{6cd}\x03\x02\x02\x02\u{6cb}\u{6c9}\x03\x02\x02\x02\u{6cb}\u{6cc}\x03\
	\x02\x02\x02\u{6cc}\u{6ce}\x03\x02\x02\x02\u{6cd}\u{6cb}\x03\x02\x02\x02\
	\u{6ce}\u{6cf}\x07\x3b\x02\x02\u{6cf}\u{6d1}\x05\u{176}\u{bc}\x02\u{6d0}\
	\u{6d2}\x05\u{120}\u{91}\x02\u{6d1}\u{6d0}\x03\x02\x02\x02\u{6d1}\u{6d2}\
	\x03\x02\x02\x02\u{6d2}\u{11f}\x03\x02\x02\x02\u{6d3}\u{6d4}\x07\u{106}\
	\x02\x02\u{6d4}\u{6d9}\x05\u{176}\u{bc}\x02\u{6d5}\u{6d6}\x07\x0b\x02\x02\
	\u{6d6}\u{6d8}\x05\u{176}\u{bc}\x02\u{6d7}\u{6d5}\x03\x02\x02\x02\u{6d8}\
	\u{6db}\x03\x02\x02\x02\u{6d9}\u{6d7}\x03\x02\x02\x02\u{6d9}\u{6da}\x03\
	\x02\x02\x02\u{6da}\u{121}\x03\x02\x02\x02\u{6db}\u{6d9}\x03\x02\x02\x02\
	\u{6dc}\u{6dd}\x07\u{dc}\x02\x02\u{6dd}\u{6e0}\x09\x0b\x02\x02\u{6de}\u{6e1}\
	\x05\u{124}\u{93}\x02\u{6df}\u{6e1}\x05\u{126}\u{94}\x02\u{6e0}\u{6de}\x03\
	\x02\x02\x02\u{6e0}\u{6df}\x03\x02\x02\x02\u{6e0}\u{6e1}\x03\x02\x02\x02\
	\u{6e1}\u{123}\x03\x02\x02\x02\u{6e2}\u{6e3}\x07\u{106}\x02\x02\u{6e3}\u{6ec}\
	\x07\x21\x02\x02\u{6e4}\u{6e9}\x05\u{128}\u{95}\x02\u{6e5}\u{6e6}\x07\x0b\
	\x02\x02\u{6e6}\u{6e8}\x05\u{128}\u{95}\x02\u{6e7}\u{6e5}\x03\x02\x02\x02\
	\u{6e8}\u{6eb}\x03\x02\x02\x02\u{6e9}\u{6e7}\x03\x02\x02\x02\u{6e9}\u{6ea}\
	\x03\x02\x02\x02\u{6ea}\u{6ed}\x03\x02\x02\x02\u{6eb}\u{6e9}\x03\x02\x02\
	\x02\u{6ec}\u{6e4}\x03\x02\x02\x02\u{6ec}\u{6ed}\x03\x02\x02\x02\u{6ed}\
	\u{6ee}\x03\x02\x02\x02\u{6ee}\u{6ef}\x07\x0a\x02\x02\u{6ef}\u{125}\x03\
	\x02\x02\x02\u{6f0}\u{6f2}\x05\u{12c}\u{97}\x02\u{6f1}\u{6f0}\x03\x02\x02\
	\x02\u{6f2}\u{6f3}\x03\x02\x02\x02\u{6f3}\u{6f1}\x03\x02\x02\x02\u{6f3}\
	\u{6f4}\x03\x02\x02\x02\u{6f4}\u{127}\x03\x02\x02\x02\u{6f5}\u{6f6}\x07\
	\u{f7}\x02\x02\u{6f6}\u{6f7}\x07\x13\x02\x02\u{6f7}\u{729}\x05\u{1a8}\u{d5}\
	\x02\u{6f8}\u{6f9}\x07\u{10f}\x02\x02\u{6f9}\u{6fa}\x07\x13\x02\x02\u{6fa}\
	\u{729}\x05\u{20a}\u{106}\x02\u{6fb}\u{6fc}\x07\u{e5}\x02\x02\u{6fc}\u{6fd}\
	\x07\x13\x02\x02\u{6fd}\u{729}\x05\u{12a}\u{96}\x02\u{6fe}\u{6ff}\x07\u{114}\
	\x02\x02\u{6ff}\u{700}\x07\x13\x02\x02\u{700}\u{729}\x05\u{12a}\u{96}\x02\
	\u{701}\u{702}\x07\x2f\x02\x02\u{702}\u{703}\x07\x13\x02\x02\u{703}\u{729}\
	\x05\u{12a}\u{96}\x02\u{704}\u{705}\x07\u{8b}\x02\x02\u{705}\u{706}\x07\
	\x13\x02\x02\u{706}\u{729}\x09\x0c\x02\x02\u{707}\u{708}\x07\u{112}\x02\
	\x02\u{708}\u{709}\x07\x13\x02\x02\u{709}\u{729}\x05\u{1a8}\u{d5}\x02\u{70a}\
	\u{70b}\x07\u{118}\x02\x02\u{70b}\u{70c}\x07\x13\x02\x02\u{70c}\u{729}\x05\
	\u{1a8}\u{d5}\x02\u{70d}\u{70e}\x07\u{10e}\x02\x02\u{70e}\u{70f}\x07\x13\
	\x02\x02\u{70f}\u{729}\x09\x0d\x02\x02\u{710}\u{711}\x07\u{113}\x02\x02\
	\u{711}\u{712}\x07\x13\x02\x02\u{712}\u{729}\x09\x0d\x02\x02\u{713}\u{714}\
	\x07\u{8e}\x02\x02\u{714}\u{715}\x07\x13\x02\x02\u{715}\u{729}\x09\x0e\x02\
	\x02\u{716}\u{717}\x07\u{117}\x02\x02\u{717}\u{718}\x07\x13\x02\x02\u{718}\
	\u{729}\x09\x0f\x02\x02\u{719}\u{71a}\x07\x29\x02\x02\u{71a}\u{71b}\x07\
	\x13\x02\x02\u{71b}\u{729}\x07\u{138}\x02\x02\u{71c}\u{71d}\x07\u{116}\x02\
	\x02\u{71d}\u{71e}\x07\x13\x02\x02\u{71e}\u{729}\x05\u{22e}\u{118}\x02\u{71f}\
	\u{720}\x07\u{115}\x02\x02\u{720}\u{721}\x07\x13\x02\x02\u{721}\u{729}\x05\
	\u{22e}\u{118}\x02\u{722}\u{723}\x07\u{111}\x02\x02\u{723}\u{724}\x07\x13\
	\x02\x02\u{724}\u{729}\x05\u{228}\u{115}\x02\u{725}\u{726}\x07\u{110}\x02\
	\x02\u{726}\u{727}\x07\x13\x02\x02\u{727}\u{729}\x05\u{228}\u{115}\x02\u{728}\
	\u{6f5}\x03\x02\x02\x02\u{728}\u{6f8}\x03\x02\x02\x02\u{728}\u{6fb}\x03\
	\x02\x02\x02\u{728}\u{6fe}\x03\x02\x02\x02\u{728}\u{701}\x03\x02\x02\x02\
	\u{728}\u{704}\x03\x02\x02\x02\u{728}\u{707}\x03\x02\x02\x02\u{728}\u{70a}\
	\x03\x02\x02\x02\u{728}\u{70d}\x03\x02\x02\x02\u{728}\u{710}\x03\x02\x02\
	\x02\u{728}\u{713}\x03\x02\x02\x02\u{728}\u{716}\x03\x02\x02\x02\u{728}\
	\u{719}\x03\x02\x02\x02\u{728}\u{71c}\x03\x02\x02\x02\u{728}\u{71f}\x03\
	\x02\x02\x02\u{728}\u{722}\x03\x02\x02\x02\u{728}\u{725}\x03\x02\x02\x02\
	\u{729}\u{129}\x03\x02\x02\x02\u{72a}\u{72f}\x05\u{20c}\u{107}\x02\u{72b}\
	\u{72c}\x07\x0b\x02\x02\u{72c}\u{72e}\x05\u{20c}\u{107}\x02\u{72d}\u{72b}\
	\x03\x02\x02\x02\u{72e}\u{731}\x03\x02\x02\x02\u{72f}\u{72d}\x03\x02\x02\
	\x02\u{72f}\u{730}\x03\x02\x02\x02\u{730}\u{12b}\x03\x02\x02\x02\u{731}\
	\u{72f}\x03\x02\x02\x02\u{732}\u{733}\x07\u{f7}\x02\x02\u{733}\u{734}\x07\
	\x13\x02\x02\u{734}\u{740}\x05\u{248}\u{125}\x02\u{735}\u{736}\x07\u{8b}\
	\x02\x02\u{736}\u{737}\x07\x13\x02\x02\u{737}\u{740}\x09\x0c\x02\x02\u{738}\
	\u{739}\x07\u{106}\x02\x02\u{739}\u{740}\x05\u{248}\u{125}\x02\u{73a}\u{73b}\
	\x07\x3b\x02\x02\u{73b}\u{740}\x05\u{12a}\u{96}\x02\u{73c}\u{73d}\x07\x29\
	\x02\x02\u{73d}\u{73e}\x07\x13\x02\x02\u{73e}\u{740}\x07\u{138}\x02\x02\
	\u{73f}\u{732}\x03\x02\x02\x02\u{73f}\u{735}\x03\x02\x02\x02\u{73f}\u{738}\
	\x03\x02\x02\x02\u{73f}\u{73a}\x03\x02\x02\x02\u{73f}\u{73c}\x03\x02\x02\
	\x02\u{740}\u{12d}\x03\x02\x02\x02\u{741}\u{745}\x07\u{e0}\x02\x02\u{742}\
	\u{744}\x05\u{170}\u{b9}\x02\u{743}\u{742}\x03\x02\x02\x02\u{744}\u{747}\
	\x03\x02\x02\x02\u{745}\u{743}\x03\x02\x02\x02\u{745}\u{746}\x03\x02\x02\
	\x02\u{746}\u{748}\x03\x02\x02\x02\u{747}\u{745}\x03\x02\x02\x02\u{748}\
	\u{749}\x05\u{176}\u{bc}\x02\u{749}\u{74a}\x07\u{bb}\x02\x02\u{74a}\u{74b}\
	\x05\u{176}\u{bc}\x02\u{74b}\u{12f}\x03\x02\x02\x02\u{74c}\u{750}\x07\u{df}\
	\x02\x02\u{74d}\u{74f}\x05\u{170}\u{b9}\x02\u{74e}\u{74d}\x03\x02\x02\x02\
	\u{74f}\u{752}\x03\x02\x02\x02\u{750}\u{74e}\x03\x02\x02\x02\u{750}\u{751}\
	\x03\x02\x02\x02\u{751}\u{753}\x03\x02\x02\x02\u{752}\u{750}\x03\x02\x02\
	\x02\u{753}\u{754}\x05\u{176}\u{bc}\x02\u{754}\u{131}\x03\x02\x02\x02\u{755}\
	\u{759}\x07\u{e1}\x02\x02\u{756}\u{758}\x05\u{172}\u{ba}\x02\u{757}\u{756}\
	\x03\x02\x02\x02\u{758}\u{75b}\x03\x02\x02\x02\u{759}\u{757}\x03\x02\x02\
	\x02\u{759}\u{75a}\x03\x02\x02\x02\u{75a}\u{75d}\x03\x02\x02\x02\u{75b}\
	\u{759}\x03\x02\x02\x02\u{75c}\u{75e}\x05\u{134}\u{9b}\x02\u{75d}\u{75c}\
	\x03\x02\x02\x02\u{75d}\u{75e}\x03\x02\x02\x02\u{75e}\u{760}\x03\x02\x02\
	\x02\u{75f}\u{761}\x05\u{136}\u{9c}\x02\u{760}\u{75f}\x03\x02\x02\x02\u{760}\
	\u{761}\x03\x02\x02\x02\u{761}\u{763}\x03\x02\x02\x02\u{762}\u{764}\x05\
	\u{138}\u{9d}\x02\u{763}\u{762}\x03\x02\x02\x02\u{763}\u{764}\x03\x02\x02\
	\x02\u{764}\u{765}\x03\x02\x02\x02\u{765}\u{766}\x07\u{106}\x02\x02\u{766}\
	\u{768}\x07\x21\x02\x02\u{767}\u{769}\x05\u{13a}\u{9e}\x02\u{768}\u{767}\
	\x03\x02\x02\x02\u{769}\u{76a}\x03\x02\x02\x02\u{76a}\u{768}\x03\x02\x02\
	\x02\u{76a}\u{76b}\x03\x02\x02\x02\u{76b}\u{76c}\x03\x02\x02\x02\u{76c}\
	\u{76d}\x07\x0a\x02\x02\u{76d}\u{133}\x03\x02\x02\x02\u{76e}\u{76f}\x07\
	\u{bf}\x02\x02\u{76f}\u{770}\x07\x3b\x02\x02\u{770}\u{771}\x05\u{14c}\u{a7}\
	\x02\u{771}\u{772}\x07\x0b\x02\x02\u{772}\u{773}\x05\u{14c}\u{a7}\x02\u{773}\
	\u{135}\x03\x02\x02\x02\u{774}\u{775}\x07\u{c7}\x02\x02\u{775}\u{776}\x07\
	\x3b\x02\x02\u{776}\u{77b}\x05\u{17e}\u{c0}\x02\u{777}\u{778}\x07\x0b\x02\
	\x02\u{778}\u{77a}\x05\u{17e}\u{c0}\x02\u{779}\u{777}\x03\x02\x02\x02\u{77a}\
	\u{77d}\x03\x02\x02\x02\u{77b}\u{779}\x03\x02\x02\x02\u{77b}\u{77c}\x03\
	\x02\x02\x02\u{77c}\u{137}\x03\x02\x02\x02\u{77d}\u{77b}\x03\x02\x02\x02\
	\u{77e}\u{77f}\x07\x4a\x02\x02\u{77f}\u{780}\x07\x21\x02\x02\u{780}\u{785}\
	\x05\x1a\x0e\x02\u{781}\u{782}\x07\x0b\x02\x02\u{782}\u{784}\x05\x1a\x0e\
	\x02\u{783}\u{781}\x03\x02\x02\x02\u{784}\u{787}\x03\x02\x02\x02\u{785}\
	\u{783}\x03\x02\x02\x02\u{785}\u{786}\x03\x02\x02\x02\u{786}\u{788}\x03\
	\x02\x02\x02\u{787}\u{785}\x03\x02\x02\x02\u{788}\u{789}\x07\x0a\x02\x02\
	\u{789}\u{139}\x03\x02\x02\x02\u{78a}\u{78b}\x07\u{ef}\x02\x02\u{78b}\u{78d}\
	\x05\u{208}\u{105}\x02\u{78c}\u{78e}\x07\u{bd}\x02\x02\u{78d}\u{78c}\x03\
	\x02\x02\x02\u{78d}\u{78e}\x03\x02\x02\x02\u{78e}\u{790}\x03\x02\x02\x02\
	\u{78f}\u{791}\x05\u{13c}\u{9f}\x02\u{790}\u{78f}\x03\x02\x02\x02\u{790}\
	\u{791}\x03\x02\x02\x02\u{791}\u{792}\x03\x02\x02\x02\u{792}\u{793}\x07\
	\x0c\x02\x02\u{793}\u{795}\x05\u{17e}\u{c0}\x02\u{794}\u{796}\x05\u{13e}\
	\u{a0}\x02\u{795}\u{794}\x03\x02\x02\x02\u{795}\u{796}\x03\x02\x02\x02\u{796}\
	\u{797}\x03\x02\x02\x02\u{797}\u{798}\x07\x24\x02\x02\u{798}\u{13b}\x03\
	\x02\x02\x02\u{799}\u{79a}\x07\u{c1}\x02\x02\u{79a}\u{79b}\x07\x13\x02\x02\
	\u{79b}\u{79c}\x09\x10\x02\x02\u{79c}\u{13d}\x03\x02\x02\x02\u{79d}\u{79e}\
	\x07\x26\x02\x02\u{79e}\u{7a3}\x05\u{140}\u{a1}\x02\u{79f}\u{7a0}\x07\x0b\
	\x02\x02\u{7a0}\u{7a2}\x05\u{140}\u{a1}\x02\u{7a1}\u{79f}\x03\x02\x02\x02\
	\u{7a2}\u{7a5}\x03\x02\x02\x02\u{7a3}\u{7a1}\x03\x02\x02\x02\u{7a3}\u{7a4}\
	\x03\x02\x02\x02\u{7a4}\u{13f}\x03\x02\x02\x02\u{7a5}\u{7a3}\x03\x02\x02\
	\x02\u{7a6}\u{7a7}\x05\u{208}\u{105}\x02\u{7a7}\u{7a8}\x07\x13\x02\x02\u{7a8}\
	\u{7a9}\x05\u{17e}\u{c0}\x02\u{7a9}\u{141}\x03\x02\x02\x02\u{7aa}\u{7ae}\
	\x07\u{e3}\x02\x02\u{7ab}\u{7ad}\x05\u{172}\u{ba}\x02\u{7ac}\u{7ab}\x03\
	\x02\x02\x02\u{7ad}\u{7b0}\x03\x02\x02\x02\u{7ae}\u{7ac}\x03\x02\x02\x02\
	\u{7ae}\u{7af}\x03\x02\x02\x02\u{7af}\u{7b2}\x03\x02\x02\x02\u{7b0}\u{7ae}\
	\x03\x02\x02\x02\u{7b1}\u{7b3}\x05\u{1ce}\u{e8}\x02\u{7b2}\u{7b1}\x03\x02\
	\x02\x02\u{7b2}\u{7b3}\x03\x02\x02\x02\u{7b3}\u{7b5}\x03\x02\x02\x02\u{7b4}\
	\u{7b6}\x05\u{146}\u{a4}\x02\u{7b5}\u{7b4}\x03\x02\x02\x02\u{7b5}\u{7b6}\
	\x03\x02\x02\x02\u{7b6}\u{7ba}\x03\x02\x02\x02\u{7b7}\u{7bb}\x05\u{17e}\
	\u{c0}\x02\u{7b8}\u{7bb}\x05\u{1c8}\u{e5}\x02\u{7b9}\u{7bb}\x05\u{144}\u{a3}\
	\x02\u{7ba}\u{7b7}\x03\x02\x02\x02\u{7ba}\u{7b8}\x03\x02\x02\x02\u{7ba}\
	\u{7b9}\x03\x02\x02\x02\u{7bb}\u{143}\x03\x02\x02\x02\u{7bc}\u{7bd}\x07\
	\x03\x02\x02\u{7bd}\u{7be}\x07\x2d\x02\x02\u{7be}\u{7bf}\x05\u{17e}\u{c0}\
	\x02\u{7bf}\u{145}\x03\x02\x02\x02\u{7c0}\u{7c1}\x07\u{84}\x02\x02\u{7c1}\
	\u{7c2}\x07\x21\x02\x02\u{7c2}\u{7c7}\x05\u{92}\x4a\x02\u{7c3}\u{7c4}\x07\
	\x0b\x02\x02\u{7c4}\u{7c6}\x05\u{92}\x4a\x02\u{7c5}\u{7c3}\x03\x02\x02\x02\
	\u{7c6}\u{7c9}\x03\x02\x02\x02\u{7c7}\u{7c5}\x03\x02\x02\x02\u{7c7}\u{7c8}\
	\x03\x02\x02\x02\u{7c8}\u{7ca}\x03\x02\x02\x02\u{7c9}\u{7c7}\x03\x02\x02\
	\x02\u{7ca}\u{7cb}\x07\x0a\x02\x02\u{7cb}\u{147}\x03\x02\x02\x02\u{7cc}\
	\u{7d0}\x07\u{e4}\x02\x02\u{7cd}\u{7cf}\x05\u{170}\u{b9}\x02\u{7ce}\u{7cd}\
	\x03\x02\x02\x02\u{7cf}\u{7d2}\x03\x02\x02\x02\u{7d0}\u{7ce}\x03\x02\x02\
	\x02\u{7d0}\u{7d1}\x03\x02\x02\x02\u{7d1}\u{7d3}\x03\x02\x02\x02\u{7d2}\
	\u{7d0}\x03\x02\x02\x02\u{7d3}\u{7d8}\x05\u{176}\u{bc}\x02\u{7d4}\u{7d5}\
	\x07\x0b\x02\x02\u{7d5}\u{7d7}\x05\u{176}\u{bc}\x02\u{7d6}\u{7d4}\x03\x02\
	\x02\x02\u{7d7}\u{7da}\x03\x02\x02\x02\u{7d8}\u{7d6}\x03\x02\x02\x02\u{7d8}\
	\u{7d9}\x03\x02\x02\x02\u{7d9}\u{149}\x03\x02\x02\x02\u{7da}\u{7d8}\x03\
	\x02\x02\x02\u{7db}\u{7df}\x09\x11\x02\x02\u{7dc}\u{7de}\x05\u{172}\u{ba}\
	\x02\u{7dd}\u{7dc}\x03\x02\x02\x02\u{7de}\u{7e1}\x03\x02\x02\x02\u{7df}\
	\u{7dd}\x03\x02\x02\x02\u{7df}\u{7e0}\x03\x02\x02\x02\u{7e0}\u{7e2}\x03\
	\x02\x02\x02\u{7e1}\u{7df}\x03\x02\x02\x02\u{7e2}\u{7e3}\x07\x3b\x02\x02\
	\u{7e3}\u{7e8}\x05\u{14c}\u{a7}\x02\u{7e4}\u{7e5}\x07\x0b\x02\x02\u{7e5}\
	\u{7e7}\x05\u{14c}\u{a7}\x02\u{7e6}\u{7e4}\x03\x02\x02\x02\u{7e7}\u{7ea}\
	\x03\x02\x02\x02\u{7e8}\u{7e6}\x03\x02\x02\x02\u{7e8}\u{7e9}\x03\x02\x02\
	\x02\u{7e9}\u{14b}\x03\x02\x02\x02\u{7ea}\u{7e8}\x03\x02\x02\x02\u{7eb}\
	\u{7ec}\x05\u{176}\u{bc}\x02\u{7ec}\u{7ed}\x05\u{14e}\u{a8}\x02\u{7ed}\u{14d}\
	\x03\x02\x02\x02\u{7ee}\u{7f0}\x09\x12\x02\x02\u{7ef}\u{7ee}\x03\x02\x02\
	\x02\u{7ef}\u{7f0}\x03\x02\x02\x02\u{7f0}\u{7f3}\x03\x02\x02\x02\u{7f1}\
	\u{7f2}\x07\u{ba}\x02\x02\u{7f2}\u{7f4}\x09\x13\x02\x02\u{7f3}\u{7f1}\x03\
	\x02\x02\x02\u{7f3}\u{7f4}\x03\x02\x02\x02\u{7f4}\u{14f}\x03\x02\x02\x02\
	\u{7f5}\u{7f9}\x07\u{f0}\x02\x02\u{7f6}\u{7f8}\x05\u{170}\u{b9}\x02\u{7f7}\
	\u{7f6}\x03\x02\x02\x02\u{7f8}\u{7fb}\x03\x02\x02\x02\u{7f9}\u{7f7}\x03\
	\x02\x02\x02\u{7f9}\u{7fa}\x03\x02\x02\x02\u{7fa}\u{804}\x03\x02\x02\x02\
	\u{7fb}\u{7f9}\x03\x02\x02\x02\u{7fc}\u{801}\x05\u{176}\u{bc}\x02\u{7fd}\
	\u{7fe}\x07\x0b\x02\x02\u{7fe}\u{800}\x05\u{176}\u{bc}\x02\u{7ff}\u{7fd}\
	\x03\x02\x02\x02\u{800}\u{803}\x03\x02\x02\x02\u{801}\u{7ff}\x03\x02\x02\
	\x02\u{801}\u{802}\x03\x02\x02\x02\u{802}\u{805}\x03\x02\x02\x02\u{803}\
	\u{801}\x03\x02\x02\x02\u{804}\u{7fc}\x03\x02\x02\x02\u{804}\u{805}\x03\
	\x02\x02\x02\u{805}\u{807}\x03\x02\x02\x02\u{806}\u{808}\x05\u{152}\u{aa}\
	\x02\u{807}\u{806}\x03\x02\x02\x02\u{807}\u{808}\x03\x02\x02\x02\u{808}\
	\u{151}\x03\x02\x02\x02\u{809}\u{80a}\x07\x3b\x02\x02\u{80a}\u{80b}\x05\
	\u{176}\u{bc}\x02\u{80b}\u{80c}\x07\x0b\x02\x02\u{80c}\u{80d}\x05\u{176}\
	\u{bc}\x02\u{80d}\u{80f}\x03\x02\x02\x02\u{80e}\u{810}\x05\u{154}\u{ab}\
	\x02\u{80f}\u{80e}\x03\x02\x02\x02\u{80f}\u{810}\x03\x02\x02\x02\u{810}\
	\u{153}\x03\x02\x02\x02\u{811}\u{812}\x07\x39\x02\x02\u{812}\u{813}\x07\
	\x13\x02\x02\u{813}\u{814}\x05\u{22c}\u{117}\x02\u{814}\u{155}\x03\x02\x02\
	\x02\u{815}\u{819}\x09\x14\x02\x02\u{816}\u{818}\x05\u{170}\u{b9}\x02\u{817}\
	\u{816}\x03\x02\x02\x02\u{818}\u{81b}\x03\x02\x02\x02\u{819}\u{817}\x03\
	\x02\x02\x02\u{819}\u{81a}\x03\x02\x02\x02\u{81a}\u{81c}\x03\x02\x02\x02\
	\u{81b}\u{819}\x03\x02\x02\x02\u{81c}\u{81d}\x05\u{176}\u{bc}\x02\u{81d}\
	\u{157}\x03\x02\x02\x02\u{81e}\u{822}\x07\u{f9}\x02\x02\u{81f}\u{821}\x05\
	\u{170}\u{b9}\x02\u{820}\u{81f}\x03\x02\x02\x02\u{821}\u{824}\x03\x02\x02\
	\x02\u{822}\u{820}\x03\x02\x02\x02\u{822}\u{823}\x03\x02\x02\x02\u{823}\
	\u{825}\x03\x02\x02\x02\u{824}\u{822}\x03\x02\x02\x02\u{825}\u{826}\x05\
	\u{176}\u{bc}\x02\u{826}\u{827}\x07\x3b\x02\x02\u{827}\u{828}\x05\u{14c}\
	\u{a7}\x02\u{828}\u{159}\x03\x02\x02\x02\u{829}\u{82a}\x07\u{fa}\x02\x02\
	\u{82a}\u{82b}\x05\u{176}\u{bc}\x02\u{82b}\u{82c}\x07\u{bb}\x02\x02\u{82c}\
	\u{82e}\x05\u{176}\u{bc}\x02\u{82d}\u{82f}\x05\u{15c}\u{af}\x02\u{82e}\u{82d}\
	\x03\x02\x02\x02\u{82e}\u{82f}\x03\x02\x02\x02\u{82f}\u{15b}\x03\x02\x02\
	\x02\u{830}\u{831}\x07\x3b\x02\x02\u{831}\u{832}\x05\u{14c}\u{a7}\x02\u{832}\
	\u{15d}\x03\x02\x02\x02\u{833}\u{838}\x05\u{160}\u{b1}\x02\u{834}\u{835}\
	\x07\x0b\x02\x02\u{835}\u{837}\x05\u{160}\u{b1}\x02\u{836}\u{834}\x03\x02\
	\x02\x02\u{837}\u{83a}\x03\x02\x02\x02\u{838}\u{836}\x03\x02\x02\x02\u{838}\
	\u{839}\x03\x02\x02\x02\u{839}\u{15f}\x03\x02\x02\x02\u{83a}\u{838}\x03\
	\x02\x02\x02\u{83b}\u{83d}\x07\u{fb}\x02\x02\u{83c}\u{83e}\x05\u{176}\u{bc}\
	\x02\u{83d}\u{83c}\x03\x02\x02\x02\u{83d}\u{83e}\x03\x02\x02\x02\u{83e}\
	\u{83f}\x03\x02\x02\x02\u{83f}\u{840}\x07\u{bb}\x02\x02\u{840}\u{842}\x05\
	\u{176}\u{bc}\x02\u{841}\u{843}\x05\u{162}\u{b2}\x02\u{842}\u{841}\x03\x02\
	\x02\x02\u{842}\u{843}\x03\x02\x02\x02\u{843}\u{844}\x03\x02\x02\x02\u{844}\
	\u{845}\x07\x3b\x02\x02\u{845}\u{846}\x05\u{14c}\u{a7}\x02\u{846}\u{161}\
	\x03\x02\x02\x02\u{847}\u{848}\x07\u{106}\x02\x02\u{848}\u{849}\x07\u{c0}\
	\x02\x02\u{849}\u{84a}\x07\x13\x02\x02\u{84a}\u{84b}\x05\u{176}\u{bc}\x02\
	\u{84b}\u{163}\x03\x02\x02\x02\u{84c}\u{850}\x07\u{100}\x02\x02\u{84d}\u{84f}\
	\x05\u{172}\u{ba}\x02\u{84e}\u{84d}\x03\x02\x02\x02\u{84f}\u{852}\x03\x02\
	\x02\x02\u{850}\u{84e}\x03\x02\x02\x02\u{850}\u{851}\x03\x02\x02\x02\u{851}\
	\u{853}\x03\x02\x02\x02\u{852}\u{850}\x03\x02\x02\x02\u{853}\u{858}\x05\
	\u{166}\u{b4}\x02\u{854}\u{855}\x07\x0b\x02\x02\u{855}\u{857}\x05\u{166}\
	\u{b4}\x02\u{856}\u{854}\x03\x02\x02\x02\u{857}\u{85a}\x03\x02\x02\x02\u{858}\
	\u{856}\x03\x02\x02\x02\u{858}\u{859}\x03\x02\x02\x02\u{859}\u{165}\x03\
	\x02\x02\x02\u{85a}\u{858}\x03\x02\x02\x02\u{85b}\u{85f}\x05\u{1e8}\u{f5}\
	\x02\u{85c}\u{85f}\x05\u{1e2}\u{f2}\x02\u{85d}\u{85f}\x05\u{1d0}\u{e9}\x02\
	\u{85e}\u{85b}\x03\x02\x02\x02\u{85e}\u{85c}\x03\x02\x02\x02\u{85e}\u{85d}\
	\x03\x02\x02\x02\u{85f}\u{167}\x03\x02\x02\x02\u{860}\u{864}\x09\x15\x02\
	\x02\u{861}\u{863}\x05\u{170}\u{b9}\x02\u{862}\u{861}\x03\x02\x02\x02\u{863}\
	\u{866}\x03\x02\x02\x02\u{864}\u{862}\x03\x02\x02\x02\u{864}\u{865}\x03\
	\x02\x02\x02\u{865}\u{867}\x03\x02\x02\x02\u{866}\u{864}\x03\x02\x02\x02\
	\u{867}\u{868}\x05\u{176}\u{bc}\x02\u{868}\u{169}\x03\x02\x02\x02\u{869}\
	\u{86c}\x05\x52\x2a\x02\u{86a}\u{86c}\x05\u{16c}\u{b7}\x02\u{86b}\u{869}\
	\x03\x02\x02\x02\u{86b}\u{86a}\x03\x02\x02\x02\u{86c}\u{16b}\x03\x02\x02\
	\x02\u{86d}\u{871}\x05\u{1ee}\u{f8}\x02\u{86e}\u{870}\x05\u{16e}\u{b8}\x02\
	\u{86f}\u{86e}\x03\x02\x02\x02\u{870}\u{873}\x03\x02\x02\x02\u{871}\u{86f}\
	\x03\x02\x02\x02\u{871}\u{872}\x03\x02\x02\x02\u{872}\u{16d}\x03\x02\x02\
	\x02\u{873}\u{871}\x03\x02\x02\x02\u{874}\u{875}\x07\x05\x02\x02\u{875}\
	\u{876}\x05\x56\x2c\x02\u{876}\u{16f}\x03\x02\x02\x02\u{877}\u{878}\x09\
	\x16\x02\x02\u{878}\u{87b}\x07\x13\x02\x02\u{879}\u{87c}\x05\u{21a}\u{10e}\
	\x02\u{87a}\u{87c}\x05\u{228}\u{115}\x02\u{87b}\u{879}\x03\x02\x02\x02\u{87b}\
	\u{87a}\x03\x02\x02\x02\u{87c}\u{171}\x03\x02\x02\x02\u{87d}\u{87e}\x09\
	\x17\x02\x02\u{87e}\u{881}\x07\x13\x02\x02\u{87f}\u{882}\x05\u{21a}\u{10e}\
	\x02\u{880}\u{882}\x05\u{228}\u{115}\x02\u{881}\u{87f}\x03\x02\x02\x02\u{881}\
	\u{880}\x03\x02\x02\x02\u{882}\u{173}\x03\x02\x02\x02\u{883}\u{884}\x07\
	\u{13e}\x02\x02\u{884}\u{887}\x07\x13\x02\x02\u{885}\u{888}\x05\u{21a}\u{10e}\
	\x02\u{886}\u{888}\x05\u{228}\u{115}\x02\u{887}\u{885}\x03\x02\x02\x02\u{887}\
	\u{886}\x03\x02\x02\x02\u{888}\u{175}\x03\x02\x02\x02\u{889}\u{88b}\x05\
	\u{178}\u{bd}\x02\u{88a}\u{889}\x03\x02\x02\x02\u{88a}\u{88b}\x03\x02\x02\
	\x02\u{88b}\u{88c}\x03\x02\x02\x02\u{88c}\u{88d}\x05\u{17e}\u{c0}\x02\u{88d}\
	\u{177}\x03\x02\x02\x02\u{88e}\u{891}\x05\u{21e}\u{110}\x02\u{88f}\u{891}\
	\x05\u{17a}\u{be}\x02\u{890}\u{88e}\x03\x02\x02\x02\u{890}\u{88f}\x03\x02\
	\x02\x02\u{891}\u{892}\x03\x02\x02\x02\u{892}\u{893}\x07\x13\x02\x02\u{893}\
	\u{179}\x03\x02\x02\x02\u{894}\u{895}\x07\x21\x02\x02\u{895}\u{89a}\x05\
	\u{21e}\u{110}\x02\u{896}\u{897}\x07\x0b\x02\x02\u{897}\u{899}\x05\u{21e}\
	\u{110}\x02\u{898}\u{896}\x03\x02\x02\x02\u{899}\u{89c}\x03\x02\x02\x02\
	\u{89a}\u{898}\x03\x02\x02\x02\u{89a}\u{89b}\x03\x02\x02\x02\u{89b}\u{89d}\
	\x03\x02\x02\x02\u{89c}\u{89a}\x03\x02\x02\x02\u{89d}\u{89e}\x07\x0a\x02\
	\x02\u{89e}\u{17b}\x03\x02\x02\x02\u{89f}\u{8a0}\x05\u{20a}\u{106}\x02\u{8a0}\
	\u{8a1}\x07\x11\x02\x02\u{8a1}\u{8a2}\x05\u{1c0}\u{e1}\x02\u{8a2}\u{17d}\
	\x03\x02\x02\x02\u{8a3}\u{8a4}\x05\u{180}\u{c1}\x02\u{8a4}\u{17f}\x03\x02\
	\x02\x02\u{8a5}\u{8a9}\x05\u{184}\u{c3}\x02\u{8a6}\u{8a8}\x05\u{182}\u{c2}\
	\x02\u{8a7}\u{8a6}\x03\x02\x02\x02\u{8a8}\u{8ab}\x03\x02\x02\x02\u{8a9}\
	\u{8a7}\x03\x02\x02\x02\u{8a9}\u{8aa}\x03\x02\x02\x02\u{8aa}\u{181}\x03\
	\x02\x02\x02\u{8ab}\u{8a9}\x03\x02\x02\x02\u{8ac}\u{8ad}\x07\u{be}\x02\x02\
	\u{8ad}\u{8ae}\x05\u{184}\u{c3}\x02\u{8ae}\u{183}\x03\x02\x02\x02\u{8af}\
	\u{8b3}\x05\u{188}\u{c5}\x02\u{8b0}\u{8b2}\x05\u{186}\u{c4}\x02\u{8b1}\u{8b0}\
	\x03\x02\x02\x02\u{8b2}\u{8b5}\x03\x02\x02\x02\u{8b3}\u{8b1}\x03\x02\x02\
	\x02\u{8b3}\u{8b4}\x03\x02\x02\x02\u{8b4}\u{185}\x03\x02\x02\x02\u{8b5}\
	\u{8b3}\x03\x02\x02\x02\u{8b6}\u{8b7}\x07\x2d\x02\x02\u{8b7}\u{8b8}\x05\
	\u{188}\u{c5}\x02\u{8b8}\u{187}\x03\x02\x02\x02\u{8b9}\u{8bf}\x05\u{192}\
	\u{ca}\x02\u{8ba}\u{8bf}\x05\u{18a}\u{c6}\x02\u{8bb}\u{8bf}\x05\u{18c}\u{c7}\
	\x02\u{8bc}\u{8bf}\x05\u{18e}\u{c8}\x02\u{8bd}\u{8bf}\x05\u{190}\u{c9}\x02\
	\u{8be}\u{8b9}\x03\x02\x02\x02\u{8be}\u{8ba}\x03\x02\x02\x02\u{8be}\u{8bb}\
	\x03\x02\x02\x02\u{8be}\u{8bc}\x03\x02\x02\x02\u{8be}\u{8bd}\x03\x02\x02\
	\x02\u{8bf}\u{189}\x03\x02\x02\x02\u{8c0}\u{8c1}\x05\u{192}\u{ca}\x02\u{8c1}\
	\u{8c2}\x09\x18\x02\x02\u{8c2}\u{8c3}\x05\u{192}\u{ca}\x02\u{8c3}\u{18b}\
	\x03\x02\x02\x02\u{8c4}\u{8c5}\x05\u{192}\u{ca}\x02\u{8c5}\u{8c6}\x09\x19\
	\x02\x02\u{8c6}\u{8c7}\x07\x21\x02\x02\u{8c7}\u{8cc}\x05\u{1a6}\u{d4}\x02\
	\u{8c8}\u{8c9}\x07\x0b\x02\x02\u{8c9}\u{8cb}\x05\u{1a6}\u{d4}\x02\u{8ca}\
	\u{8c8}\x03\x02\x02\x02\u{8cb}\u{8ce}\x03\x02\x02\x02\u{8cc}\u{8ca}\x03\
	\x02\x02\x02\u{8cc}\u{8cd}\x03\x02\x02\x02\u{8cd}\u{8cf}\x03\x02\x02\x02\
	\u{8ce}\u{8cc}\x03\x02\x02\x02\u{8cf}\u{8d0}\x07\x0a\x02\x02\u{8d0}\u{18d}\
	\x03\x02\x02\x02\u{8d1}\u{8d2}\x05\u{192}\u{ca}\x02\u{8d2}\u{8d3}\x09\x1a\
	\x02\x02\u{8d3}\u{8d4}\x07\x21\x02\x02\u{8d4}\u{8d5}\x05\u{1a6}\u{d4}\x02\
	\u{8d5}\u{8d6}\x07\x12\x02\x02\u{8d6}\u{8d7}\x05\u{1a6}\u{d4}\x02\u{8d7}\
	\u{8d8}\x07\x0a\x02\x02\u{8d8}\u{18f}\x03\x02\x02\x02\u{8d9}\u{8da}\x07\
	\x03\x02\x02\u{8da}\u{8db}\x07\x14\x02\x02\u{8db}\u{8dc}\x05\u{192}\u{ca}\
	\x02\u{8dc}\u{191}\x03\x02\x02\x02\u{8dd}\u{8e0}\x05\u{194}\u{cb}\x02\u{8de}\
	\u{8df}\x09\x1b\x02\x02\u{8df}\u{8e1}\x05\u{194}\u{cb}\x02\u{8e0}\u{8de}\
	\x03\x02\x02\x02\u{8e0}\u{8e1}\x03\x02\x02\x02\u{8e1}\u{193}\x03\x02\x02\
	\x02\u{8e2}\u{8e6}\x05\u{198}\u{cd}\x02\u{8e3}\u{8e5}\x05\u{196}\u{cc}\x02\
	\u{8e4}\u{8e3}\x03\x02\x02\x02\u{8e5}\u{8e8}\x03\x02\x02\x02\u{8e6}\u{8e4}\
	\x03\x02\x02\x02\u{8e6}\u{8e7}\x03\x02\x02\x02\u{8e7}\u{195}\x03\x02\x02\
	\x02\u{8e8}\u{8e6}\x03\x02\x02\x02\u{8e9}\u{8ea}\x09\x1c\x02\x02\u{8ea}\
	\u{8eb}\x05\u{198}\u{cd}\x02\u{8eb}\u{197}\x03\x02\x02\x02\u{8ec}\u{8f0}\
	\x05\u{19c}\u{cf}\x02\u{8ed}\u{8ef}\x05\u{19a}\u{ce}\x02\u{8ee}\u{8ed}\x03\
	\x02\x02\x02\u{8ef}\u{8f2}\x03\x02\x02\x02\u{8f0}\u{8ee}\x03\x02\x02\x02\
	\u{8f0}\u{8f1}\x03\x02\x02\x02\u{8f1}\u{199}\x03\x02\x02\x02\u{8f2}\u{8f0}\
	\x03\x02\x02\x02\u{8f3}\u{8f4}\x09\x1d\x02\x02\u{8f4}\u{8f5}\x05\u{19c}\
	\u{cf}\x02\u{8f5}\u{19b}\x03\x02\x02\x02\u{8f6}\u{8f9}\x05\u{19e}\u{d0}\
	\x02\u{8f7}\u{8f9}\x05\u{1a4}\u{d3}\x02\u{8f8}\u{8f6}\x03\x02\x02\x02\u{8f8}\
	\u{8f7}\x03\x02\x02\x02\u{8f9}\u{19d}\x03\x02\x02\x02\u{8fa}\u{8fe}\x05\
	\u{1a6}\u{d4}\x02\u{8fb}\u{8fd}\x05\u{1a0}\u{d1}\x02\u{8fc}\u{8fb}\x03\x02\
	\x02\x02\u{8fd}\u{900}\x03\x02\x02\x02\u{8fe}\u{8fc}\x03\x02\x02\x02\u{8fe}\
	\u{8ff}\x03\x02\x02\x02\u{8ff}\u{19f}\x03\x02\x02\x02\u{900}\u{8fe}\x03\
	\x02\x02\x02\u{901}\u{904}\x05\u{1a2}\u{d2}\x02\u{902}\u{904}\x07\x0c\x02\
	\x02\u{903}\u{901}\x03\x02\x02\x02\u{903}\u{902}\x03\x02\x02\x02\u{904}\
	\u{905}\x03\x02\x02\x02\u{905}\u{906}\x05\u{1a6}\u{d4}\x02\u{906}\u{1a1}\
	\x03\x02\x02\x02\u{907}\u{908}\x09\x1e\x02\x02\u{908}\u{1a3}\x03\x02\x02\
	\x02\u{909}\u{90a}\x07\x03\x02\x02\u{90a}\u{90b}\x05\u{1a2}\u{d2}\x02\u{90b}\
	\u{90c}\x05\u{1a6}\u{d4}\x02\u{90c}\u{1a5}\x03\x02\x02\x02\u{90d}\u{90f}\
	\x09\x1c\x02\x02\u{90e}\u{90d}\x03\x02\x02\x02\u{90e}\u{90f}\x03\x02\x02\
	\x02\u{90f}\u{910}\x03\x02\x02\x02\u{910}\u{911}\x05\u{1a8}\u{d5}\x02\u{911}\
	\u{1a7}\x03\x02\x02\x02\u{912}\u{916}\x05\u{1aa}\u{d6}\x02\u{913}\u{916}\
	\x05\u{1ac}\u{d7}\x02\u{914}\u{916}\x05\u{1b8}\u{dd}\x02\u{915}\u{912}\x03\
	\x02\x02\x02\u{915}\u{913}\x03\x02\x02\x02\u{915}\u{914}\x03\x02\x02\x02\
	\u{916}\u{1a9}\x03\x02\x02\x02\u{917}\u{91b}\x05\u{1bc}\u{df}\x02\u{918}\
	\u{91b}\x05\u{1ca}\u{e6}\x02\u{919}\u{91b}\x05\u{1b6}\u{dc}\x02\u{91a}\u{917}\
	\x03\x02\x02\x02\u{91a}\u{918}\x03\x02\x02\x02\u{91a}\u{919}\x03\x02\x02\
	\x02\u{91b}\u{1ab}\x03\x02\x02\x02\u{91c}\u{91e}\x05\u{1aa}\u{d6}\x02\u{91d}\
	\u{91f}\x05\u{1ae}\u{d8}\x02\u{91e}\u{91d}\x03\x02\x02\x02\u{91f}\u{920}\
	\x03\x02\x02\x02\u{920}\u{91e}\x03\x02\x02\x02\u{920}\u{921}\x03\x02\x02\
	\x02\u{921}\u{1ad}\x03\x02\x02\x02\u{922}\u{926}\x05\u{1b0}\u{d9}\x02\u{923}\
	\u{926}\x05\u{1b2}\u{da}\x02\u{924}\u{926}\x05\u{1b4}\u{db}\x02\u{925}\u{922}\
	\x03\x02\x02\x02\u{925}\u{923}\x03\x02\x02\x02\u{925}\u{924}\x03\x02\x02\
	\x02\u{926}\u{1af}\x03\x02\x02\x02\u{927}\u{928}\x07\x11\x02\x02\u{928}\
	\u{929}\x05\u{21c}\u{10f}\x02\u{929}\u{1b1}\x03\x02\x02\x02\u{92a}\u{92b}\
	\x07\x20\x02\x02\u{92b}\u{92c}\x05\u{17e}\u{c0}\x02\u{92c}\u{92d}\x07\x07\
	\x02\x02\u{92d}\u{1b3}\x03\x02\x02\x02\u{92e}\u{92f}\x07\x11\x02\x02\u{92f}\
	\u{930}\x07\x20\x02\x02\u{930}\u{931}\x05\u{17e}\u{c0}\x02\u{931}\u{932}\
	\x07\x07\x02\x02\u{932}\u{1b5}\x03\x02\x02\x02\u{933}\u{935}\x07\u{fc}\x02\
	\x02\u{934}\u{936}\x05\u{1ba}\u{de}\x02\u{935}\u{934}\x03\x02\x02\x02\u{935}\
	\u{936}\x03\x02\x02\x02\u{936}\u{937}\x03\x02\x02\x02\u{937}\u{938}\x07\
	\x21\x02\x02\u{938}\u{939}\x05\x4e\x28\x02\u{939}\u{93a}\x07\x0a\x02\x02\
	\u{93a}\u{1b7}\x03\x02\x02\x02\u{93b}\u{93d}\x07\u{fd}\x02\x02\u{93c}\u{93e}\
	\x05\u{1ba}\u{de}\x02\u{93d}\u{93c}\x03\x02\x02\x02\u{93d}\u{93e}\x03\x02\
	\x02\x02\u{93e}\u{93f}\x03\x02\x02\x02\u{93f}\u{940}\x07\x21\x02\x02\u{940}\
	\u{941}\x05\x4e\x28\x02\u{941}\u{942}\x07\x0a\x02\x02\u{942}\u{1b9}\x03\
	\x02\x02\x02\u{943}\u{944}\x07\u{8b}\x02\x02\u{944}\u{945}\x07\x13\x02\x02\
	\u{945}\u{946}\x07\u{a5}\x02\x02\u{946}\u{1bb}\x03\x02\x02\x02\u{947}\u{94b}\
	\x05\u{1c0}\u{e1}\x02\u{948}\u{94a}\x05\u{1be}\u{e0}\x02\u{949}\u{948}\x03\
	\x02\x02\x02\u{94a}\u{94d}\x03\x02\x02\x02\u{94b}\u{949}\x03\x02\x02\x02\
	\u{94b}\u{94c}\x03\x02\x02\x02\u{94c}\u{1bd}\x03\x02\x02\x02\u{94d}\u{94b}\
	\x03\x02\x02\x02\u{94e}\u{94f}\x07\x11\x02\x02\u{94f}\u{950}\x05\u{1c0}\
	\u{e1}\x02\u{950}\u{1bf}\x03\x02\x02\x02\u{951}\u{954}\x05\u{1c2}\u{e2}\
	\x02\u{952}\u{954}\x05\u{1c6}\u{e4}\x02\u{953}\u{951}\x03\x02\x02\x02\u{953}\
	\u{952}\x03\x02\x02\x02\u{954}\u{1c1}\x03\x02\x02\x02\u{955}\u{956}\x05\
	\u{20a}\u{106}\x02\u{956}\u{95f}\x07\x21\x02\x02\u{957}\u{95c}\x05\u{1c4}\
	\u{e3}\x02\u{958}\u{959}\x07\x0b\x02\x02\u{959}\u{95b}\x05\u{1c4}\u{e3}\
	\x02\u{95a}\u{958}\x03\x02\x02\x02\u{95b}\u{95e}\x03\x02\x02\x02\u{95c}\
	\u{95a}\x03\x02\x02\x02\u{95c}\u{95d}\x03\x02\x02\x02\u{95d}\u{960}\x03\
	\x02\x02\x02\u{95e}\u{95c}\x03\x02\x02\x02\u{95f}\u{957}\x03\x02\x02\x02\
	\u{95f}\u{960}\x03\x02\x02\x02\u{960}\u{961}\x03\x02\x02\x02\u{961}\u{962}\
	\x07\x0a\x02\x02\u{962}\u{1c3}\x03\x02\x02\x02\u{963}\u{966}\x05\u{176}\
	\u{bc}\x02\u{964}\u{966}\x05\u{1c8}\u{e5}\x02\u{965}\u{963}\x03\x02\x02\
	\x02\u{965}\u{964}\x03\x02\x02\x02\u{966}\u{1c5}\x03\x02\x02\x02\u{967}\
	\u{968}\x07\x44\x02\x02\u{968}\u{96a}\x07\x21\x02\x02\u{969}\u{96b}\x05\
	\u{176}\u{bc}\x02\u{96a}\u{969}\x03\x02\x02\x02\u{96a}\u{96b}\x03\x02\x02\
	\x02\u{96b}\u{96c}\x03\x02\x02\x02\u{96c}\u{96d}\x07\x0a\x02\x02\u{96d}\
	\u{1c7}\x03\x02\x02\x02\u{96e}\u{96f}\x07\x03\x02\x02\u{96f}\u{1c9}\x03\
	\x02\x02\x02\u{970}\u{978}\x05\u{22a}\u{116}\x02\u{971}\u{978}\x05\u{1cc}\
	\u{e7}\x02\u{972}\u{978}\x05\u{1f0}\u{f9}\x02\u{973}\u{978}\x05\u{1f6}\u{fc}\
	\x02\u{974}\u{978}\x05\u{1ee}\u{f8}\x02\u{975}\u{978}\x05\u{1fc}\u{ff}\x02\
	\u{976}\u{978}\x05\u{1d0}\u{e9}\x02\u{977}\u{970}\x03\x02\x02\x02\u{977}\
	\u{971}\x03\x02\x02\x02\u{977}\u{972}\x03\x02\x02\x02\u{977}\u{973}\x03\
	\x02\x02\x02\u{977}\u{974}\x03\x02\x02\x02\u{977}\u{975}\x03\x02\x02\x02\
	\u{977}\u{976}\x03\x02\x02\x02\u{978}\u{1cb}\x03\x02\x02\x02\u{979}\u{97b}\
	\x05\u{20a}\u{106}\x02\u{97a}\u{97c}\x05\u{1ce}\u{e8}\x02\u{97b}\u{97a}\
	\x03\x02\x02\x02\u{97b}\u{97c}\x03\x02\x02\x02\u{97c}\u{1cd}\x03\x02\x02\
	\x02\u{97d}\u{97e}\x07\x48\x02\x02\u{97e}\u{97f}\x07\x13\x02\x02\u{97f}\
	\u{980}\x09\x1f\x02\x02\u{980}\u{1cf}\x03\x02\x02\x02\u{981}\u{982}\x07\
	\x21\x02\x02\u{982}\u{983}\x05\x4c\x27\x02\u{983}\u{984}\x07\x0a\x02\x02\
	\u{984}\u{1d1}\x03\x02\x02\x02\u{985}\u{986}\x07\u{d8}\x02\x02\u{986}\u{987}\
	\x05\u{20a}\u{106}\x02\u{987}\u{988}\x07\x61\x02\x02\u{988}\u{989}\x05\u{17e}\
	\u{c0}\x02\u{989}\u{98a}\x07\u{f8}\x02\x02\u{98a}\u{98b}\x05\u{17e}\u{c0}\
	\x02\u{98b}\u{98c}\x07\u{ef}\x02\x02\u{98c}\u{98d}\x05\u{17e}\u{c0}\x02\
	\u{98d}\u{1d3}\x03\x02\x02\x02\u{98e}\u{991}\x05\u{1e2}\u{f2}\x02\u{98f}\
	\u{991}\x05\u{1d6}\u{ec}\x02\u{990}\u{98e}\x03\x02\x02\x02\u{990}\u{98f}\
	\x03\x02\x02\x02\u{991}\u{1d5}\x03\x02\x02\x02\u{992}\u{994}\x05\u{1e2}\
	\u{f2}\x02\u{993}\u{995}\x05\u{1d8}\u{ed}\x02\u{994}\u{993}\x03\x02\x02\
	\x02\u{995}\u{996}\x03\x02\x02\x02\u{996}\u{994}\x03\x02\x02\x02\u{996}\
	\u{997}\x03\x02\x02\x02\u{997}\u{1d7}\x03\x02\x02\x02\u{998}\u{99c}\x05\
	\u{1da}\u{ee}\x02\u{999}\u{99c}\x05\u{1dc}\u{ef}\x02\u{99a}\u{99c}\x05\u{1de}\
	\u{f0}\x02\u{99b}\u{998}\x03\x02\x02\x02\u{99b}\u{999}\x03\x02\x02\x02\u{99b}\
	\u{99a}\x03\x02\x02\x02\u{99c}\u{1d9}\x03\x02\x02\x02\u{99d}\u{99e}\x07\
	\x11\x02\x02\u{99e}\u{99f}\x05\u{1e0}\u{f1}\x02\u{99f}\u{1db}\x03\x02\x02\
	\x02\u{9a0}\u{9a1}\x07\x20\x02\x02\u{9a1}\u{9a2}\x05\u{17e}\u{c0}\x02\u{9a2}\
	\u{9a3}\x07\x07\x02\x02\u{9a3}\u{1dd}\x03\x02\x02\x02\u{9a4}\u{9a5}\x07\
	\x11\x02\x02\u{9a5}\u{9a6}\x07\x20\x02\x02\u{9a6}\u{9a7}\x05\u{17e}\u{c0}\
	\x02\u{9a7}\u{9a8}\x07\x07\x02\x02\u{9a8}\u{1df}\x03\x02\x02\x02\u{9a9}\
	\u{9ad}\x05\u{1e4}\u{f3}\x02\u{9aa}\u{9ad}\x05\u{21e}\u{110}\x02\u{9ab}\
	\u{9ad}\x05\u{1e6}\u{f4}\x02\u{9ac}\u{9a9}\x03\x02\x02\x02\u{9ac}\u{9aa}\
	\x03\x02\x02\x02\u{9ac}\u{9ab}\x03\x02\x02\x02\u{9ad}\u{1e1}\x03\x02\x02\
	\x02\u{9ae}\u{9af}\x05\u{1e0}\u{f1}\x02\u{9af}\u{1e3}\x03\x02\x02\x02\u{9b0}\
	\u{9b1}\x07\x04\x02\x02\u{9b1}\u{1e5}\x03\x02\x02\x02\u{9b2}\u{9b3}\x09\
	\x20\x02\x02\u{9b3}\u{1e7}\x03\x02\x02\x02\u{9b4}\u{9b8}\x05\u{20e}\u{108}\
	\x02\u{9b5}\u{9b8}\x05\u{1bc}\u{df}\x02\u{9b6}\u{9b8}\x05\u{1ea}\u{f6}\x02\
	\u{9b7}\u{9b4}\x03\x02\x02\x02\u{9b7}\u{9b5}\x03\x02\x02\x02\u{9b7}\u{9b6}\
	\x03\x02\x02\x02\u{9b8}\u{1e9}\x03\x02\x02\x02\u{9b9}\u{9ba}\x05\u{1bc}\
	\u{df}\x02\u{9ba}\u{9bb}\x07\x11\x02\x02\u{9bb}\u{9bc}\x05\u{1ec}\u{f7}\
	\x02\u{9bc}\u{1eb}\x03\x02\x02\x02\u{9bd}\u{9c0}\x05\u{222}\u{112}\x02\u{9be}\
	\u{9c0}\x05\u{1e0}\u{f1}\x02\u{9bf}\u{9bd}\x03\x02\x02\x02\u{9bf}\u{9be}\
	\x03\x02\x02\x02\u{9c0}\u{1ed}\x03\x02\x02\x02\u{9c1}\u{9c2}\x07\x43\x02\
	\x02\u{9c2}\u{9c3}\x07\u{13d}\x02\x02\u{9c3}\u{9c4}\x05\u{1f2}\u{fa}\x02\
	\u{9c4}\u{1ef}\x03\x02\x02\x02\u{9c5}\u{9c9}\x07\x49\x02\x02\u{9c6}\u{9c8}\
	\x05\u{172}\u{ba}\x02\u{9c7}\u{9c6}\x03\x02\x02\x02\u{9c8}\u{9cb}\x03\x02\
	\x02\x02\u{9c9}\u{9c7}\x03\x02\x02\x02\u{9c9}\u{9ca}\x03\x02\x02\x02\u{9ca}\
	\u{9cc}\x03\x02\x02\x02\u{9cb}\u{9c9}\x03\x02\x02\x02\u{9cc}\u{9cd}\x05\
	\u{1f2}\u{fa}\x02\u{9cd}\u{9cf}\x07\x20\x02\x02\u{9ce}\u{9d0}\x05\u{228}\
	\u{115}\x02\u{9cf}\u{9ce}\x03\x02\x02\x02\u{9cf}\u{9d0}\x03\x02\x02\x02\
	\u{9d0}\u{9d5}\x03\x02\x02\x02\u{9d1}\u{9d2}\x07\x0b\x02\x02\u{9d2}\u{9d4}\
	\x05\u{228}\u{115}\x02\u{9d3}\u{9d1}\x03\x02\x02\x02\u{9d4}\u{9d7}\x03\x02\
	\x02\x02\u{9d5}\u{9d3}\x03\x02\x02\x02\u{9d5}\u{9d6}\x03\x02\x02\x02\u{9d6}\
	\u{9d9}\x03\x02\x02\x02\u{9d7}\u{9d5}\x03\x02\x02\x02\u{9d8}\u{9da}\x07\
	\x0b\x02\x02\u{9d9}\u{9d8}\x03\x02\x02\x02\u{9d9}\u{9da}\x03\x02\x02\x02\
	\u{9da}\u{9db}\x03\x02\x02\x02\u{9db}\u{9dc}\x07\x07\x02\x02\u{9dc}\u{1f1}\
	\x03\x02\x02\x02\u{9dd}\u{9df}\x07\x21\x02\x02\u{9de}\u{9e0}\x05\u{1f4}\
	\u{fb}\x02\u{9df}\u{9de}\x03\x02\x02\x02\u{9df}\u{9e0}\x03\x02\x02\x02\u{9e0}\
	\u{9e5}\x03\x02\x02\x02\u{9e1}\u{9e2}\x07\x0b\x02\x02\u{9e2}\u{9e4}\x05\
	\u{1f4}\u{fb}\x02\u{9e3}\u{9e1}\x03\x02\x02\x02\u{9e4}\u{9e7}\x03\x02\x02\
	\x02\u{9e5}\u{9e3}\x03\x02\x02\x02\u{9e5}\u{9e6}\x03\x02\x02\x02\u{9e6}\
	\u{9e9}\x03\x02\x02\x02\u{9e7}\u{9e5}\x03\x02\x02\x02\u{9e8}\u{9ea}\x07\
	\x0b\x02\x02\u{9e9}\u{9e8}\x03\x02\x02\x02\u{9e9}\u{9ea}\x03\x02\x02\x02\
	\u{9ea}\u{9eb}\x03\x02\x02\x02\u{9eb}\u{9ec}\x07\x0a\x02\x02\u{9ec}\u{1f3}\
	\x03\x02\x02\x02\u{9ed}\u{9ee}\x05\u{208}\u{105}\x02\u{9ee}\u{9ef}\x07\x0c\
	\x02\x02\u{9ef}\u{9f0}\x05\u{204}\u{103}\x02\u{9f0}\u{1f5}\x03\x02\x02\x02\
	\u{9f1}\u{9f5}\x09\x21\x02\x02\u{9f2}\u{9f4}\x05\u{172}\u{ba}\x02\u{9f3}\
	\u{9f2}\x03\x02\x02\x02\u{9f4}\u{9f7}\x03\x02\x02\x02\u{9f5}\u{9f3}\x03\
	\x02\x02\x02\u{9f5}\u{9f6}\x03\x02\x02\x02\u{9f6}\u{9f8}\x03\x02\x02\x02\
	\u{9f7}\u{9f5}\x03\x02\x02\x02\u{9f8}\u{9f9}\x05\u{1f2}\u{fa}\x02\u{9f9}\
	\u{9fa}\x07\x20\x02\x02\u{9fa}\u{9ff}\x05\u{248}\u{125}\x02\u{9fb}\u{9fc}\
	\x07\x0b\x02\x02\u{9fc}\u{9fe}\x05\u{248}\u{125}\x02\u{9fd}\u{9fb}\x03\x02\
	\x02\x02\u{9fe}\u{a01}\x03\x02\x02\x02\u{9ff}\u{9fd}\x03\x02\x02\x02\u{9ff}\
	\u{a00}\x03\x02\x02\x02\u{a00}\u{a02}\x03\x02\x02\x02\u{a01}\u{9ff}\x03\
	\x02\x02\x02\u{a02}\u{a04}\x07\x07\x02\x02\u{a03}\u{a05}\x05\u{1f8}\u{fd}\
	\x02\u{a04}\u{a03}\x03\x02\x02\x02\u{a04}\u{a05}\x03\x02\x02\x02\u{a05}\
	\u{1f7}\x03\x02\x02\x02\u{a06}\u{a07}\x07\u{106}\x02\x02\u{a07}\u{a13}\x07\
	\x21\x02\x02\u{a08}\u{a0d}\x05\u{1fa}\u{fe}\x02\u{a09}\u{a0a}\x07\x0b\x02\
	\x02\u{a0a}\u{a0c}\x05\u{1fa}\u{fe}\x02\u{a0b}\u{a09}\x03\x02\x02\x02\u{a0c}\
	\u{a0f}\x03\x02\x02\x02\u{a0d}\u{a0b}\x03\x02\x02\x02\u{a0d}\u{a0e}\x03\
	\x02\x02\x02\u{a0e}\u{a11}\x03\x02\x02\x02\u{a0f}\u{a0d}\x03\x02\x02\x02\
	\u{a10}\u{a12}\x07\x0b\x02\x02\u{a11}\u{a10}\x03\x02\x02\x02\u{a11}\u{a12}\
	\x03\x02\x02\x02\u{a12}\u{a14}\x03\x02\x02\x02\u{a13}\u{a08}\x03\x02\x02\
	\x02\u{a13}\u{a14}\x03\x02\x02\x02\u{a14}\u{a15}\x03\x02\x02\x02\u{a15}\
	\u{a16}\x07\x0a\x02\x02\u{a16}\u{1f9}\x03\x02\x02\x02\u{a17}\u{a18}\x05\
	\u{208}\u{105}\x02\u{a18}\u{a1c}\x07\x13\x02\x02\u{a19}\u{a1d}\x05\u{248}\
	\u{125}\x02\u{a1a}\u{a1d}\x09\x22\x02\x02\u{a1b}\u{a1d}\x05\u{208}\u{105}\
	\x02\u{a1c}\u{a19}\x03\x02\x02\x02\u{a1c}\u{a1a}\x03\x02\x02\x02\u{a1c}\
	\u{a1b}\x03\x02\x02\x02\u{a1d}\u{1fb}\x03\x02\x02\x02\u{a1e}\u{a1f}\x07\
	\u{9e}\x02\x02\u{a1f}\u{a20}\x07\x21\x02\x02\u{a20}\u{a21}\x05\u{248}\u{125}\
	\x02\u{a21}\u{a22}\x07\x0a\x02\x02\u{a22}\u{a23}\x05\u{1fe}\u{100}\x02\u{a23}\
	\u{a24}\x05\u{200}\u{101}\x02\u{a24}\u{a25}\x05\u{202}\u{102}\x02\u{a25}\
	\u{1fd}\x03\x02\x02\x02\u{a26}\u{a27}\x07\x37\x02\x02\u{a27}\u{a28}\x07\
	\x21\x02\x02\u{a28}\u{a29}\x05\x4c\x27\x02\u{a29}\u{a2a}\x07\x0a\x02\x02\
	\u{a2a}\u{1ff}\x03\x02\x02\x02\u{a2b}\u{a2c}\x07\x4d\x02\x02\u{a2c}\u{a2d}\
	\x07\x21\x02\x02\u{a2d}\u{a2e}\x05\x4c\x27\x02\u{a2e}\u{a2f}\x07\x0a\x02\
	\x02\u{a2f}\u{201}\x03\x02\x02\x02\u{a30}\u{a31}\x07\x2a\x02\x02\u{a31}\
	\u{a32}\x07\x21\x02\x02\u{a32}\u{a33}\x05\u{150}\u{a9}\x02\u{a33}\u{a34}\
	\x07\x0a\x02\x02\u{a34}\u{203}\x03\x02\x02\x02\u{a35}\u{a36}\x09\x23\x02\
	\x02\u{a36}\u{205}\x03\x02\x02\x02\u{a37}\u{a38}\x09\x24\x02\x02\u{a38}\
	\u{207}\x03\x02\x02\x02\u{a39}\u{a3a}\x05\u{21e}\u{110}\x02\u{a3a}\u{209}\
	\x03\x02\x02\x02\u{a3b}\u{a3c}\x05\u{21c}\u{10f}\x02\u{a3c}\u{20b}\x03\x02\
	\x02\x02\u{a3d}\u{a3e}\x05\u{21e}\u{110}\x02\u{a3e}\u{20d}\x03\x02\x02\x02\
	\u{a3f}\u{a40}\x05\u{222}\u{112}\x02\u{a40}\u{20f}\x03\x02\x02\x02\u{a41}\
	\u{a44}\x05\u{20a}\u{106}\x02\u{a42}\u{a44}\x05\u{20e}\u{108}\x02\u{a43}\
	\u{a41}\x03\x02\x02\x02\u{a43}\u{a42}\x03\x02\x02\x02\u{a44}\u{211}\x03\
	\x02\x02\x02\u{a45}\u{a46}\x07\u{13e}\x02\x02\u{a46}\u{213}\x03\x02\x02\
	\x02\u{a47}\u{a48}\x09\x25\x02\x02\u{a48}\u{215}\x03\x02\x02\x02\u{a49}\
	\u{a4a}\x09\x26\x02\x02\u{a4a}\u{217}\x03\x02\x02\x02\u{a4b}\u{a4c}\x07\
	\x20\x02\x02\u{a4c}\u{a4d}\x05\u{248}\u{125}\x02\u{a4d}\u{a4e}\x07\x07\x02\
	\x02\u{a4e}\u{219}\x03\x02\x02\x02\u{a4f}\u{a52}\x05\u{212}\u{10a}\x02\u{a50}\
	\u{a52}\x05\u{214}\u{10b}\x02\u{a51}\u{a4f}\x03\x02\x02\x02\u{a51}\u{a50}\
	\x03\x02\x02\x02\u{a52}\u{21b}\x03\x02\x02\x02\u{a53}\u{a57}\x05\u{212}\
	\u{10a}\x02\u{a54}\u{a57}\x05\u{214}\u{10b}\x02\u{a55}\u{a57}\x05\u{218}\
	\u{10d}\x02\u{a56}\u{a53}\x03\x02\x02\x02\u{a56}\u{a54}\x03\x02\x02\x02\
	\u{a56}\u{a55}\x03\x02\x02\x02\u{a57}\u{21d}\x03\x02\x02\x02\u{a58}\u{a5d}\
	\x05\u{212}\u{10a}\x02\u{a59}\u{a5d}\x05\u{214}\u{10b}\x02\u{a5a}\u{a5d}\
	\x05\u{216}\u{10c}\x02\u{a5b}\u{a5d}\x05\u{218}\u{10d}\x02\u{a5c}\u{a58}\
	\x03\x02\x02\x02\u{a5c}\u{a59}\x03\x02\x02\x02\u{a5c}\u{a5a}\x03\x02\x02\
	\x02\u{a5c}\u{a5b}\x03\x02\x02\x02\u{a5d}\u{21f}\x03\x02\x02\x02\u{a5e}\
	\u{a62}\x05\u{212}\u{10a}\x02\u{a5f}\u{a62}\x05\u{214}\u{10b}\x02\u{a60}\
	\u{a62}\x05\u{216}\u{10c}\x02\u{a61}\u{a5e}\x03\x02\x02\x02\u{a61}\u{a5f}\
	\x03\x02\x02\x02\u{a61}\u{a60}\x03\x02\x02\x02\u{a62}\u{221}\x03\x02\x02\
	\x02\u{a63}\u{a65}\x05\u{224}\u{113}\x02\u{a64}\u{a63}\x03\x02\x02\x02\u{a64}\
	\u{a65}\x03\x02\x02\x02\u{a65}\u{a66}\x03\x02\x02\x02\u{a66}\u{a6a}\x07\
	\x03\x02\x02\u{a67}\u{a69}\x05\u{226}\u{114}\x02\u{a68}\u{a67}\x03\x02\x02\
	\x02\u{a69}\u{a6c}\x03\x02\x02\x02\u{a6a}\u{a68}\x03\x02\x02\x02\u{a6a}\
	\u{a6b}\x03\x02\x02\x02\u{a6b}\u{223}\x03\x02\x02\x02\u{a6c}\u{a6a}\x03\
	\x02\x02\x02\u{a6d}\u{a71}\x07\u{13e}\x02\x02\u{a6e}\u{a71}\x05\u{214}\u{10b}\
	\x02\u{a6f}\u{a71}\x05\u{216}\u{10c}\x02\u{a70}\u{a6d}\x03\x02\x02\x02\u{a70}\
	\u{a6e}\x03\x02\x02\x02\u{a70}\u{a6f}\x03\x02\x02\x02\u{a71}\u{225}\x03\
	\x02\x02\x02\u{a72}\u{a78}\x07\u{13e}\x02\x02\u{a73}\u{a78}\x05\u{214}\u{10b}\
	\x02\u{a74}\u{a78}\x05\u{216}\u{10c}\x02\u{a75}\u{a78}\x07\u{133}\x02\x02\
	\u{a76}\u{a78}\x07\x03\x02\x02\u{a77}\u{a72}\x03\x02\x02\x02\u{a77}\u{a73}\
	\x03\x02\x02\x02\u{a77}\u{a74}\x03\x02\x02\x02\u{a77}\u{a75}\x03\x02\x02\
	\x02\u{a77}\u{a76}\x03\x02\x02\x02\u{a78}\u{227}\x03\x02\x02\x02\u{a79}\
	\u{a7c}\x05\u{230}\u{119}\x02\u{a7a}\u{a7c}\x05\u{22a}\u{116}\x02\u{a7b}\
	\u{a79}\x03\x02\x02\x02\u{a7b}\u{a7a}\x03\x02\x02\x02\u{a7c}\u{229}\x03\
	\x02\x02\x02\u{a7d}\u{a89}\x05\u{232}\u{11a}\x02\u{a7e}\u{a89}\x05\u{234}\
	\u{11b}\x02\u{a7f}\u{a89}\x05\u{236}\u{11c}\x02\u{a80}\u{a89}\x05\u{238}\
	\u{11d}\x02\u{a81}\u{a89}\x05\u{23a}\u{11e}\x02\u{a82}\u{a89}\x05\u{23c}\
	\u{11f}\x02\u{a83}\u{a89}\x05\u{23e}\u{120}\x02\u{a84}\u{a89}\x05\u{240}\
	\u{121}\x02\u{a85}\u{a89}\x05\u{242}\u{122}\x02\u{a86}\u{a89}\x05\u{248}\
	\u{125}\x02\u{a87}\u{a89}\x05\u{24a}\u{126}\x02\u{a88}\u{a7d}\x03\x02\x02\
	\x02\u{a88}\u{a7e}\x03\x02\x02\x02\u{a88}\u{a7f}\x03\x02\x02\x02\u{a88}\
	\u{a80}\x03\x02\x02\x02\u{a88}\u{a81}\x03\x02\x02\x02\u{a88}\u{a82}\x03\
	\x02\x02\x02\u{a88}\u{a83}\x03\x02\x02\x02\u{a88}\u{a84}\x03\x02\x02\x02\
	\u{a88}\u{a85}\x03\x02\x02\x02\u{a88}\u{a86}\x03\x02\x02\x02\u{a88}\u{a87}\
	\x03\x02\x02\x02\u{a89}\u{22b}\x03\x02\x02\x02\u{a8a}\u{a92}\x05\u{232}\
	\u{11a}\x02\u{a8b}\u{a92}\x05\u{234}\u{11b}\x02\u{a8c}\u{a92}\x05\u{236}\
	\u{11c}\x02\u{a8d}\u{a92}\x05\u{238}\u{11d}\x02\u{a8e}\u{a92}\x05\u{230}\
	\u{119}\x02\u{a8f}\u{a92}\x05\u{23a}\u{11e}\x02\u{a90}\u{a92}\x05\u{23c}\
	\u{11f}\x02\u{a91}\u{a8a}\x03\x02\x02\x02\u{a91}\u{a8b}\x03\x02\x02\x02\
	\u{a91}\u{a8c}\x03\x02\x02\x02\u{a91}\u{a8d}\x03\x02\x02\x02\u{a91}\u{a8e}\
	\x03\x02\x02\x02\u{a91}\u{a8f}\x03\x02\x02\x02\u{a91}\u{a90}\x03\x02\x02\
	\x02\u{a92}\u{22d}\x03\x02\x02\x02\u{a93}\u{a99}\x05\u{232}\u{11a}\x02\u{a94}\
	\u{a99}\x05\u{234}\u{11b}\x02\u{a95}\u{a99}\x05\u{236}\u{11c}\x02\u{a96}\
	\u{a99}\x05\u{238}\u{11d}\x02\u{a97}\u{a99}\x05\u{230}\u{119}\x02\u{a98}\
	\u{a93}\x03\x02\x02\x02\u{a98}\u{a94}\x03\x02\x02\x02\u{a98}\u{a95}\x03\
	\x02\x02\x02\u{a98}\u{a96}\x03\x02\x02\x02\u{a98}\u{a97}\x03\x02\x02\x02\
	\u{a99}\u{22f}\x03\x02\x02\x02\u{a9a}\u{a9d}\x05\u{244}\u{123}\x02\u{a9b}\
	\u{a9d}\x05\u{246}\u{124}\x02\u{a9c}\u{a9a}\x03\x02\x02\x02\u{a9c}\u{a9b}\
	\x03\x02\x02\x02\u{a9d}\u{231}\x03\x02\x02\x02\u{a9e}\u{a9f}\x07\u{133}\
	\x02\x02\u{a9f}\u{233}\x03\x02\x02\x02\u{aa0}\u{aa1}\x07\u{134}\x02\x02\
	\u{aa1}\u{235}\x03\x02\x02\x02\u{aa2}\u{aa3}\x07\u{135}\x02\x02\u{aa3}\u{237}\
	\x03\x02\x02\x02\u{aa4}\u{aa5}\x07\u{136}\x02\x02\u{aa5}\u{239}\x03\x02\
	\x02\x02\u{aa6}\u{aa7}\x07\u{139}\x02\x02\u{aa7}\u{23b}\x03\x02\x02\x02\
	\u{aa8}\u{aa9}\x07\u{13a}\x02\x02\u{aa9}\u{23d}\x03\x02\x02\x02\u{aaa}\u{aab}\
	\x07\u{138}\x02\x02\u{aab}\u{23f}\x03\x02\x02\x02\u{aac}\u{aad}\x07\u{13d}\
	\x02\x02\u{aad}\u{241}\x03\x02\x02\x02\u{aae}\u{aaf}\x07\u{13b}\x02\x02\
	\u{aaf}\u{243}\x03\x02\x02\x02\u{ab0}\u{ab1}\x09\x1c\x02\x02\u{ab1}\u{ab2}\
	\x07\u{133}\x02\x02\u{ab2}\u{245}\x03\x02\x02\x02\u{ab3}\u{ab4}\x09\x1c\
	\x02\x02\u{ab4}\u{ab5}\x07\u{135}\x02\x02\u{ab5}\u{247}\x03\x02\x02\x02\
	\u{ab6}\u{aba}\x07\u{137}\x02\x02\u{ab7}\u{ab9}\x07\u{137}\x02\x02\u{ab8}\
	\u{ab7}\x03\x02\x02\x02\u{ab9}\u{abc}\x03\x02\x02\x02\u{aba}\u{ab8}\x03\
	\x02\x02\x02\u{aba}\u{abb}\x03\x02\x02\x02\u{abb}\u{249}\x03\x02\x02\x02\
	\u{abc}\u{aba}\x03\x02\x02\x02\u{abd}\u{abe}\x07\u{11f}\x02\x02\u{abe}\u{abf}\
	\x07\x21\x02\x02\u{abf}\u{ac0}\x05\u{24c}\u{127}\x02\u{ac0}\u{ac1}\x07\x0a\
	\x02\x02\u{ac1}\u{24b}\x03\x02\x02\x02\u{ac2}\u{ace}\x05\u{252}\u{12a}\x02\
	\u{ac3}\u{ace}\x05\u{254}\u{12b}\x02\u{ac4}\u{ace}\x05\u{256}\u{12c}\x02\
	\u{ac5}\u{ace}\x05\u{258}\u{12d}\x02\u{ac6}\u{ace}\x05\u{260}\u{131}\x02\
	\u{ac7}\u{ace}\x05\u{25a}\u{12e}\x02\u{ac8}\u{ace}\x05\u{24e}\u{128}\x02\
	\u{ac9}\u{ace}\x05\u{262}\u{132}\x02\u{aca}\u{ace}\x05\u{25c}\u{12f}\x02\
	\u{acb}\u{ace}\x05\u{25e}\u{130}\x02\u{acc}\u{ace}\x05\u{24a}\u{126}\x02\
	\u{acd}\u{ac2}\x03\x02\x02\x02\u{acd}\u{ac3}\x03\x02\x02\x02\u{acd}\u{ac4}\
	\x03\x02\x02\x02\u{acd}\u{ac5}\x03\x02\x02\x02\u{acd}\u{ac6}\x03\x02\x02\
	\x02\u{acd}\u{ac7}\x03\x02\x02\x02\u{acd}\u{ac8}\x03\x02\x02\x02\u{acd}\
	\u{ac9}\x03\x02\x02\x02\u{acd}\u{aca}\x03\x02\x02\x02\u{acd}\u{acb}\x03\
	\x02\x02\x02\u{acd}\u{acc}\x03\x02\x02\x02\u{ace}\u{24d}\x03\x02\x02\x02\
	\u{acf}\u{ad8}\x07\x1f\x02\x02\u{ad0}\u{ad5}\x05\u{250}\u{129}\x02\u{ad1}\
	\u{ad2}\x07\x0b\x02\x02\u{ad2}\u{ad4}\x05\u{250}\u{129}\x02\u{ad3}\u{ad1}\
	\x03\x02\x02\x02\u{ad4}\u{ad7}\x03\x02\x02\x02\u{ad5}\u{ad3}\x03\x02\x02\
	\x02\u{ad5}\u{ad6}\x03\x02\x02\x02\u{ad6}\u{ad9}\x03\x02\x02\x02\u{ad7}\
	\u{ad5}\x03\x02\x02\x02\u{ad8}\u{ad0}\x03\x02\x02\x02\u{ad8}\u{ad9}\x03\
	\x02\x02\x02\u{ad9}\u{ada}\x03\x02\x02\x02\u{ada}\u{adb}\x07\x06\x02\x02\
	\u{adb}\u{24f}\x03\x02\x02\x02\u{adc}\u{add}\x07\u{137}\x02\x02\u{add}\u{ade}\
	\x07\x0c\x02\x02\u{ade}\u{adf}\x05\u{24c}\u{127}\x02\u{adf}\u{251}\x03\x02\
	\x02\x02\u{ae0}\u{ae9}\x07\x20\x02\x02\u{ae1}\u{ae6}\x05\u{24c}\u{127}\x02\
	\u{ae2}\u{ae3}\x07\x0b\x02\x02\u{ae3}\u{ae5}\x05\u{24c}\u{127}\x02\u{ae4}\
	\u{ae2}\x03\x02\x02\x02\u{ae5}\u{ae8}\x03\x02\x02\x02\u{ae6}\u{ae4}\x03\
	\x02\x02\x02\u{ae6}\u{ae7}\x03\x02\x02\x02\u{ae7}\u{aea}\x03\x02\x02\x02\
	\u{ae8}\u{ae6}\x03\x02\x02\x02\u{ae9}\u{ae1}\x03\x02\x02\x02\u{ae9}\u{aea}\
	\x03\x02\x02\x02\u{aea}\u{aeb}\x03\x02\x02\x02\u{aeb}\u{aec}\x07\x07\x02\
	\x02\u{aec}\u{253}\x03\x02\x02\x02\u{aed}\u{aee}\x07\u{138}\x02\x02\u{aee}\
	\u{255}\x03\x02\x02\x02\u{aef}\u{af0}\x07\u{139}\x02\x02\u{af0}\u{257}\x03\
	\x02\x02\x02\u{af1}\u{af2}\x07\u{13d}\x02\x02\u{af2}\u{259}\x03\x02\x02\
	\x02\u{af3}\u{af4}\x07\u{b9}\x02\x02\u{af4}\u{25b}\x03\x02\x02\x02\u{af5}\
	\u{af9}\x07\u{137}\x02\x02\u{af6}\u{af8}\x07\u{137}\x02\x02\u{af7}\u{af6}\
	\x03\x02\x02\x02\u{af8}\u{afb}\x03\x02\x02\x02\u{af9}\u{af7}\x03\x02\x02\
	\x02\u{af9}\u{afa}\x03\x02\x02\x02\u{afa}\u{25d}\x03\x02\x02\x02\u{afb}\
	\u{af9}\x03\x02\x02\x02\u{afc}\u{afd}\x07\u{13a}\x02\x02\u{afd}\u{25f}\x03\
	\x02\x02\x02\u{afe}\u{b00}\x07\x0d\x02\x02\u{aff}\u{afe}\x03\x02\x02\x02\
	\u{aff}\u{b00}\x03\x02\x02\x02\u{b00}\u{b01}\x03\x02\x02\x02\u{b01}\u{b02}\
	\x07\u{133}\x02\x02\u{b02}\u{261}\x03\x02\x02\x02\u{b03}\u{b05}\x07\x0d\
	\x02\x02\u{b04}\u{b03}\x03\x02\x02\x02\u{b04}\u{b05}\x03\x02\x02\x02\u{b05}\
	\u{b06}\x03\x02\x02\x02\u{b06}\u{b07}\x07\u{135}\x02\x02\u{b07}\u{263}\x03\
	\x02\x02\x02\u{105}\u{26b}\u{26f}\u{27a}\u{287}\u{293}\u{29e}\u{2a8}\u{2c3}\
	\u{2c9}\u{2d2}\u{2de}\u{2ed}\u{2f1}\u{2f4}\u{2fa}\u{300}\u{305}\u{30b}\u{315}\
	\u{324}\u{329}\u{331}\u{343}\u{352}\u{359}\u{35f}\u{363}\u{36d}\u{376}\u{380}\
	\u{38a}\u{393}\u{3c6}\u{3cc}\u{3e7}\u{3ed}\u{3f9}\u{400}\u{40a}\u{40f}\u{418}\
	\u{41f}\u{424}\u{42f}\u{43b}\u{440}\u{44c}\u{44f}\u{454}\u{457}\u{45c}\u{460}\
	\u{46b}\u{476}\u{47b}\u{47f}\u{48e}\u{497}\u{49c}\u{4a3}\u{4aa}\u{4ad}\u{4ba}\
	\u{4c6}\u{4cd}\u{4d5}\u{4d8}\u{4dd}\u{4e8}\u{4fa}\u{500}\u{509}\u{50e}\u{518}\
	\u{520}\u{523}\u{52c}\u{532}\u{53a}\u{53d}\u{546}\u{550}\u{55c}\u{560}\u{567}\
	\u{570}\u{579}\u{581}\u{584}\u{599}\u{5a1}\u{5a7}\u{5aa}\u{5b1}\u{5c3}\u{5c7}\
	\u{5d2}\u{5d9}\u{5e1}\u{5e5}\u{5e8}\u{5f7}\u{600}\u{608}\u{60c}\u{610}\u{614}\
	\u{61e}\u{627}\u{62a}\u{62f}\u{633}\u{636}\u{63a}\u{63e}\u{648}\u{651}\u{65a}\
	\u{660}\u{664}\u{669}\u{677}\u{67c}\u{68b}\u{694}\u{697}\u{69f}\u{6a8}\u{6ab}\
	\u{6b3}\u{6b6}\u{6be}\u{6c1}\u{6c5}\u{6cb}\u{6d1}\u{6d9}\u{6e0}\u{6e9}\u{6ec}\
	\u{6f3}\u{728}\u{72f}\u{73f}\u{745}\u{750}\u{759}\u{75d}\u{760}\u{763}\u{76a}\
	\u{77b}\u{785}\u{78d}\u{790}\u{795}\u{7a3}\u{7ae}\u{7b2}\u{7b5}\u{7ba}\u{7c7}\
	\u{7d0}\u{7d8}\u{7df}\u{7e8}\u{7ef}\u{7f3}\u{7f9}\u{801}\u{804}\u{807}\u{80f}\
	\u{819}\u{822}\u{82e}\u{838}\u{83d}\u{842}\u{850}\u{858}\u{85e}\u{864}\u{86b}\
	\u{871}\u{87b}\u{881}\u{887}\u{88a}\u{890}\u{89a}\u{8a9}\u{8b3}\u{8be}\u{8cc}\
	\u{8e0}\u{8e6}\u{8f0}\u{8f8}\u{8fe}\u{903}\u{90e}\u{915}\u{91a}\u{920}\u{925}\
	\u{935}\u{93d}\u{94b}\u{953}\u{95c}\u{95f}\u{965}\u{96a}\u{977}\u{97b}\u{990}\
	\u{996}\u{99b}\u{9ac}\u{9b7}\u{9bf}\u{9c9}\u{9cf}\u{9d5}\u{9d9}\u{9df}\u{9e5}\
	\u{9e9}\u{9f5}\u{9ff}\u{a04}\u{a0d}\u{a11}\u{a13}\u{a1c}\u{a43}\u{a51}\u{a56}\
	\u{a5c}\u{a61}\u{a64}\u{a6a}\u{a70}\u{a77}\u{a7b}\u{a88}\u{a91}\u{a98}\u{a9c}\
	\u{aba}\u{acd}\u{ad5}\u{ad8}\u{ae6}\u{ae9}\u{af9}\u{aff}\u{b04}";

